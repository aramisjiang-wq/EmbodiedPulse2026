## Updated on 2025.12.17
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#manipulation>Manipulation</a></li>
    <li><a href=#vlm>VLM</a></li>
    <li><a href=#vla>VLA</a></li>
    <li><a href=#humanoid>Humanoid</a></li>
    <li><a href=#dexterous>Dexterous</a></li>
    <li><a href=#perception>Perception</a></li>
    <li><a href=#planning>Planning</a></li>
    <li><a href=#rl/il>RL/IL</a></li>
    <li><a href=#locomotion>Locomotion</a></li>
    <li><a href=#uncategorized>Uncategorized</a></li>
  </ol>
</details>

## Manipulation

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-12-12**|**AnchorDream: Repurposing Video Diffusion for Embodiment-Aware Robot Data Synthesis**|Vitor Guizilini Team|[2512.11797](http://arxiv.org/abs/2512.11797)|**[link](https://jay-ye.github.io/AnchorDream/)**|
|**2025-12-12**|**UniBYD: A Unified Framework for Learning Robotic Manipulation Across Embodiments Beyond Imitation of Human Demonstrations**|Jinqiao Wang Team|[2512.11609](http://arxiv.org/abs/2512.11609)|null|
|**2025-12-12**|**Cross-Entropy Optimization of Physically Grounded Task and Motion Plans**|Javier Alonso-Mora Team|[2512.11571](http://arxiv.org/abs/2512.11571)|null|
|**2025-12-12**|**Towards Logic-Aware Manipulation: A Knowledge Primitive for VLM-Based Assistants in Smart Manufacturing**|Daqiang Guo Team|[2512.11275](http://arxiv.org/abs/2512.11275)|null|
|**2025-12-11**|**Learning Category-level Last-meter Navigation from RGB Demonstrations of a Single-instance**|Karthik Desingh Team|[2512.11173](http://arxiv.org/abs/2512.11173)|null|
|**2025-12-11**|**Iterative Compositional Data Generation for Robot Control**|Eric Eaton Team|[2512.10891](http://arxiv.org/abs/2512.10891)|null|
|**2025-12-11**|**XDen-1K: A Density Field Dataset of Real-World Objects**|Jingyi Yu Team|[2512.10668](http://arxiv.org/abs/2512.10668)|null|
|**2025-12-11**|**DeMapGS: Simultaneous Mesh Deformation and Surface Attribute Mapping via Gaussian Splatting**|Takeshi Oishi Team|[2512.10572](http://arxiv.org/abs/2512.10572)|**[link](https://shuyizhou495.github.io/DeMapGS-project-page/)**|
|**2025-12-11**|**Design and Validation of an Under-actuated Robotic Finger with Synchronous Tendon Routing**|Weibang Bai Team|[2512.10349](http://arxiv.org/abs/2512.10349)|null|
|**2025-12-10**|**Fast Functionally Redundant Inverse Kinematics for Robotic Toolpath Optimisation in Manufacturing Tasks**|Tirthankar Bandyopadhyay Team|[2512.10116](http://arxiv.org/abs/2512.10116)|**[link](https://ssl.linklings.net/conferences/acra/acra2025_proceedings/views/includes/files/pap149s2.pdf)**|
|**2025-12-10**|**Closing the Train-Test Gap in World Models for Gradient-Based Planning**|Micah Goldblum Team|[2512.09929](http://arxiv.org/abs/2512.09929)|null|
|**2025-12-10**|**HiF-VLA: Hindsight, Insight and Foresight through Motion Representation for Vision-Language-Action Models**|Donglin Wang Team|[2512.09928](http://arxiv.org/abs/2512.09928)|**[link](https://hifvla.github.io)**|
|**2025-12-10**|**Simultaneous Tactile-Visual Perception for Learning Multimodal Robot Manipulation**|Yixin Zhu Team|[2512.09851](http://arxiv.org/abs/2512.09851)|null|
|**2025-12-10**|**ViTA-Seg: Vision Transformer for Amodal Segmentation in Robotics**|Paolo Roberto Massenio Team|[2512.09510](http://arxiv.org/abs/2512.09510)|null|
|**2025-12-10**|**Development of a Compliant Gripper for Safe Robot-Assisted Trouser Dressing-Undressing**|Yasuhisa Hasegawa Team|[2512.09462](http://arxiv.org/abs/2512.09462)|null|
|**2025-12-10**|**H2R-Grounder: A Paired-Data-Free Paradigm for Translating Human Interaction Videos into Physically Grounded Robot Videos**|Mike Zheng Shou Team|[2512.09406](http://arxiv.org/abs/2512.09406)|null|
|**2025-12-10**|**One-Shot Real-World Demonstration Synthesis for Scalable Bimanual Manipulation**|Kui Jia Team|[2512.09297](http://arxiv.org/abs/2512.09297)|null|
|**2025-12-10**|**UPETrack: Unidirectional Position Estimation for Tracking Occluded Deformable Linear Objects**|Shifeng Huang Team|[2512.09283](http://arxiv.org/abs/2512.09283)|null|
|**2025-12-09**|**Masked Generative Policy for Robotic Control**|Paul Henderson Team|[2512.09101](http://arxiv.org/abs/2512.09101)|null|
|**2025-12-09**|**Bridging Scale Discrepancies in Robotic Control via Language-Based Action Representations**|Ting Liu Team|[2512.08548](http://arxiv.org/abs/2512.08548)|null|
|**2025-12-09**|**Curriculum Guided Massive Multi Agent System Solving For Robust Long Horizon Tasks**|Kalathur Chenchu Kishore Kumar Team|[2512.08545](http://arxiv.org/abs/2512.08545)|null|
|**2025-12-09**|**Learning Robot Manipulation from Audio World Models**|Michael Gienger Team|[2512.08405](http://arxiv.org/abs/2512.08405)|null|
|**2025-12-09**|**Embodied Tree of Thoughts: Deliberate Manipulation Planning with Embodied World Model**|Rui Chen Team|[2512.08188](http://arxiv.org/abs/2512.08188)|**[link](https://embodied-tree-of-thoughts.github.io)**|
|**2025-12-08**|**An Introduction to Deep Reinforcement and Imitation Learning**|Pedro Santana Team|[2512.08052](http://arxiv.org/abs/2512.08052)|null|
|**2025-12-08**|**DiffusionDriveV2: Reinforcement Learning-Constrained Truncated Diffusion Modeling in End-to-End Autonomous Driving**|Xinggang Wang Team|[2512.07745](http://arxiv.org/abs/2512.07745)|null|
|**2025-12-08**|**Delay-Aware Diffusion Policy: Bridging the Observation-Execution Gap in Dynamic Tasks**|Shayegan Omidshafiei Team|[2512.07697](http://arxiv.org/abs/2512.07697)|null|
|**2025-12-08**|**See Once, Then Act: Vision-Language-Action Model with Task Learning from One-Shot Video Demonstrations**|Yufeng Yue Team|[2512.07582](http://arxiv.org/abs/2512.07582)|null|
|**2025-12-08**|**Affordance Field Intervention: Enabling VLAs to Escape Memory Traps in Robotic Manipulation**|Chang Xu Team|[2512.07472](http://arxiv.org/abs/2512.07472)|null|
|**2025-12-08**|**ESPADA: Execution Speedup via Semantics Aware Demonstration Data Downsampling for Imitation Learning**|Byoung-Tak Zhang Team|[2512.07371](http://arxiv.org/abs/2512.07371)|**[link](https://project-espada.github.io/espada/)**|
|**2025-12-08**|**Benchmarking Humanoid Imitation Learning with Motion Difficulty**|Yipeng Qin Team|[2512.07248](http://arxiv.org/abs/2512.07248)|null|
|**2025-12-08**|**VFM-VLM: Vision Foundation Model and Vision Language Model based Visual Comparison for 3D Pose Estimation**|Sungho Kim Team|[2512.07215](http://arxiv.org/abs/2512.07215)|null|
|**2025-12-08**|**Sample from What You See: Visuomotor Policy Learning via Diffusion Bridge with Observation-Embedded Stochastic Differential Equation**|Ye Shi Team|[2512.07212](http://arxiv.org/abs/2512.07212)|null|
|**2025-12-07**|**A Hetero-Associative Sequential Memory Model Utilizing Neuromorphic Signals: Validated on a Mobile Manipulator**|Gordon Cheng Team|[2512.07032](http://arxiv.org/abs/2512.07032)|null|
|**2025-12-07**|**VideoVLA: Video Generators Can Be Generalizable Robot Manipulators**|Baining Guo Team|[2512.06963](http://arxiv.org/abs/2512.06963)|**[link](https://videovla-nips2025.github.io)**|
|**2025-12-07**|**MIND-V: Hierarchical Video Generation for Long-Horizon Robotic Manipulation with RL-based Physical Alignment**|Xiu Li Team|[2512.06628](http://arxiv.org/abs/2512.06628)|null|
|**2025-12-05**|**REWW-ARM -- Remote Wire-Driven Mobile Robot: Design, Control, and Experimental Validation**|Kei Okada Team|[2512.06192](http://arxiv.org/abs/2512.06192)|null|
|**2025-12-04**|**Closed-Loop Robotic Manipulation of Transparent Substrates for Self-Driving Laboratories using Deep Learning Micro-Error Correction**|Alexander E. Siemenn Team|[2512.06038](http://arxiv.org/abs/2512.06038)|null|
|**2025-12-03**|**VAT: Vision Action Transformer by Unlocking Full Representation of ViT**|Weixin Mao Team|[2512.06013](http://arxiv.org/abs/2512.06013)|null|
|**2025-12-05**|**SIMPACT: Simulation-Enabled Action Planning using Vision-Language Models**|Yilun Du Team|[2512.05955](http://arxiv.org/abs/2512.05955)|null|
|**2025-12-05**|**Correspondence-Oriented Imitation Learning: Flexible Visuomotor Control with 3D Conditioning**|Kuan Fang Team|[2512.05953](http://arxiv.org/abs/2512.05953)|null|
|**2025-12-05**|**World Models That Know When They Don't Know: Controllable Video Generation with Calibrated Uncertainty**|Anirudha Majumdar Team|[2512.05927](http://arxiv.org/abs/2512.05927)|null|
|**2025-12-05**|**Real-time Remote Tracking and Autonomous Planning for Whale Rendezvous using Robots**|Stephanie Gil Team|[2512.05808](http://arxiv.org/abs/2512.05808)|null|
|**2025-12-05**|**3D Path Planning for Robot-assisted Vertebroplasty from Arbitrary Bi-plane X-ray via Differentiable Rendering**|Mathias Unberath Team|[2512.05803](http://arxiv.org/abs/2512.05803)|null|
|**2025-12-05**|**Curvature-Regularized Variational Autoencoder for 3D Scene Reconstruction from Sparse Depth**|Soodeh Bakhshandeh Team|[2512.05783](http://arxiv.org/abs/2512.05783)|null|
|**2025-12-05**|**An Integrated System for WEEE Sorting Employing X-ray Imaging, AI-based Object Detection and Segmentation, and Delta Robot Manipulation**|Panagiotis Chatzakos Team|[2512.05599](http://arxiv.org/abs/2512.05599)|null|
|**2025-12-05**|**A Comprehensive Framework for Automated Quality Control in the Automotive Industry**|Panagiotis Chatzakos Team|[2512.05579](http://arxiv.org/abs/2512.05579)|null|
|**2025-12-05**|**MIND: Multi-rationale INtegrated Discriminative Reasoning Framework for Multi-modal Large Models**|Xiangyu Yue Team|[2512.05530](http://arxiv.org/abs/2512.05530)|null|
|**2025-12-05**|**Distributed scalable coupled policy algorithm for networked multi-agent reinforcement learning**|Wei Ren Team|[2512.05447](http://arxiv.org/abs/2512.05447)|null|
|**2025-12-05**|**State-Conditional Adversarial Learning: An Off-Policy Visual Domain Transfer Method for End-to-End Imitation Learning**|Shengfan Cao Team|[2512.05335](http://arxiv.org/abs/2512.05335)|null|
|**2025-12-04**|**Disturbance Compensation for Safe Kinematic Control of Robotic Systems with Closed Architecture**|Qin Lin Team|[2512.05292](http://arxiv.org/abs/2512.05292)|null|
|**2025-12-04**|**Uncertainty-Aware Data-Efficient AI: An Information-Theoretic Perspective**|Yaniv Romano Team|[2512.05267](http://arxiv.org/abs/2512.05267)|null|
|**2025-12-04**|**Age-Inclusive 3D Human Mesh Recovery for Action-Preserving Data Anonymization**|Petros Maragos Team|[2512.05259](http://arxiv.org/abs/2512.05259)|null|
|**2025-12-04**|**IE2Video: Adapting Pretrained Diffusion Models for Event-Based Video Reconstruction**|Yihui Ren Team|[2512.05240](http://arxiv.org/abs/2512.05240)|null|
|**2025-12-04**|**Two-Stage Camera Calibration Method for Multi-Camera Systems Using Scene Geometry**|Aleksandr Abramov Team|[2512.05171](http://arxiv.org/abs/2512.05171)|null|
|**2025-12-04**|**STARE-VLA: Progressive Stage-Aware Reinforcement for Fine-Tuning Vision-Language-Action Models**|Benjamin Busam Team|[2512.05107](http://arxiv.org/abs/2512.05107)|null|
|**2025-12-04**|**From Generated Human Videos to Physically Plausible Robot Trajectories**|Roei Herzig Team|[2512.05094](http://arxiv.org/abs/2512.05094)|**[link](https://genmimic.github.io)**|
|**2025-12-04**|**Object Reconstruction under Occlusion with Generative Priors and Contact-induced Constraints**|Michael Posa Team|[2512.05079](http://arxiv.org/abs/2512.05079)|**[link](https://contactgen3d.github.io/)**|
|**2025-12-04**|**Nex-N1: Agentic Models Trained via a Unified Ecosystem for Large-Scale Environment Construction**|Xipeng Qiu Team|[2512.04987](http://arxiv.org/abs/2512.04987)|null|
|**2025-12-04**|**Hybrid-Diffusion Models: Combining Open-loop Routines with Visuomotor Diffusion Policies**|Danica Kragic Team|[2512.04960](http://arxiv.org/abs/2512.04960)|null|
|**2025-12-04**|**FASTer: Toward Efficient Autoregressive Vision Language Action Modeling via Neural Action Tokenization**|Hang Zhao Team|[2512.04952](http://arxiv.org/abs/2512.04952)|null|
|**2025-12-04**|**Hoi! -- A Multimodal Dataset for Force-Grounded, Cross-View Articulated Manipulation**|Zuria Bauer Team|[2512.04884](http://arxiv.org/abs/2512.04884)|null|
|**2025-12-04**|**MOVE: A Simple Motion-Based Data Collection Paradigm for Spatial Generalization in Robotic Manipulation**|Gao Huang Team|[2512.04813](http://arxiv.org/abs/2512.04813)|null|
|**2025-12-04**|**Bridging Simulation and Reality: Cross-Domain Transfer with Semantic 2D Gaussian Splatting**|Xuguang Lan Team|[2512.04731](http://arxiv.org/abs/2512.04731)|null|
|**2025-12-04**|**TRINITY: An Evolved LLM Coordinator**|Yujin Tang Team|[2512.04695](http://arxiv.org/abs/2512.04695)|null|
|**2025-12-04**|**Gauss-Newton accelerated MPPI Control**|Johannes Reuter Team|[2512.04579](http://arxiv.org/abs/2512.04579)|null|
|**2025-12-05**|**GTM: Simulating the World of Tools for AI Agents**|Jiyan He Team|[2512.04535](http://arxiv.org/abs/2512.04535)|null|
|**2025-12-04**|**MARL Warehouse Robots**|Salmon Riaz Team|[2512.04463](http://arxiv.org/abs/2512.04463)|**[link](https://pallman14.github.io/MARL-QMIX-Warehouse-Robots/)**|
|**2025-12-04**|**Vision-Language-Action Models for Selective Robotic Disassembly: A Case Study on Critical Component Extraction from Desktops**|Minghui Zheng Team|[2512.04446](http://arxiv.org/abs/2512.04446)|null|
|**2025-12-04**|**Bridging Probabilistic Inference and Behavior Trees: An Interactive Framework for Adaptive Multi-Robot Cooperation**|Changju Wu Team|[2512.04404](http://arxiv.org/abs/2512.04404)|null|
|**2025-12-04**|**Development of a 15-Degree-of-Freedom Bionic Hand with Cable-Driven Transmission and Distributed Actuation**|Hesheng Wang Team|[2512.04399](http://arxiv.org/abs/2512.04399)|null|
|**2025-12-03**|**ResponsibleRobotBench: Benchmarking Responsible Robot Manipulation using Multi-modal Large Language Models**|Jianwei Zhang Team|[2512.04308](http://arxiv.org/abs/2512.04308)|**[link](https://sites.google.com/view/responsible-robotbench)**|
|**2025-12-03**|**Driving Beyond Privilege: Distilling Dense-Reward Knowledge into Sparse-Reward Policies**|Jaerock Kwon Team|[2512.04279](http://arxiv.org/abs/2512.04279)|null|
|**2025-12-03**|**SpaceTools: Tool-Augmented Spatial Reasoning via Double Interactive RL**|Jonathan Tremblay Team|[2512.04069](http://arxiv.org/abs/2512.04069)|null|
|**2025-12-03**|**When to Say "Hi" - Learn to Open a Conversation with an in-the-wild Dataset**|Anja Richert Team|[2512.03991](http://arxiv.org/abs/2512.03991)|null|
|**2025-12-03**|**Guided Flow Policy: Learning from High-Value Actions in Offline Reinforcement Learning**|Justin Carpentier Team|[2512.03973](http://arxiv.org/abs/2512.03973)|null|
|**2025-12-03**|**Classification of User Satisfaction in HRI with Social Signals in the Wild**|Anja Richert Team|[2512.03945](http://arxiv.org/abs/2512.03945)|null|
|**2025-12-03**|**Autonomous Reinforcement Learning Robot Control with Intel's Loihi 2 Neuromorphic Hardware**|Carl Glen Henshaw Team|[2512.03911](http://arxiv.org/abs/2512.03911)|null|
|**2025-12-03**|**Comparison of neural network training strategies for the simulation of dynamical systems**|Andreas Körner Team|[2512.03851](http://arxiv.org/abs/2512.03851)|null|
|**2025-12-03**|**Cross-embodied Co-design for Dexterous Hands**|Xiaolong Wang Team|[2512.03743](http://arxiv.org/abs/2512.03743)|null|
|**2025-12-03**|**Crossing the Sim2Real Gap Between Simulation and Ground Testing to Space Deployment of Autonomous Free-flyer Control**|Carl Glen Henshaw Team|[2512.03736](http://arxiv.org/abs/2512.03736)|null|
|**2025-12-03**|**Autonomous Planning In-space Assembly Reinforcement-learning free-flYer (APIARY) International Space Station Astrobee Testing**|Carl Glen Henshaw Team|[2512.03729](http://arxiv.org/abs/2512.03729)|null|
|**2025-12-03**|**PosA-VLA: Enhancing Action Generation via Pose-Conditioned Anchor Attention**|Mingming Gong Team|[2512.03724](http://arxiv.org/abs/2512.03724)|null|
|**2025-12-03**|**ContactRL: Safe Reinforcement Learning based Motion Planning for Contact based Human Robot Collaboration**|Emma Li Team|[2512.03707](http://arxiv.org/abs/2512.03707)|null|
|**2025-12-03**|**A Novel Approach to Tomato Harvesting Using a Hybrid Gripper with Semantic Segmentation and Keypoint Detection**|Bishakh Bhattacharya Team|[2512.03684](http://arxiv.org/abs/2512.03684)|null|
|**2025-12-03**|**RoboScape-R: Unified Reward-Observation World Models for Generalizable Robotics Training via RL**|Yong Li Team|[2512.03556](http://arxiv.org/abs/2512.03556)|null|
|**2025-12-03**|**AdaPower: Specializing World Foundation Models for Predictive Manipulation**|Kai Xu Team|[2512.03538](http://arxiv.org/abs/2512.03538)|null|
|**2025-12-03**|**PerFACT: Motion Policy with LLM-Powered Dataset Synthesis and Fusion Action-Chunking Transformers**|Minghui Zheng Team|[2512.03444](http://arxiv.org/abs/2512.03444)|null|
|**2025-12-03**|**Multimodal Reinforcement Learning with Agentic Verifier for AI Agents**|Jianfeng Gao Team|[2512.03438](http://arxiv.org/abs/2512.03438)|null|
|**2025-12-03**|**World Models for Autonomous Navigation of Terrestrial Robots from LIDAR Observations**|Daniel Fernando Tello Gamarra Team|[2512.03429](http://arxiv.org/abs/2512.03429)|null|
|**2025-12-03**|**What Is The Best 3D Scene Representation for Robotics? From Geometric to Foundation Models**|Weidong Chen Team|[2512.03422](http://arxiv.org/abs/2512.03422)|null|
|**2025-12-03**|**GOMP: Grasped Object Manifold Projection for Multimodal Imitation Learning of Manipulation**|Nima Fazeli Team|[2512.03347](http://arxiv.org/abs/2512.03347)|null|
|**2025-12-02**|**KALIKO: Kalman-Implicit Koopman Operator Learning For Prediction of Nonlinear Dynamical Systems**|Aaron D. Ames Team|[2512.03256](http://arxiv.org/abs/2512.03256)|null|
|**2025-12-02**|**Video2Act: A Dual-System Video Diffusion Policy with Robotic Spatio-Motional Modeling**|Shanghang Zhang Team|[2512.03044](http://arxiv.org/abs/2512.03044)|null|
|**2025-12-02**|**SMP: Reusable Score-Matching Motion Priors for Physics-Based Character Control**|Xue Bin Peng Team|[2512.03028](http://arxiv.org/abs/2512.03028)|null|
|**2025-12-02**|**Experimental Characterization of Fingertip Trajectory following for a 3-DoF Series-Parallel Hybrid Robotic Finger**|Nilanjan Chakraborty Team|[2512.02951](http://arxiv.org/abs/2512.02951)|null|
|**2025-12-02**|**SwarmDiffusion: End-To-End Traversability-Guided Diffusion for Embodiment-Agnostic Navigation of Heterogeneous Robots**|Dzmitry Tsetserukou Team|[2512.02851](http://arxiv.org/abs/2512.02851)|null|
|**2025-12-02**|**Phase-Adaptive LLM Framework with Multi-Stage Validation for Construction Robot Task Allocation: A Systematic Benchmark Against Traditional Optimization Algorithms**|Hongrui Yu Team|[2512.02810](http://arxiv.org/abs/2512.02810)|null|
|**2025-12-02**|**Diagnose, Correct, and Learn from Manipulation Failures via Visual Symbols**|Yong-Lu Li Team|[2512.02787](http://arxiv.org/abs/2512.02787)|null|
|**2025-12-02**|**RoboWheel: A Data Engine from Real-World Human Demonstrations for Cross-Embodiment Robotic Learning**|Haoqian Wang Team|[2512.02729](http://arxiv.org/abs/2512.02729)|null|
|**2025-12-02**|**SAM2Grasp: Resolve Multi-modal Grasping via Prompt-conditioned Temporal Action Prediction**|Yong Zhao Team|[2512.02609](http://arxiv.org/abs/2512.02609)|null|
|**2025-12-02**|**From Imitation to Discrimination: Toward A Generalized Curriculum Advantage Mechanism Enhancing Cross-Domain Reasoning Tasks**|Guoquan Zhang Team|[2512.02580](http://arxiv.org/abs/2512.02580)|null|
|**2025-12-02**|**In-Context Distillation with Self-Consistency Cascades: A Simple, Training-Free Way to Reduce LLM Agent Costs**|Kayvon Fatahalian Team|[2512.02543](http://arxiv.org/abs/2512.02543)|null|
|**2025-12-02**|**Synthetic Error Injection Fails to Elicit Self-Correction In Language Models**|Stuart Russell Team|[2512.02389](http://arxiv.org/abs/2512.02389)|null|
|**2025-12-01**|**EfficientFlow: Efficient Equivariant Flow Policy Learning for Embodied AI**|Xiangyu Xu Team|[2512.02020](http://arxiv.org/abs/2512.02020)|**[link](https://efficientflow.github.io/)**|
|**2025-12-01**|**Generative Video Motion Editing with 3D Point Tracks**|Zhengqi Li Team|[2512.02015](http://arxiv.org/abs/2512.02015)|**[link](https://edit-by-track.github.io)**|
|**2025-12-01**|**ManualVLA: A Unified VLA Model for Chain-of-Thought Manual Generation and Robotic Manipulation**|Shanghang Zhang Team|[2512.02013](http://arxiv.org/abs/2512.02013)|null|
|**2025-12-01**|**Learning Sim-to-Real Humanoid Locomotion in 15 Minutes**|Pieter Abbeel Team|[2512.01996](http://arxiv.org/abs/2512.01996)|**[link](https://younggyo.me/fastsac-humanoid)**|
|**2025-12-01**|**Guardian: Detecting Robotic Planning and Execution Errors with Vision-Language Models**|Cordelia Schmid Team|[2512.01946](http://arxiv.org/abs/2512.01946)|**[link](https://www.di.ens.fr/willow/research/guardian/.)**|
|**2025-12-01**|**Real-World Robot Control by Deep Active Inference With a Temporally Hierarchical World Model**|Shingo Murata Team|[2512.01924](http://arxiv.org/abs/2512.01924)|null|
|**2025-12-01**|**SARL: Spatially-Aware Self-Supervised Representation Learning for Visuo-Tactile Perception**|Dandan Zhang Team|[2512.01908](http://arxiv.org/abs/2512.01908)|null|
|**2025-12-01**|**Register Any Point: Scaling 3D Point Cloud Registration by Flow Matching**|Cyrill Stachniss Team|[2512.01850](http://arxiv.org/abs/2512.01850)|null|
|**2025-12-01**|**GR-RL: Going Dexterous and Precise for Long-Horizon Robotic Manipulation**|Yonghui Wu Team|[2512.01801](http://arxiv.org/abs/2512.01801)|null|
|**2025-12-01**|**IGen: Scalable Data Generation for Robot Learning from Open-World Images**|Zhi Wang Team|[2512.01773](http://arxiv.org/abs/2512.01773)|null|
|**2025-12-01**|**DiG-Flow: Discrepancy-Guided Flow Matching for Robust VLA Models**|Zongqing Lu Team|[2512.01715](http://arxiv.org/abs/2512.01715)|null|
|**2025-12-01**|**SPARK: Sim-ready Part-level Articulated Reconstruction with VLM Knowledge**|Chenfanfu Jiang Team|[2512.01629](http://arxiv.org/abs/2512.01629)|**[link](https://heyumeng.com/SPARK/index.html.)**|
|**2025-12-01**|**A Cross-Embodiment Gripper Benchmark for Rigid-Object Manipulation in Aerial and Industrial Robotics**|Ivan Virgala Team|[2512.01598](http://arxiv.org/abs/2512.01598)|null|
|**2025-12-01**|**On robotic manipulators with time-dependent inertial parameters: From physical consistency to boundedness of the mass matrix**|Johann Reger Team|[2512.01482](http://arxiv.org/abs/2512.01482)|null|
|**2025-12-01**|**$\mathbf{M^3A}$ Policy: Mutable Material Manipulation Augmentation Policy through Photometric Re-rendering**|Jianfei Yang Team|[2512.01446](http://arxiv.org/abs/2512.01446)|null|
|**2025-12-01**|**PointNet4D: A Lightweight 4D Point Cloud Video Backbone for Online and Offline Perception in Robotic Applications**|Jiayang Ao Team|[2512.01383](http://arxiv.org/abs/2512.01383)|null|
|**2025-12-01**|**Modality-Augmented Fine-Tuning of Foundation Robot Policies for Cross-Embodiment Manipulation on GR1 and G1**|Songhwai Oh Team|[2512.01358](http://arxiv.org/abs/2512.01358)|null|
|**2025-12-01**|**Discovering Self-Protective Falling Policy for Humanoid Robot via Deep Reinforcement Learning**|Donglin Wang Team|[2512.01336](http://arxiv.org/abs/2512.01336)|null|
|**2025-12-01**|**TabletopGen: Instance-Level Interactive 3D Tabletop Scene Generation from Text or Single Image**|Hu Su Team|[2512.01204](http://arxiv.org/abs/2512.01204)|**[link](https://d-robotics-ai-lab.github.io/TabletopGen.project/)**|
|**2025-12-01**|**Real-World Reinforcement Learning of Active Perception Behaviors**|Dinesh Jayaraman Team|[2512.01188](http://arxiv.org/abs/2512.01188)|null|
|**2025-11-30**|**Opening the Sim-to-Real Door for Humanoid Pixel-to-Action Policy Transfer**|Yuke Zhu Team|[2512.01061](http://arxiv.org/abs/2512.01061)|**[link](https://doorman-humanoid.github.io/)**|
|**2025-11-30**|**Autonomous Grasping On Quadruped Robot With Task Level Interaction**|Chastine Fatichah Team|[2512.01052](http://arxiv.org/abs/2512.01052)|null|
|**2025-11-30**|**CycleManip: Enabling Cyclic Task Manipulation via Effective Historical Perception and Understanding**|Wei-Shi Zheng Team|[2512.01022](http://arxiv.org/abs/2512.01022)|**[link](https://isee-laboratory.github.io/OmniDexGrasp/)**|
|**2025-11-30**|**Constant-Time Motion Planning with Manipulation Behaviors**|Maxim Likhachev Team|[2512.00939](http://arxiv.org/abs/2512.00939)|null|
|**2025-11-29**|**Image Generation as a Visual Planner for Robotic Manipulation**|Ye Pang Team|[2512.00532](http://arxiv.org/abs/2512.00532)|null|
|**2025-11-29**|**Sample-Efficient Expert Query Control in Active Imitation Learning via Conformal Prediction**|Lars Lindemann Team|[2512.00453](http://arxiv.org/abs/2512.00453)|null|
|**2025-11-29**|**MILE: A Mechanically Isomorphic Exoskeleton Data Collection System with Fingertip Visuotactile Sensing for Dexterous Manipulation**|Xiangyang Zhu Team|[2512.00324](http://arxiv.org/abs/2512.00324)|null|
|**2025-11-26**|**Hyper-GoalNet: Goal-Conditioned Manipulation Policy Learning with HyperNetworks**|Yanchao Yang Team|[2512.00085](http://arxiv.org/abs/2512.00085)|null|
|**2025-11-25**|**A Hierarchical Framework for Humanoid Locomotion with Supernumerary Limbs**|Bowen Zhi Team|[2512.00077](http://arxiv.org/abs/2512.00077)|null|
|**2025-11-25**|**Bootstrap Dynamic-Aware 3D Visual Representation for Scalable Robot Learning**|Renjing Xu Team|[2512.00074](http://arxiv.org/abs/2512.00074)|null|
|**2025-11-28**|**From CAD to POMDP: Probabilistic Planning for Robotic Disassembly of End-of-Life Products**|Jürgen Fleischer Team|[2511.23407](http://arxiv.org/abs/2511.23407)|null|
|**2025-11-28**|**SafeHumanoid: VLM-RAG-driven Control of Upper Body Impedance for Humanoid Robot**|Dzmitry Tsetserukou Team|[2511.23300](http://arxiv.org/abs/2511.23300)|null|
|**2025-11-28**|**Synthetic Industrial Object Detection: GenAI vs. Feature-Based Methods**|Jörg Krüger Team|[2511.23241](http://arxiv.org/abs/2511.23241)|null|
|**2025-11-28**|**Obstruction reasoning for robotic grasping**|Fabio Poiesi Team|[2511.23186](http://arxiv.org/abs/2511.23186)|null|
|**2025-11-28**|**LatBot: Distilling Universal Latent Actions for Vision-Language-Action Models**|Jianlong Fu Team|[2511.23034](http://arxiv.org/abs/2511.23034)|**[link](https://mm-robot.github.io/distill_latent_action/)**|
|**2025-11-28**|**Commanding Humanoid by Free-form Language: A Large Language Action Model with Unified Motion Vocabulary**|Jingya Wang Team|[2511.22963](http://arxiv.org/abs/2511.22963)|**[link](https://humanoidlla.github.io/)**|
|**2025-11-28**|**DM $^3$ T: Harmonizing Modalities via Diffusion for Multi-Object Tracking**|Zhenbo Li Team|[2511.22896](http://arxiv.org/abs/2511.22896)|null|
|**2025-11-27**|**Switching control of underactuated multi-channel systems with input constraints for cooperative manipulation**|H. Jin Kim Team|[2511.22810](http://arxiv.org/abs/2511.22810)|null|
|**2025-11-27**|**Distracted Robot: How Visual Clutter Undermine Robotic Manipulation**|Xuan Zhao Team|[2511.22780](http://arxiv.org/abs/2511.22780)|null|
|**2025-11-27**|**Improving Robotic Manipulation Robustness via NICE Scene Surgery**|Amir Rasouli Team|[2511.22777](http://arxiv.org/abs/2511.22777)|null|
|**2025-11-27**|**CAPE: Context-Aware Diffusion Policy Via Proximal Mode Expansion for Collision Avoidance**|Amir Rasouli Team|[2511.22773](http://arxiv.org/abs/2511.22773)|null|
|**2025-11-27**|**Beyond Egocentric Limits: Multi-View Depth-Based Learning for Robust Quadrupedal Locomotion**|Wael Suleiman Team|[2511.22744](http://arxiv.org/abs/2511.22744)|**[link](https://anonymous.4open.science/r/multiview-parkour-6FB8)**|
|**2025-11-27**|**Deadlock-Free Hybrid RL-MAPF Framework for Zero-Shot Multi-Robot Navigation**|Mingyu Cai Team|[2511.22685](http://arxiv.org/abs/2511.22685)|null|
|**2025-11-27**|**Beyond Success: Refining Elegant Robot Manipulation from Mixed-Quality Data via Just-in-Time Intervention**|Meibao Yao Team|[2511.22555](http://arxiv.org/abs/2511.22555)|null|
|**2025-11-27**|**RealD $^2$ iff: Bridging Real-World Gap in Robot Manipulation via Depth Diffusion**|Jianhua Sun Team|[2511.22505](http://arxiv.org/abs/2511.22505)|null|
|**2025-11-27**|**Visual-Geometry Diffusion Policy: Robust Generalization via Complementarity-Aware Multimodal Fusion**|Jitendra Malik Team|[2511.22445](http://arxiv.org/abs/2511.22445)|null|
|**2025-11-27**|**Exposing Vulnerabilities in RL: A Novel Stealthy Backdoor Attack through Reward Poisoning**|Junfeng Wu Team|[2511.22415](http://arxiv.org/abs/2511.22415)|null|
|**2025-11-27**|**BINDER: Instantly Adaptive Mobile Manipulation with Open-Vocabulary Commands**|Jonghyun Choi Team|[2511.22364](http://arxiv.org/abs/2511.22364)|null|
|**2025-11-27**|**Nonholonomic Narrow Dead-End Escape with Deep Reinforcement Learning**|Zichun Wang Team|[2511.22338](http://arxiv.org/abs/2511.22338)|null|
|**2025-11-27**|**3D Affordance Keypoint Detection for Robotic Manipulation**|Marcelo H Ang Team|[2511.22195](http://arxiv.org/abs/2511.22195)|null|
|**2025-11-26**|**PAT3D: Physics-Augmented Text-to-3D Scene Generation**|Minchen Li Team|[2511.21978](http://arxiv.org/abs/2511.21978)|null|
|**2025-11-26**|**Massively Parallel Imitation Learning of Mouse Forelimb Musculoskeletal Reaching Dynamics**|Talmo Pereira Team|[2511.21848](http://arxiv.org/abs/2511.21848)|null|
|**2025-11-26**|**TraceGen: World Modeling in 3D Trace Space Enables Learning from Cross-Embodiment Videos**|Furong Huang Team|[2511.21690](http://arxiv.org/abs/2511.21690)|null|
|**2025-11-26**|**VacuumVLA: Boosting VLA Capabilities via a Unified Suction and Gripping Tool for Complex Robotic Manipulation**|Shaoshuai Shi Team|[2511.21557](http://arxiv.org/abs/2511.21557)|null|
|**2025-11-26**|**$\mathcal{E}_0$ : Enhancing Generalization and Fine-Grained Control in VLA Models via Continuized Discrete Diffusion**|Guangrun Wang Team|[2511.21542](http://arxiv.org/abs/2511.21542)|null|
|**2025-11-26**|**Hybrid Control for Robotic Nut Tightening Task**|Dmitri Kovalenko Team|[2511.21366](http://arxiv.org/abs/2511.21366)|null|
|**2025-11-26**|**Neural NMPC through Signed Distance Field Encoding for Collision Avoidance**|Kostas Alexis Team|[2511.21312](http://arxiv.org/abs/2511.21312)|null|
|**2025-11-26**|**Sampling-Based Optimization with Parallelized Physics Simulator for Bimanual Manipulation**|Arun Kumar Singh Team|[2511.21264](http://arxiv.org/abs/2511.21264)|null|
|**2025-11-26**|**When Robots Obey the Patch: Universal Transferable Patch Attacks on Vision-Language-Action Models**|Xudong Jiang Team|[2511.21192](http://arxiv.org/abs/2511.21192)|null|
|**2025-11-26**|**Kinematics-Aware Multi-Policy Reinforcement Learning for Force-Capable Humanoid Loco-Manipulation**|Qijun Chen Team|[2511.21169](http://arxiv.org/abs/2511.21169)|null|
|**2025-11-26**|**MarketGen: A Scalable Simulation Platform with Auto-Generated Embodied Supermarket Environments**|Zhaoxiang Zhang Team|[2511.21161](http://arxiv.org/abs/2511.21161)|**[link](https://xuhu0529.github.io/MarketGen)**|
|**2025-11-26**|**Maglev-Pentabot: Magnetic Levitation System for Non-Contact Manipulation using Deep Reinforcement Learning**|Zongfu Yu Team|[2511.21149](http://arxiv.org/abs/2511.21149)|null|
|**2025-11-26**|**SocialNav: Training Human-Inspired Foundation Model for Socially-Aware Embodied Navigation**|Yu Zhang Team|[2511.21135](http://arxiv.org/abs/2511.21135)|null|
|**2025-11-26**|**Dual-Agent Reinforcement Learning for Adaptive and Cost-Aware Visual-Inertial Odometry**|Guangbin Dou Team|[2511.21083](http://arxiv.org/abs/2511.21083)|null|
|**2025-11-26**|**AerialMind: Towards Referring Multi-Object Tracking in UAV Scenarios**|Qing-Long Han Team|[2511.21053](http://arxiv.org/abs/2511.21053)|null|
|**2025-11-26**|**Staggered Environment Resets Improve Massively Parallel On-Policy Reinforcement Learning**|Hao Su Team|[2511.21011](http://arxiv.org/abs/2511.21011)|null|
|**2025-11-25**|**Dynamic Test-Time Compute Scaling in Control Policy: Difficulty-Aware Stochastic Interpolant Policy**|Eric Vanden-Eijnden Team|[2511.20906](http://arxiv.org/abs/2511.20906)|null|
|**2025-11-25**|**ACE-F: A Cross Embodiment Foldable System with Force Feedback for Dexterous Teleoperation**|Xiaolong Wang Team|[2511.20887](http://arxiv.org/abs/2511.20887)|null|
|**2025-11-25**|**MODEST: Multi-Optics Depth-of-Field Stereo Dataset**|Dante Lok Team|[2511.20853](http://arxiv.org/abs/2511.20853)|null|
|**2025-11-25**|**NOIR 2.0: Neural Signal Operated Intelligent Robots for Everyday Activities**|Alex Hodges Team|[2511.20848](http://arxiv.org/abs/2511.20848)|null|
|**2025-11-25**|**OVAL-Grasp: Open-Vocabulary Affordance Localization for Task Oriented Grasping**|Odest Chadwicke Jenkins Team|[2511.20841](http://arxiv.org/abs/2511.20841)|null|
|**2025-11-25**|**Conformal Safety Monitoring for Flight Testing: A Case Study in Data-Driven Safety Learning**|Mac Schwager Team|[2511.20811](http://arxiv.org/abs/2511.20811)|null|
|**2025-11-25**|**Reinforcing Action Policies by Prophesying**|Li Zhang Team|[2511.20633](http://arxiv.org/abs/2511.20633)|**[link](https://LogosRoboticsGroup.github.io/ProphRL)**|
|**2025-11-25**|**Safe and Stable Neural Network Dynamical Systems for Robot Motion Planning**|Abdalla Swikir Team|[2511.20593](http://arxiv.org/abs/2511.20593)|null|
|**2025-11-25**|**Gated Uncertainty-Aware Runtime Dual Invariants for Neural Signal-Controlled Robotics**|Oiwi Parker Jones Team|[2511.20570](http://arxiv.org/abs/2511.20570)|null|
|**2025-11-25**|**Metric, inertially aligned monocular state estimation via kinetodynamic priors**|Laurent Kneip Team|[2511.20496](http://arxiv.org/abs/2511.20496)|null|
|**2025-11-25**|**Improved adaptive wind driven optimization algorithm for real-time path planning**|Le-le Mao Team|[2511.20394](http://arxiv.org/abs/2511.20394)|null|
|**2025-11-25**|**ArtiBench and ArtiBrain: Benchmarking Generalizable Vision-Language Articulated Object Manipulation**|Yan Xia Team|[2511.20330](http://arxiv.org/abs/2511.20330)|null|
|**2025-11-25**|**How Robot Kinematics Influence Human Performance in Virtual Robot-to-Human Handover Tasks**|Joost C. Dessing Team|[2511.20299](http://arxiv.org/abs/2511.20299)|null|
|**2025-11-25**|**HAFO: A Force-Adaptive Control Framework for Humanoid Robots in Intense Interaction Environments**|Bin He Team|[2511.20275](http://arxiv.org/abs/2511.20275)|null|
|**2025-11-25**|**CostNav: A Navigation Benchmark for Cost-Aware Evaluation of Embodied Agents**|Yunsung Lee Team|[2511.20216](http://arxiv.org/abs/2511.20216)|null|
|**2025-11-25**|**WPT: World-to-Policy Transfer via Online World Model Distillation**|Xu Yan Team|[2511.20095](http://arxiv.org/abs/2511.20095)|null|
|**2025-11-25**|**Energy Costs and Neural Complexity Evolution in Changing Environments**|Geoff Nitschke Team|[2511.20018](http://arxiv.org/abs/2511.20018)|null|
|**2025-11-25**|**ShapeForce: Low-Cost Soft Robotic Wrist for Contact-Rich Manipulation**|Lin Shao Team|[2511.19955](http://arxiv.org/abs/2511.19955)|null|
|**2025-11-25**|**Collaborate sim and real: Robot Bin Packing Learning in Real-world and Physical Engine**|Tian He Team|[2511.19932](http://arxiv.org/abs/2511.19932)|null|
|**2025-11-25**|**Complex Instruction Following with Diverse Style Policies in Football Games**|Chen Chen Team|[2511.19885](http://arxiv.org/abs/2511.19885)|null|
|**2025-11-25**|**GigaWorld-0: World Models as Data Engine to Empower Embodied AI**|Zheng Zhu Team|[2511.19861](http://arxiv.org/abs/2511.19861)|**[link](https://gigaworld0.github.io/)**|
|**2025-11-25**|**Unifying Perception and Action: A Hybrid-Modality Pipeline with Implicit Visual Chain-of-Thought for Robotic Action Generation**|Sanglu Lu Team|[2511.19859](http://arxiv.org/abs/2511.19859)|null|
|**2025-11-24**|**Multi-Hypotheses Ego-Tracking for Resilient Navigation**|Roberto Galeazzi Team|[2511.19770](http://arxiv.org/abs/2511.19770)|null|
|**2025-11-24**|**Robot-Powered Data Flywheels: Deploying Robots in the Wild for Continual Data Collection and Foundation Model Adaptation**|Dorsa Sadigh Team|[2511.19647](http://arxiv.org/abs/2511.19647)|null|
|**2025-11-24**|**Mixture of Horizons in Action Chunking**|Mingyu Ding Team|[2511.19433](http://arxiv.org/abs/2511.19433)|null|
|**2025-11-24**|**Real-Time Object Tracking with On-Device Deep Learning for Adaptive Beamforming in Dynamic Acoustic Environments**|Maximo Cobos Team|[2511.19396](http://arxiv.org/abs/2511.19396)|null|
|**2025-11-24**|**Rethinking Intermediate Representation for VLM-based Robot Manipulation**|Chi-Wing Fu Team|[2511.19315](http://arxiv.org/abs/2511.19315)|null|
|**2025-11-24**|**Efficient Optimization of a Permanent Magnet Array for a Stable 2D Trap**|Tian Qiu Team|[2511.19201](http://arxiv.org/abs/2511.19201)|null|
|**2025-11-24**|**Analysis of Deep-Learning Methods in an ISO/TS 15066-Compliant Human-Robot Safety Framework**|Andreas Mueller Team|[2511.19094](http://arxiv.org/abs/2511.19094)|null|
|**2025-11-24**|**ReEXplore: Improving MLLMs for Embodied Exploration with Contextualized Retrospective Experience Replay**|Volker Tresp Team|[2511.19033](http://arxiv.org/abs/2511.19033)|null|
|**2025-11-24**|**Multi-Agent Monocular Dense SLAM With 3D Reconstruction Priors**|Yuchen Zhou Team|[2511.19031](http://arxiv.org/abs/2511.19031)|null|
|**2025-11-24**|**AVA-VLA: Improving Vision-Language-Action models with Active Visual Attention**|Xiaoyuan Yu Team|[2511.18960](http://arxiv.org/abs/2511.18960)|null|
|**2025-11-24**|**Learning to Compress Graphs via Dual Agents for Consistent Topological Robustness Evaluation**|Tao Jia Team|[2511.18958](http://arxiv.org/abs/2511.18958)|null|
|**2025-11-24**|**Compressor-VLA: Instruction-Guided Visual Token Compression for Efficient Robotic Manipulation**|Wenjing Qian Team|[2511.18950](http://arxiv.org/abs/2511.18950)|null|
|**2025-11-24**|**Accelerating Reinforcement Learning via Error-Related Human Brain Signals**|Hyo-Jeong Jang Team|[2511.18878](http://arxiv.org/abs/2511.18878)|null|
|**2025-11-24**|**AutoOdom: Learning Auto-regressive Proprioceptive Odometry for Legged Locomotion**|Mingguo Zhao Team|[2511.18857](http://arxiv.org/abs/2511.18857)|null|
|**2025-11-24**|**Any4D: Open-Prompt 4D Generation from Natural Language and Images**|Qiao Sun Team|[2511.18746](http://arxiv.org/abs/2511.18746)|null|
|**2025-11-23**|**AutoFocus-IL: VLM-based Saliency Maps for Data-Efficient Visual Imitation Learning without Extra Human Annotations**|Erdem Biyik Team|[2511.18617](http://arxiv.org/abs/2511.18617)|**[link](http://autofocus-il.github.io/)**|
|**2025-11-23**|**Object-centric Task Representation and Transfer using Diffused Orientation Fields**|Sylvain Calinon Team|[2511.18563](http://arxiv.org/abs/2511.18563)|null|
|**2025-11-23**|**SafeFall: Learning Protective Control for Humanoid Robots**|Siyuan Huang Team|[2511.18509](http://arxiv.org/abs/2511.18509)|null|
|**2025-11-23**|**ORIGAMISPACE: Benchmarking Multimodal LLMs in Multi-Step Spatial Reasoning with Mathematical Constraints**|Yinghui Xu Team|[2511.18450](http://arxiv.org/abs/2511.18450)|null|
|**2025-11-23**|**Learning Visually Interpretable Oscillator Networks for Soft Continuum Robots from Video**|Takehisa Yairi Team|[2511.18322](http://arxiv.org/abs/2511.18322)|null|
|**2025-11-23**|**MicCheck: Repurposing Off-the-Shelf Pin Microphones for Easy and Low-Cost Contact Sensing**|Jia-Yeu Lin Team|[2511.18299](http://arxiv.org/abs/2511.18299)|null|
|**2025-11-23**|**Dreaming Falcon: Physics-Informed Model-Based Reinforcement Learning for Quadcopters**|Matthew McCrink Team|[2511.18243](http://arxiv.org/abs/2511.18243)|null|
|**2025-11-21**|**RynnVLA-002: A Unified Vision-Language-Action and World Model**|Hao Chen Team|[2511.17502](http://arxiv.org/abs/2511.17502)|null|
|**2025-11-21**|**RoboCOIN: An Open-Sourced Bimanual Robotic Data COllection for INtegrated Manipulation**|Guocai Yao Team|[2511.17441](http://arxiv.org/abs/2511.17441)|null|
|**2025-11-21**|**SPEAR-1: Scaling Beyond Robot Demonstrations via 3D Understanding**|Danda Pani Paudel Team|[2511.17411](http://arxiv.org/abs/2511.17411)|null|
|**2025-11-21**|**Feasibility of Embodied Dynamics Based Bayesian Learning for Continuous Pursuit Motion Control of Assistive Mobile Robots in the Built Environment**|Vineet R. Kamat Team|[2511.17401](http://arxiv.org/abs/2511.17401)|null|
|**2025-11-21**|**Agility Meets Stability: Versatile Humanoid Control with Heterogeneous Data**|Hongyang Li Team|[2511.17373](http://arxiv.org/abs/2511.17373)|null|
|**2025-11-21**|**METIS: Multi-Source Egocentric Training for Integrated Dexterous Vision-Language-Action Model**|Shanghang Zhang Team|[2511.17366](http://arxiv.org/abs/2511.17366)|null|
|**2025-11-21**|**A ROS2 Interface for Universal Robots Collaborative Manipulators Based on ur_rtde**|Jacopo Aleotti Team|[2511.17237](http://arxiv.org/abs/2511.17237)|null|
|**2025-11-21**|**VLA-4D: Embedding 4D Awareness into Vision-Language-Action Models for SpatioTemporally Coherent Robotic Manipulation**|Gim Hee Lee Team|[2511.17199](http://arxiv.org/abs/2511.17199)|null|
|**2025-11-21**|**H-GAR: A Hierarchical Interaction Framework via Goal-Driven Observation-Action Refinement for Robotic Manipulation**|Zitong Yu Team|[2511.17079](http://arxiv.org/abs/2511.17079)|**[link](https://github.com/JiuTian-VL/H-GAR)**|
|**2025-11-21**|**MfNeuPAN: Proactive End-to-End Navigation in Dynamic Environments via Direct Multi-Frame Point Constraints**|Hong Zhang Team|[2511.17013](http://arxiv.org/abs/2511.17013)|null|
|**2025-11-21**|**Stable Offline Hand-Eye Calibration for any Robot with Just One Mark**|Yu-Gang Jiang Team|[2511.17001](http://arxiv.org/abs/2511.17001)|null|
|**2025-11-20**|**Dexterity from Smart Lenses: Multi-Fingered Robot Manipulation with In-the-Wild Human Demonstrations**|Homanga Bharadhwaj Team|[2511.16661](http://arxiv.org/abs/2511.16661)|null|
|**2025-11-20**|**InternData-A1: Pioneering High-Fidelity Synthetic Data for Pre-training Generalist Policy**|Jiangmiao Pang Team|[2511.16651](http://arxiv.org/abs/2511.16651)|null|
|**2025-11-20**|**Toward Artificial Palpation: Representation Learning of Touch on Soft Bodies**|Aviv Tamar Team|[2511.16596](http://arxiv.org/abs/2511.16596)|null|
|**2025-11-20**|**Green Resilience of Cyber-Physical Systems: Doctoral Dissertation**|Diaeddin Rimawi Team|[2511.16593](http://arxiv.org/abs/2511.16593)|null|
|**2025-11-21**|**VLA-Pruner: Temporal-Aware Dual-Level Visual Token Pruning for Efficient Vision-Language-Action Inference**|Bo Zhao Team|[2511.16449](http://arxiv.org/abs/2511.16449)|null|
|**2025-11-20**|**Graph Neural Networks for Surgical Scene Segmentation**|Danail Stoyanov Team|[2511.16430](http://arxiv.org/abs/2511.16430)|null|
|**2025-11-20**|**LAOF: Robust Latent Action Learning with Optical Flow Constraints**|Wei Li Team|[2511.16407](http://arxiv.org/abs/2511.16407)|**[link](https://github.com/XizoB/LAOF)**|
|**2025-11-20**|**Homogeneous Proportional-Integral-Derivative Controller in Mobile Robotic Manipulators**|Andrey Polyakov Team|[2511.16406](http://arxiv.org/abs/2511.16406)|null|
|**2025-11-20**|**Robot Metacognition: Decision Making with Confidence for Tool Invention**|Pablo Lanillos Team|[2511.16390](http://arxiv.org/abs/2511.16390)|null|
|**2025-11-20**|**Beyond Generative AI: World Models for Clinical Prediction, Counterfactuals, and Planning**|Mohammad Yaqub Team|[2511.16333](http://arxiv.org/abs/2511.16333)|null|
|**2025-11-20**|**Safe and Optimal Variable Impedance Control via Certified Reinforcement Learning**|Ravi Prakash Team|[2511.16330](http://arxiv.org/abs/2511.16330)|null|
|**2025-11-20**|**InEKFormer: A Hybrid State Estimator for Humanoid Robots**|Frank Kirchner Team|[2511.16306](http://arxiv.org/abs/2511.16306)|null|
|**2025-11-20**|**DynaMimicGen: A Data Generation Framework for Robot Learning of Dynamic Tasks**|Anna Valente Team|[2511.16223](http://arxiv.org/abs/2511.16223)|null|
|**2025-11-20**|**When Alignment Fails: Multimodal Adversarial Attacks on Vision-Language-Action Models**|Yaochu Jin Team|[2511.16203](http://arxiv.org/abs/2511.16203)|null|
|**2025-11-20**|**Mantis: A Versatile Vision-Language-Action Model with Disentangled Visual Foresight**|Zhijie Deng Team|[2511.16175](http://arxiv.org/abs/2511.16175)|null|
|**2025-11-20**|**EvoVLA: Self-Evolving Vision-Language-Action Model**|Hao Tang Team|[2511.16166](http://arxiv.org/abs/2511.16166)|null|
|**2025-11-20**|**MagBotSim: Physics-Based Simulation and Reinforcement Learning Environments for Magnetic Robotics**|Klaus Neumann Team|[2511.16158](http://arxiv.org/abs/2511.16158)|null|
|**2025-11-20**|**Real-Time 3D Object Detection with Inference-Aligned Learning**|Nan Xue Team|[2511.16140](http://arxiv.org/abs/2511.16140)|null|
|**2025-11-20**|**Bi-AQUA: Bilateral Control-Based Imitation Learning for Underwater Robot Arms via Lighting-Aware Action Chunking with Transformers**|Yuki Uranishi Team|[2511.16050](http://arxiv.org/abs/2511.16050)|null|
|**2025-11-20**|**PushingBots: Collaborative Pushing via Neural Accelerated Combinatorial Hybrid Optimization**|Meng Guo Team|[2511.15995](http://arxiv.org/abs/2511.15995)|null|
|**2025-11-19**|**Optimus-Q: Utilizing Federated Learning in Adaptive Robots for Intelligent Nuclear Power Plant Operations through Quantum Cryptography**|Sajedul Talukder Team|[2511.15614](http://arxiv.org/abs/2511.15614)|null|
|**2025-11-19**|**SRPO: Self-Referential Policy Optimization for Vision-Language-Action Models**|Xipeng Qiu Team|[2511.15605](http://arxiv.org/abs/2511.15605)|null|
|**2025-11-19**|**Learning from Mistakes: Loss-Aware Memory Enhanced Continual Learning for LiDAR Place Recognition**|Tiantian Feng Team|[2511.15597](http://arxiv.org/abs/2511.15597)|null|
|**2025-11-19**|**NMPC-based Motion Planning with Adaptive Weighting for Dynamic Object Interception**|Steven Liu Team|[2511.15532](http://arxiv.org/abs/2511.15532)|null|
|**2025-11-19**|**Decentralized Gaussian Process Classification and an Application in Subsea Robotics**|James McMahon Team|[2511.15529](http://arxiv.org/abs/2511.15529)|null|
|**2025-11-19**|**Theoretical Closed-loop Stability Bounds for Dynamical System Coupled with Diffusion Policies**|François Ferland Team|[2511.15520](http://arxiv.org/abs/2511.15520)|null|
|**2025-11-19**|**IPR-1: Interactive Physical Reasoner**|Yong-Lu Li Team|[2511.15407](http://arxiv.org/abs/2511.15407)|null|
|**2025-11-19**|**Platform-Agnostic Reinforcement Learning Framework for Safe Exploration of Cluttered Environments with Graph Attention**|George Nikolakopoulos Team|[2511.15358](http://arxiv.org/abs/2511.15358)|null|
|**2025-11-19**|**Adversarial Attack on Black-Box Multi-Agent by Adaptive Perturbation**|Fanjiang Xu Team|[2511.15292](http://arxiv.org/abs/2511.15292)|null|
|**2025-11-19**|**Path Planning through Multi-Agent Reinforcement Learning in Dynamic Environments**|Moharram Challenger Team|[2511.15284](http://arxiv.org/abs/2511.15284)|null|
|**2025-11-19**|**Look, Zoom, Understand: The Robotic Eyeball for Embodied Perception**|Wenzhao Lian Team|[2511.15279](http://arxiv.org/abs/2511.15279)|null|
|**2025-11-19**|**Behavior Trees vs Executable Ontologies: a Comparative Analysis of Robot Control Paradigms**|Alexander Boldachev Team|[2511.15274](http://arxiv.org/abs/2511.15274)|null|
|**2025-11-19**|**Symmetry-Breaking in Multi-Agent Navigation: Winding Number-Aware MPC with a Learned Topological Strategy**|Tadashi Kozuno Team|[2511.15239](http://arxiv.org/abs/2511.15239)|null|
|**2025-11-19**|**Efficient Transformer-Integrated Deep Neural Architectures for Robust EEG Decoding of Complex Visual Imagery**|Byoung-Hee Kwon Team|[2511.15218](http://arxiv.org/abs/2511.15218)|null|
|**2025-11-19**|**VIRAL: Visual Sim-to-Real at Scale for Humanoid Loco-Manipulation**|Yuke Zhu Team|[2511.15200](http://arxiv.org/abs/2511.15200)|**[link](https://viral-humanoid.github.io/)**|
|**2025-11-19**|**Eq.Bot: Enhance Robotic Manipulation Learning via Group Equivariant Canonicalization**|Zhenzhou Shao Team|[2511.15194](http://arxiv.org/abs/2511.15194)|null|
|**2025-11-19**|**Learning Depth from Past Selves: Self-Evolution Contrast for Robust Depth Estimation**|Yong Huang Team|[2511.15167](http://arxiv.org/abs/2511.15167)|null|
|**2025-11-19**|**An Alignment-Based Approach to Learning Motions from Demonstrations**|Julie A Shah Team|[2511.14988](http://arxiv.org/abs/2511.14988)|null|
|**2025-11-18**|**Automated laboratory x-ray diffractometer and fluorescence spectrometer for high-throughput materials characterization**|Todd C. Hufnagel Team|[2511.14905](http://arxiv.org/abs/2511.14905)|**[link](https://doi.org/10.34863/e8bx-pk70)**|
|**2025-11-19**|**$π^{*}_{0.6}$ : a VLA That Learns From Experience**|Zhiyuan Zhou Team|[2511.14759](http://arxiv.org/abs/2511.14759)|null|
|**2025-11-18**|**HMC: Learning Heterogeneous Meta-Control for Contact-Rich Loco-Manipulation**|Xiaolong Wang Team|[2511.14756](http://arxiv.org/abs/2511.14756)|null|
|**2025-11-18**|**Masked IRL: LLM-Guided Reward Disambiguation from Demonstrations and Language**|Andreea Bobu Team|[2511.14565](http://arxiv.org/abs/2511.14565)|null|
|**2025-11-18**|**A Neuro-Symbolic Framework for Reasoning under Perceptual Uncertainty: Bridging Continuous Perception and Discrete Symbolic Planning**|Shengwen Yu Team|[2511.14533](http://arxiv.org/abs/2511.14533)|null|
|**2025-11-18**|**Achieving Safe Control Online through Integration of Harmonic Control Lyapunov-Barrier Functions with Unsafe Object-Centric Action Policies**|Matthias Scheutz Team|[2511.14434](http://arxiv.org/abs/2511.14434)|null|
|**2025-11-18**|**Self-Supervised Multisensory Pretraining for Contact-Rich Robot Reinforcement Learning**|Georgia Chalvatzaki Team|[2511.14427](http://arxiv.org/abs/2511.14427)|null|
|**2025-11-18**|**Continuous Vision-Language-Action Co-Learning with Semantic-Physical Alignment for Behavioral Cloning**|Hongpeng Wang Team|[2511.14396](http://arxiv.org/abs/2511.14396)|**[link](https://qhemu.github.io/CCoL/)**|
|**2025-11-18**|**MA-SLAM: Active SLAM in Large-Scale Unknown Environment using Map Aware Deep Reinforcement Learning**|Yi Jiang Team|[2511.14330](http://arxiv.org/abs/2511.14330)|null|
|**2025-11-18**|**NeuralBoneReg: A Novel Self-Supervised Method for Robust and Accurate Multi-Modal Bone Surface Registration**|Philipp Fürnstahl Team|[2511.14286](http://arxiv.org/abs/2511.14286)|null|
|**2025-11-18**|**Towards Deploying VLA without Fine-Tuning: Plug-and-Play Inference-Time VLA Policy Steering via Embodied Evolutionary Diffusion**|Fei Chen Team|[2511.14178](http://arxiv.org/abs/2511.14178)|null|
|**2025-11-18**|**RoboTidy : A 3D Gaussian Splatting Household Tidying Benchmark for Embodied Navigation and Action**|Jiayu Chen Team|[2511.14161](http://arxiv.org/abs/2511.14161)|null|
|**2025-11-18**|**AsyncVLA: Asynchronous Flow Matching for Vision-Language-Action Models**|Biqing Qi Team|[2511.14148](http://arxiv.org/abs/2511.14148)|null|
|**2025-11-17**|**From Power to Precision: Learning Fine-grained Dexterity for Multi-fingered Robotic Hands**|Xiaolong Wang Team|[2511.13710](http://arxiv.org/abs/2511.13710)|**[link](https://jianglongye.com/power-to-precision)**|
|**2025-11-17**|**OpenRoboCare: A Multimodal Multi-Task Expert Demonstration Dataset for Robot Caregiving**|Tapomayukh Bhattacharjee Team|[2511.13707](http://arxiv.org/abs/2511.13707)|null|
|**2025-11-17**|**PhysX-Anything: Simulation-Ready Physical 3D Assets from Single Image**|Ziwei Liu Team|[2511.13648](http://arxiv.org/abs/2511.13648)|**[link](https://physx-anything.github.io/)**|
|**2025-11-17**|**Contact-Safe Reinforcement Learning with ProMP Reparameterization and Energy Awareness**|Luis Figueredo Team|[2511.13459](http://arxiv.org/abs/2511.13459)|null|
|**2025-11-17**|**ZeroDexGrasp: Zero-Shot Task-Oriented Dexterous Grasp Synthesis with Prompt-Based Multi-Stage Semantic Reasoning**|Ruizhen Hu Team|[2511.13327](http://arxiv.org/abs/2511.13327)|null|
|**2025-11-17**|**EL3DD: Extended Latent 3D Diffusion for Language Conditioned Multitask Manipulation**|Sven Behnke Team|[2511.13312](http://arxiv.org/abs/2511.13312)|null|
|**2025-11-17**|**Robust Control Design Using a Hybrid-Gain Finite-Time Sliding-Mode Controller**|Fernando A. C. C. Fontes Team|[2511.13260](http://arxiv.org/abs/2511.13260)|null|
|**2025-11-17**|**Difficulty-Aware Label-Guided Denoising for Monocular 3D Object Detection**|Dongbo Min Team|[2511.13195](http://arxiv.org/abs/2511.13195)|null|
|**2025-11-17**|**Orientation-Free Neural Network-Based Bias Estimation for Low-Cost Stationary Accelerometers**|Itzik Klein Team|[2511.13071](http://arxiv.org/abs/2511.13071)|null|
|**2025-11-17**|**Learning Branching Policies for MILPs with Proximal Policy Optimization**|Amal El Fallah Seghrouchni Team|[2511.12986](http://arxiv.org/abs/2511.12986)|null|
|**2025-11-17**|**ArtiWorld: LLM-Driven Articulation of 3D Objects in Scenes**|Feng Zheng Team|[2511.12977](http://arxiv.org/abs/2511.12977)|null|
|**2025-11-17**|**DiffuDepGrasp: Diffusion-based Depth Noise Modeling Empowers Sim2Real Robotic Grasping**|Dongbin Zhao Team|[2511.12912](http://arxiv.org/abs/2511.12912)|null|
|**2025-11-17**|**Uni-Hand: Universal Hand Motion Forecasting in Egocentric Views**|Hesheng Wang Team|[2511.12878](http://arxiv.org/abs/2511.12878)|null|
|**2025-11-17**|**Structured Imitation Learning of Interactive Policies through Inverse Games**|Todd Murphey Team|[2511.12848](http://arxiv.org/abs/2511.12848)|**[link](https://sites.google.com/view/gai-hri/)**|
|**2025-11-17**|**Mapping fNIRS Signals to Agent Performance: Toward Reinforcement Learning from Neural Feedback**|Jivko SInapov Team|[2511.12844](http://arxiv.org/abs/2511.12844)|null|
|**2025-11-16**|**Scalable Multi-Objective and Meta Reinforcement Learning via Gradient Estimation**|Hongyang R. Zhang Team|[2511.12779](http://arxiv.org/abs/2511.12779)|null|
|**2025-11-16**|**Task-Aware Morphology Optimization of Planar Manipulators via Reinforcement Learning**|Sohom Chakrabarty Team|[2511.12650](http://arxiv.org/abs/2511.12650)|null|
|**2025-11-16**|**Botany Meets Robotics in Alpine Scree Monitoring**|Manolo Garabini Team|[2511.12526](http://arxiv.org/abs/2511.12526)|null|
|**2025-11-16**|**RoboAfford++: A Generative AI-Enhanced Dataset for Multimodal Affordance Learning in Robotic Manipulation and Navigation**|Long Chen Team|[2511.12436](http://arxiv.org/abs/2511.12436)|null|
|**2025-11-16**|**VLA-R: Vision-Language Action Retrieval toward Open-World End-to-End Autonomous Driving**|David Hyunchul Shim Team|[2511.12405](http://arxiv.org/abs/2511.12405)|null|
|**2025-11-14**|**Volumetric Ergodic Control**|Todd Murphey Team|[2511.11533](http://arxiv.org/abs/2511.11533)|null|
|**2025-11-14**|**Terrain Costmap Generation via Scaled Preference Conditioning**|Joydeep Biswas Team|[2511.11529](http://arxiv.org/abs/2511.11529)|null|
|**2025-11-14**|**Scalable Policy Evaluation with Video World Models**|Lin Yen-Chen Team|[2511.11520](http://arxiv.org/abs/2511.11520)|null|
|**2025-11-14**|**Collaborative Representation Learning for Alignment of Tactile, Language, and Vision Modalities**|Jingyuan Chen Team|[2511.11512](http://arxiv.org/abs/2511.11512)|null|
|**2025-11-14**|**Rethinking Progression of Memory State in Robotic Manipulation: An Object-Centric Perspective**|Ngan Le Team|[2511.11478](http://arxiv.org/abs/2511.11478)|null|
|**2025-11-14**|**Simulating an Autonomous System in CARLA using ROS 2**|Mohamed Al-Musleh Team|[2511.11310](http://arxiv.org/abs/2511.11310)|null|
|**2025-11-14**|**Experiences from Benchmarking Vision-Language-Action Models for Robotic Manipulation**|Xi Zheng Team|[2511.11298](http://arxiv.org/abs/2511.11298)|null|
|**2025-11-14**|**Sashimi-Bot: Autonomous Tri-manual Advanced Manipulation and Cutting of Deformable Objects**|Ekrem Misimi Team|[2511.11223](http://arxiv.org/abs/2511.11223)|null|
|**2025-11-14**|**Humanoid Whole-Body Badminton via Multi-Stage Reinforcement Learning**|Xiaoyu Ren Team|[2511.11218](http://arxiv.org/abs/2511.11218)|null|
|**2025-11-14**|**One-to-N Backdoor Attack in 3D Point Cloud via Spherical Trigger**|Chongxia Wang Team|[2511.11210](http://arxiv.org/abs/2511.11210)|null|
|**2025-11-14**|**Viper-F1: Fast and Fine-Grained Multimodal Understanding with Cross-Modal State-Space Modulation**|Debesh Jha Team|[2511.11177](http://arxiv.org/abs/2511.11177)|null|
|**2025-11-14**|**Phys-Liquid: A Physics-Informed Dataset for Estimating 3D Geometry and Volume of Transparent Deformable Liquids**|Tian Xia Team|[2511.11077](http://arxiv.org/abs/2511.11077)|**[link](https://github.com/dualtransparency/Phys-Liquid-AAAI)**|
|**2025-11-14**|**AdaptPNP: Integrating Prehensile and Non-Prehensile Skills for Adaptive Robotic Manipulation**|Lin Shao Team|[2511.11052](http://arxiv.org/abs/2511.11052)|null|
|**2025-11-14**|**Autonomous Vehicle Path Planning by Searching With Differentiable Simulation**|Luc Van Gool Team|[2511.11043](http://arxiv.org/abs/2511.11043)|null|
|**2025-11-14**|**Dexterous Manipulation Transfer via Progressive Kinematic-Dynamic Alignment**|Yi Sun Team|[2511.10987](http://arxiv.org/abs/2511.10987)|null|
|**2025-11-14**|**Collaborative Multi-Robot Non-Prehensile Manipulation via Flow-Matching Co-Generation**|Jiaoyang Li Team|[2511.10874](http://arxiv.org/abs/2511.10874)|null|
|**2025-11-14**|**WetExplorer: Automating Wetland Greenhouse-Gas Surveys with an Autonomous Mobile Robot**|Xuping Zhang Team|[2511.10864](http://arxiv.org/abs/2511.10864)|null|
|**2025-11-13**|**SURFACEBENCH: Can Self-Evolving LLMs Find the Equations of 3D Scientific Surfaces?**|Chandan K. Reddy Team|[2511.10833](http://arxiv.org/abs/2511.10833)|null|
|**2025-11-13**|**Expert Consensus-based Video-Based Assessment Tool for Workflow Analysis in Minimally Invasive Colorectal Surgery: Development and Validation of ColoWorkflow**|Nicolas Padoy Team|[2511.10766](http://arxiv.org/abs/2511.10766)|null|
|**2025-11-13**|**Attentive Feature Aggregation or: How Policies Learn to Stop Worrying about Robustness and Attend to Task-Relevant Visual Cues**|Chris Xiaoxuan Lu Team|[2511.10762](http://arxiv.org/abs/2511.10762)|null|
|**2025-11-13**|**Robot Crash Course: Learning Soft and Stylized Falling**|Moritz Bächer Team|[2511.10635](http://arxiv.org/abs/2511.10635)|null|
|**2025-11-13**|**OmniVGGT: Omni-Modality Driven Visual Geometry Grounded**|Ziwei Liu Team|[2511.10560](http://arxiv.org/abs/2511.10560)|**[link](https://livioni.github.io/OmniVGGT-offcial/)**|
|**2025-11-13**|**SemanticVLA: Semantic-Aligned Sparsification and Enhancement for Efficient Robotic Manipulation**|Liqiang Nie Team|[2511.10518](http://arxiv.org/abs/2511.10518)|**[link](https://github.com/JiuTian-VL/SemanticVLA)**|
|**2025-11-13**|**RoboBenchMart: Benchmarking Robots in Retail Environment**|Vlad Shakhuro Team|[2511.10276](http://arxiv.org/abs/2511.10276)|null|
|**2025-11-13**|**Learning a Thousand Tasks in a Day**|Edward Johns Team|[2511.10110](http://arxiv.org/abs/2511.10110)|**[link](https://www.science.org/doi/10.1126/scirobotics.adv7594.)**|
|**2025-11-13**|**Opinion: Towards Unified Expressive Policy Optimization for Robust Robot Learning**|Xiaocong Li Team|[2511.10087](http://arxiv.org/abs/2511.10087)|null|
|**2025-11-13**|**Physics-informed Machine Learning for Static Friction Modeling in Robotic Manipulators Based on Kolmogorov-Arnold Networks**|Yinghua Liu Team|[2511.10079](http://arxiv.org/abs/2511.10079)|null|
|**2025-11-13**|**Efficient Verification and Falsification of ReLU Neural Barrier Certificates**|Bai Xue Team|[2511.10015](http://arxiv.org/abs/2511.10015)|null|
|**2025-11-13**|**Audio-VLA: Adding Contact Audio Perception to Vision-Language-Action Model for Robotic Manipulation**|Changbo Wang Team|[2511.09958](http://arxiv.org/abs/2511.09958)|null|
|**2025-11-13**|**A Study on Enhancing the Generalization Ability of Visuomotor Policies via Data Augmentation**|Hanwen Wang Team|[2511.09932](http://arxiv.org/abs/2511.09932)|null|
|**2025-11-13**|**Harnessing Bounded-Support Evolution Strategies for Policy Refinement**|Fabio Ramos Team|[2511.09923](http://arxiv.org/abs/2511.09923)|null|
|**2025-11-13**|**Evolving Rules: Imitation and Best Response Learning in Cournot Oligopoly**|Boyu Zhang Team|[2511.09839](http://arxiv.org/abs/2511.09839)|null|
|**2025-11-13**|**Provably Safe Stein Variational Clarity-Aware Informative Planning**|Dimitra Panagou Team|[2511.09836](http://arxiv.org/abs/2511.09836)|**[link](https://usahai18.github.io/stein_clarity/))**|
|**2025-11-12**|**A Robust Task-Level Control Architecture for Learned Dynamical Systems**|Naira Hovakimyan Team|[2511.09790](http://arxiv.org/abs/2511.09790)|null|
|**2025-11-12**|**Out-of-Distribution Generalization with a SPARC: Racing 100 Unseen Vehicles with a Single Policy**|Peter R. Wurman Team|[2511.09737](http://arxiv.org/abs/2511.09737)|**[link](https://github.com/bramgrooten/sparc)**|
|**2025-11-12**|**Baby Sophia: A Developmental Approach to Self-Exploration through Self-Touch and Hand Regard**|Katerina Pastra Team|[2511.09727](http://arxiv.org/abs/2511.09727)|null|
|**2025-11-12**|**SEBA: Sample-Efficient Black-Box Attacks on Visual Reinforcement Learning**|Haibo Hu Team|[2511.09681](http://arxiv.org/abs/2511.09681)|null|
|**2025-11-12**|**Statistically Consistent Approximate Model Predictive Control**|Melanie N. Zeilinger Team|[2511.09661](http://arxiv.org/abs/2511.09661)|null|
|**2025-11-12**|**IFG: Internet-Scale Guidance for Functional Grasping Generation**|Deepak Pathak Team|[2511.09558](http://arxiv.org/abs/2511.09558)|**[link](https://ifgrasping.github.io/)**|
|**2025-11-12**|**SpatialActor: Exploring Disentangled Spatial Representations for Robust Robotic Manipulation**|Gao Huang Team|[2511.09555](http://arxiv.org/abs/2511.09555)|**[link](https://shihao1895.github.io/SpatialActor)**|
|**2025-11-10**|**Lightning Grasp: High Performance Procedural Grasp Synthesis with Contact Fields**|Pieter Abbeel Team|[2511.07418](http://arxiv.org/abs/2511.07418)|**[link](https://github.com/zhaohengyin/lightning-grasp)**|
|**2025-11-10**|**Robot Learning from a Physical World Model**|Yue Wang Team|[2511.07416](http://arxiv.org/abs/2511.07416)|**[link](https://pointscoder.github.io/PhysWorld_Web/)**|
|**2025-11-10**|**Enabling Off-Policy Imitation Learning with Deep Actor Critic Stabilization**|Shalabh Bhatnagar Team|[2511.07288](http://arxiv.org/abs/2511.07288)|null|
|**2025-11-10**|**SlotVLA: Towards Modeling of Object-Relation Representations in Robotic Manipulation**|Ngan Le Team|[2511.06754](http://arxiv.org/abs/2511.06754)|null|
|**2025-11-10**|**Physically-Grounded Goal Imagination: Physics-Informed Variational Autoencoder for Self-Supervised Reinforcement Learning**|Nam Pham Hai Team|[2511.06745](http://arxiv.org/abs/2511.06745)|null|
|**2025-11-10**|**Rapidly Learning Soft Robot Control via Implicit Time-Stepping**|Dezhong Tong Team|[2511.06667](http://arxiv.org/abs/2511.06667)|**[link](https://github.com/QuantuMope/dismech-rl)**|
|**2025-11-09**|**Real Garment Benchmark (RGBench): A Comprehensive Benchmark for Robotic Garment Manipulation featuring a High-Fidelity Scalable Simulator**|Ruigang Yang Team|[2511.06434](http://arxiv.org/abs/2511.06434)|null|
|**2025-11-09**|**ExpReS-VLA: Specializing Vision-Language-Action Models Through Experience Replay and Retrieval**|Jeff Ichnowski Team|[2511.06202](http://arxiv.org/abs/2511.06202)|null|
|**2025-11-08**|**Exploring Category-level Articulated Object Pose Tracking on SE(3) Manifolds**|Jun Liu Team|[2511.05996](http://arxiv.org/abs/2511.05996)|null|
|**2025-11-08**|**Gentle Manipulation Policy Learning via Demonstrations from VLM Planned Atomic Skills**|Renjing Xu Team|[2511.05855](http://arxiv.org/abs/2511.05855)|null|
|**2025-11-08**|**VLAD-Grasp: Zero-shot Grasp Detection via Vision-Language Models**|Aniket Bera Team|[2511.05791](http://arxiv.org/abs/2511.05791)|null|
|**2025-11-07**|**VLM-driven Skill Selection for Robotic Assembly Tasks**|Chang-Hyun Kim Team|[2511.05680](http://arxiv.org/abs/2511.05680)|null|
|**2025-11-07**|**EveryDayVLA: A Vision-Language-Action Model for Affordable Robotic Manipulation**|Samuel Dickerson Team|[2511.05397](http://arxiv.org/abs/2511.05397)|null|
|**2025-11-07**|**ETHOS: A Robotic Encountered-Type Haptic Display for Social Interaction in Virtual Reality**|Matthew K. X. J. Pan Team|[2511.05379](http://arxiv.org/abs/2511.05379)|null|
|**2025-11-07**|**Force-Safe Environment Maps and Real-Time Detection for Soft Robot Manipulators**|Andrew P. Sabelhaus Team|[2511.05307](http://arxiv.org/abs/2511.05307)|null|
|**2025-11-07**|**Context-aware Learned Mesh-based Simulation via Trajectory-Level Meta-Learning**|Gerhard Neumann Team|[2511.05234](http://arxiv.org/abs/2511.05234)|null|
|**2025-11-07**|**Let Me Show You: Learning by Retrieving from Egocentric Video for Robotic Manipulation**|Feifei Feng Team|[2511.05199](http://arxiv.org/abs/2511.05199)|null|
|**2025-11-07**|**Follow-Me in Micro-Mobility with End-to-End Imitation Learning**|Jorge Peña Queralta Team|[2511.05158](http://arxiv.org/abs/2511.05158)|null|
|**2025-11-07**|**TAPOM: Task-Space Topology-Guided Motion Planning for Manipulating Elongated Object in Cluttered Environments**|Yijiang Huang Team|[2511.05052](http://arxiv.org/abs/2511.05052)|null|
|**2025-11-07**|**MoE-DP: An MoE-Enhanced Diffusion Policy for Robust Long-Horizon Robotic Manipulation with Skill Decomposition and Failure Recovery**|Huazhe Xu Team|[2511.05007](http://arxiv.org/abs/2511.05007)|null|
|**2025-11-06**|**Isaac Lab: A GPU-Accelerated Simulation Framework for Multi-Modal Robot Learning**|Gavriel State Team|[2511.04831](http://arxiv.org/abs/2511.04831)|**[link](https://github.com/isaac-sim/IsaacLab)**|
|**2025-11-06**|**Unified Multimodal Diffusion Forcing for Forceful Manipulation**|Dmitry Berenson Team|[2511.04812](http://arxiv.org/abs/2511.04812)|**[link](https://unified-df.github.io)**|
|**2025-11-06**|**ReGen: Generative Robot Simulation via Inverse Design**|Daniela Rus Team|[2511.04769](http://arxiv.org/abs/2511.04769)|null|
|**2025-11-06**|**X-Diffusion: Training Diffusion Policies on Cross-Embodiment Human Demonstrations**|Kushal Kedia Team|[2511.04671](http://arxiv.org/abs/2511.04671)|null|
|**2025-11-06**|**Real-to-Sim Robot Policy Evaluation with Gaussian Splatting Simulation of Soft-Body Interactions**|Yunzhu Li Team|[2511.04665](http://arxiv.org/abs/2511.04665)|**[link](https://real2sim-eval.github.io/)**|
|**2025-11-06**|**ForeRobo: Unlocking Infinite Simulation Data for 3D Goal-driven Robotic Manipulation**|Chunsheng Liu Team|[2511.04381](http://arxiv.org/abs/2511.04381)|null|
|**2025-11-06**|**GraSP-VLA: Graph-based Symbolic Action Representation for Long-Horizon Planning with VLA Policies**|Cédric Buche Team|[2511.04357](http://arxiv.org/abs/2511.04357)|null|
|**2025-11-06**|**Learning Vision-Driven Reactive Soccer Skills for Humanoid Robots**|Mingguo Zhao Team|[2511.03996](http://arxiv.org/abs/2511.03996)|**[link](https://humanoid-kick.github.io)**|
|**2025-11-05**|**Investigating Robot Control Policy Learning for Autonomous X-ray-guided Spine Procedures**|Mathias Unberath Team|[2511.03882](http://arxiv.org/abs/2511.03882)|null|
|**2025-11-05**|**Going Beyond Expert Performance via Deep Implicit Imitation Reinforcement Learning**|Georgios Chalkiadakis Team|[2511.03616](http://arxiv.org/abs/2511.03616)|null|
|**2025-11-05**|**Imitation Learning in the Deep Learning Era: A Novel Taxonomy and Recent Advances**|Georgios Chalkiadakis Team|[2511.03565](http://arxiv.org/abs/2511.03565)|null|
|**2025-11-05**|**Development of the Bioinspired Tendon-Driven DexHand 021 with Proprioceptive Compliance Control**|Sheng Yi Team|[2511.03481](http://arxiv.org/abs/2511.03481)|null|
|**2025-11-05**|**Learning-based Cooperative Robotic Paper Wrapping: A Unified Control Policy with Residual Force Control**|Kensuke Harada Team|[2511.03181](http://arxiv.org/abs/2511.03181)|null|
|**2025-11-05**|**Learning Natural and Robust Hexapod Locomotion over Complex Terrains via Motion Priors based on Deep Reinforcement Learning**|Feng Gao Team|[2511.03167](http://arxiv.org/abs/2511.03167)|null|
|**2025-11-05**|**ISC-Perception: A Hybrid Computer Vision Dataset for Object Detection in Novel Steel Assembly**|Debra F. Laefer Team|[2511.03098](http://arxiv.org/abs/2511.03098)|null|
|**2025-11-04**|**3D Cal: An Open-Source Software Library for Calibrating Tactile Sensors**|Gregory Reardon Team|[2511.03078](http://arxiv.org/abs/2511.03078)|null|
|**2025-11-04**|**Audience Amplified: Virtual Audiences in Asynchronously Performed AR Theater**|Tobias Höllerer Team|[2511.02807](http://arxiv.org/abs/2511.02807)|null|
|**2025-11-04**|**Dexterous Robotic Piano Playing at Scale**|Dieter Büchler Team|[2511.02504](http://arxiv.org/abs/2511.02504)|null|
|**2025-11-04**|**LACY: A Vision-Language Model-based Language-Action Cycle for Self-Improving Robotic Manipulation**|Changhyun Choi Team|[2511.02239](http://arxiv.org/abs/2511.02239)|**[link](https://vla2026.github.io/LACY/)**|
|**2025-10-31**|**A Step Toward World Models: A Survey on Robotic Manipulation**|Heng Tao Shen Team|[2511.02097](http://arxiv.org/abs/2511.02097)|null|
|**2025-11-03**|**TRACE: Textual Reasoning for Affordance Coordinate Extraction**|Matthew S. Brown Team|[2511.01999](http://arxiv.org/abs/2511.01999)|null|
|**2025-11-01**|**iFlyBot-VLA Technical Report**|Jia Pan Team|[2511.01914](http://arxiv.org/abs/2511.01914)|null|
|**2025-11-03**|**SE(3)-PoseFlow: Estimating 6D Pose Distributions for Uncertainty-Aware Robotic Manipulation**|Georgia Chalvatzaki Team|[2511.01501](http://arxiv.org/abs/2511.01501)|null|
|**2025-11-03**|**RobustVLA: Robustness-Aware Reinforcement Post-Training for Vision-Language-Action Models**|Donglin Wang Team|[2511.01331](http://arxiv.org/abs/2511.01331)|null|
|**2025-11-03**|**Improving Needle Penetration via Precise Rotational Insertion Using Iterative Learning Control**|Tsu-Chin Tsao Team|[2511.01256](http://arxiv.org/abs/2511.01256)|null|
|**2025-11-03**|**Embodiment Transfer Learning for Vision-Language-Action Models**|Yaxin Peng Team|[2511.01224](http://arxiv.org/abs/2511.01224)|null|
|**2025-11-02**|**Deployable Vision-driven UAV River Navigation via Human-in-the-loop Preference Alignment**|Nina Mahmoudian Team|[2511.01083](http://arxiv.org/abs/2511.01083)|null|
|**2025-11-02**|**GauDP: Reinventing Multi-Agent Collaboration through Gaussian-Image Synergy in Diffusion Policies**|Ruimao Zhang Team|[2511.00998](http://arxiv.org/abs/2511.00998)|**[link](https://ziyeeee.github.io/gaudp.io/)**|
|**2025-11-01**|**Improving Robustness to Out-of-Distribution States in Imitation Learning via Deep Koopman-Boosted Diffusion Policy**|Zhongliang Jiang Team|[2511.00555](http://arxiv.org/abs/2511.00555)|null|
|**2025-10-31**|**EgoMI: Learning Active Vision and Whole-Body Manipulation from Egocentric Human Demonstrations**|Philipp Wu Team|[2511.00153](http://arxiv.org/abs/2511.00153)|null|
|**2025-10-31**|**Whole-Body Proprioceptive Morphing: A Modular Soft Gripper for Robust Cross-Scale Grasping**|Xiaonan Huang Team|[2510.27666](http://arxiv.org/abs/2510.27666)|null|
|**2025-10-31**|**Toward Accurate Long-Horizon Robotic Manipulation: Language-to-Action with Foundation Models via Scene Graphs**|Shinkyu Park Team|[2510.27558](http://arxiv.org/abs/2510.27558)|null|
|**2025-10-31**|**When AI Trading Agents Compete: Adverse Selection of Meta-Orders by Reinforcement Learning-Based Market Making**|Nick Firoozye Team|[2510.27334](http://arxiv.org/abs/2510.27334)|null|
|**2025-10-31**|**Learning Generalizable Visuomotor Policy through Dynamics-Alignment**|Jungwoo Lee Team|[2510.27114](http://arxiv.org/abs/2510.27114)|null|
|**2025-10-30**|**Hybrid Consistency Policy: Decoupling Multi-Modal Diversity and Real-Time Efficiency in Robotic Manipulation**|Qiaojun Yu Team|[2510.26670](http://arxiv.org/abs/2510.26670)|null|
|**2025-10-31**|**An Impulse Control Approach to Market Making in a Hawkes LOB Market**|Philip Treleaven Team|[2510.26438](http://arxiv.org/abs/2510.26438)|null|
|**2025-10-30**|**Human-in-the-loop Online Rejection Sampling for Robotic Manipulation**|Yansong Tang Team|[2510.26406](http://arxiv.org/abs/2510.26406)|null|
|**2025-10-30**|**Beyond Imitation: Constraint-Aware Trajectory Generation with Flow Matching For End-to-End Autonomous Driving**|Yandan Luo Team|[2510.26292](http://arxiv.org/abs/2510.26292)|null|
|**2025-10-30**|**Learning to Manage Investment Portfolios beyond Simple Utility Functions**|J. Doyne Farmer Team|[2510.26165](http://arxiv.org/abs/2510.26165)|null|
|**2025-10-28**|**A Humanoid Visual-Tactile-Action Dataset for Contact-Rich Manipulation**|Kyung-Joong Kim Team|[2510.25725](http://arxiv.org/abs/2510.25725)|null|
|**2025-10-29**|**Sim-to-Real Gentle Manipulation of Deformable and Fragile Objects with Stress-Guided Reinforcement Learning**|Florian T. Pokorny Team|[2510.25405](http://arxiv.org/abs/2510.25405)|null|
|**2025-10-29**|**SynHLMA:Synthesizing Hand Language Manipulation for Articulated Object with Discrete Human Object Interaction Representation**|Dan Guo Team|[2510.25268](http://arxiv.org/abs/2510.25268)|null|
|**2025-10-29**|**Time-Optimal Transport of Loosely Placed Liquid Filled Cups along Prescribed Paths**|Andreas Mueller Team|[2510.25255](http://arxiv.org/abs/2510.25255)|null|
|**2025-10-29**|**Hybrid Vision Servoing with Depp Alignment and GRU-Based Occlusion Recovery**|Jongseong Brad Choi Team|[2510.25233](http://arxiv.org/abs/2510.25233)|null|
|**2025-10-29**|**Learning Spatial-Aware Manipulation Ordering**|Jian Pu Team|[2510.25138](http://arxiv.org/abs/2510.25138)|null|
|**2025-10-29**|**NanoVLA: Routing Decoupled Vision-Language Understanding for Nano-sized Generalist Robotic Policies**|Jinghui Lu Team|[2510.25122](http://arxiv.org/abs/2510.25122)|null|
|**2025-10-28**|**Fare: Failure Resilience in Learned Visual Navigation Control**|David Hsu Team|[2510.24680](http://arxiv.org/abs/2510.24680)|null|
|**2025-10-28**|**Advancing site-specific disease and pest management in precision agriculture: From reasoning-driven foundation models to adaptive, feedback-based learning**|Arnold W. Schumann Team|[2510.24650](http://arxiv.org/abs/2510.24650)|null|
|**2025-10-28**|**DynaRend: Learning 3D Dynamics via Masked Future Rendering for Robotic Manipulation**|Gang Hua Team|[2510.24261](http://arxiv.org/abs/2510.24261)|null|
|**2025-10-28**|**Manipulate as Human: Learning Task-oriented Manipulation Skills by Adversarial Motion Priors**|Yue Gao Team|[2510.24257](http://arxiv.org/abs/2510.24257)|null|
|**2025-10-28**|**Blindfolded Experts Generalize Better: Insights from Robotic Manipulation and Videogames**|Aviv Tamar Team|[2510.24194](http://arxiv.org/abs/2510.24194)|null|
|**2025-10-28**|**PFEA: An LLM-based High-Level Natural Language Planning and Feedback Embodied Agent for Human-Centered AI**|Philip Dames Team|[2510.24109](http://arxiv.org/abs/2510.24109)|null|
|**2025-10-28**|**ZTRS: Zero-Imitation End-to-end Autonomous Driving with Trajectory Scoring**|Jose M. Alvarez Team|[2510.24108](http://arxiv.org/abs/2510.24108)|null|
|**2025-10-28**|**Learning Parameterized Skills from Demonstrations**|George Konidaris Team|[2510.24095](http://arxiv.org/abs/2510.24095)|null|
|**2025-10-28**|**Language-Conditioned Representations and Mixture-of-Experts Policy for Robust Multi-Task Robotic Manipulation**|Jiashuo Bai Team|[2510.24055](http://arxiv.org/abs/2510.24055)|null|
|**2025-10-27**|**Adaptive Keyframe Selection for Scalable 3D Scene Reconstruction in Dynamic Environments**|Giuseppe Loianno Team|[2510.23928](http://arxiv.org/abs/2510.23928)|null|
|**2025-10-29**|**RoboOmni: Proactive Robot Manipulation in Omni-modal Context**|Xipeng Qiu Team|[2510.23763](http://arxiv.org/abs/2510.23763)|null|
|**2025-10-27**|**RobotArena $\infty$ : Scalable Robot Benchmarking via Real-to-Sim Translation**|Katerina Fragkiadaki Team|[2510.23571](http://arxiv.org/abs/2510.23571)|**[link](https://robotarenainf.github.io)**|
|**2025-10-27**|**Optimal Dimensioning of Elastic-Link Manipulators regarding Lifetime Estimation**|Andreas Mueller Team|[2510.23234](http://arxiv.org/abs/2510.23234)|null|
|**2025-10-27**|**Workspace Registration and Collision Detection for Industrial Robotics Applications**|Andreas Mueller Team|[2510.23227](http://arxiv.org/abs/2510.23227)|null|
|**2025-10-27**|**Finding 3D Scene Analogies with Multimodal Foundation Models**|Young Min Kim Team|[2510.23184](http://arxiv.org/abs/2510.23184)|null|
|**2025-10-27**|**ManiDP: Manipulability-Aware Diffusion Policy for Posture-Dependent Bimanual Manipulation**|Fei Chen Team|[2510.23016](http://arxiv.org/abs/2510.23016)|null|
|**2025-10-26**|**Learning Neural Observer-Predictor Models for Limb-level Sampling-based Locomotion Planning**|Guoquan Huang Team|[2510.22789](http://arxiv.org/abs/2510.22789)|null|
|**2025-10-26**|**Edge Collaborative Gaussian Splatting with Integrated Rendering and Communication**|Chengzhong Xu Team|[2510.22718](http://arxiv.org/abs/2510.22718)|null|
|**2025-10-26**|**FastVLM: Self-Speculative Decoding for Fast Vision-Language Model Inference**|Manjesh Kumar Hanawal Team|[2510.22641](http://arxiv.org/abs/2510.22641)|null|
|**2025-10-25**|**A Novel Multi-Timescale Stability-Preserving Hierarchical Reinforcement Learning Controller Framework for Adaptive Control in High-Dimensional Dynamical Systems**|Benyamin Safizadeh Team|[2510.22420](http://arxiv.org/abs/2510.22420)|null|
|**2025-10-25**|**ACG: Action Coherence Guidance for Flow-based VLA models**|Jaegul Choo Team|[2510.22201](http://arxiv.org/abs/2510.22201)|null|
|**2025-10-25**|**RaycastGrasp: Eye-Gaze Interaction with Wearable Devices for Robotic Manipulation**|Yang Ye Team|[2510.22113](http://arxiv.org/abs/2510.22113)|null|
|**2025-10-24**|**Two-Steps Diffusion Policy for Robotic Manipulation via Genetic Denoising**|Yinchuan Li Team|[2510.21991](http://arxiv.org/abs/2510.21991)|null|
|**2025-10-27**|**On Uncertainty Calibration for Equivariant Functions**|Robin Walters Team|[2510.21691](http://arxiv.org/abs/2510.21691)|**[link](https://github.com/EdwardBerman/EquiUQ)**|
|**2025-10-24**|**Enhancing Tactile-based Reinforcement Learning for Robotic Control**|Sethu Vijayakumar Team|[2510.21609](http://arxiv.org/abs/2510.21609)|null|
|**2025-10-24**|**Scalable Vision-Language-Action Model Pretraining for Robotic Manipulation with Real-Life Human Activity Videos**|Baining Guo Team|[2510.21571](http://arxiv.org/abs/2510.21571)|**[link](https://microsoft.github.io/VITRA/)**|
|**2025-10-24**|**Learning Neural Control Barrier Functions from Expert Demonstrations using Inverse Constraint Learning**|Hussein Sibai Team|[2510.21560](http://arxiv.org/abs/2510.21560)|null|
|**2025-10-24**|**Generalizable Hierarchical Skill Learning via Object-Centric Representation**|Robert Platt Team|[2510.21121](http://arxiv.org/abs/2510.21121)|null|
|**2025-10-23**|**BioDet: Boosting Industrial Object Detection with Image Preprocessing Strategies**|Benjamin Busam Team|[2510.21000](http://arxiv.org/abs/2510.21000)|null|
|**2025-10-23**|**SutureBot: A Precision Framework & Benchmark For Autonomous End-to-End Suturing**|Axel Krieger Team|[2510.20965](http://arxiv.org/abs/2510.20965)|null|
|**2025-10-23**|**GSWorld: Closed-Loop Photo-Realistic Simulation Suite for Robotic Manipulation**|Xiaolong Wang Team|[2510.20813](http://arxiv.org/abs/2510.20813)|null|
|**2025-10-23**|**FieldGen: From Teleoperated Pre-Manipulation Trajectories to Field-Guided Data Generation**|Yao Mu Team|[2510.20774](http://arxiv.org/abs/2510.20774)|**[link](https://fieldgen.github.io/)**|
|**2025-10-23**|**A Parameter-Linear Formulation of the Optimal Path Following Problem for Robotic Manipulator**|Andreas Mueller Team|[2510.20496](http://arxiv.org/abs/2510.20496)|null|
|**2025-10-23**|**Dual Control Reference Generation for Optimal Pick-and-Place Execution under Payload Uncertainty**|Tom Lefebvre Team|[2510.20483](http://arxiv.org/abs/2510.20483)|null|
|**2025-10-23**|**PointMapPolicy: Structured Point Cloud Processing for Multi-Modal Imitation Learning**|Gerhard Neumann Team|[2510.20406](http://arxiv.org/abs/2510.20406)|null|
|**2025-10-23**|**NeuralTouch: Neural Descriptors for Precise Sim-to-Real Tactile Robot Control**|Nathan F. Lepora Team|[2510.20390](http://arxiv.org/abs/2510.20390)|null|
|**2025-10-23**|**MemER: Scaling Up Memory for Robot Control via Experience Retrieval**|Chelsea Finn Team|[2510.20328](http://arxiv.org/abs/2510.20328)|**[link](https://jen-pan.github.io/memer/)**|
|**2025-10-22**|**Approximate Model Predictive Control for Microgrid Energy Management via Imitation Learning**|Bart De Schutter Team|[2510.20040](http://arxiv.org/abs/2510.20040)|null|
|**2025-10-22**|**Seed3D 1.0: From Images to High-Fidelity Simulation-Ready 3D Assets**|Xuanmeng Zhang Team|[2510.19944](http://arxiv.org/abs/2510.19944)|**[link](https://seed.bytedance.com/seed3d)**|
|**2025-10-25**|**Using Non-Expert Data to Robustify Imitation Learning via Offline Reinforcement Learning**|Abhishek Gupta Team|[2510.19495](http://arxiv.org/abs/2510.19495)|null|
|**2025-10-22**|**Seeing Across Views: Benchmarking Spatial Reasoning of Vision-Language Models in Robotic Scenes**|Baining Guo Team|[2510.19400](http://arxiv.org/abs/2510.19400)|**[link](https://github.com/microsoft/MV-RoboBench)**|
|**2025-10-22**|**Using Temperature Sampling to Effectively Train Robot Learning Policies on Imbalanced Datasets**|Bernadette Bucher Team|[2510.19373](http://arxiv.org/abs/2510.19373)|null|
|**2025-10-22**|**Imitation Learning Policy based on Multi-Step Consistent Integration Shortcut Model**|Jie Zhao Team|[2510.19356](http://arxiv.org/abs/2510.19356)|null|
|**2025-10-22**|**Unified Reinforcement and Imitation Learning for Vision-Language Models**|Yueh-Hua Wu Team|[2510.19307](http://arxiv.org/abs/2510.19307)|**[link](https://byungkwanlee.github.io/RIL-page)**|
|**2025-10-22**|**TARMAC: A Taxonomy for Robot Manipulation in Chemistry**|Jihong Zhu Team|[2510.19289](http://arxiv.org/abs/2510.19289)|null|
|**2025-10-21**|**A Cross-Environment and Cross-Embodiment Path Planning Framework via a Conditional Diffusion Model**|Homayoun Najjaran Team|[2510.19128](http://arxiv.org/abs/2510.19128)|null|
|**2025-10-21**|**Efficient Model-Based Reinforcement Learning for Robot Control via Online Learning**|Marco Hutter Team|[2510.18518](http://arxiv.org/abs/2510.18518)|null|
|**2025-10-23**|**MoTVLA: A Vision-Language-Action Model with Unified Fast-Slow Reasoning**|Heng Yang Team|[2510.18337](http://arxiv.org/abs/2510.18337)|null|
|**2025-10-21**|**MoMaGen: Generating Demonstrations under Soft and Hard Constraints for Multi-Step Bimanual Mobile Manipulation**|Li Fei-Fei Team|[2510.18316](http://arxiv.org/abs/2510.18316)|null|
|**2025-10-20**|**Quality Over Quantity: Curating Contact-Based Robot Datasets Improves Learning**|Ian Abraham Team|[2510.18137](http://arxiv.org/abs/2510.18137)|null|
|**2025-10-20**|**R2BC: Multi-Agent Imitation Learning from Single-Agent Demonstrations**|Daniel S. Brown Team|[2510.18085](http://arxiv.org/abs/2510.18085)|null|
|**2025-10-20**|**SPACeR: Self-Play Anchoring with Centralized Reference Models**|Wei Zhan Team|[2510.18060](http://arxiv.org/abs/2510.18060)|**[link](https://spacer-ai.github.io/)**|
|**2025-10-20**|**RESample: A Robust Data Augmentation Framework via Exploratory Sampling for Robotic Manipulation**|Ziwei Wang Team|[2510.17640](http://arxiv.org/abs/2510.17640)|null|
|**2025-10-20**|**Learned Inertial Odometry for Cycling Based on Mixture of Experts Algorithm**|Xiaoji Niu Team|[2510.17604](http://arxiv.org/abs/2510.17604)|null|
|**2025-10-20**|**Plasma Shape Control via Zero-shot Generative Reinforcement Learning**|Wulyu Zhong Team|[2510.17531](http://arxiv.org/abs/2510.17531)|null|
|**2025-10-20**|**A Generalization of Input-Output Linearization via Dynamic Switching Between Melds of Output Functions**|Antonio Franchi Team|[2510.17448](http://arxiv.org/abs/2510.17448)|null|
|**2025-10-22**|**OmniVIC: A Self-Improving Variable Impedance Controller with Vision-Language In-Context Learning for Safe Robotic Manipulation**|Arash Ajoudani Team|[2510.17150](http://arxiv.org/abs/2510.17150)|**[link](https://sites.google.com/view/omni-vic})**|
|**2025-10-20**|**Decentralized Real-Time Planning for Multi-UAV Cooperative Manipulation via Imitation Learning**|Sihao Sun Team|[2510.17143](http://arxiv.org/abs/2510.17143)|null|
|**2025-10-20**|**Learning to Design Soft Hands using Reward Models**|Sha Yi Team|[2510.17086](http://arxiv.org/abs/2510.17086)|null|
|**2025-10-19**|**End-to-end Listen, Look, Speak and Act**|Chao Zhang Team|[2510.16756](http://arxiv.org/abs/2510.16756)|null|
|**2025-10-18**|**MoS-VLA: A Vision-Language-Action Model with One-Shot Skill Adaptation**|Ufuk Topcu Team|[2510.16617](http://arxiv.org/abs/2510.16617)|null|
|**2025-10-18**|**Buzz, Choose, Forget: A Meta-Bandit Framework for Bee-Like Decision Making**|Jean-Michel Loubes Team|[2510.16462](http://arxiv.org/abs/2510.16462)|null|
|**2025-10-18**|**Learning to Optimize Edge Robotics: A Fast Integrated Perception-Motion-Communication Approach**|Chengzhong Xu Team|[2510.16424](http://arxiv.org/abs/2510.16424)|null|
|**2025-10-17**|**DeGrip: A Compact Cable-driven Robotic Gripper for Desktop Disassembly**|Minghui Zheng Team|[2510.16231](http://arxiv.org/abs/2510.16231)|null|
|**2025-10-17**|**DexCanvas: Bridging Human Demonstrations and Robot Learning for Dexterous Manipulation**|Yiwen Lu Team|[2510.15786](http://arxiv.org/abs/2510.15786)|null|
|**2025-10-22**|**VO-DP: Semantic-Geometric Adaptive Diffusion Policy for Vision-Only Robotic Manipulation**|Bin He Team|[2510.15530](http://arxiv.org/abs/2510.15530)|null|
|**2025-10-17**|**Exploring Conditions for Diffusion models in Robotic Control**|Taekyung Kim Team|[2510.15510](http://arxiv.org/abs/2510.15510)|**[link](https://orca-rc.github.io/)**|
|**2025-10-17**|**Perfect Prediction or Plenty of Proposals? What Matters Most in Planning for Autonomous Driving**|Joschka Boedecker Team|[2510.15505](http://arxiv.org/abs/2510.15505)|null|
|**2025-10-17**|**Learning to Answer from Correct Demonstrations**|Nathan Srebro Team|[2510.15464](http://arxiv.org/abs/2510.15464)|null|
|**2025-10-17**|**GaussGym: An open-source real-to-sim framework for learning locomotion from pixels**|Pieter Abbeel Team|[2510.15352](http://arxiv.org/abs/2510.15352)|null|
|**2025-10-16**|**RM-RL: Role-Model Reinforcement Learning for Precise Robot Manipulation**|Jianfei Yang Team|[2510.15189](http://arxiv.org/abs/2510.15189)|null|
|**2025-10-18**|**VT-Refine: Learning Bimanual Assembly with Visuo-Tactile Feedback via Simulation Fine-Tuning**|Yunzhu Li Team|[2510.14930](http://arxiv.org/abs/2510.14930)|**[link](https://binghao-huang.github.io/vt_refine/)**|
|**2025-10-16**|**SADCHER: Scheduling using Attention-based Dynamic Coalitions of Heterogeneous Robots in Real-Time**|Javier Alonso-Mora Team|[2510.14851](http://arxiv.org/abs/2510.14851)|**[link](https://autonomousrobots.nl/paper_websites/sadcher_MRTA/)**|
|**2025-10-16**|**RL-100: Performant Robotic Manipulation with Real-World Reinforcement Learning**|Huazhe Xu Team|[2510.14830](http://arxiv.org/abs/2510.14830)|**[link](https://lei-kun.github.io/RL-100/)**|
|**2025-10-16**|**Open TeleDex: A Hardware-Agnostic Teleoperation System for Imitation Learning based Dexterous Manipulation**|Shan An Team|[2510.14771](http://arxiv.org/abs/2510.14771)|null|
|**2025-10-16**|**Accelerated Multi-Modal Motion Planning Using Context-Conditioned Diffusion Models**|Wilm Decré Team|[2510.14615](http://arxiv.org/abs/2510.14615)|null|
|**2025-10-16**|**Restoring Noisy Demonstration for Imitation Learning With Diffusion Models**|Shao-Hua Sun Team|[2510.14467](http://arxiv.org/abs/2510.14467)|null|
|**2025-10-16**|**Expertise need not monopolize: Action-Specialized Mixture of Experts for Vision-Language-Action Learning**|Yao Mu Team|[2510.14300](http://arxiv.org/abs/2510.14300)|null|
|**2025-10-15**|**ViTacGen: Robotic Pushing with Vision-to-Touch Generation**|Shan Luo Team|[2510.14117](http://arxiv.org/abs/2510.14117)|null|
|**2025-10-15**|**Optimistic Reinforcement Learning-Based Skill Insertions for Task and Motion Planning**|Bram Vanderborght Team|[2510.14065](http://arxiv.org/abs/2510.14065)|null|
|**2025-10-17**|**CausalVerse: Benchmarking Causal Representation Learning with Configurable High-Fidelity Simulations**|Kun Zhang Team|[2510.14049](http://arxiv.org/abs/2510.14049)|null|
|**2025-10-15**|**LIBERO-Plus: In-depth Robustness Analysis of Vision-Language-Action Models**|Xipeng Qiu Team|[2510.13626](http://arxiv.org/abs/2510.13626)|null|
|**2025-10-15**|**Efficient Force and Stiffness Prediction in Robotic Produce Handling with a Piezoresistive Pressure Sensor**|Xiaobo Tan Team|[2510.13616](http://arxiv.org/abs/2510.13616)|**[link](https://drive.google.com/drive/folders/1jol-_z6gaUfjpL1Qi7EG420usTbVSodv?usp=sharing)**|
|**2025-10-15**|**Active Tactile Exploration for Rigid Body Pose and Shape Estimation**|Michael Posa Team|[2510.13595](http://arxiv.org/abs/2510.13595)|null|
|**2025-10-15**|**Tactile-Conditioned Diffusion Policy for Force-Aware Robotic Manipulation**|Jan Peters Team|[2510.13324](http://arxiv.org/abs/2510.13324)|null|
|**2025-10-15**|**Model-agnostic Adversarial Attack and Defense for Vision-Language-Action Models**|Jingfeng Zhang Team|[2510.13237](http://arxiv.org/abs/2510.13237)|null|
|**2025-10-15**|**Beyond Static LLM Policies: Imitation-Enhanced Reinforcement Learning for Recommendation**|Sen Wang Team|[2510.13229](http://arxiv.org/abs/2510.13229)|null|
|**2025-10-15**|**VLA-0: Building State-of-the-Art VLAs with Zero Modification**|Fabio Ramos Team|[2510.13054](http://arxiv.org/abs/2510.13054)|null|
|**2025-10-14**|**Development of a Linear Guide-Rail Testbed for Physically Emulating ISAM Operations**|Christopher Petersen Team|[2510.13005](http://arxiv.org/abs/2510.13005)|null|
|**2025-10-14**|**Actron3D: Learning Actionable Neural Functions from Videos for Transferable Robotic Manipulation**|Stefan Leutenegger Team|[2510.12971](http://arxiv.org/abs/2510.12971)|null|
|**2025-10-14**|**Learning to Grasp Anything by Playing with Random Toys**|Roei Herzig Team|[2510.12866](http://arxiv.org/abs/2510.12866)|null|
|**2025-10-14**|**CoIRL-AD: Collaborative-Competitive Imitation-Reinforcement Learning in Latent World Models for Autonomous Driving**|Jiangtao Gong Team|[2510.12560](http://arxiv.org/abs/2510.12560)|null|
|**2025-10-14**|**Automated Behavior Planning for Fruit Tree Pruning via Redundant Robot Manipulators: Addressing the Behavior Planning Challenge**|Bram Vanderborght Team|[2510.12509](http://arxiv.org/abs/2510.12509)|null|
|**2025-10-14**|**Fast Visuomotor Policy for Robotic Manipulation**|Wenqiang Zhang Team|[2510.12483](http://arxiv.org/abs/2510.12483)|null|
|**2025-10-14**|**Robot Learning: A Tutorial**|Michel Aractingi Team|[2510.12403](http://arxiv.org/abs/2510.12403)|null|
|**2025-10-14**|**Improving Generative Behavior Cloning via Self-Guidance and Adaptive Chunking**|Eunhyeok Park Team|[2510.12392](http://arxiv.org/abs/2510.12392)|null|
|**2025-10-14**|**Learning Social Navigation from Positive and Negative Demonstrations and Rule-Based Specifications**|Sungjoon Choi Team|[2510.12215](http://arxiv.org/abs/2510.12215)|**[link](https://chanwookim971024.github.io/PioneeR/)**|
|**2025-10-13**|**Phys2Real: Fusing VLM Priors with Interactive Online Adaptation for Uncertainty-Aware Sim-to-Real Manipulation**|Mac Schwager Team|[2510.11689](http://arxiv.org/abs/2510.11689)|null|
|**2025-10-14**|**ManiAgent: An Agentic Framework for General Robotic Manipulation**|Xudong Liu Team|[2510.11660](http://arxiv.org/abs/2510.11660)|null|
|**2025-10-13**|**HiMaCon: Discovering Hierarchical Manipulation Concepts from Unlabeled Multi-Modal Data**|Yanchao Yang Team|[2510.11321](http://arxiv.org/abs/2510.11321)|null|
|**2025-10-13**|**FOSSIL: Harnessing Feedback on Suboptimal Samples for Data-Efficient Generalisation with Imitation Learning for Embodied Vision-and-Language Tasks**|Alessandro Suglia Team|[2510.11307](http://arxiv.org/abs/2510.11307)|null|
|**2025-10-13**|**DemoHLM: From One Demonstration to Generalizable Humanoid Loco-Manipulation**|Zongqing Lu Team|[2510.11258](http://arxiv.org/abs/2510.11258)|null|
|**2025-10-13**|**Flow Matching-Based Autonomous Driving Planning with Advanced Interactive Behavior Modeling**|Jingjing Liu Team|[2510.11083](http://arxiv.org/abs/2510.11083)|null|
|**2025-10-13**|**Towards a Unified Understanding of Robot Manipulation: A Comprehensive Survey**|Badong Chen Team|[2510.10903](http://arxiv.org/abs/2510.10903)|null|
|**2025-10-12**|**High-Fidelity Simulated Data Generation for Real-World Zero-Shot Robotic Manipulation Learning with Gaussian Splatting**|Hua Zou Team|[2510.10637](http://arxiv.org/abs/2510.10637)|null|
|**2025-10-12**|**Population-Coded Spiking Neural Networks for High-Dimensional Robotic Control**|Jeethu Sreenivas Amuthan Team|[2510.10516](http://arxiv.org/abs/2510.10516)|null|
|**2025-10-12**|**Data-driven simulator of multi-animal behavior with unknown dynamics via offline and online reinforcement learning**|Yoshinobu Kawahara Team|[2510.10451](http://arxiv.org/abs/2510.10451)|null|
|**2025-10-11**|**X-VLA: Soft-Prompted Transformer as Scalable Cross-Embodiment Vision-Language-Action Model**|Xianyuan Zhan Team|[2510.10274](http://arxiv.org/abs/2510.10274)|null|
|**2025-10-11**|**A3RNN: Bi-directional Fusion of Bottom-up and Top-down Process for Developmental Visual Attention in Robots**|Tetsuya Ogata Team|[2510.10221](http://arxiv.org/abs/2510.10221)|null|
|**2025-10-11**|**UF-RNN: Real-Time Adaptive Motion Generation Using Uncertainty-Driven Foresight Prediction**|Tetsuya Ogata Team|[2510.10217](http://arxiv.org/abs/2510.10217)|null|
|**2025-10-15**|**Ctrl-World: A Controllable Generative World Model for Robot Manipulation**|Chelsea Finn Team|[2510.10125](http://arxiv.org/abs/2510.10125)|null|
|**2025-10-10**|**VITA-VLA: Efficiently Teaching Vision-Language Models to Act via Action Expert Distillation**|Caifeng Shan Team|[2510.09607](http://arxiv.org/abs/2510.09607)|**[link](https://ltbai.github.io/VITA-VLA/)**|
|**2025-10-13**|**Guiding Energy-Efficient Locomotion through Impact Mitigation Rewards**|Alireza Ramezani Team|[2510.09543](http://arxiv.org/abs/2510.09543)|null|
|**2025-10-10**|**Autonomous Soft Robotic Guidewire Navigation via Imitation Learning**|Axel Krieger Team|[2510.09497](http://arxiv.org/abs/2510.09497)|null|
|**2025-10-13**|**Near-Optimal Second-Order Guarantees for Model-Based Adversarial Imitation Learning**|Weitong Zhang Team|[2510.09487](http://arxiv.org/abs/2510.09487)|null|
|**2025-10-13**|**Failure Prediction at Runtime for Generative Robot Policies**|Angela P. Schoellig Team|[2510.09459](http://arxiv.org/abs/2510.09459)|**[link](https://tum-lsy.github.io/fiper_website.)**|
|**2025-10-10**|**Rate optimal learning of equilibria from data**|Giorgia Ramponi Team|[2510.09325](http://arxiv.org/abs/2510.09325)|null|
|**2025-10-10**|**Glovity: Learning Dexterous Contact-Rich Manipulation via Spatial Wrench Feedback Teleoperation System**|Pai Zheng Team|[2510.09229](http://arxiv.org/abs/2510.09229)|null|
|**2025-10-10**|**FM-IRL: Flow-Matching for Reward Modeling and Policy Regularization in Reinforcement Learning**|Ivor Tsang Team|[2510.09222](http://arxiv.org/abs/2510.09222)|null|
|**2025-10-10**|**When a Robot is More Capable than a Human: Learning from Constrained Demonstrators**|Erdem Bıyık Team|[2510.09096](http://arxiv.org/abs/2510.09096)|null|
|**2025-10-10**|**iMoWM: Taming Interactive Multi-Modal World Model for Robotic Manipulation**|Ziwei Wang Team|[2510.09036](http://arxiv.org/abs/2510.09036)|null|
|**2025-10-09**|**Humanoid Everyday: A Comprehensive Robotic Dataset for Open-World Humanoid Manipulation**|Yue Wang Team|[2510.08807](http://arxiv.org/abs/2510.08807)|null|
|**2025-10-09**|**Geometry-aware Policy Imitation**|Sylvain Calinon Team|[2510.08787](http://arxiv.org/abs/2510.08787)|null|
|**2025-10-09**|**Point and Go: Intuitive Reference Frame Reallocation in Mode Switching for Assistive Robotics**|M. Jagersand Team|[2510.08753](http://arxiv.org/abs/2510.08753)|null|
|**2025-10-09**|**Agent Learning via Early Experience**|Yifan Wu Team|[2510.08558](http://arxiv.org/abs/2510.08558)|null|
|**2025-10-09**|**R2RGEN: Real-to-Real 3D Data Generation for Spatially Generalized Manipulation**|Jiwen Lu Team|[2510.08547](http://arxiv.org/abs/2510.08547)|**[link](https://r2rgen.github.io/)**|
|**2025-10-09**|**Unlocking 3D Affordance Segmentation with 2D Semantic Knowledge**|Wei Shen Team|[2510.08316](http://arxiv.org/abs/2510.08316)|null|
|**2025-10-09**|**FastUMI-100K: Advancing Data-driven Robotic Manipulation with a Large-scale UMI-style Dataset**|Xuelong Li Team|[2510.08022](http://arxiv.org/abs/2510.08022)|null|
|**2025-10-09**|**DM1: MeanFlow with Dispersive Regularization for 1-Step Robotic Manipulation**|Weibing Li Team|[2510.07865](http://arxiv.org/abs/2510.07865)|**[link](https://guowei-zou.github.io/dm1/)**|
|**2025-10-09**|**Trajectory Conditioned Cross-embodiment Skill Transfer**|Bin Zhao Team|[2510.07773](http://arxiv.org/abs/2510.07773)|null|
|**2025-10-11**|**Differentiable Particle Optimization for Fast Sequential Manipulation**|Zachary Kingston Team|[2510.07674](http://arxiv.org/abs/2510.07674)|null|
|**2025-10-08**|**WristWorld: Generating Wrist-Views via 4D World Models for Robotic Manipulation**|Shanghang Zhang Team|[2510.07313](http://arxiv.org/abs/2510.07313)|null|
|**2025-10-09**|**TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics**|Shanghang Zhang Team|[2510.07181](http://arxiv.org/abs/2510.07181)|null|
|**2025-10-08**|**DecompGAIL: Learning Realistic Traffic Behaviors with Decomposed Multi-Agent Generative Adversarial Imitation Learning**|Chen Lv Team|[2510.06913](http://arxiv.org/abs/2510.06913)|null|
|**2025-10-07**|**Webscale-RL: Automated Data Pipeline for Scaling RL Data to Pretraining Levels**|Weiran Yao Team|[2510.06499](http://arxiv.org/abs/2510.06499)|null|
|**2025-10-07**|**EmbodiedCoder: Parameterized Embodied Mobile Manipulation via Modern Coding Model**|Zhaoxiang Zhang Team|[2510.06207](http://arxiv.org/abs/2510.06207)|**[link](https://anonymous.4open.science/w/Embodied-Coder/)**|
|**2025-10-07**|**Differentiable Model Predictive Control on the GPU**|Thomas Lew Team|[2510.06179](http://arxiv.org/abs/2510.06179)|null|
|**2025-10-07**|**Towards Autonomous Tape Handling for Robotic Wound Redressing**|Michael Yip Team|[2510.06127](http://arxiv.org/abs/2510.06127)|null|
|**2025-10-07**|**Learning to Crawl: Latent Model-Based Reinforcement Learning for Soft Robotic Adaptive Locomotion**|Robin Chhabra Team|[2510.05957](http://arxiv.org/abs/2510.05957)|null|
|**2025-10-07**|**VCoT-Grasp: Grasp Foundation Models with Visual Chain-of-Thought Reasoning for Language-driven Grasp Generation**|Badong Chen Team|[2510.05827](http://arxiv.org/abs/2510.05827)|null|
|**2025-10-07**|**DeLTa: Demonstration and Language-Guided Novel Transparent Object Manipulation**|Kuk-Jin Yoon Team|[2510.05662](http://arxiv.org/abs/2510.05662)|**[link](https://sites.google.com/view/DeLTa25/)**|
|**2025-10-07**|**Teaching Machines to Speak Using Articulatory Control**|Gopala Anumanchipalli Team|[2510.05619](http://arxiv.org/abs/2510.05619)|null|
|**2025-10-07**|**Correlation-Aware Dual-View Pose and Velocity Estimation for Dynamic Robotic Manipulation**|Farrokh Janabi-Sharifi Team|[2510.05536](http://arxiv.org/abs/2510.05536)|null|
|**2025-10-06**|**VER: Vision Expert Transformer for Robot Learning via Foundation Distillation and Dynamic Routing**|Masayoshi Tomizuka Team|[2510.05213](http://arxiv.org/abs/2510.05213)|null|
|**2025-10-06**|**Curiosity-Driven Co-Development of Action and Language in Robots Through Self-Exploration**|Jun Tani Team|[2510.05013](http://arxiv.org/abs/2510.05013)|null|
|**2025-10-06**|**Hands-Free Heritage: Automated 3D Scanning for Cultural Heritage Digitization**|Arianna Traviglia Team|[2510.04781](http://arxiv.org/abs/2510.04781)|null|
|**2025-10-06**|**MobRT: A Digital Twin-Based Framework for Scalable Learning in Mobile Manipulation**|Wenjie Song Team|[2510.04592](http://arxiv.org/abs/2510.04592)|null|
|**2025-10-05**|**Reliable and Scalable Robot Policy Evaluation with Imperfect Simulators**|Anirudha Majumdar Team|[2510.04354](http://arxiv.org/abs/2510.04354)|null|
|**2025-10-05**|**RAP: 3D Rasterization Augmented End-to-End Planning**|Alexandre Alahi Team|[2510.04333](http://arxiv.org/abs/2510.04333)|null|
|**2025-10-04**|**NoTVLA: Narrowing of Dense Action Trajectories for Generalizable Robot Manipulation**|Chunhua Shen Team|[2510.03895](http://arxiv.org/abs/2510.03895)|null|
|**2025-10-04**|**EmbodiSwap for Zero-Shot Robot Imitation Learning**|Yiannis Aloimonos Team|[2510.03706](http://arxiv.org/abs/2510.03706)|**[link](https://drive.google.com/file/d/1UccngwgPqUwPMhBja7JrXfZoTquCx_Qe/view?usp=sharing)**|
|**2025-10-04**|**Dissecting Larval Zebrafish Hunting using Deep Reinforcement Learning Trained RNN Agents**|Kanaka Rajan Team|[2510.03699](http://arxiv.org/abs/2510.03699)|null|
|**2025-10-04**|**Learning to Act Through Contact: A Unified View of Multi-Task Robot Learning**|Majid Khadiv Team|[2510.03599](http://arxiv.org/abs/2510.03599)|null|
|**2025-10-03**|**Warm-Starting Optimization-Based Motion Planning for Robotic Manipulators via Point Cloud-Conditioned Flow Matching**|Xiao Liang Team|[2510.03460](http://arxiv.org/abs/2510.03460)|null|
|**2025-10-03**|**Mask2IV: Interaction-Centric Video Generation via Mask Trajectories**|Laura Sevilla-Lara Team|[2510.03135](http://arxiv.org/abs/2510.03135)|**[link](https://reagan1311.github.io/mask2iv)**|
|**2025-10-03**|**Learning Stability Certificate for Robotics in Real-World Environments**|Zhe Shen Team|[2510.03123](http://arxiv.org/abs/2510.03123)|null|
|**2025-10-06**|**Distributional Inverse Reinforcement Learning**|Anqi Wu Team|[2510.03013](http://arxiv.org/abs/2510.03013)|null|
|**2025-10-03**|**Action Deviation-Aware Inference for Low-Latency Wireless Robots**|Seong-Lyun Kim Team|[2510.02851](http://arxiv.org/abs/2510.02851)|null|
|**2025-10-03**|**Flow with the Force Field: Learning 3D Compliant Flow Matching Policies from Force and Demonstration-Guided Simulation Data**|Nadia Figueroa Team|[2510.02738](http://arxiv.org/abs/2510.02738)|null|
|**2025-10-02**|**A Recipe for Efficient Sim-to-Real Transfer in Manipulation with Online Imitation-Pretrained World Models**|Hao Su Team|[2510.02538](http://arxiv.org/abs/2510.02538)|null|
|**2025-10-02**|**U-LAG: Uncertainty-Aware, Lag-Adaptive Goal Retargeting for Robotic Manipulation**|Anujith Muraleedharan Team|[2510.02526](http://arxiv.org/abs/2510.02526)|null|
|**2025-10-02**|**Beyond Imitation: Recovering Dense Rewards from Demonstrations**|Gholamreza Haffari Team|[2510.02493](http://arxiv.org/abs/2510.02493)|null|
|**2025-10-02**|**ARMADA: Autonomous Online Failure Detection and Human Shared Control Empower Scalable Real-world Deployment and Adaptation**|Cewu Lu Team|[2510.02298](http://arxiv.org/abs/2510.02298)|null|
|**2025-10-02**|**Do You Know Where Your Camera Is? View-Invariant Policy Learning with Camera Conditioning**|Matthew R. Walter Team|[2510.02268](http://arxiv.org/abs/2510.02268)|null|
|**2025-10-02**|**GRACE: A Language Model Framework for Explainable Inverse Reinforcement Learning**|Bogdan Mazoure Team|[2510.02180](http://arxiv.org/abs/2510.02180)|null|
|**2025-10-02**|**Fine-Tuning Flow Matching via Maximum Likelihood Estimation of Reconstructions**|Shihua Li Team|[2510.02081](http://arxiv.org/abs/2510.02081)|null|
|**2025-10-02**|**Contrastive Representation Regularization for Vision-Language-Action Models**|Jinwoo Shin Team|[2510.01711](http://arxiv.org/abs/2510.01711)|null|
|**2025-10-02**|**Symskill: Symbol and Skill Co-Invention for Data-Efficient and Real-Time Long-Horizon Manipulation**|Nadia Figueroa Team|[2510.01661](http://arxiv.org/abs/2510.01661)|**[link](https://sites.google.com/view/symskill))**|
|**2025-10-02**|**FailSafe: Reasoning and Recovery from Failures in Vision-Language-Action Models**|Bihan Wen Team|[2510.01642](http://arxiv.org/abs/2510.01642)|**[link](https://jimntu.github.io/FailSafe/)**|
|**2025-10-02**|**MIMIC: Integrating Diverse Personality Traits for Better Game Testing Using Large Language Model**|Lili Wei Team|[2510.01635](http://arxiv.org/abs/2510.01635)|null|
|**2025-10-02**|**ActiveUMI: Robotic Manipulation with Active Perception from Robot-Free Human Demonstrations**|Yi Xu Team|[2510.01607](http://arxiv.org/abs/2510.01607)|**[link](https://activeumi.github.io)**|
|**2025-10-02**|**MiniBEE: A New Form Factor for Compact Bimanual Dexterity**|Matei Ciocarlie Team|[2510.01603](http://arxiv.org/abs/2510.01603)|null|
|**2025-10-02**|**Predictive Preference Learning from Human Interventions**|Bolei Zhou Team|[2510.01545](http://arxiv.org/abs/2510.01545)|**[link](https://metadriverse.github.io/ppl)**|
|**2025-10-02**|**Information Seeking for Robust Decision Making under Partial Observability**|Tsung-Wei Ke Team|[2510.01531](http://arxiv.org/abs/2510.01531)|**[link](https://infoseekerllm.github.io)**|
|**2025-10-01**|**Online Hierarchical Policy Learning using Physics Priors for Robot Navigation in Unknown Environments**|Ahmed H. Qureshi Team|[2510.01519](http://arxiv.org/abs/2510.01519)|null|
|**2025-10-01**|**Density-Ratio Weighted Behavioral Cloning: Learning Control Policies from Corrupted Datasets**|Ali Baheri Team|[2510.01479](http://arxiv.org/abs/2510.01479)|null|
|**2025-10-01**|**AFFORD2ACT: Affordance-Guided Automatic Keypoint Selection for Generalizable and Lightweight Robotic Manipulation**|Pratap Tokekar Team|[2510.01433](http://arxiv.org/abs/2510.01433)|null|
|**2025-10-01**|**How Well do Diffusion Policies Learn Kinematic Constraint Manifolds?**|Russ Tedrake Team|[2510.01404](http://arxiv.org/abs/2510.01404)|**[link](https://diffusion-learns-kinematic.github.io)**|
|**2025-10-01**|**Temporal Score Rescaling for Temperature Sampling in Diffusion and Flow Models**|Shubham Tulsiani Team|[2510.01184](http://arxiv.org/abs/2510.01184)|null|
|**2025-10-01**|**Prometheus: Universal, Open-Source Mocap-Based Teleoperation System with Force Feedback for Dataset Collection in Robot Learning**|D. Tsetserukou Team|[2510.01023](http://arxiv.org/abs/2510.01023)|null|
|**2025-10-01**|**On Discovering Algorithms for Adversarial Imitation Learning**|Pradeep Varakantham Team|[2510.00922](http://arxiv.org/abs/2510.00922)|null|
|**2025-10-01**|**TubeDAgger: Reducing the Number of Expert Interventions with Stochastic Reach-Tubes**|Sophie A. Neubauer Team|[2510.00906](http://arxiv.org/abs/2510.00906)|null|
|**2025-09-30**|**MLA: A Multisensory Language-Action Model for Multimodal Understanding and Forecasting in Robotic Manipulation**|Shanghang Zhang Team|[2509.26642](http://arxiv.org/abs/2509.26642)|null|
|**2025-09-30**|**Learning from Hallucinating Critical Points for Navigation in Dynamic Environments**|Xuesu Xiao Team|[2509.26513](http://arxiv.org/abs/2509.26513)|null|
|**2025-09-30**|**Anomaly detection for generic failure monitoring in robotic assembly, screwing and manipulation**|Kevin Haninger Team|[2509.26308](http://arxiv.org/abs/2509.26308)|null|
|**2025-09-30**|**Noise-Guided Transport for Imitation Learning**|Alexandros Kalousis Team|[2509.26294](http://arxiv.org/abs/2509.26294)|null|
|**2025-09-30**|**Reinforced Embodied Planning with Verifiable Reward for Real-World Robotic Manipulation**|Hao Chen Team|[2509.25852](http://arxiv.org/abs/2509.25852)|null|
|**2025-10-01**|**Act to See, See to Act: Diffusion-Driven Perception-Action Interplay for Adaptive Policies**|Li Cheng Team|[2509.25822](http://arxiv.org/abs/2509.25822)|null|
|**2025-09-30**|**Point-It-Out: Benchmarking Embodied Reasoning for Vision Language Models in Multi-Stage Visual Grounding**|Jiaojiao Fan Team|[2509.25794](http://arxiv.org/abs/2509.25794)|null|
|**2025-09-30**|**SAC Flow: Sample-Efficient Reinforcement Learning of Flow-Based Policies via Velocity-Reparameterized Sequential Modeling**|Wenbo Ding Team|[2509.25756](http://arxiv.org/abs/2509.25756)|null|
|**2025-09-30**|**Best of Sim and Real: Decoupled Visuomotor Manipulation via Learning Control in Simulation and Perception in Real**|Yang Gao Team|[2509.25747](http://arxiv.org/abs/2509.25747)|null|
|**2025-09-29**|**Boolean Satisfiability via Imitation Learning**|Xiangyu Xu Team|[2509.25411](http://arxiv.org/abs/2509.25411)|null|
|**2025-09-29**|**Parallel Heuristic Search as Inference for Actor-Critic Reinforcement Learning Models**|Maxim Likhachev Team|[2509.25402](http://arxiv.org/abs/2509.25402)|null|
|**2025-09-29**|**SARM: Stage-Aware Reward Modeling for Long Horizon Robot Manipulation**|Philipp Wu Team|[2509.25358](http://arxiv.org/abs/2509.25358)|null|
|**2025-09-29**|**SRMP: Search-Based Robot Motion Planning Library**|Maxim Likhachev Team|[2509.25352](http://arxiv.org/abs/2509.25352)|null|
|**2025-10-01**|**Curriculum Imitation Learning of Distributed Multi-Robot Policies**|Eduardo Montijano Team|[2509.25097](http://arxiv.org/abs/2509.25097)|null|
|**2025-09-29**|**Annotation-Free One-Shot Imitation Learning for Multi-Step Manipulation Tasks**|Ruchi Choudhary Team|[2509.24972](http://arxiv.org/abs/2509.24972)|null|
|**2025-09-29**|**MSG: Multi-Stream Generative Policies for Sample-Efficient Robotic Manipulation**|Abhinav Valada Team|[2509.24956](http://arxiv.org/abs/2509.24956)|null|
|**2025-09-29**|**World-Env: Leveraging World Model as a Virtual Environment for VLA Post-Training**|Qing Zhang Team|[2509.24948](http://arxiv.org/abs/2509.24948)|null|
|**2025-09-29**|**From Code to Action: Hierarchical Learning of Diffusion-VLM Policies**|Daniel Dijkman Team|[2509.24917](http://arxiv.org/abs/2509.24917)|null|
|**2025-09-29**|**Quantifying Generalisation in Imitation Learning**|Odinaldo Rodrigues Team|[2509.24784](http://arxiv.org/abs/2509.24784)|null|
|**2025-09-29**|**IA-VLA: Input Augmentation for Vision-Language-Action models in settings with semantically complex tasks**|Ville Kyrki Team|[2509.24768](http://arxiv.org/abs/2509.24768)|null|
|**2025-09-29**|**Stabilizing Humanoid Robot Trajectory Generation via Physics-Informed Learning and Control-Informed Steering**|Daniele Pucci Team|[2509.24697](http://arxiv.org/abs/2509.24697)|null|
|**2025-09-29**|**CEDex: Cross-Embodiment Dexterous Grasp Generation at Scale from Human-like Contact Representations**|Shan Luo Team|[2509.24661](http://arxiv.org/abs/2509.24661)|null|
|**2025-09-29**|**U-DiT Policy: U-shaped Diffusion Transformers for Robotic Manipulation**|Zhongxue Gan Team|[2509.24579](http://arxiv.org/abs/2509.24579)|null|
|**2025-09-29**|**Unlocking the Potential of Soft Actor-Critic for Imitation Learning**|Frank Kirchner Team|[2509.24539](http://arxiv.org/abs/2509.24539)|null|
|**2025-09-29**|**Learning to Sample: Reinforcement Learning-Guided Sampling for Autonomous Vehicle Motion Planning**|Johannes Betz Team|[2509.24313](http://arxiv.org/abs/2509.24313)|null|
|**2025-09-29**|**FreeAction: Training-Free Techniques for Enhanced Fidelity of Trajectory-to-Video Generation**|Minsu Cho Team|[2509.24241](http://arxiv.org/abs/2509.24241)|null|
|**2025-09-29**|**ViReSkill: Vision-Grounded Replanning with Skill Memory for LLM-Based Planning in Lifelong Robot Learning**|Yang You Team|[2509.24219](http://arxiv.org/abs/2509.24219)|null|
|**2025-09-29**|**Preference-Based Long-Horizon Robotic Stacking with Multimodal Large Language Models**|Sethu Vijayakumar Team|[2509.24163](http://arxiv.org/abs/2509.24163)|null|
|**2025-09-29**|**Memory Transfer Planning: LLM-driven Context-Aware Code Adaptation for Robot Manipulation**|Yang You Team|[2509.24160](http://arxiv.org/abs/2509.24160)|null|
|**2025-09-28**|**Mash, Spread, Slice! Learning to Manipulate Object States via Visual Spatial Progress**|Kristen Grauman Team|[2509.24129](http://arxiv.org/abs/2509.24129)|null|
|**2025-09-28**|**DexFlyWheel: A Scalable and Self-improving Data Generation Framework for Dexterous Manipulation**|Yuanpei Chen Team|[2509.23829](http://arxiv.org/abs/2509.23829)|null|
|**2025-09-28**|**Control Your Robot: A Unified System for Robot Control and Policy Deployment**|Bingshan Hu Team|[2509.23823](http://arxiv.org/abs/2509.23823)|**[link](https://github.com/Tian-Nian/control_your_robot)**|
|**2025-09-30**|**Sequence Pathfinder for Multi-Agent Pickup and Delivery in the Warehouse**|Ying Wen Team|[2509.23778](http://arxiv.org/abs/2509.23778)|null|
|**2025-09-26**|**Pixel Motion Diffusion is What We Need for Robot Control**|Michael S. Ryoo Team|[2509.22652](http://arxiv.org/abs/2509.22652)|null|
|**2025-09-26**|**VLA-Reasoner: Empowering Vision-Language-Action Models with Reasoning via Online Monte Carlo Tree Search**|Ziwei Wang Team|[2509.22643](http://arxiv.org/abs/2509.22643)|null|
|**2025-09-26**|**Learn the Ropes, Then Trust the Wins: Self-imitation with Progressive Exploration for Agentic Reinforcement Learning**|Xing Sun Team|[2509.22601](http://arxiv.org/abs/2509.22601)|null|
|**2025-09-26**|**EgoDemoGen: Novel Egocentric Demonstration Generation Enables Viewpoint-Robust Manipulation**|Liang Wang Team|[2509.22578](http://arxiv.org/abs/2509.22578)|null|
|**2025-09-26**|**Learning to Ball: Composing Policies for Long-Horizon Basketball Moves**|C. Karen Liu Team|[2509.22442](http://arxiv.org/abs/2509.22442)|**[link](http://pei-xu.github.io/basketball.)**|
|**2025-09-26**|**EMMA: Generalizing Real-World Robot Manipulation via Generative Visual Transfer**|Guan Huang Team|[2509.22407](http://arxiv.org/abs/2509.22407)|null|
|**2025-09-26**|**ReLAM: Learning Anticipation Model for Rewarding Visual Robotic Manipulation**|Yang Yu Team|[2509.22402](http://arxiv.org/abs/2509.22402)|null|
|**2025-09-26**|**RoboView-Bias: Benchmarking Visual Bias in Embodied Agents for Robotic Manipulation**|Shuchao Pang Team|[2509.22356](http://arxiv.org/abs/2509.22356)|null|
|**2025-09-26**|**DemoGrasp: Universal Dexterous Grasping from a Single Demonstration**|Zongqing Lu Team|[2509.22149](http://arxiv.org/abs/2509.22149)|null|
|**2025-09-26**|**Action-aware Dynamic Pruning for Efficient Vision-Language-Action Manipulation**|Chang Xu Team|[2509.22093](http://arxiv.org/abs/2509.22093)|null|
|**2025-09-26**|**Teaching Transformers to Solve Combinatorial Problems through Efficient Trial & Error**|Christos Tzamos Team|[2509.22023](http://arxiv.org/abs/2509.22023)|null|
|**2025-09-26**|**WAVE: Worm Gear-based Adaptive Variable Elasticity for Decoupling Actuators from External Forces**|Kazutoshi Tanaka Team|[2509.21878](http://arxiv.org/abs/2509.21878)|null|
|**2025-09-26**|**Learning Multi-Skill Legged Locomotion Using Conditional Adversarial Motion Priors**|Qinchuan Li Team|[2509.21810](http://arxiv.org/abs/2509.21810)|null|
|**2025-09-26**|**The Turkish Ice Cream Robot: Examining Playful Deception in Social Human-Robot Interactions**|Matthew Pan Team|[2509.21776](http://arxiv.org/abs/2509.21776)|**[link](https://hyeonseong-kim98.github.io/turkish-ice-cream-robot/)**|
|**2025-09-25**|**Generating Stable Placements via Physics-guided Diffusion Models**|Jonathan Kelly Team|[2509.21664](http://arxiv.org/abs/2509.21664)|null|
|**2025-09-25**|**Inverse Reinforcement Learning Using Just Classification and a Few Regressions**|Aurélien Bibaut Team|[2509.21172](http://arxiv.org/abs/2509.21172)|null|
|**2025-09-25**|**ImaginationPolicy: Towards Generalizable, Precise and Reliable End-to-End Policy for Robotic Manipulation**|Kui Jia Team|[2509.20841](http://arxiv.org/abs/2509.20841)|**[link](https://sites.google.com/view/imaginationpolicy)**|
|**2025-09-25**|**Joint Flow Trajectory Optimization For Feasible Robot Motion Generation from Video Demonstrations**|Weiming Zhi Team|[2509.20703](http://arxiv.org/abs/2509.20703)|null|
|**2025-09-24**|**Large Pre-Trained Models for Bimanual Manipulation in 3D**|David Meger Team|[2509.20579](http://arxiv.org/abs/2509.20579)|null|
|**2025-09-24**|**Selective Progress-Aware Querying for Human-in-the-Loop Reinforcement Learning**|Anamika J H Team|[2509.20541](http://arxiv.org/abs/2509.20541)|null|
|**2025-09-26**|**mindmap: Spatial Memory in Deep Feature Maps for 3D Action Policies**|Shiwei Sheng Team|[2509.20297](http://arxiv.org/abs/2509.20297)|null|
|**2025-09-24**|**Discrete Diffusion for Reflective Vision-Language-Action Models in Autonomous Driving**|Xianpeng Lang Team|[2509.20109](http://arxiv.org/abs/2509.20109)|null|
|**2025-09-24**|**LLM Trainer: Automated Robotic Data Generating via Demonstration Augmentation using LLMs**|Amir Barati Farimani Team|[2509.20070](http://arxiv.org/abs/2509.20070)|null|
|**2025-09-25**|**Generalist Robot Manipulation beyond Action Labeled Data**|Danda Pani Paudel Team|[2509.19958](http://arxiv.org/abs/2509.19958)|null|
|**2025-09-24**|**SAGE:State-Aware Guided End-to-End Policy for Multi-Stage Sequential Tasks via Hidden Markov Decision Process**|JingYuan Wang Team|[2509.19853](http://arxiv.org/abs/2509.19853)|null|
|**2025-09-24**|**TopoCut: Learning Multi-Step Cutting with Spectral Rewards and Discrete Diffusion Policies**|Animesh Garg Team|[2509.19712](http://arxiv.org/abs/2509.19712)|null|
|**2025-09-24**|**RoboSSM: Scalable In-context Imitation Learning via State-Space Models**|Peter Stone Team|[2509.19658](http://arxiv.org/abs/2509.19658)|null|
|**2025-09-23**|**EgoBridge: Domain Adaptation for Generalizable Imitation from Egocentric Human Data**|Danfei Xu Team|[2509.19626](http://arxiv.org/abs/2509.19626)|null|
|**2025-09-23**|**From Space to Time: Enabling Adaptive Safety with Learned Value Functions via Disturbance Recasting**|Sylvia L. Herbert Team|[2509.19597](http://arxiv.org/abs/2509.19597)|null|
|**2025-09-23**|**Agentic Scene Policies: Unifying Space, Semantics, and Affordances for Robot Action**|Liam Paull Team|[2509.19571](http://arxiv.org/abs/2509.19571)|**[link](https://montrealrobotics.ca/agentic-scene-policies.github.io/)**|
|**2025-09-23**|**Score the Steps, Not Just the Goal: VLM-Based Subgoal Evaluation for Robotic Manipulation**|Chi-Guhn Lee Team|[2509.19524](http://arxiv.org/abs/2509.19524)|null|
|**2025-09-23**|**Self-evolved Imitation Learning in Simulated World**|Zhihe Lu Team|[2509.19460](http://arxiv.org/abs/2509.19460)|null|
|**2025-09-23**|**ROPA: Synthetic Robot Pose Generation for RGB-D Bimanual Data Augmentation**|Daniel Seita Team|[2509.19454](http://arxiv.org/abs/2509.19454)|null|
|**2025-09-23**|**SOE: Sample-Efficient Robot Policy Self-Improvement via On-Manifold Exploration**|Cewu Lu Team|[2509.19292](http://arxiv.org/abs/2509.19292)|null|
|**2025-09-23**|**Imitation-Guided Bimanual Planning for Stable Manipulation under Changing External Forces**|Arash Ajoudani Team|[2509.19261](http://arxiv.org/abs/2509.19261)|null|
|**2025-09-23**|**FUNCanon: Learning Pose-Aware Action Primitives via Functional Object Canonicalization for Generalizable Robotic Manipulation**|Jianwei Zhang Team|[2509.19102](http://arxiv.org/abs/2509.19102)|**[link](https://sites.google.com/view/funcanon)**|
|**2025-09-23**|**World4RL: Diffusion World Models for Policy Refinement with Reinforcement Learning for Robotic Manipulation**|Dongbin Zhao Team|[2509.19080](http://arxiv.org/abs/2509.19080)|null|
|**2025-09-23**|**ManipForce: Force-Guided Policy Learning with Frequency-Aware Representation for Contact-Rich Manipulation**|Kyoobin Lee Team|[2509.19047](http://arxiv.org/abs/2509.19047)|null|
|**2025-09-23**|**Eva-VLA: Evaluating Vision-Language-Action Models' Robustness Under Real-World Physical Variations**|Wen Yao Team|[2509.18953](http://arxiv.org/abs/2509.18953)|null|
|**2025-09-23**|**Bi-VLA: Bilateral Control-Based Imitation Learning via Vision-Language Fusion for Action Generation**|Thanpimon Buamanee Team|[2509.18865](http://arxiv.org/abs/2509.18865)|null|
|**2025-09-23**|**DexSkin: High-Coverage Conformable Robotic Skin for Learning Contact-Rich Manipulation**|Jiajun Wu Team|[2509.18830](http://arxiv.org/abs/2509.18830)|null|
|**2025-09-23**|**VGGT-DP: Generalizable Robot Control via Vision Foundation Models**|Zhi Wang Team|[2509.18778](http://arxiv.org/abs/2509.18778)|null|
|**2025-09-23**|**MV-UMI: A Scalable Multi-View Interface for Cross-Embodiment Learning**|Fares Abu-Dakka Team|[2509.18757](http://arxiv.org/abs/2509.18757)|**[link](https://mv-umi.github.io)**|
|**2025-09-23**|**Learning Obstacle Avoidance using Double DQN for Quadcopter Navigation**|Sanket Gujar Team|[2509.18734](http://arxiv.org/abs/2509.18734)|null|
|**2025-09-23**|**3D Flow Diffusion Policy: Visuomotor Policy Learning via Generating Flow in 3D Space**|Kyoobin Lee Team|[2509.18676](http://arxiv.org/abs/2509.18676)|null|
|**2025-09-24**|**Do You Need Proprioceptive States in Visuomotor Policies?**|Yang Gao Team|[2509.18644](http://arxiv.org/abs/2509.18644)|**[link](https://statefreepolicy.github.io)**|
|**2025-09-23**|**Generalizable Domain Adaptation for Sim-and-Real Policy Co-Training**|Danfei Xu Team|[2509.18631](http://arxiv.org/abs/2509.18631)|null|
|**2025-09-23**|**SINGER: An Onboard Generalist Vision-Language Navigation Policy for Drones**|Mac Schwager Team|[2509.18610](http://arxiv.org/abs/2509.18610)|null|
|**2025-09-23**|**Growing with Your Embodied Agent: A Human-in-the-Loop Lifelong Code Generation Framework for Long-Horizon Manipulation Skills**|Alois Knoll Team|[2509.18597](http://arxiv.org/abs/2509.18597)|null|
|**2025-09-23**|**A scaling law for large-deformation contact in soft materials**|Huajian Gao Team|[2509.18581](http://arxiv.org/abs/2509.18581)|null|
|**2025-09-22**|**Robotic Skill Diversification via Active Mutation of Reward Functions in Reinforcement Learning During a Liquid Pouring Task**|Luka Peternel Team|[2509.18463](http://arxiv.org/abs/2509.18463)|null|
|**2025-09-22**|**Learning Geometry-Aware Nonprehensile Pushing and Pulling with Dexterous Hands**|Daniel Seita Team|[2509.18455](http://arxiv.org/abs/2509.18455)|null|
|**2025-09-22**|**PrioriTouch: Adapting to User Contact Preferences for Whole-Arm Physical Human-Robot Interaction**|Tapomayukh Bhattacharjee Team|[2509.18447](http://arxiv.org/abs/2509.18447)|null|
|**2025-09-22**|**ByteWrist: A Parallel Robotic Wrist Enabling Flexible and Anthropomorphic Motion for Confined Spaces**|Zeyu Ren Team|[2509.18084](http://arxiv.org/abs/2509.18084)|**[link](https://bytewrist.github.io/)**|
|**2025-09-22**|**Prepare Before You Act: Learning From Humans to Rearrange Initial States**|Dylan P. Losey Team|[2509.18043](http://arxiv.org/abs/2509.18043)|null|
|**2025-09-22**|**FinFlowRL: An Imitation-Reinforcement Learning Framework for Adaptive Stochastic Control in Finance**|Ruixun Zhang Team|[2509.17964](http://arxiv.org/abs/2509.17964)|null|
|**2025-09-22**|**ComposableNav: Instruction-Following Navigation in Dynamic Environments via Composable Diffusion**|Joydeep Biswas Team|[2509.17941](http://arxiv.org/abs/2509.17941)|**[link](https://amrl.cs.utexas.edu/ComposableNav/)**|
|**2025-09-22**|**DriveDPO: Policy Learning via Safety DPO For End-to-End Autonomous Driving**|Zhaoxiang Zhang Team|[2509.17940](http://arxiv.org/abs/2509.17940)|null|
|**2025-09-23**|**RoboSeek: You Need to Interact with Your Objects**|Yatong Han Team|[2509.17783](http://arxiv.org/abs/2509.17783)|null|
|**2025-09-22**|**MotionTrans: Human VR Data Enable Motion-Level Learning for Robotic Manipulation Policies**|Yang Gao Team|[2509.17759](http://arxiv.org/abs/2509.17759)|null|
|**2025-09-22**|**EigenSafe: A Spectral Framework for Learning-Based Stochastic Safety Filtering**|H. Jin Kim Team|[2509.17750](http://arxiv.org/abs/2509.17750)|null|
|**2025-09-22**|**DINOv3-Diffusion Policy: Self-Supervised Large Visual Model for Visuomotor Diffusion Policy Learning**|Zidong Chen Team|[2509.17684](http://arxiv.org/abs/2509.17684)|null|
|**2025-09-22**|**Learning Dexterous Manipulation with Quantized Hand State**|Cewu Lu Team|[2509.17450](http://arxiv.org/abs/2509.17450)|null|
|**2025-09-22**|**Fast Trajectory Planner with a Reinforcement Learning-based Controller for Robotic Manipulators**|Hamidreza Kasaei Team|[2509.17381](http://arxiv.org/abs/2509.17381)|**[link](https://sites.google.com/view/ftp4rm/home)**|
|**2025-09-21**|**Scalable Multi Agent Diffusion Policies for Coverage Control**|Alejandro Ribeiro Team|[2509.17244](http://arxiv.org/abs/2509.17244)|null|
|**2025-09-21**|**Ratatouille: Imitation Learning Ingredients for Real-world Social Robot Navigation**|Timothy D. Barfoot Team|[2509.17204](http://arxiv.org/abs/2509.17204)|null|
|**2025-09-21**|**MAST: Multi-Agent Spatial Transformer for Learning to Collaborate**|Alejandro Ribeiro Team|[2509.17195](http://arxiv.org/abs/2509.17195)|null|
|**2025-09-21**|**Imagine2Act: Leveraging Object-Action Motion Consistency from Imagined Goals for Robotic Manipulation**|Hao Dong Team|[2509.17125](http://arxiv.org/abs/2509.17125)|null|
|**2025-09-21**|**RoboManipBaselines: A Unified Framework for Imitation Learning in Robotic Manipulation across Real and Simulated Environments**|Yukiyasu Domae Team|[2509.17057](http://arxiv.org/abs/2509.17057)|null|
|**2025-09-21**|**FILIC: Dual-Loop Force-Guided Imitation Learning with Impedance Torque Control for Contact-Rich Manipulation Tasks**|Guyue Zhou Team|[2509.17053](http://arxiv.org/abs/2509.17053)|null|
|**2025-09-21**|**Generalized Momenta-Based Koopman Formalism for Robust Control of Euler-Lagrangian Systems**|Jishnu Keshavan Team|[2509.17010](http://arxiv.org/abs/2509.17010)|null|
|**2025-09-21**|**End2Race: Efficient End-to-End Imitation Learning for Real-Time F1Tenth Racing**|Henry X. Liu Team|[2509.16894](http://arxiv.org/abs/2509.16894)|null|
|**2025-09-20**|**Robot Learning with Sparsity and Scarcity**|Jingxi Xu Team|[2509.16834](http://arxiv.org/abs/2509.16834)|null|
|**2025-09-19**|**Efficient Detection of Objects Near a Robot Manipulator via Miniature Time-of-Flight Sensors**|Michael Gleicher Team|[2509.16122](http://arxiv.org/abs/2509.16122)|null|
|**2025-09-19**|**I-FailSense: Towards General Robotic Failure Detection with Vision-Language Models**|Mohamed Chetouani Team|[2509.16072](http://arxiv.org/abs/2509.16072)|null|
|**2025-09-19**|**Compose by Focus: Scene Graph-based Atomic Skills**|Heng Yang Team|[2509.16053](http://arxiv.org/abs/2509.16053)|null|
|**2025-09-19**|**Learning Safety for Obstacle Avoidance via Control Barrier Functions**|Calin A. Belta Team|[2509.16037](http://arxiv.org/abs/2509.16037)|null|
|**2025-09-19**|**Improving Robotic Manipulation with Efficient Geometry-Aware Vision Encoder**|Ian Reid Team|[2509.15880](http://arxiv.org/abs/2509.15880)|**[link](https://evggt.github.io/)**|
|**2025-09-19**|**All-Electric Heavy-Duty Robotic Manipulator: Actuator Configuration Optimization and Sensorless Control**|Jouni Mattila Team|[2509.15778](http://arxiv.org/abs/2509.15778)|null|
|**2025-09-19**|**GP3: A 3D Geometry-Aware Policy with Multi-View Images for Robotic Manipulation**|Deli Zhao Team|[2509.15733](http://arxiv.org/abs/2509.15733)|null|
|**2025-09-19**|**Imagination at Inference: Synthesizing In-Hand Views for Robust Visuomotor Policy Inference**|Yoshihiko Nakamura Team|[2509.15717](http://arxiv.org/abs/2509.15717)|null|
|**2025-09-18**|**Implicit Kinodynamic Motion Retargeting for Human-to-humanoid Imitation Learning**|Haodong Zhang Team|[2509.15443](http://arxiv.org/abs/2509.15443)|null|
|**2025-09-18**|**RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation**|Xin Li Team|[2509.15212](http://arxiv.org/abs/2509.15212)|**[link](https://github.com/alibaba-damo-academy/RynnVLA-001)**|
|**2025-09-18**|**Self-Improving Embodied Foundation Models**|Igor Mordatch Team|[2509.15155](http://arxiv.org/abs/2509.15155)|null|
|**2025-09-18**|**A Nonlinear Scaling-based Design of Control Lyapunov-barrier Function for Relative Degree 2 Case and its Application to Safe Feedback Linearization**|Gyunghoon Park Team|[2509.15071](http://arxiv.org/abs/2509.15071)|null|
|**2025-09-18**|**Reinforcement Learning Agent for a 2D Shooter Game**|Hamza A. A. Gardi Team|[2509.15042](http://arxiv.org/abs/2509.15042)|null|
|**2025-09-19**|**Affordance-Based Disambiguation of Surgical Instructions for Collaborative Robot-Assisted Surgery**|Yasuhisa Hasegawa Team|[2509.14967](http://arxiv.org/abs/2509.14967)|null|
|**2025-09-18**|**Robot Control Stack: A Lean Ecosystem for Robot Learning at Scale**|Florian Walter Team|[2509.14932](http://arxiv.org/abs/2509.14932)|null|
|**2025-09-18**|**exUMI: Extensible Robot Teaching System with Action-aware Task-agnostic Tactile Representation**|Yong-Lu Li Team|[2509.14688](http://arxiv.org/abs/2509.14688)|null|
|**2025-09-18**|**SimCoachCorpus: A naturalistic dataset with language and trajectories for embodied teaching**|Guy Rosman Team|[2509.14548](http://arxiv.org/abs/2509.14548)|null|
|**2025-09-18**|**Learning to Pick: A Visuomotor Policy for Clustered Strawberry Picking**|Chen Peng Team|[2509.14530](http://arxiv.org/abs/2509.14530)|null|
|**2025-09-17**|**Learning Discrete Abstractions for Visual Rearrangement Tasks Using Vision-Guided Graph Coloring**|Constantinos Chamzas Team|[2509.14460](http://arxiv.org/abs/2509.14460)|null|
|**2025-09-17**|**LeVR: A Modular VR Teleoperation Framework for Imitation Learning in Dexterous Manipulation**|Han Liu Team|[2509.14349](http://arxiv.org/abs/2509.14349)|null|
|**2025-09-17**|**MIMIC-D: Multi-modal Imitation for MultI-agent Coordination with Decentralized Diffusion Policies**|Negar Mehr Team|[2509.14159](http://arxiv.org/abs/2509.14159)|null|
|**2025-09-17**|**SeqVLA: Sequential Task Execution for Long-Horizon Manipulation with Completion-Aware Vision-Language-Action Model**|Yiming Feng Team|[2509.14138](http://arxiv.org/abs/2509.14138)|null|
|**2025-09-17**|**PhysicalAgent: Towards General Cognitive Robotics with Foundation World Models**|Dzmitry Tsetserukou Team|[2509.13903](http://arxiv.org/abs/2509.13903)|null|
|**2025-09-17**|**Dual-Actor Fine-Tuning of VLA Models: A Talk-and-Tweak Human-in-the-Loop Approach**|Yangwei You Team|[2509.13774](http://arxiv.org/abs/2509.13774)|null|
|**2025-09-17**|**Motion Adaptation Across Users and Tasks for Exoskeletons via Meta-Learning**|Houcheng Li Team|[2509.13736](http://arxiv.org/abs/2509.13736)|null|
|**2025-09-17**|**Reinforcement Learning for Robotic Insertion of Flexible Cables in Industrial Settings**|Changjoo Nam Team|[2509.13731](http://arxiv.org/abs/2509.13731)|null|
|**2025-09-17**|**HGACNet: Hierarchical Graph Attention Network for Cross-Modal Point Cloud Completion**|I-Ming Chen Team|[2509.13692](http://arxiv.org/abs/2509.13692)|null|
|**2025-09-16**|**TreeIRL: Safe Urban Driving with Tree Search and Inverse Reinforcement Learning**|Yunqing Hu Team|[2509.13579](http://arxiv.org/abs/2509.13579)|null|
|**2025-09-18**|**StageACT: Stage-Conditioned Imitation for Robust Humanoid Door Opening**|Shayegan Omidshafiei Team|[2509.13200](http://arxiv.org/abs/2509.13200)|null|
|**2025-09-16**|**A Design Co-Pilot for Task-Tailored Manipulators**|Matthias Althoff Team|[2509.13077](http://arxiv.org/abs/2509.13077)|null|
|**2025-09-16**|**Deep Learning for Model-Free Prediction of Thermal States of Robot Joint Motors**|Eric Guiffo Kaigom Team|[2509.12739](http://arxiv.org/abs/2509.12739)|null|
|**2025-09-16**|**Safety filtering of robotic manipulation under environment uncertainty: a computational approach**|Martin Servin Team|[2509.12674](http://arxiv.org/abs/2509.12674)|null|
|**2025-09-16**|**ActiveVLN: Towards Active Exploration via Multi-Turn RL in Vision-and-Language Navigation**|Feng Zheng Team|[2509.12618](http://arxiv.org/abs/2509.12618)|null|
|**2025-09-16**|**Robust Online Residual Refinement via Koopman-Guided Dynamics Modeling**|Donglin Wang Team|[2509.12562](http://arxiv.org/abs/2509.12562)|null|
|**2025-09-16**|**Pre-trained Visual Representations Generalize Where it Matters in Model-Based Reinforcement Learning**|Sebastian W. Pattinson Team|[2509.12531](http://arxiv.org/abs/2509.12531)|null|
|**2025-09-15**|**Geometric Red-Teaming for Robotic Manipulation**|Zackory Erickson Team|[2509.12379](http://arxiv.org/abs/2509.12379)|null|
|**2025-09-15**|**Deceptive Risk Minimization: Out-of-Distribution Generalization by Deceiving Distribution Shift Detectors**|Anirudha Majumdar Team|[2509.12081](http://arxiv.org/abs/2509.12081)|null|
|**2025-09-15**|**Imitation Learning as Return Distribution Matching**|Alberto Maria Metelli Team|[2509.12026](http://arxiv.org/abs/2509.12026)|null|
|**2025-09-15**|**Gesture-Based Robot Control Integrating Mm-wave Radar and Behavior Trees**|Stephan Sigg Team|[2509.12008](http://arxiv.org/abs/2509.12008)|null|
|**2025-09-15**|**Learning to Generate 4D LiDAR Sequences**|Wei Tsang Ooi Team|[2509.11959](http://arxiv.org/abs/2509.11959)|**[link](https://lidarcrafter.github.io/)**|
|**2025-09-15**|**Learning Representations in Video Game Agents with Supervised Contrastive Imitation Learning**|Tim Bradley Team|[2509.11880](http://arxiv.org/abs/2509.11880)|null|
|**2025-09-15**|**Tenma: Robust Cross-Embodiment Robot Manipulation with Diffusion Transformer**|Luhui Hu Team|[2509.11865](http://arxiv.org/abs/2509.11865)|null|
|**2025-09-17**|**TrajBooster: Boosting Humanoid Whole-Body Manipulation via Trajectory-Centric Learning**|Donglin Wang Team|[2509.11839](http://arxiv.org/abs/2509.11839)|null|
|**2025-09-15**|**Inference-stage Adaptation-projection Strategy Adapts Diffusion Policy to Cross-manipulators Scenarios**|Alois Knoll Team|[2509.11621](http://arxiv.org/abs/2509.11621)|null|
|**2025-09-15**|**RAPTOR: A Foundation Policy for Quadrotor Control**|Giuseppe Loianno Team|[2509.11481](http://arxiv.org/abs/2509.11481)|null|
|**2025-09-17**|**Enhancing Generalization in Vision-Language-Action Models by Preserving Pretrained Representations**|Xuanlin Li Team|[2509.11417](http://arxiv.org/abs/2509.11417)|**[link](https://gen-vla.github.io/)**|
|**2025-09-14**|**ActivePose: Active 6D Object Pose Estimation and Tracking for Robotic Manipulation**|Yizhao Wang Team|[2509.11364](http://arxiv.org/abs/2509.11364)|null|
|**2025-09-14**|**MEMBOT: Memory-Based Robot in Intermittent POMDP**|Eyan Noronha Team|[2509.11225](http://arxiv.org/abs/2509.11225)|null|
|**2025-09-14**|**SAMP: Spatial Anchor-based Motion Policy for Collision-Aware Robotic Manipulators**|Jun Ma Team|[2509.11185](http://arxiv.org/abs/2509.11185)|null|
|**2025-09-14**|**ManiVID-3D: Generalizable View-Invariant Reinforcement Learning for Robotic Manipulation via Disentangled 3D Representations**|Jun Ma Team|[2509.11125](http://arxiv.org/abs/2509.11125)|null|
|**2025-09-16**|**FEWT: Improving Humanoid Robot Perception with Frequency-Enhanced Wavelet-based Transformers**|Zhigong Song Team|[2509.11109](http://arxiv.org/abs/2509.11109)|null|
|**2025-09-14**|**End-to-End Visual Autonomous Parking via Control-Aided Attention**|Chen Feng Team|[2509.11090](http://arxiv.org/abs/2509.11090)|null|
|**2025-09-14**|**FragmentGPT: A Unified GPT Model for Fragment Growing, Linking, and Merging in Molecular Design**|Rick Stevens Team|[2509.11044](http://arxiv.org/abs/2509.11044)|null|
|**2025-09-13**|**ImMimic: Cross-Domain Imitation from Human Videos via Mapping and Interpolation**|Danfei Xu Team|[2509.10952](http://arxiv.org/abs/2509.10952)|null|
|**2025-09-11**|**Self-Augmented Robot Trajectory: Efficient Imitation Learning via Safe Self-augmentation with Demonstrator-annotated Precision**|Yukiyasu Domae Team|[2509.09893](http://arxiv.org/abs/2509.09893)|null|
|**2025-09-11**|**Off Policy Lyapunov Stability in Reinforcement Learning**|Daniela Constantinescu Team|[2509.09863](http://arxiv.org/abs/2509.09863)|null|
|**2025-09-11**|**MimicDroid: In-Context Learning for Humanoid Robot Manipulation from Human Play Videos**|Yuke Zhu Team|[2509.09769](http://arxiv.org/abs/2509.09769)|null|
|**2025-09-11**|**SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning**|Ning Ding Team|[2509.09674](http://arxiv.org/abs/2509.09674)|null|
|**2025-09-11**|**Dexplore: Scalable Neural Control for Dexterous Manipulation from Reference-Scoped Exploration**|Wei Yang Team|[2509.09671](http://arxiv.org/abs/2509.09671)|null|
|**2025-09-11**|**A Neuromorphic Incipient Slip Detection System using Papillae Morphology**|Benjamin Ward-Cherrier Team|[2509.09546](http://arxiv.org/abs/2509.09546)|null|
|**2025-09-11**|**KoopMotion: Learning Almost Divergence Free Koopman Flow Fields for Motion Planning**|M. Ani Hsieh Team|[2509.09074](http://arxiv.org/abs/2509.09074)|null|
|**2025-09-11**|**Joint Model-based Model-free Diffusion for Planning with Constraints**|Shreyas Kousik Team|[2509.08775](http://arxiv.org/abs/2509.08775)|null|
|**2025-09-10**|**SocialNav-SUB: Benchmarking VLMs for Scene Understanding in Social Robot Navigation**|Peter Stone Team|[2509.08757](http://arxiv.org/abs/2509.08757)|**[link](https://larg.github.io/socialnav-sub)**|
|**2025-09-10**|**PegasusFlow: Parallel Rolling-Denoising Score Sampling for Robot Diffusion Planner Flow Matching**|Liang Ding Team|[2509.08435](http://arxiv.org/abs/2509.08435)|null|
|**2025-09-10**|**Grasp Like Humans: Learning Generalizable Multi-Fingered Grasping from Human Proprioceptive Sensorimotor Integration**|Huimin Lu Team|[2509.08354](http://arxiv.org/abs/2509.08354)|null|
|**2025-09-10**|**Input-gated Bilateral Teleoperation: An Easy-to-implement Force Feedback Teleoperation Method for Low-cost Hardware**|Tetsuya Ogata Team|[2509.08226](http://arxiv.org/abs/2509.08226)|null|
|**2025-09-09**|**TA-VLA: Elucidating the Design Space of Torque-aware Vision-Language-Action Models**|Hao Zhao Team|[2509.07962](http://arxiv.org/abs/2509.07962)|**[link](https://zzongzheng0918.github.io/Torque-Aware-VLA.github.io/})**|
|**2025-09-09**|**Graph-Fused Vision-Language-Action for Policy Reasoning in Multi-Arm Robotic Manipulation**|Yingbai Hu Team|[2509.07957](http://arxiv.org/abs/2509.07957)|null|
|**2025-09-09**|**RaC: Robot Learning for Long-Horizon Tasks by Scaling Recovery and Correction**|Aviral Kumar Team|[2509.07953](http://arxiv.org/abs/2509.07953)|null|
|**2025-09-09**|**Text2Touch: Tactile In-Hand Manipulation with LLM-Designed Reward Functions**|Nathan F. Lepora Team|[2509.07445](http://arxiv.org/abs/2509.07445)|null|
|**2025-09-08**|**Quantum Machine Learning and Grover's Algorithm for Quantum Optimization of Robotic Manipulators**|Howard Li Team|[2509.07216](http://arxiv.org/abs/2509.07216)|null|
|**2025-09-08**|**Design of Input-Output Observers for a Population of Systems with Bounded Frequency-Domain Variation using $DK$ -iteration**|James Richard Forbes Team|[2509.07201](http://arxiv.org/abs/2509.07201)|null|
|**2025-09-08**|**First Plan Then Evaluate: Use a Vectorized Motion Planner for Grasping**|Tucker Hermans Team|[2509.07162](http://arxiv.org/abs/2509.07162)|null|
|**2025-09-08**|**Deep Reactive Policy: Learning Reactive Manipulator Motion Planning for Dynamic Environments**|Deepak Pathak Team|[2509.06953](http://arxiv.org/abs/2509.06953)|null|
|**2025-09-10**|**LLaDA-VLA: Vision Language Diffusion Action Models**|Xiaoyan Sun Team|[2509.06932](http://arxiv.org/abs/2509.06932)|null|
|**2025-09-08**|**Cortex-Synth: Differentiable Topology-Aware 3D Skeleton Synthesis with Hierarchical Graph Attention**|Mohamed Zayaan S Team|[2509.06705](http://arxiv.org/abs/2509.06705)|null|
|**2025-09-08**|**Group Effect Enhanced Generative Adversarial Imitation Learning for Individual Travel Behavior Modeling under Incentives**|Zhenliang Ma Team|[2509.06656](http://arxiv.org/abs/2509.06656)|null|
|**2025-09-08**|**Musculoskeletal simulation of limb movement biomechanics in Drosophila melanogaster**|Pavan Ramdya Team|[2509.06426](http://arxiv.org/abs/2509.06426)|null|
|**2025-09-07**|**O $^3$ Afford: One-Shot 3D Object-to-Object Affordance Grounding for Generalizable Robotic Manipulation**|Yen-Ling Kuo Team|[2509.06233](http://arxiv.org/abs/2509.06233)|**[link](https://o3afford.github.io/)**|
|**2025-09-07**|**Robotic Manipulation Framework Based on Semantic Keypoints for Packing Shoes of Different Sizes, Shapes, and Softness**|Zhendong Dai Team|[2509.06048](http://arxiv.org/abs/2509.06048)|**[link](https://authors.elsevier.com/c/1lgjX3HdG3supQ)**|
|**2025-09-06**|**TeleopLab: Accessible and Intuitive Teleoperation of a Robotic Manipulator for Remote Labs**|John Liu Team|[2509.05547](http://arxiv.org/abs/2509.05547)|null|
|**2025-09-05**|**OpenEgo: A Large-Scale Multimodal Egocentric Dataset for Dexterous Manipulation**|Yu Xiang Team|[2509.05513](http://arxiv.org/abs/2509.05513)|null|
|**2025-09-04**|**Long-Horizon Visual Imitation Learning via Plan and Code Reflection**|Yunde Jia Team|[2509.05368](http://arxiv.org/abs/2509.05368)|null|
|**2025-09-08**|**Sticker-TTS: Learn to Utilize Historical Experience with a Sticker-driven Test-Time Scaling Framework**|Ji-Rong Wen Team|[2509.05007](http://arxiv.org/abs/2509.05007)|null|
|**2025-09-05**|**Imitation Learning Based on Disentangled Representation Learning of Behavioral Characteristics**|Toshiaki Tsuji Team|[2509.04737](http://arxiv.org/abs/2509.04737)|null|
|**2025-09-04**|**Surformer v2: A Multimodal Classifier for Surface Understanding from Touch and Vision**|Noorbakhsh Amiri Golilarz Team|[2509.04658](http://arxiv.org/abs/2509.04658)|null|
|**2025-09-04**|**Planning from Point Clouds over Continuous Actions for Multi-object Rearrangement**|David Held Team|[2509.04645](http://arxiv.org/abs/2509.04645)|**[link](https://planning-from-point-clouds.github.io/))**|
|**2025-09-04**|**Action Chunking with Transformers for Image-Based Spacecraft Guidance and Control**|Richard Linares Team|[2509.04628](http://arxiv.org/abs/2509.04628)|null|
|**2025-09-04**|**In-Context Policy Adaptation via Cross-Domain Skill Diffusion**|Honguk Woo Team|[2509.04535](http://arxiv.org/abs/2509.04535)|null|
|**2025-09-04**|**EMMA: Scaling Mobile Manipulation via Egocentric Human Data**|Danfei Xu Team|[2509.04443](http://arxiv.org/abs/2509.04443)|null|
|**2025-09-04**|**Balancing Signal and Variance: Adaptive Offline RL Post-Training for VLA Flow Models**|Donglin Wang Team|[2509.04063](http://arxiv.org/abs/2509.04063)|null|
|**2025-09-04**|**FPC-VLA: A Vision-Language-Action Framework with a Supervisor for Failure Prediction and Correction**|Jingtai Liu Team|[2509.04018](http://arxiv.org/abs/2509.04018)|null|
|**2025-09-04**|**Weakly-Supervised Learning of Dense Functional Correspondences**|Jiajun Wu Team|[2509.03893](http://arxiv.org/abs/2509.03893)|**[link](https://dense-functional-correspondence.github.io/)**|
|**2025-09-05**|**Learning Multi-Stage Pick-and-Place with a Legged Mobile Manipulator**|Wei Xu Team|[2509.03859](http://arxiv.org/abs/2509.03859)|null|
|**2025-09-03**|**The Role of Embodiment in Intuitive Whole-Body Teleoperation for Mobile Manipulation**|Georgia Chalvatzaki Team|[2509.03222](http://arxiv.org/abs/2509.03222)|null|
|**2025-09-03**|**Autonomous Learning From Success and Failure: Goal-Conditioned Supervised Learning with Negative Feedback**|Daniel A. Braun Team|[2509.03206](http://arxiv.org/abs/2509.03206)|null|
|**2025-09-03**|**Forbal: Force Balanced 2-5 Degree of Freedom Robot Manipulator Built from a Five Bar Linkage**|Matteo Bottin Team|[2509.03119](http://arxiv.org/abs/2509.03119)|null|
|**2025-09-02**|**Generalizable Skill Learning for Construction Robots with Crowdsourced Natural Language Instructions, Composable Skills Standardization, and Large Language Model**|Carol C. Menassa Team|[2509.02876](http://arxiv.org/abs/2509.02876)|null|
|**2025-09-02**|**Power Grid Control with Graph-Based Distributed Reinforcement Learning**|Marcello Restelli Team|[2509.02861](http://arxiv.org/abs/2509.02861)|null|
|**2025-09-04**|**Plan Verification for LLM-Based Embodied Task Completion Agents**|Gokhan Tur Team|[2509.02761](http://arxiv.org/abs/2509.02761)|null|
|**2025-09-02**|**Manipulation as in Simulation: Enabling Accurate Geometry Perception in Robots**|Bingyi Kang Team|[2509.02530](http://arxiv.org/abs/2509.02530)|**[link](https://manipulation-as-in-simulation.github.io/)**|
|**2025-09-02**|**U-ARM : Ultra low-cost general teleoperation interface for robot manipulation**|Bo Zhao Team|[2509.02437](http://arxiv.org/abs/2509.02437)|null|
|**2025-09-05**|**Align-Then-stEer: Adapting the Vision-Language Action Models through Unified Latent Guidance**|Xuelong Li Team|[2509.02055](http://arxiv.org/abs/2509.02055)|null|
|**2025-09-01**|**ManiFlow: A General Robot Manipulation Policy via Consistency Flow Training**|Dieter Fox Team|[2509.01819](http://arxiv.org/abs/2509.01819)|null|
|**2025-09-01**|**Non-conflicting Energy Minimization in Reinforcement Learning based Robot Control**|Stefan Lee Team|[2509.01765](http://arxiv.org/abs/2509.01765)|null|
|**2025-09-01**|**Fail2Progress: Learning from Real-World Robot Failures with Stein Variational Inference**|Tucker Hermans Team|[2509.01746](http://arxiv.org/abs/2509.01746)|null|
|**2025-09-01**|**Articulated Object Estimation in the Wild**|Abhinav Valada Team|[2509.01708](http://arxiv.org/abs/2509.01708)|null|
|**2025-09-01**|**Data Retrieval with Importance Weights for Few-Shot Imitation Learning**|Joey Hejna Team|[2509.01657](http://arxiv.org/abs/2509.01657)|null|
|**2025-09-01**|**Disentangled Multi-Context Meta-Learning: Unlocking robust and Generalized Task Learning**|Seongil Hong Team|[2509.01297](http://arxiv.org/abs/2509.01297)|null|
|**2025-08-31**|**One-Step Model Predictive Path Integral for Manipulator Motion Planning Using Configuration Space Distance Fields**|Kenji Kawashima Team|[2509.00836](http://arxiv.org/abs/2509.00836)|null|
|**2025-08-31**|**An Effective Trajectory Planning and an Optimized Path Planning for a 6-Degree-of-Freedom Robot Manipulator**|Masahiko Mikawa Team|[2509.00828](http://arxiv.org/abs/2509.00828)|null|
|**2025-08-31**|**Inverse Kinematics for a 6-Degree-of-Freedom Robot Manipulator Using Comprehensive Gröbner Systems**|Masahiko Mikawa Team|[2509.00823](http://arxiv.org/abs/2509.00823)|null|
|**2025-08-30**|**Learning Dolly-In Filming From Demonstration Using a Ground-Based Robot**|Wenbin Li Team|[2509.00574](http://arxiv.org/abs/2509.00574)|null|
|**2025-08-30**|**NeuralSVCD for Efficient Swept Volume Collision Detection**|Beomjoon Kim Team|[2509.00499](http://arxiv.org/abs/2509.00499)|null|
|**2025-08-29**|**Can a mobile robot learn from a pedestrian model to prevent the sidewalk salsa?**|David Abbink Team|[2508.21690](http://arxiv.org/abs/2508.21690)|null|
|**2025-08-29**|**Robust Convex Model Predictive Control with collision avoidance guarantees for robot manipulators**|Thomas B. Schön Team|[2508.21677](http://arxiv.org/abs/2508.21677)|null|
|**2025-08-29**|**Learning Agile Gate Traversal via Analytical Optimal Policy Gradient**|Lin Zhao Team|[2508.21592](http://arxiv.org/abs/2508.21592)|null|
|**2025-08-29**|**Estimated Informed Anytime Search for Sampling-Based Planning via Adaptive Sampler**|Alois Knoll Team|[2508.21549](http://arxiv.org/abs/2508.21549)|null|
|**2025-08-29**|**Few-Shot Neuro-Symbolic Imitation Learning for Long-Horizon Planning and Acting**|Matthias Scheutz Team|[2508.21501](http://arxiv.org/abs/2508.21501)|null|
|**2025-08-29**|**RoboInspector: Unveiling the Unreliability of Policy Code for LLM-enabled Robotic Manipulation**|Yuanchao Shu Team|[2508.21378](http://arxiv.org/abs/2508.21378)|null|
|**2025-08-29**|**Dynamics-Compliant Trajectory Diffusion for Super-Nominal Payload Manipulation**|Alessandro Roncone Team|[2508.21375](http://arxiv.org/abs/2508.21375)|null|
|**2025-08-29**|**Learning to Assemble the Soma Cube with Legal-Action Masked DQN and Safe ZYZ Regrasp on a Doosan M0609**|Sawoong Kim Team|[2508.21272](http://arxiv.org/abs/2508.21272)|null|
|**2025-08-28**|**Learning on the Fly: Rapid Policy Adaptation via Differentiable Simulation**|Davide Scaramuzza Team|[2508.21065](http://arxiv.org/abs/2508.21065)|null|
|**2025-08-28**|**Rapid Mismatch Estimation via Neural Network Informed Variational Inference**|Nadia Figueroa Team|[2508.21007](http://arxiv.org/abs/2508.21007)|**[link](https://mateusz-jaszczuk.github.io/rme/)**|
|**2025-08-29**|**UltraTac: Integrated Ultrasound-Augmented Visuotactile Sensor for Enhanced Robotic Perception**|Wenbo Ding Team|[2508.20982](http://arxiv.org/abs/2508.20982)|null|
|**2025-08-28**|**Deep Fuzzy Optimization for Batch-Size and Nearest Neighbors in Optimal Robot Motion Planning**|Alois Knoll Team|[2508.20884](http://arxiv.org/abs/2508.20884)|null|
|**2025-08-28**|**Learning Primitive Embodied World Models: Towards Scalable Robotic Learning**|Qinying Gu Team|[2508.20840](http://arxiv.org/abs/2508.20840)|null|
|**2025-08-28**|**Non-expert to Expert Motion Translation Using Generative Adversarial Networks**|Seiichiro Katsura Team|[2508.20740](http://arxiv.org/abs/2508.20740)|null|
|**2025-08-28**|**SimShear: Sim-to-Real Shear-based Tactile Servoing**|Nathan F. Lepora Team|[2508.20561](http://arxiv.org/abs/2508.20561)|null|
|**2025-08-31**|**HERMES: Human-to-Robot Embodied Learning from Multi-Source Motion Data for Mobile Dexterous Manipulation**|Huazhe Xu Team|[2508.20085](http://arxiv.org/abs/2508.20085)|null|
|**2025-08-28**|**Long-VLA: Unleashing Long-Horizon Capability of Vision Language Action Model for Robot Manipulation**|Donglin Wang Team|[2508.19958](http://arxiv.org/abs/2508.19958)|**[link](https://long-vla.github.io)**|
|**2025-08-28**|**Ego-centric Predictive Model Conditioned on Hand Trajectories**|Mike Zheng Shou Team|[2508.19852](http://arxiv.org/abs/2508.19852)|null|
|**2025-08-27**|**APT*: Asymptotically Optimal Motion Planning via Adaptively Prolated Elliptical R-Nearest Neighbors**|Alois Knoll Team|[2508.19790](http://arxiv.org/abs/2508.19790)|null|
|**2025-08-27**|**Impedance Primitive-augmented Hierarchical Reinforcement Learning for Sequential Tasks**|Jens Kober Team|[2508.19607](http://arxiv.org/abs/2508.19607)|null|
|**2025-08-26**|**Gentle Object Retraction in Dense Clutter Using Multimodal Force Sensing and Imitation Learning**|Mark Cutkosky Team|[2508.19476](http://arxiv.org/abs/2508.19476)|null|
|**2025-08-26**|**LaVA-Man: Learning Visual Action Representations for Robot Manipulation**|Changjae Oh Team|[2508.19391](http://arxiv.org/abs/2508.19391)|null|
|**2025-08-26**|**Inference of Human-derived Specifications of Object Placement via Demonstration**|Julie A Shah Team|[2508.19367](http://arxiv.org/abs/2508.19367)|null|
|**2025-08-26**|**MemoryVLA: Perceptual-Cognitive Memory in Vision-Language-Action Models for Robotic Manipulation**|Gao Huang Team|[2508.19236](http://arxiv.org/abs/2508.19236)|**[link](https://shihao1895.github.io/MemoryVLA)**|
|**2025-08-26**|**LSD-3D: Large-Scale 3D Driving Scene Generation with Geometry Grounding**|Felix Heide Team|[2508.19204](http://arxiv.org/abs/2508.19204)|**[link](https://light.princeton.edu/LSD-3D)**|
|**2025-08-27**|**AutoRing: Imitation Learning--based Autonomous Intraocular Foreign Body Removal Manipulation with Eye Surgical Robot**|Jian Wu Team|[2508.19191](http://arxiv.org/abs/2508.19191)|null|
|**2025-08-28**|**From Tabula Rasa to Emergent Abilities: Discovering Robot Skills via Real-World Unsupervised Quality-Diversity**|Antoine Cully Team|[2508.19172](http://arxiv.org/abs/2508.19172)|null|
|**2025-08-26**|**Playstyle and Artificial Intelligence: An Initial Blueprint Through the Lens of Video Games**|Chiu-Chou Lin Team|[2508.19152](http://arxiv.org/abs/2508.19152)|null|
|**2025-08-26**|**AS2FM: Enabling Statistical Model Checking of ROS 2 Systems for Robust Autonomy**|Matteo Morelli Team|[2508.18820](http://arxiv.org/abs/2508.18820)|null|
|**2025-08-26**|**HyperTASR: Hypernetwork-Driven Task-Aware Scene Representations for Robust Manipulation**|Yanchao Yang Team|[2508.18802](http://arxiv.org/abs/2508.18802)|null|
|**2025-08-26**|**Deep Sensorimotor Control by Imitating Predictive Models of Human Motion**|Antonio Loquercio Team|[2508.18691](http://arxiv.org/abs/2508.18691)|**[link](https://hgaurav2k.github.io/trackr/)**|
|**2025-08-26**|**Integration of Robot and Scene Kinematics for Sequential Mobile Manipulation Planning**|Song-Chun Zhu Team|[2508.18627](http://arxiv.org/abs/2508.18627)|null|
|**2025-08-25**|**PneuGelSight: Soft Robotic Vision-Based Proprioception and Tactile Sensing**|Wenzhen Yuan Team|[2508.18443](http://arxiv.org/abs/2508.18443)|null|
|**2025-08-25**|**Maintenance automation: methods for robotics manipulation planning and execution**|Alexander Verl Team|[2508.18399](http://arxiv.org/abs/2508.18399)|null|
|**2025-08-26**|**FlowVLA: Thinking in Motion with a Visual Chain of Thought**|Haoang Li Team|[2508.18269](http://arxiv.org/abs/2508.18269)|null|
|**2025-08-25**|**No Need to Look! Locating and Grasping Objects by a Robot Arm Covered with Sensitive Skin**|Matej Hoffmann Team|[2508.17986](http://arxiv.org/abs/2508.17986)|null|
|**2025-08-25**|**SEBVS: Synthetic Event-based Visual Servoing for Robot Navigation and Manipulation**|Bharatesh Chakravarthi Team|[2508.17643](http://arxiv.org/abs/2508.17643)|null|
|**2025-08-25**|**GWM: Towards Scalable Gaussian World Models for Robotic Manipulation**|Siyuan Huang Team|[2508.17600](http://arxiv.org/abs/2508.17600)|**[link](https://gaussian-world-model.github.io/)**|
|**2025-08-24**|**LodeStar: Long-horizon Dexterity via Synthetic Data Augmentation from Human Demonstrations**|Hao Su Team|[2508.17547](http://arxiv.org/abs/2508.17547)|null|
|**2025-08-24**|**Variational Shape Inference for Grasp Diffusion on SE(3)**|Aniket Bera Team|[2508.17482](http://arxiv.org/abs/2508.17482)|null|
|**2025-08-24**|**ReviBranch: Deep Reinforcement Learning for Branch-and-Bound with Revived Trajectories**|Jiaping Xiao Team|[2508.17452](http://arxiv.org/abs/2508.17452)|null|
|**2025-08-24**|**Robotic Manipulation via Imitation Learning: Taxonomy, Evolution, Benchmark, and Challenges**|Liming Chen Team|[2508.17449](http://arxiv.org/abs/2508.17449)|null|
|**2025-08-24**|**OVITA: Open-Vocabulary Interpretable Trajectory Adaptations**|Ravi Prakash Team|[2508.17260](http://arxiv.org/abs/2508.17260)|**[link](https://github.com/anurag1000101/OVITA)**|
|**2025-08-24**|**4D Visual Pre-training for Robot Learning**|Huazhe Xu Team|[2508.17230](http://arxiv.org/abs/2508.17230)|null|
|**2025-08-21**|**UnPose: Uncertainty-Guided Diffusion Priors for Zero-Shot Pose Estimation**|Binbin Xu Team|[2508.15972](http://arxiv.org/abs/2508.15972)|**[link](https://frankzhaodong.github.io/UnPose)**|
|**2025-08-21**|**Spatial Policy: Guiding Visuomotor Robotic Manipulation with Spatial-Aware Modeling and Reasoning**|Wenwu Zhu Team|[2508.15874](http://arxiv.org/abs/2508.15874)|null|
|**2025-08-21**|**Search-Based Credit Assignment for Offline Preference-Based Reinforcement Learning**|Houqiang Li Team|[2508.15327](http://arxiv.org/abs/2508.15327)|null|
|**2025-08-20**|**A Vision-Based Shared-Control Teleoperation Scheme for Controlling the Robotic Arm of a Four-Legged Robot**|Marcelo Becker Team|[2508.14994](http://arxiv.org/abs/2508.14994)|null|
|**2025-08-19**|**Learning to Drive Ethically: Embedding Moral Reasoning into Autonomous Driving**|Ostap Okhrin Team|[2508.14926](http://arxiv.org/abs/2508.14926)|null|
|**2025-08-20**|**FBI: Learning Dexterous In-hand Manipulation with Dynamic Visuotactile Shortcut Policy**|Cewu Lu Team|[2508.14441](http://arxiv.org/abs/2508.14441)|null|
|**2025-08-20**|**Offline Imitation Learning upon Arbitrary Demonstrations by Pre-Training Dynamics Representations**|Na Li Team|[2508.14383](http://arxiv.org/abs/2508.14383)|null|
|**2025-08-20**|**Action-Constrained Imitation Learning**|Ping-Chun Hsieh Team|[2508.14379](http://arxiv.org/abs/2508.14379)|null|
|**2025-08-20**|**Learning Point Cloud Representations with Pose Continuity for Depth-Based Category-Level 6D Object Pose Estimation**|Ioannis Stamos Team|[2508.14358](http://arxiv.org/abs/2508.14358)|null|
|**2025-08-19**|**Train Once, Deploy Anywhere: Realize Data-Efficient Dynamic Object Manipulation**|Hengshuang Zhao Team|[2508.14042](http://arxiv.org/abs/2508.14042)|null|
|**2025-08-19**|**Embodied-R1: Reinforced Embodied Reasoning for General Robotic Manipulation**|Jianye Hao Team|[2508.13998](http://arxiv.org/abs/2508.13998)|null|
|**2025-08-19**|**Toward Deployable Multi-Robot Collaboration via a Symbolically-Guided Decision Transformer**|Paul Asunda Team|[2508.13877](http://arxiv.org/abs/2508.13877)|null|
|**2025-08-18**|**Decoding Communications with Partial Information**|Peter McBurney Team|[2508.13326](http://arxiv.org/abs/2508.13326)|null|
|**2025-08-18**|**Precise Action-to-Video Generation Through Visual Action Prompts**|Ruizhen Hu Team|[2508.13104](http://arxiv.org/abs/2508.13104)|**[link](https://zju3dv.github.io/VAP/)**|
|**2025-08-18**|**Grounding Actions in Camera Space: Observation-Centric Vision-Language-Action Policy**|Zhi Hou Team|[2508.13103](http://arxiv.org/abs/2508.13103)|null|
|**2025-08-18**|**Large VLM-based Vision-Language-Action Models for Robotic Manipulation: A Survey**|Liqiang Nie Team|[2508.13073](http://arxiv.org/abs/2508.13073)|**[link](https://github.com/JiuTian-VL/Large-VLM-based-VLA-for-Robotic-Manipulation)**|
|**2025-08-18**|**PROD: Palpative Reconstruction of Deformable Objects through Elastostatic Signed Distance Functions**|Hamza El-Kebir Team|[2508.12554](http://arxiv.org/abs/2508.12554)|null|
|**2025-08-17**|**EgoLoc: A Generalizable Solution for Temporal Interaction Localization in Egocentric Videos**|Hesheng Wang Team|[2508.12349](http://arxiv.org/abs/2508.12349)|null|
|**2025-08-17**|**Bimanual Robot-Assisted Dressing: A Spherical Coordinate-Based Strategy for Tight-Fitting Garments**|Jihong Zhu Team|[2508.12274](http://arxiv.org/abs/2508.12274)|null|
|**2025-08-17**|**Robot Trains Robot: Automatic Real-World Policy Adaptation and Learning for Humanoids**|Shuran Song Team|[2508.12252](http://arxiv.org/abs/2508.12252)|null|
|**2025-08-16**|**Belief-Conditioned One-Step Diffusion: Real-Time Trajectory Planning with Just-Enough Sensing**|Melkior Ornik Team|[2508.12166](http://arxiv.org/abs/2508.12166)|null|
|**2025-08-16**|**OASIS: Real-Time Opti-Acoustic Sensing for Intervention Systems in Unstructured Environments**|Richard Camilli Team|[2508.12071](http://arxiv.org/abs/2508.12071)|null|
|**2025-08-16**|**Fully Spiking Actor-Critic Neural Network for Robotic Manipulation**|Guanghui Sun Team|[2508.12038](http://arxiv.org/abs/2508.12038)|null|
|**2025-08-16**|**OmniD: Generalizable Robot Manipulation Policy via Image-Based BEV Representation**|Xiaozhu Ju Team|[2508.11898](http://arxiv.org/abs/2508.11898)|null|
|**2025-08-15**|**Limitation Learning: Catching Adverse Dialog with GAIL**|Rahul Zalkikar Team|[2508.11767](http://arxiv.org/abs/2508.11767)|null|
|**2025-08-15**|**MultiPark: Multimodal Parking Transformer with Next-Segment Prediction**|Tong Qin Team|[2508.11537](http://arxiv.org/abs/2508.11537)|null|
|**2025-08-15**|**Learning Differentiable Reachability Maps for Optimization-based Humanoid Motion Generation**|Fumio Kanehiro Team|[2508.11275](http://arxiv.org/abs/2508.11275)|null|
|**2025-08-15**|**Multi-Group Equivariant Augmentation for Reinforcement Learning in Robot Manipulation**|Kwok Wai Samuel Au Team|[2508.11204](http://arxiv.org/abs/2508.11204)|null|
|**2025-08-15**|**Actor-Critic for Continuous Action Chunks: A Reinforcement Learning Framework for Long-Horizon Robotic Manipulation with Sparse Reward**|Yu-Gang Jiang Team|[2508.11143](http://arxiv.org/abs/2508.11143)|null|
|**2025-08-14**|**Robot Policy Evaluation for Sim-to-Real Transfer: A Benchmarking Perspective**|Fabio Ramos Team|[2508.11117](http://arxiv.org/abs/2508.11117)|null|
|**2025-08-14**|**GenFlowRL: Shaping Rewards with Generative Object-Centric Flow in Visual Reinforcement Learning**|Ruohan Gao Team|[2508.11049](http://arxiv.org/abs/2508.11049)|null|
|**2025-08-14**|**3D FlowMatch Actor: Unified 3D Policy for Single- and Dual-Arm Manipulation**|Katerina Fragkiadaki Team|[2508.11002](http://arxiv.org/abs/2508.11002)|null|
|**2025-08-15**|**KDPE: A Kernel Density Estimation Strategy for Diffusion Policy Trajectory Selection**|Lorenzo Natale Team|[2508.10511](http://arxiv.org/abs/2508.10511)|null|
|**2025-08-14**|**Large Model Empowered Embodied AI: A Survey on Decision-Making and Embodied Learning**|Ping Kuang Team|[2508.10399](http://arxiv.org/abs/2508.10399)|null|
|**2025-08-14**|**Leveraging OS-Level Primitives for Robotic Action Management**|Haibo Chen Team|[2508.10259](http://arxiv.org/abs/2508.10259)|null|
|**2025-08-13**|**Masquerade: Learning from In-the-wild Human Videos using Data-Editing**|Jeannette Bohg Team|[2508.09976](http://arxiv.org/abs/2508.09976)|**[link](https://masquerade-robot.github.io/)**|
|**2025-08-13**|**Toward Human-Robot Teaming: Learning Handover Behaviors from 3D Scenes**|Changjae Oh Team|[2508.09855](http://arxiv.org/abs/2508.09855)|null|
|**2025-08-13**|**Physical Autoregressive Model for Robotic Manipulation without Action Pretraining**|Guangrun Wang Team|[2508.09822](http://arxiv.org/abs/2508.09822)|null|
|**2025-08-13**|**Immersive Teleoperation of Beyond-Human-Scale Robotic Manipulators: Challenges and Future Directions**|Jouni Mattila Team|[2508.09700](http://arxiv.org/abs/2508.09700)|null|
|**2025-08-13**|**CaRoBio: 3D Cable Routing with a Bio-inspired Gripper Fingernail**|Fumin Zhang Team|[2508.09558](http://arxiv.org/abs/2508.09558)|null|
|**2025-08-13**|**Reactive Model Predictive Contouring Control for Robot Manipulators**|Jaeheung Park Team|[2508.09502](http://arxiv.org/abs/2508.09502)|null|
|**2025-08-13**|**DAgger Diffusion Navigation: DAgger Boosted Diffusion Policy for Vision-Language Navigation**|Liqiang Nie Team|[2508.09444](http://arxiv.org/abs/2508.09444)|null|
|**2025-08-13**|**GeoVLA: Empowering 3D Representations in Vision-Language-Action Models**|Jiale Cao Team|[2508.09071](http://arxiv.org/abs/2508.09071)|**[link](https://linsun449.github.io/GeoVLA/)**|
|**2025-08-12**|**Unsupervised Skill Discovery as Exploration for Learning Agile Locomotion**|Sehoon Ha Team|[2508.08982](http://arxiv.org/abs/2508.08982)|null|
|**2025-08-12**|**Reducing Cognitive Load in Multi-Agent Reinforcement Learning for Mathematical Problem Solving: Decoupling Reasoning and Code Generation**|Yang Li Team|[2508.08882](http://arxiv.org/abs/2508.08882)|null|
|**2025-08-12**|**Visual Prompting for Robotic Manipulation with Annotation-Guided Pick-and-Place Using ACT**|Yukiyasu Domae Team|[2508.08748](http://arxiv.org/abs/2508.08748)|null|
|**2025-08-12**|**Towards Safe Imitation Learning via Potential Field-Guided Flow Matching**|Yoshihiko Nakamura Team|[2508.08707](http://arxiv.org/abs/2508.08707)|null|
|**2025-08-12**|**OmniVTLA: Vision-Tactile-Language-Action Model with Semantic-Aligned Tactile Sensing**|Hengdi Zhang Team|[2508.08706](http://arxiv.org/abs/2508.08706)|null|
|**2025-08-11**|**ReconDreamer-RL: Enhancing Reinforcement Learning via Diffusion-based Scene Reconstruction**|Wenjun Mei Team|[2508.08170](http://arxiv.org/abs/2508.08170)|null|
|**2025-08-11**|**AimBot: A Simple Auxiliary Visual Cue to Enhance Spatial Awareness of Visuomotor Policies**|Joyce Chai Team|[2508.08113](http://arxiv.org/abs/2508.08113)|null|
|**2025-08-13**|**AgentWorld: An Interactive Simulation Platform for Scene Construction and Mobile Robotic Manipulation**|Lei Han Team|[2508.07770](http://arxiv.org/abs/2508.07770)|null|
|**2025-08-11**|**GraphCoT-VLA: A 3D Spatial-Aware Reasoning Vision-Language-Action Model for Robotic Manipulation with Ambiguous Instructions**|Hong Zhang Team|[2508.07650](http://arxiv.org/abs/2508.07650)|null|
|**2025-08-11**|**AR-VRM: Imitating Human Motions for Visual Robot Manipulation with Analogical Reasoning**|Yang Liu Team|[2508.07626](http://arxiv.org/abs/2508.07626)|null|
|**2025-08-10**|**Collision-Free Trajectory Planning and control of Robotic Manipulator using Energy-Based Artificial Potential Field (E-APF)**|Manoranjan Sinha Team|[2508.07323](http://arxiv.org/abs/2508.07323)|null|
|**2025-08-10**|**Multimodal Spiking Neural Network for Space Robotic Manipulation**|Guanghui Sun Team|[2508.07287](http://arxiv.org/abs/2508.07287)|null|
|**2025-08-09**|**DexFruit: Dexterous Manipulation and Gaussian Splatting Inspection of Fruit**|Monroe Kennedy III Team|[2508.07118](http://arxiv.org/abs/2508.07118)|null|
|**2025-08-09**|**From Imitation to Optimization: A Comparative Study of Offline Learning for Autonomous Driving**|Antonio Guillen-Perez Team|[2508.07029](http://arxiv.org/abs/2508.07029)|null|
|**2025-08-09**|**Manipulator for people with limited abilities**|Arkady Yuschenko Team|[2508.06969](http://arxiv.org/abs/2508.06969)|null|
|**2025-08-09**|**Learning a Vision-Based Footstep Planner for Hierarchical Walking Control**|Michael Posa Team|[2508.06779](http://arxiv.org/abs/2508.06779)|null|
|**2025-08-08**|**Towards Balanced Behavior Cloning from Imbalanced Datasets**|Dylan P. Losey Team|[2508.06319](http://arxiv.org/abs/2508.06319)|null|
|**2025-08-08**|**Surrogate-Enhanced Modeling and Adaptive Modular Control of All-Electric Heavy-Duty Robotic Manipulators**|Jouni Mattila Team|[2508.06313](http://arxiv.org/abs/2508.06313)|null|
|**2025-08-08**|**ADPro: a Test-time Adaptive Diffusion Policy for Robot Manipulation via Manifold and Initial Noise Constraints**|Liming Chen Team|[2508.06266](http://arxiv.org/abs/2508.06266)|null|
|**2025-08-08**|**Incremental Language Understanding for Online Motion Planning of Robot Manipulators**|Matthias Scheutz Team|[2508.06095](http://arxiv.org/abs/2508.06095)|null|
|**2025-08-08**|**Society of Mind Meets Real-Time Strategy: A Hierarchical Multi-Agent Framework for Strategic Reasoning**|Jonghyun Choi Team|[2508.06042](http://arxiv.org/abs/2508.06042)|null|
|**2025-08-08**|**PASG: A Closed-Loop Framework for Automated Geometric Primitive Extraction and Semantic Anchoring in Robotic Manipulation**|Yao Mu Team|[2508.05976](http://arxiv.org/abs/2508.05976)|null|
|**2025-08-07**|**Genie Envisioner: A Unified World Foundation Platform for Robotic Manipulation**|Guanghui Ren Team|[2508.05635](http://arxiv.org/abs/2508.05635)|**[link](https://genie-envisioner.github.io/)**|
|**2025-08-07**|**Towards Generalizable Safety in Crowd Navigation via Conformal Uncertainty Handling**|Jiachen Li Team|[2508.05634](http://arxiv.org/abs/2508.05634)|**[link](https://gen-safe-nav.github.io/.)**|
|**2025-08-07**|**Robust adaptive fuzzy sliding mode control for trajectory tracking for of cylindrical manipulator**|Nga Nguyen Thi Team|[2508.05584](http://arxiv.org/abs/2508.05584)|null|
|**2025-08-07**|**Do Robots Really Need Anthropomorphic Hands?**|Nicolás Navarro-Guerrero Team|[2508.05415](http://arxiv.org/abs/2508.05415)|null|
|**2025-08-07**|**Real-Time Iteration Scheme for Diffusion Policy**|Danica Kragic Team|[2508.05396](http://arxiv.org/abs/2508.05396)|null|
|**2025-08-07**|**ASkDAgger: Active Skill-level Data Aggregation for Interactive Imitation Learning**|Jens Kober Team|[2508.05310](http://arxiv.org/abs/2508.05310)|null|
|**2025-08-07**|**Learning to See and Act: Task-Aware View Planning for Robotic Manipulation**|Liang Lin Team|[2508.05186](http://arxiv.org/abs/2508.05186)|**[link](https://hcplab-sysu.github.io/TAVP)**|
|**2025-08-07**|**Cognitive Duality for Adaptive Web Agents**|Zheng Hu Team|[2508.05081](http://arxiv.org/abs/2508.05081)|null|
|**2025-08-07**|**Analyzing the Impact of Multimodal Perception on Sample Complexity and Optimization Landscapes in Imitation Learning**|Temitope Lukman Adebanjo Team|[2508.05077](http://arxiv.org/abs/2508.05077)|null|
|**2025-08-06**|**INTENTION: Inferring Tendencies of Humanoid Robot Motion Through Interactive Intuition and Grounded VLM**|Nikos Tsagarakis Team|[2508.04931](http://arxiv.org/abs/2508.04931)|**[link](https://robo-intention.github.io)**|
|**2025-08-06**|**Optimization of sliding control parameters for a 3-dof robot arm using genetic algorithm (GA)**|Le Tieu Nien Team|[2508.04009](http://arxiv.org/abs/2508.04009)|null|
|**2025-08-05**|**Constraint-Preserving Data Generation for Visuomotor Policy Learning**|Jeannette Bohg Team|[2508.03944](http://arxiv.org/abs/2508.03944)|**[link](https://cp-gen.github.io)**|
|**2025-08-05**|**DiWA: Diffusion Policy Adaptation with World Models**|Abhinav Valada Team|[2508.03645](http://arxiv.org/abs/2508.03645)|null|
|**2025-08-05**|**ActionSink: Toward Precise Robot Manipulation with Dynamic Integration of Action Flow**|Xiaodan Liang Team|[2508.03218](http://arxiv.org/abs/2508.03218)|null|
|**2025-08-05**|**Safety-Aware Imitation Learning via MPC-Guided Disturbance Injection**|Somil Bansal Team|[2508.03129](http://arxiv.org/abs/2508.03129)|null|
|**2025-08-07**|**Hand-Eye Autonomous Delivery: Learning Humanoid Navigation, Locomotion and Reaching**|C. Karen Liu Team|[2508.03068](http://arxiv.org/abs/2508.03068)|null|
|**2025-08-05**|**Aerobatic maneuvers in insect-scale flapping-wing aerial robots via deep-learned robust tube model predictive control**|YuFeng Chen Team|[2508.03043](http://arxiv.org/abs/2508.03043)|null|
|**2025-08-04**|**Learning User Interaction Forces using Vision for a Soft Finger Exosuit**|Thomas George Thuruthel Team|[2508.02870](http://arxiv.org/abs/2508.02870)|null|
|**2025-08-04**|**Manip4Care: Robotic Manipulation of Human Limbs for Solving Assistive Tasks**|Ahmed H. Qureshi Team|[2508.02649](http://arxiv.org/abs/2508.02649)|null|
|**2025-08-04**|**D2PPO: Diffusion Policy Policy Optimization with Dispersive Loss**|Haitao Wang Team|[2508.02644](http://arxiv.org/abs/2508.02644)|null|
|**2025-08-01**|**On-Device Diffusion Transformer Policy for Efficient Robot Manipulation**|Dong Xu Team|[2508.00697](http://arxiv.org/abs/2508.00697)|null|
|**2025-08-01**|**HannesImitation: Grasping with the Hannes Prosthetic Hand via Imitation Learning**|Lorenzo Natale Team|[2508.00491](http://arxiv.org/abs/2508.00491)|null|
|**2025-08-01**|**Energy Efficient Trajectory Control and Resource Allocation in Multi-UAV-assisted MEC via Deep Reinforcement Learning**|Dusit Niyato Team|[2508.00261](http://arxiv.org/abs/2508.00261)|null|
|**2025-07-31**|**RAGNet: Large-scale Reasoning-based Affordance Segmentation Benchmark towards General Grasping**|Jianbing Shen Team|[2507.23734](http://arxiv.org/abs/2507.23734)|**[link](https://github.com/wudongming97/AffordanceNet)**|
|**2025-07-31**|**villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models**|Jiang Bian Team|[2507.23682](http://arxiv.org/abs/2507.23682)|**[link](https://aka.ms/villa-x)**|
|**2025-08-01**|**H-RDT: Human Manipulation Enhanced Bimanual Robotic Manipulation**|Jun Zhu Team|[2507.23523](http://arxiv.org/abs/2507.23523)|null|
|**2025-07-31**|**Policy Learning from Large Vision-Language Model Feedback without Reward Modeling**|Chang D. Yoo Team|[2507.23391](http://arxiv.org/abs/2507.23391)|null|
|**2025-07-30**|**In-between Motion Generation Based Multi-Style Quadruped Robot Locomotion**|Peng Lu Team|[2507.23053](http://arxiv.org/abs/2507.23053)|null|
|**2025-07-30**|**Improving Generalization Ability of Robotic Imitation Learning by Resolving Causal Confusion in Observations**|Brendan Tidd Team|[2507.22380](http://arxiv.org/abs/2507.22380)|null|
|**2025-07-29**|**RL from Teacher-Model Refinement: Gradual Imitation Learning for Machine Translation**|Pengcheng He Team|[2507.22219](http://arxiv.org/abs/2507.22219)|null|
|**2025-07-29**|**A Nonlinear MPC Framework for Loco-Manipulation of Quadrupedal Robots with Non-Negligible Manipulator Dynamics**|Kaveh Akbari Hamed Team|[2507.22042](http://arxiv.org/abs/2507.22042)|null|
|**2025-07-29**|**From Seeing to Experiencing: Scaling Navigation Foundation Models with Reinforcement Learning**|Bolei Zhou Team|[2507.22028](http://arxiv.org/abs/2507.22028)|null|
|**2025-07-29**|**DISCOVERSE: Efficient Robot Simulation in Complex High-Fidelity Environments**|Guyue Zhou Team|[2507.21981](http://arxiv.org/abs/2507.21981)|null|
|**2025-07-29**|**MoDeSuite: Robot Learning Task Suite for Benchmarking Mobile Manipulation with Deformable Objects**|Joni Pajarinen Team|[2507.21796](http://arxiv.org/abs/2507.21796)|null|
|**2025-07-29**|**Pretraining a Unified PDDL Domain from Real-World Demonstrations for Generalizable Robot Task Planning**|Panpan Cai Team|[2507.21545](http://arxiv.org/abs/2507.21545)|null|
|**2025-07-29**|**Model Predictive Adversarial Imitation Learning for Planning from Observation**|Byron Boots Team|[2507.21533](http://arxiv.org/abs/2507.21533)|null|
|**2025-07-29**|**Retrieve-Augmented Generation for Speeding up Diffusion Policy without Additional Training**|Yutaka Matsuo Team|[2507.21452](http://arxiv.org/abs/2507.21452)|null|
|**2025-07-28**|**Fluidically Innervated Lattices Make Versatile and Durable Tactile Sensors**|Daniela Rus Team|[2507.21225](http://arxiv.org/abs/2507.21225)|null|
|**2025-07-28**|**FMimic: Foundation Models are Fine-grained Action Learners from Human Videos**|Yufeng Yue Team|[2507.20622](http://arxiv.org/abs/2507.20622)|null|
|**2025-07-28**|**Learning Physical Interaction Skills from Human Demonstrations**|Kwonjoon Lee Team|[2507.20445](http://arxiv.org/abs/2507.20445)|null|
|**2025-07-23**|**ERMV: Editing 4D Robotic Multi-view images to enhance embodied agents**|Hesheng Wang Team|[2507.17462](http://arxiv.org/abs/2507.17462)|null|
|**2025-07-23**|**Ctx2TrajGen: Traffic Context-Aware Microscale Vehicle Trajectories using Generative Adversarial Imitation Learning**|Byeongjoon Noh Team|[2507.17418](http://arxiv.org/abs/2507.17418)|null|
|**2025-07-23**|**Confounded Causal Imitation Learning with Instrumental Variables**|Zhi Geng Team|[2507.17309](http://arxiv.org/abs/2507.17309)|null|
|**2025-07-23**|**Prolonging Tool Life: Learning Skillful Use of General-purpose Tools through Lifespan-guided Reinforcement Learning**|Takamitsu Matsubara Team|[2507.17275](http://arxiv.org/abs/2507.17275)|null|
|**2025-07-23**|**Towards Human-level Intelligence via Human-like Whole-Body Manipulation**|Zhaohui An Team|[2507.17141](http://arxiv.org/abs/2507.17141)|null|
|**2025-07-22**|**Evaluating Uncertainty and Quality of Visual Language Action-enabled Robots**|Aitor Arrieta Team|[2507.17049](http://arxiv.org/abs/2507.17049)|null|
|**2025-07-19**|**Sensor-Space Based Robust Kinematic Control of Redundant Soft Manipulator by Learning**|Charlie C. L. Wang Team|[2507.16842](http://arxiv.org/abs/2507.16842)|null|
|**2025-07-22**|**ThinkAct: Vision-Language-Action Reasoning via Reinforced Visual Latent Planning**|Fu-En Yang Team|[2507.16815](http://arxiv.org/abs/2507.16815)|null|
|**2025-07-22**|**Equivariant Goal Conditioned Contrastive Reinforcement Learning**|Robert Platt Team|[2507.16139](http://arxiv.org/abs/2507.16139)|null|
|**2025-07-21**|**Look, Focus, Act: Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers**|Iman Soltani Team|[2507.15833](http://arxiv.org/abs/2507.15833)|null|
|**2025-07-21**|**Strong, Accurate, and Low-Cost Robot Manipulator**|Donghyun Kim Team|[2507.15693](http://arxiv.org/abs/2507.15693)|null|
|**2025-07-21**|**Being-H0: Vision-Language-Action Pretraining from Large-Scale Human Videos**|Zongqing Lu Team|[2507.15597](http://arxiv.org/abs/2507.15597)|null|
|**2025-07-22**|**GR-3 Technical Report**|Yichu Yang Team|[2507.15493](http://arxiv.org/abs/2507.15493)|null|
|**2025-07-20**|**Learning-Based Modeling of a Magnetically Steerable Soft Suction Device for Endoscopic Endonasal Interventions**|Eric Diller Team|[2507.15155](http://arxiv.org/abs/2507.15155)|null|
|**2025-07-20**|**Reinforcement Learning for Flow-Matching Policies**|Somayeh Sojoudi Team|[2507.15073](http://arxiv.org/abs/2507.15073)|null|
|**2025-07-20**|**Touch in the Wild: Learning Fine-Grained Manipulation with a Portable Visuo-Tactile Gripper**|Yunzhu Li Team|[2507.15062](http://arxiv.org/abs/2507.15062)|null|
|**2025-07-20**|**LLM-Enhanced Multi-Agent Reinforcement Learning with Expert Workflow for Real-Time P2P Energy Trading**|Lu Zhang Team|[2507.14995](http://arxiv.org/abs/2507.14995)|null|
|**2025-07-20**|**Heterogeneous object manipulation on nonlinear soft surface through linear controller**|Andres Faiña Team|[2507.14967](http://arxiv.org/abs/2507.14967)|null|
|**2025-07-20**|**KGN-Pro: Keypoint-Based Grasp Prediction through Probabilistic 2D-3D Correspondence Learning**|Guangyao Zhai Team|[2507.14820](http://arxiv.org/abs/2507.14820)|null|
|**2025-07-19**|**BT-TL-DMPs: A Novel Robot TAMP Framework Combining Behavior Tree, Temporal Logic and Dynamical Movement Primitives**|Yongchun Fang Team|[2507.14582](http://arxiv.org/abs/2507.14582)|null|
|**2025-07-18**|**Improving Low-Cost Teleoperation: Augmenting GELLO with Force**|Kai Arulkumaran Team|[2507.13602](http://arxiv.org/abs/2507.13602)|null|
|**2025-07-17**|**The Imitation Game: Turing Machine Imitator is Length Generalizable Reasoner**|Kai Chen Team|[2507.13332](http://arxiv.org/abs/2507.13332)|null|
|**2025-07-17**|**ZipMPC: Compressed Context-Dependent MPC Cost via Imitation Learning**|Johannes A. Stork Team|[2507.13088](http://arxiv.org/abs/2507.13088)|null|
|**2025-07-17**|**Generalist Bimanual Manipulation via Foundation Video Diffusion Models**|Jun Zhu Team|[2507.12898](http://arxiv.org/abs/2507.12898)|null|
|**2025-07-17**|**Supervised Fine Tuning on Curated Data is Reinforcement Learning (and can be improved)**|Jost Tobias Springenberg Team|[2507.12856](http://arxiv.org/abs/2507.12856)|null|
|**2025-07-17**|**DEMONSTRATE: Zero-shot Language to Robotic Control via Multi-task Demonstration Learning**|Melanie N. Zeilinger Team|[2507.12855](http://arxiv.org/abs/2507.12855)|null|
|**2025-07-17**|**Learning to Predict Mobile Robot Stability in Off-Road Environments**|Parikshit Maini Team|[2507.12731](http://arxiv.org/abs/2507.12731)|null|
|**2025-07-18**|**EgoVLA: Learning Vision-Language-Action Models from Egocentric Human Videos**|Xiaolong Wang Team|[2507.12440](http://arxiv.org/abs/2507.12440)|null|
|**2025-07-16**|**The Developments and Challenges towards Dexterous and Embodied Robotic Manipulation: A Survey**|Jiming Chen Team|[2507.11840](http://arxiv.org/abs/2507.11840)|null|
|**2025-07-15**|**Let's Think in Two Steps: Mitigating Agreement Bias in MLLMs with Self-Grounded Verification**|Zsolt Kira Team|[2507.11662](http://arxiv.org/abs/2507.11662)|null|
|**2025-07-15**|**MPC-based Coarse-to-Fine Motion Planning for Robotic Object Transportation in Cluttered Environments**|Steven Liu Team|[2507.11211](http://arxiv.org/abs/2507.11211)|null|
|**2025-07-15**|**A Robust Controller based on Gaussian Processes for Robotic Manipulators with Unknown Uncertainty**|Ruggero Carli Team|[2507.11170](http://arxiv.org/abs/2507.11170)|null|
|**2025-07-15**|**Enhancing Autonomous Manipulator Control with Human-in-loop for Uncertain Assembly Environments**|Kazuya Yoshida Team|[2507.11006](http://arxiv.org/abs/2507.11006)|null|
|**2025-07-15**|**Object-Centric Mobile Manipulation through SAM2-Guided Perception and Imitation Learning**|Jun Morimoto Team|[2507.10899](http://arxiv.org/abs/2507.10899)|null|
|**2025-07-14**|**Versatile and Generalizable Manipulation via Goal-Conditioned Reinforcement Learning with Grounded Object Detection**|Colin Bellinger Team|[2507.10814](http://arxiv.org/abs/2507.10814)|null|
|**2025-07-14**|**rt-RISeg: Real-Time Model-Free Robot Interactive Segmentation for Active Instance-Level Object Understanding**|Kaiyu Hang Team|[2507.10776](http://arxiv.org/abs/2507.10776)|null|
|**2025-07-14**|**A New Dataset and Performance Benchmark for Real-time Spacecraft Segmentation in Onboard Flight Computers**|Arko Barman Team|[2507.10775](http://arxiv.org/abs/2507.10775)|null|
|**2025-07-14**|**Vision Language Action Models in Robotic Manipulation: A Systematic Review**|Irfan Hussain Team|[2507.10672](http://arxiv.org/abs/2507.10672)|null|
|**2025-07-16**|**GHPO: Adaptive Guidance for Stable and Efficient LLM Reinforcement Learning**|Dandan Tu Team|[2507.10628](http://arxiv.org/abs/2507.10628)|null|
|**2025-07-14**|**MP1: Mean Flow Tames Policy Learning in 1-step for Robotic Manipulation**|Mengyuan Liu Team|[2507.10543](http://arxiv.org/abs/2507.10543)|null|
|**2025-07-14**|**Prompt Informed Reinforcement Learning for Visual Coverage Path Planning**|Venkat Margapuri Team|[2507.10284](http://arxiv.org/abs/2507.10284)|null|
|**2025-07-14**|**Should We Ever Prefer Decision Transformer for Offline Reinforcement Learning?**|Keith Ross Team|[2507.10174](http://arxiv.org/abs/2507.10174)|null|
|**2025-07-16**|**MTF-Grasp: A Multi-tier Federated Learning Approach for Robotic Grasping**|Monowar Bhuyan Team|[2507.10158](http://arxiv.org/abs/2507.10158)|null|
|**2025-07-13**|**Learning to Control Dynamical Agents via Spiking Neural Networks and Metropolis-Hastings Sampling**|Ali Al-Zawqari Team|[2507.09540](http://arxiv.org/abs/2507.09540)|null|
|**2025-07-13**|**Self-supervised Pretraining for Integrated Prediction and Planning of Automated Vehicles**|Keqiang Li Team|[2507.09537](http://arxiv.org/abs/2507.09537)|null|
|**2025-07-13**|**SegVec3D: A Method for Vector Embedding of 3D Objects Oriented Towards Robot manipulation**|Boyu Wang Team|[2507.09459](http://arxiv.org/abs/2507.09459)|null|
|**2025-07-12**|**DAA*: Deep Angular A Star for Image-based Path Planning**|Zhiwei Xu Team|[2507.09305](http://arxiv.org/abs/2507.09305)|null|
|**2025-07-15**|**Learning and Transferring Better with Depth Information in Visual Reinforcement Learning**|Jingdong Zhao Team|[2507.09180](http://arxiv.org/abs/2507.09180)|null|
|**2025-07-12**|**PRAG: Procedural Action Generator**|Karla Stepanova Team|[2507.09167](http://arxiv.org/abs/2507.09167)|null|
|**2025-07-12**|**Towards Human-level Dexterity via Robot Learning**|Gagan Khandate Team|[2507.09117](http://arxiv.org/abs/2507.09117)|null|
|**2025-07-11**|**Imitation Learning in Continuous Action Spaces: Mitigating Compounding Error without Interaction**|Max Simchowitz Team|[2507.09061](http://arxiv.org/abs/2507.09061)|null|
|**2025-07-11**|**Behavioral Exploration: Learning to Explore via In-Context Adaptation**|Sergey Levine Team|[2507.09041](http://arxiv.org/abs/2507.09041)|null|
|**2025-07-11**|**Learning human-to-robot handovers through 3D scene reconstruction**|Changjae Oh Team|[2507.08726](http://arxiv.org/abs/2507.08726)|null|
|**2025-07-11**|**Learning Robust Motion Skills via Critical Adversarial Attacks for Humanoid Robots**|Yue Gao Team|[2507.08303](http://arxiv.org/abs/2507.08303)|null|
|**2025-07-11**|**CL3R: 3D Reconstruction and Contrastive Learning for Enhanced Robotic Manipulation Representations**|He Wang Team|[2507.08262](http://arxiv.org/abs/2507.08262)|null|
|**2025-07-10**|**Imitation Learning for Obstacle Avoidance Using End-to-End CNN-Based Sensor Fusion**|Raafat E. Shalaby Team|[2507.08112](http://arxiv.org/abs/2507.08112)|null|
|**2025-07-15**|**EXPO: Stable Reinforcement Learning with Expressive Policies**|Chelsea Finn Team|[2507.07986](http://arxiv.org/abs/2507.07986)|null|
|**2025-07-15**|**Reinforcement Learning with Action Chunking**|Sergey Levine Team|[2507.07969](http://arxiv.org/abs/2507.07969)|null|
|**2025-07-09**|**Self-Wearing Adaptive Garments via Soft Robotic Unfurling**|Allison M. Okamura Team|[2507.07221](http://arxiv.org/abs/2507.07221)|null|
|**2025-07-09**|**Hierarchical Reinforcement Learning for Articulated Tool Manipulation with Multifingered Hand**|Xinjun Sheng Team|[2507.06822](http://arxiv.org/abs/2507.06822)|null|
|**2025-07-09**|**Learning safe, constrained policies via imitation learning: Connection to Probabilistic Inference and a Naive Algorithm**|George A. Vouros Team|[2507.06780](http://arxiv.org/abs/2507.06780)|null|
|**2025-07-13**|**Spatial-Temporal Aware Visuomotor Diffusion Policy Learning**|Yanwei Fu Team|[2507.06710](http://arxiv.org/abs/2507.06710)|null|
|**2025-07-09**|**Value from Observations: Towards Large-Scale Imitation Learning via Self-Improvement**|Martin Riedmiller Team|[2507.06701](http://arxiv.org/abs/2507.06701)|null|
|**2025-07-09**|**Goal-Oriented Skill Abstraction for Offline Multi-Task Reinforcement Learning**|Jian Cheng Team|[2507.06628](http://arxiv.org/abs/2507.06628)|null|
|**2025-07-09**|**Q-STAC: Q-Guided Stein Variational Model Predictive Actor-Critic**|Fabio Ramos Team|[2507.06625](http://arxiv.org/abs/2507.06625)|null|
|**2025-07-09**|**Token Bottleneck: One Token to Remember Dynamics**|Sangdoo Yun Team|[2507.06543](http://arxiv.org/abs/2507.06543)|null|
|**2025-07-08**|**Learning to Evaluate Autonomous Behaviour in Human-Robot Interaction**|Alessio Del Bue Team|[2507.06404](http://arxiv.org/abs/2507.06404)|null|
|**2025-07-08**|**EC-Flow: Enabling Versatile Robotic Manipulation from Action-Unlabeled Videos via Embodiment-Centric Flow**|Liang Wang Team|[2507.06224](http://arxiv.org/abs/2507.06224)|null|
|**2025-07-08**|**Is Diversity All You Need for Scalable Robotic Manipulation?**|Hongyang Li Team|[2507.06219](http://arxiv.org/abs/2507.06219)|null|
|**2025-07-08**|**Fast Bilateral Teleoperation and Imitation Learning Using Sensorless Force Control via Accurate Dynamics Model**|Toshiaki Tsuji Team|[2507.06174](http://arxiv.org/abs/2507.06174)|null|
|**2025-07-08**|**Learning Agile Tensile Perching for Aerial Robots from Demonstrations**|Basaran Bahadir Kocer Team|[2507.06172](http://arxiv.org/abs/2507.06172)|null|
|**2025-07-08**|**SCCRUB: Surface Cleaning Compliant Robot Utilizing Bristles**|Jeffrey Ian Lipton Team|[2507.06053](http://arxiv.org/abs/2507.06053)|null|
|**2025-07-08**|**LeAD: The LLM Enhanced Planning System Converged with End-to-end Autonomous Driving**|Jian Sun Team|[2507.05754](http://arxiv.org/abs/2507.05754)|null|
|**2025-07-08**|**Hybrid Diffusion Policies with Projective Geometric Algebra for Efficient Robot Manipulation Learning**|Daniel Rakita Team|[2507.05695](http://arxiv.org/abs/2507.05695)|null|
|**2025-07-08**|**Integrating Diffusion-based Multi-task Learning with Online Reinforcement Learning for Robust Quadruped Robot Control**|Bin Liang Team|[2507.05674](http://arxiv.org/abs/2507.05674)|null|
|**2025-07-08**|**Stable Tracking-in-the-Loop Control of Cable-Driven Surgical Manipulators under Erroneous Kinematic Chains**|Michael C. Yip Team|[2507.05663](http://arxiv.org/abs/2507.05663)|null|
|**2025-07-08**|**DreamGrasp: Zero-Shot 3D Multi-Object Reconstruction from Partial-View Images for Robotic Manipulation**|Frank Chongwoo Park Team|[2507.05627](http://arxiv.org/abs/2507.05627)|null|
|**2025-07-07**|**Gaussian Process-Based Active Exploration Strategies in Vision and Touch**|Nadia Figueroa Team|[2507.05522](http://arxiv.org/abs/2507.05522)|null|
|**2025-07-07**|**A Careful Examination of Large Behavior Models for Multitask Dexterous Manipulation**|Russ Tedrake Team|[2507.05331](http://arxiv.org/abs/2507.05331)|null|
|**2025-07-07**|**VOTE: Vision-Language-Action Optimization with Trajectory Ensemble Voting**|Yanzhi Wang Team|[2507.05116](http://arxiv.org/abs/2507.05116)|null|
|**2025-07-07**|**When Imitation Learning Outperforms Reinforcement Learning in Surgical Action Planning**|Sebastien Ourselin Team|[2507.05011](http://arxiv.org/abs/2507.05011)|null|
|**2025-07-07**|**Training-free Generation of Temporally Consistent Rewards from VLMs**|Jian Tang Team|[2507.04789](http://arxiv.org/abs/2507.04789)|null|
|**2025-07-07**|**DRAE: Dynamic Retrieval-Augmented Expert Networks for Lifelong Learning and Task Adaptation in Robotics**|Mingsheng Shang Team|[2507.04661](http://arxiv.org/abs/2507.04661)|null|
|**2025-07-07**|**PRISM: Pointcloud Reintegrated Inference via Segmentation and Cross-attention for Manipulation**|Chee-Meng Chew Team|[2507.04633](http://arxiv.org/abs/2507.04633)|null|
|**2025-07-07**|**Learning Robust Stereo Matching in the Wild with Selective Mixture-of-Experts**|Junjie Hu Team|[2507.04631](http://arxiv.org/abs/2507.04631)|null|
|**2025-07-06**|**VLM-TDP: VLM-guided Trajectory-conditioned Diffusion Policy for Robust Long-Horizon Manipulation**|Lei Han Team|[2507.04524](http://arxiv.org/abs/2507.04524)|null|
|**2025-07-06**|**DreamVLA: A Vision-Language-Action Model Dreamed with Comprehensive World Knowledge**|Xin Jin Team|[2507.04447](http://arxiv.org/abs/2507.04447)|null|
|**2025-07-06**|**Wavelet Policy: Lifting Scheme for Policy Learning in Long-Horizon Tasks**|Yi Fang Team|[2507.04331](http://arxiv.org/abs/2507.04331)|null|
|**2025-07-05**|**Are Learning-Based Approaches Ready for Real-World Indoor Navigation? A Case for Imitation Learning**|Sebastian Houben Team|[2507.04086](http://arxiv.org/abs/2507.04086)|null|
|**2025-07-05**|**Breaking Imitation Bottlenecks: Reinforced Diffusion Powers Diverse Trajectory Generation**|Yadan Luo Team|[2507.04049](http://arxiv.org/abs/2507.04049)|null|
|**2025-07-08**|**RwoR: Generating Robot Demonstrations from Human Hand Collection for Policy Learning without Robot**|Hao Dong Team|[2507.03930](http://arxiv.org/abs/2507.03930)|null|
|**2025-07-05**|**DK-RRT: Deep Koopman RRT for Collision-Aware Motion Planning of Space Manipulators in Dynamic Debris Environments**|Dezhi Yu Team|[2507.03878](http://arxiv.org/abs/2507.03878)|null|
|**2025-07-04**|**Dexterous Teleoperation of 20-DoF ByteDexter Hand via Human Motion Retargeting**|Zeyu Ren Team|[2507.03227](http://arxiv.org/abs/2507.03227)|null|
|**2025-07-02**|**cVLA: Towards Efficient Camera-Space VLAs**|Thomas Brox Team|[2507.02190](http://arxiv.org/abs/2507.02190)|null|
|**2025-07-02**|**Towards Bio-Inspired Robotic Trajectory Planning via Self-Supervised RNN**|Matthias Kerzel Team|[2507.02171](http://arxiv.org/abs/2507.02171)|null|
|**2025-07-02**|**TypeTele: Releasing Dexterity in Teleoperation by Dexterous Manipulation Types**|Wei-Shi Zheng Team|[2507.01857](http://arxiv.org/abs/2507.01857)|null|
|**2025-07-02**|**S3D: A Spatial Steerable Surgical Drilling Framework for Robotic Spinal Fixation Procedures**|Farshid Alambeigi Team|[2507.01779](http://arxiv.org/abs/2507.01779)|null|
|**2025-07-03**|**TriVLA: A Triple-System-Based Unified Vision-Language-Action Model for General Robot Control**|Yanwei Fu Team|[2507.01424](http://arxiv.org/abs/2507.01424)|null|
|**2025-07-01**|**Search-Based Robot Motion Planning With Distance-Based Adaptive Motion Primitives**|Bakir Lacevic Team|[2507.01198](http://arxiv.org/abs/2507.01198)|null|
|**2025-07-01**|**Imitation Learning for Satellite Attitude Control under Unknown Perturbations**|Xiaoli Bai Team|[2507.01161](http://arxiv.org/abs/2507.01161)|null|
|**2025-07-01**|**SonoGym: High Performance Simulation for Challenging Surgical Tasks with Robotic Ultrasound**|Philipp Fürnstahl Team|[2507.01152](http://arxiv.org/abs/2507.01152)|null|
|**2025-07-01**|**Geometry-aware 4D Video Generation for Robot Manipulation**|Shuran Song Team|[2507.01099](http://arxiv.org/abs/2507.01099)|null|
|**2025-07-01**|**DexWrist: A Robotic Wrist for Constrained and Dynamic Manipulation**|Pulkit Agrawal Team|[2507.01008](http://arxiv.org/abs/2507.01008)|null|
|**2025-07-04**|**Robotic Manipulation by Imitating Generated Videos Without Physical Demonstrations**|Yunzhu Li Team|[2507.00990](http://arxiv.org/abs/2507.00990)|null|
|**2025-07-01**|**HumanoidGen: Data Generation for Bimanual Dexterous Manipulation via LLM Reasoning**|Chenjia Bai Team|[2507.00833](http://arxiv.org/abs/2507.00833)|null|
|**2025-07-01**|**Learning Steerable Imitation Controllers from Unstructured Animal Motions**|Stelian Coros Team|[2507.00677](http://arxiv.org/abs/2507.00677)|null|
|**2025-07-01**|**RoboEval: Where Robotic Manipulation Meets Structured and Scalable Evaluation**|Siddhartha Srinivasa Team|[2507.00435](http://arxiv.org/abs/2507.00435)|null|
|**2025-07-01**|**Adapt Your Body: Mitigating Proprioception Shifts in Imitation Learning**|Yang Gao Team|[2506.23944](http://arxiv.org/abs/2506.23944)|null|
|**2025-06-30**|**World4Omni: A Zero-Shot Framework from Image Generation World Model to Robotic Manipulation**|Lin Shao Team|[2506.23919](http://arxiv.org/abs/2506.23919)|null|
|**2025-06-30**|**Advancing Learnable Multi-Agent Pathfinding Solvers with Active Fine-Tuning**|Alexey Skrynnik Team|[2506.23793](http://arxiv.org/abs/2506.23793)|null|
|**2025-06-30**|**PAC Bench: Do Foundation Models Understand Prerequisites for Executing Manipulation Policies?**|Ransalu Senanayake Team|[2506.23725](http://arxiv.org/abs/2506.23725)|null|
|**2025-07-04**|**ParticleFormer: A 3D Point Cloud World Model for Multi-Object, Multi-Material Robotic Manipulation**|Mac Schwager Team|[2506.23126](http://arxiv.org/abs/2506.23126)|null|
|**2025-06-29**|**Learning Motion Skills with Adaptive Assistive Curriculum Force in Humanoid Robots**|Yue Gao Team|[2506.23125](http://arxiv.org/abs/2506.23125)|null|
|**2025-06-28**|**Hierarchical Vision-Language Planning for Multi-Step Humanoid Manipulation**|Navid Azizan Team|[2506.22827](http://arxiv.org/abs/2506.22827)|null|
|**2025-06-28**|**SPI-BoTER: Error Compensation for Industrial Robots via Sparse Attention Masking and Hybrid Loss with Spatial-Physical Information**|Yuqiang Wu Team|[2506.22788](http://arxiv.org/abs/2506.22788)|null|
|**2025-06-28**|**Learning Efficient Robotic Garment Manipulation with Standardization**|Bin He Team|[2506.22769](http://arxiv.org/abs/2506.22769)|null|
|**2025-06-28**|**RoboPearls: Editable Video Simulation for Robot Manipulation**|Xiaodan Liang Team|[2506.22756](http://arxiv.org/abs/2506.22756)|null|
|**2025-06-27**|**Spherical Pendulum with Quad-Rotor Thrust Vectoring Actuation -- A Novel Mechatronics and Control Benchmark Platform**|Tsu-Chin Tsao Team|[2506.22410](http://arxiv.org/abs/2506.22410)|null|
|**2025-06-27**|**RoboEnvision: A Long-Horizon Video Generation Model for Multi-Task Robot Manipulation**|Abhinav Valada Team|[2506.22007](http://arxiv.org/abs/2506.22007)|null|
|**2025-06-26**|**Experimental investigation of pose informed reinforcement learning for skid-steered visual navigation**|Venkat Krovi Team|[2506.21732](http://arxiv.org/abs/2506.21732)|null|
|**2025-06-24**|**Ark: An Open-source Python-based Framework for Robot Learning**|Haitham Bou-Ammar Team|[2506.21628](http://arxiv.org/abs/2506.21628)|null|
|**2025-06-24**|**FrankenBot: Brain-Morphic Modular Orchestration for Robotic Manipulation with Vision-Language Models**|Huiping Zhuang Team|[2506.21627](http://arxiv.org/abs/2506.21627)|null|
|**2025-06-26**|**ACTLLM: Action Consistency Tuned Large Language Model**|Chenliang Xu Team|[2506.21250](http://arxiv.org/abs/2506.21250)|null|
|**2025-07-02**|**World-aware Planning Narratives Enhance Large Vision-Language Model Planner**|Xipeng Qiu Team|[2506.21230](http://arxiv.org/abs/2506.21230)|null|
|**2025-06-26**|**UAIbot: Beginner-friendly web-based simulator for interactive robotics learning and research**|Vinicius Mariano Gonçalves Team|[2506.21178](http://arxiv.org/abs/2506.21178)|null|
|**2025-06-26**|**Knowledge-Driven Imitation Learning: Enabling Generalization Across Diverse Conditions**|Cewu Lu Team|[2506.21057](http://arxiv.org/abs/2506.21057)|null|
|**2025-06-26**|**Parallels Between VLA Model Post-Training and Human Motor Learning: Progress, Challenges, and Trends**|Zeng-Guang Hou Team|[2506.20966](http://arxiv.org/abs/2506.20966)|null|
|**2025-06-25**|**Learning-Based Distance Estimation for 360° Single-Sensor Setups**|Andreas Zell Team|[2506.20586](http://arxiv.org/abs/2506.20586)|null|
|**2025-06-25**|**Learn to Position -- A Novel Meta Method for Robotic Positioning**|Xiaoming Tao Team|[2506.20445](http://arxiv.org/abs/2506.20445)|null|
|**2025-06-25**|**Beyond-Expert Performance with Limited Demonstrations: Efficient Imitation Learning with Double Exploration**|Quanquan Gu Team|[2506.20307](http://arxiv.org/abs/2506.20307)|null|
|**2025-06-24**|**Unified Vision-Language-Action Model**|Zhaoxiang Zhang Team|[2506.19850](http://arxiv.org/abs/2506.19850)|null|
|**2025-06-24**|**T-Rex: Task-Adaptive Spatial Representation Extraction for Robotic Manipulation with Vision-Language Models**|Qingyao Wu Team|[2506.19498](http://arxiv.org/abs/2506.19498)|null|
|**2025-06-24**|**Is an object-centric representation beneficial for robotic manipulation ?**|Liming Chen Team|[2506.19408](http://arxiv.org/abs/2506.19408)|null|
|**2025-06-24**|**Robotic Perception with a Large Tactile-Vision-Language Model for Physical Property Inference**|Nutan Chen Team|[2506.19303](http://arxiv.org/abs/2506.19303)|null|
|**2025-06-25**|**AnchorDP3: 3D Affordance Guided Sparse Diffusion Policy for Robotic Manipulation**|Hui Shen Team|[2506.19269](http://arxiv.org/abs/2506.19269)|null|
|**2025-06-24**|**Robust Behavior Cloning Via Global Lipschitz Regularization**|Sean B. Andersson Team|[2506.19250](http://arxiv.org/abs/2506.19250)|null|
|**2025-06-23**|**CUPID: Curating Data your Robot Loves with Influence Functions**|Jeannette Bohg Team|[2506.19121](http://arxiv.org/abs/2506.19121)|null|
|**2025-06-23**|**Multimodal Anomaly Detection with a Mixture-of-Experts**|Dongheui Lee Team|[2506.19077](http://arxiv.org/abs/2506.19077)|null|
|**2025-06-25**|**FORTE: Tactile Force and Slip Sensing on Compliant Fingers for Delicate Manipulation**|Lillian Chin Team|[2506.18960](http://arxiv.org/abs/2506.18960)|null|
|**2025-06-23**|**RAG-6DPose: Retrieval-Augmented 6D Pose Estimation via Leveraging CAD as Knowledge Base**|Xiangyang Xue Team|[2506.18856](http://arxiv.org/abs/2506.18856)|null|
|**2025-06-23**|**SViP: Sequencing Bimanual Visuomotor Policies with Object-Centric Motion Primitives**|Jia Pan Team|[2506.18825](http://arxiv.org/abs/2506.18825)|null|
|**2025-06-23**|**Learning Point Correspondences In Radar 3D Point Clouds For Radar-Inertial Odometry**|Jan Steinbrener Team|[2506.18580](http://arxiv.org/abs/2506.18580)|null|
|**2025-06-23**|**Robots and Children that Learn Together : Improving Knowledge Retention by Teaching Peer-Like Interactive Robots**|Alessandro Di Nuovo Team|[2506.18365](http://arxiv.org/abs/2506.18365)|null|
|**2025-06-23**|**Robotic Manipulation of a Rotating Chain with Bottom End Fixed**|Quang-Cuong Pham Team|[2506.18355](http://arxiv.org/abs/2506.18355)|null|
|**2025-06-23**|**Sharpening the Spear: Adaptive Expert-Guided Adversarial Attack Against DRL-based Autonomous Driving Policies**|Xiaolin Chang Team|[2506.18304](http://arxiv.org/abs/2506.18304)|null|
|**2025-06-23**|**Learning Approach to Efficient Vision-based Active Tracking of a Flying Target by an Unmanned Aerial Vehicle**|Souma Chowdhury Team|[2506.18264](http://arxiv.org/abs/2506.18264)|null|
|**2025-06-22**|**RoboTwin 2.0: A Scalable Data Generator and Benchmark with Strong Domain Randomization for Robust Bimanual Robotic Manipulation**|Yao Mu Team|[2506.18088](http://arxiv.org/abs/2506.18088)|null|
|**2025-06-21**|**RLRC: Reinforcement Learning-based Recovery for Compressed Vision-Language-Action Models**|Xiao Li Team|[2506.17639](http://arxiv.org/abs/2506.17639)|null|
|**2025-06-21**|**Imitation Learning for Active Neck Motion Enabling Robot Manipulation beyond the Field of View**|Yasuo Kuniyoshi Team|[2506.17624](http://arxiv.org/abs/2506.17624)|null|
|**2025-06-20**|**Kinematic Model Optimization via Differentiable Contact Manifold for In-Space Manipulation**|Satyandra K. Gupta Team|[2506.17458](http://arxiv.org/abs/2506.17458)|null|
|**2025-06-20**|**Monocular One-Shot Metric-Depth Alignment for RGB-Based Robot Grasping**|Jingjin Yu Team|[2506.17110](http://arxiv.org/abs/2506.17110)|null|
|**2025-06-24**|**Learning Accurate Whole-body Throwing with High-frequency Residual Policy and Pullback Tube Acceleration**|Marco Hutter Team|[2506.16986](http://arxiv.org/abs/2506.16986)|null|
|**2025-06-20**|**Compliant Residual DAgger: Improving Real-World Contact-Rich Manipulation with Human Corrections**|Shuran Song Team|[2506.16685](http://arxiv.org/abs/2506.16685)|null|
|**2025-06-19**|**CodeDiffuser: Attention-Enhanced Diffusion Policy via VLM-Generated Code for Instruction Ambiguity**|Yunzhu Li Team|[2506.16652](http://arxiv.org/abs/2506.16652)|null|
|**2025-06-19**|**Reimagination with Test-time Observation Interventions: Distractor-Robust World Model Predictions for Visual Model Predictive Control**|Ran Tian Team|[2506.16565](http://arxiv.org/abs/2506.16565)|null|
|**2025-06-19**|**An Optimization-Augmented Control Framework for Single and Coordinated Multi-Arm Robotic Manipulation**|Ozgur S. Oguz Team|[2506.16555](http://arxiv.org/abs/2506.16555)|null|
|**2025-06-19**|**Human2LocoMan: Learning Versatile Quadrupedal Manipulation with Human Pretraining**|Ding Zhao Team|[2506.16475](http://arxiv.org/abs/2506.16475)|null|
|**2025-06-19**|**GoalLadder: Incremental Goal Discovery with Vision-Language Models**|Shimon Whiteson Team|[2506.16396](http://arxiv.org/abs/2506.16396)|null|
|**2025-06-19**|**CapsDT: Diffusion-Transformer for Capsule Robot Manipulation**|Hongliang Ren Team|[2506.16263](http://arxiv.org/abs/2506.16263)|null|
|**2025-06-19**|**ControlVLA: Few-shot Object-centric Adaptation for Pre-trained Vision-Language-Action Models**|Siyuan Huang Team|[2506.16211](http://arxiv.org/abs/2506.16211)|null|
|**2025-06-19**|**FlowRAM: Grounding Flow Matching Policy with Region-Aware Mamba Framework for Robotic Manipulation**|Wei Tang Team|[2506.16201](http://arxiv.org/abs/2506.16201)|null|
|**2025-06-19**|**ViTacFormer: Learning Cross-Modal Representation for Visuo-Tactile Dexterous Manipulation**|Jitendra Malik Team|[2506.15953](http://arxiv.org/abs/2506.15953)|null|
|**2025-06-18**|**Learning from Planned Data to Improve Robotic Pick-and-Place Planning Efficiency**|Kensuke Harada Team|[2506.15920](http://arxiv.org/abs/2506.15920)|null|
|**2025-06-18**|**Improving Robotic Manipulation: Techniques for Object Pose Estimation, Accommodating Positional Uncertainty, and Disassembly Tasks from Examples**|Viral Rasik Galaiya Team|[2506.15865](http://arxiv.org/abs/2506.15865)|null|
|**2025-06-18**|**Vision in Action: Learning Active Perception from Human Demonstrations**|Shuran Song Team|[2506.15666](http://arxiv.org/abs/2506.15666)|null|
|**2025-06-18**|**Learning Task-Agnostic Skill Bases to Uncover Motor Primitives in Animal Behaviors**|Anqi Wu Team|[2506.15190](http://arxiv.org/abs/2506.15190)|null|
|**2025-06-18**|**Robust Instant Policy: Leveraging Student's t-Regression Model for Robust In-context Imitation Learning of Robot Manipulation**|Yukiyasu Domae Team|[2506.15157](http://arxiv.org/abs/2506.15157)|null|
|**2025-06-18**|**TACT: Humanoid Whole-body Contact Manipulation through Deep Imitation Learning with Tactile Modality**|Eiichi Yoshida Team|[2506.15146](http://arxiv.org/abs/2506.15146)|null|
|**2025-06-17**|**RobotSmith: Generative Robotic Tool Design for Acquisition of Complex Manipulation Skills**|Chuang Gan Team|[2506.14763](http://arxiv.org/abs/2506.14763)|null|
|**2025-06-17**|**Tactile Beyond Pixels: Multisensory Touch Representations for Robot Manipulation**|Mustafa Mukadam Team|[2506.14754](http://arxiv.org/abs/2506.14754)|null|
|**2025-06-17**|**SENIOR: Efficient Query Selection and Preference-Guided Exploration in Preference-based Reinforcement Learning**|Shuo Wang Team|[2506.14648](http://arxiv.org/abs/2506.14648)|null|
|**2025-06-17**|**Latent Action Diffusion for Cross-Embodiment Manipulation**|Robert K. Katzschmann Team|[2506.14608](http://arxiv.org/abs/2506.14608)|null|
|**2025-06-19**|**ClutterDexGrasp: A Sim-to-Real System for General Dexterous Grasping in Cluttered Scenes**|Hao Dong Team|[2506.14317](http://arxiv.org/abs/2506.14317)|null|
|**2025-06-17**|**Steering Robots with Inference-Time Interactions**|Yanwei Wang Team|[2506.14287](http://arxiv.org/abs/2506.14287)|null|
|**2025-06-17**|**AMPLIFY: Actionless Motion Priors for Robot Learning from Videos**|Animesh Garg Team|[2506.14198](http://arxiv.org/abs/2506.14198)|null|
|**2025-06-17**|**Non-Overlap-Aware Egocentric Pose Estimation for Collaborative Perception in Connected Autonomy**|Peng Gao Team|[2506.14180](http://arxiv.org/abs/2506.14180)|null|
|**2025-06-17**|**GAF: Gaussian Action Field as a Dvnamic World Model for Robotic Mlanipulation**|Yebin Liu Team|[2506.14135](http://arxiv.org/abs/2506.14135)|null|
|**2025-06-16**|**ATK: Automatic Task-driven Keypoint Selection for Robust Policy Learning**|Abhishek Gupta Team|[2506.13867](http://arxiv.org/abs/2506.13867)|null|
|**2025-06-16**|**Touch begins where vision ends: Generalizable policies for contact-rich manipulation**|Raunaq Bhirangi Team|[2506.13762](http://arxiv.org/abs/2506.13762)|null|
|**2025-06-16**|**Prompting with the Future: Open-World Model Predictive Control with Interactive Digital Twins**|Wei-Chiu Ma Team|[2506.13761](http://arxiv.org/abs/2506.13761)|null|
|**2025-06-16**|**What Matters in Learning from Large-Scale Datasets for Robot Manipulation**|Danfei Xu Team|[2506.13536](http://arxiv.org/abs/2506.13536)|null|
|**2025-06-16**|**A Survey on Imitation Learning for Contact-Rich Tasks in Robotics**|Arash Ajoudani Team|[2506.13498](http://arxiv.org/abs/2506.13498)|null|
|**2025-06-16**|**Learning Swing-up Maneuvers for a Suspended Aerial Manipulation Platform in a Hierarchical Control Framework**|Christian Ott Team|[2506.13478](http://arxiv.org/abs/2506.13478)|null|
|**2025-06-16**|**VLM-SFD: VLM-Assisted Siamese Flow Diffusion Framework for Dual-Arm Cooperative Manipulation**|Wei Pan Team|[2506.13428](http://arxiv.org/abs/2506.13428)|null|
|**2025-06-15**|**SP-VLA: A Joint Model Scheduling and Token Pruning Approach for VLA Model Acceleration**|Wenwu Zhu Team|[2506.12723](http://arxiv.org/abs/2506.12723)|null|
|**2025-06-15**|**Adapting by Analogy: OOD Generalization of Visuomotor Policies via Functional Correspondence**|Andrea Bajcsy Team|[2506.12678](http://arxiv.org/abs/2506.12678)|null|
|**2025-06-15**|**Goal-based Self-Adaptive Generative Adversarial Imitation Learning (Goal-SAGAIL) for Multi-goal Robotic Manipulation Tasks**|George Vogiatzis Team|[2506.12676](http://arxiv.org/abs/2506.12676)|null|
|**2025-06-14**|**AntiGrounding: Lifting Robotic Actions into VLM Representation Space for Decision Making**|Qingyao Wu Team|[2506.12374](http://arxiv.org/abs/2506.12374)|null|
|**2025-06-13**|**Role of Uncertainty in Model Development and Control Design for a Manufacturing Process**|Francis Assadian Team|[2506.12273](http://arxiv.org/abs/2506.12273)|null|
|**2025-06-13**|**SAIL: Faster-than-Demonstration Execution of Imitation Learning Policies**|Danfei Xu Team|[2506.11948](http://arxiv.org/abs/2506.11948)|null|
|**2025-06-13**|**mimic-one: a Scalable Model Recipe for General Purpose Robot Dexterity**|Robert K. Katzschmann Team|[2506.11916](http://arxiv.org/abs/2506.11916)|null|
|**2025-06-13**|**ExoStart: Efficient learning for dexterous manipulation with sensorized exoskeleton demonstrations**|Maria Bauza Villalonga Team|[2506.11775](http://arxiv.org/abs/2506.11775)|null|
|**2025-06-13**|**Control Architecture and Design for a Multi-robotic Visual Servoing System in Automated Manufacturing Environment**|Rongfei Li Team|[2506.11387](http://arxiv.org/abs/2506.11387)|null|
|**2025-06-12**|**Influence Functions for Data Attribution in Linear System Identification and LQR Control**|Dongmei Chen Team|[2506.11293](http://arxiv.org/abs/2506.11293)|null|
|**2025-06-12**|**Gondola: Grounded Vision Language Planning for Generalizable Robotic Manipulation**|Cordelia Schmid Team|[2506.11261](http://arxiv.org/abs/2506.11261)|null|
|**2025-06-12**|**Eye, Robot: Learning to Look to Act with a BC-RL Perception-Action Loop**|Angjoo Kanazawa Team|[2506.10968](http://arxiv.org/abs/2506.10968)|null|
|**2025-06-12**|**GENMANIP: LLM-driven Simulation for Generalizable Instruction-Following Manipulation**|Jiangmiao Pang Team|[2506.10966](http://arxiv.org/abs/2506.10966)|null|
|**2025-06-12**|**Human-Robot Navigation using Event-based Cameras and Reinforcement Learning**|Rodrigo Verschae Team|[2506.10790](http://arxiv.org/abs/2506.10790)|null|
|**2025-06-12**|**Demonstrating Multi-Suction Item Picking at Scale via Multi-Modal Learning of Pick Success**|Kapil Katyal Team|[2506.10359](http://arxiv.org/abs/2506.10359)|null|
|**2025-06-11**|**Innovative Adaptive Imaged Based Visual Servoing Control of 6 DoFs Industrial Robot Manipulators**|Francis Assadian Team|[2506.10240](http://arxiv.org/abs/2506.10240)|null|
|**2025-06-11**|**One For All: LLM-based Heterogeneous Mission Planning in Precision Agriculture**|Stefano Carpin Team|[2506.10106](http://arxiv.org/abs/2506.10106)|null|
|**2025-06-11**|**eFlesh: Highly customizable Magnetic Touch Sensing using Cut-Cell Microstructures**|Raunaq Bhirangi Team|[2506.09994](http://arxiv.org/abs/2506.09994)|null|
|**2025-06-11**|**Chain-of-Action: Trajectory Autoregressive Modeling for Robotic Manipulation**|Xiao Ma Team|[2506.09990](http://arxiv.org/abs/2506.09990)|null|
|**2025-06-11**|**From Intention to Execution: Probing the Generalization Boundaries of Vision-Language-Action Models**|Chen Feng Team|[2506.09930](http://arxiv.org/abs/2506.09930)|null|
|**2025-06-11**|**Reinforced Refinement with Self-Aware Expansion for End-to-End Autonomous Driving**|Chen Lv Team|[2506.09800](http://arxiv.org/abs/2506.09800)|null|
|**2025-06-11**|**CHIP: A multi-sensor dataset for 6D pose estimation of chairs in industrial settings**|Davide Boscaini Team|[2506.09699](http://arxiv.org/abs/2506.09699)|null|
|**2025-06-11**|**Advances on Affordable Hardware Platforms for Human Demonstration Acquisition in Agricultural Applications**|Néstor García Team|[2506.09494](http://arxiv.org/abs/2506.09494)|null|
|**2025-06-11**|**DCIRNet: Depth Completion with Iterative Refinement for Dexterous Grasping of Transparent and Reflective Objects**|Hong Liu Team|[2506.09491](http://arxiv.org/abs/2506.09491)|null|
|**2025-06-11**|**Time-Unified Diffusion Policy with Action Discrimination for Robotic Manipulation**|Le Wang Team|[2506.09422](http://arxiv.org/abs/2506.09422)|null|
|**2025-06-11**|**Analyzing Key Objectives in Human-to-Robot Retargeting for Dexterous Manipulation**|Xiang Li Team|[2506.09384](http://arxiv.org/abs/2506.09384)|null|
|**2025-06-11**|**ContextBuddy: AI-Enhanced Contextual Insights for Security Alert Investigation (Applied to Intrusion Detection)**|Cecile Paris Team|[2506.09365](http://arxiv.org/abs/2506.09365)|null|
|**2025-06-10**|**UAD: Unsupervised Affordance Distillation for Generalization in Robotic Manipulation**|Li Fei-Fei Team|[2506.09284](http://arxiv.org/abs/2506.09284)|null|
|**2025-06-10**|**Robot-Gated Interactive Imitation Learning with Adaptive Intervention Mechanism**|Bolei Zhou Team|[2506.09176](http://arxiv.org/abs/2506.09176)|null|
|**2025-06-10**|**FreqPolicy: Efficient Flow-based Visuomotor Policy via Frequency Consistency**|Jian Tang Team|[2506.08822](http://arxiv.org/abs/2506.08822)|null|
|**2025-06-10**|**Towards Biosignals-Free Autonomous Prosthetic Hand Control via Imitation Learning**|Xianta Jiang Team|[2506.08795](http://arxiv.org/abs/2506.08795)|null|
|**2025-06-10**|**Bayesian Inverse Physics for Neuro-Symbolic Robot Learning**|Frank Kirchner Team|[2506.08756](http://arxiv.org/abs/2506.08756)|null|
|**2025-06-10**|**Deep Reinforcement Learning-Based Motion Planning and PDE Control for Flexible Manipulators**|Jouni Mattila Team|[2506.08639](http://arxiv.org/abs/2506.08639)|null|
|**2025-06-10**|**RoboSwap: A GAN-driven Video Diffusion Framework For Unsupervised Robot Arm Swapping**|Gitta Kutyniok Team|[2506.08632](http://arxiv.org/abs/2506.08632)|null|
|**2025-06-10**|**Periodic Bipedal Gait Learning Using Reward Composition Based on a Novel Gait Planner for Humanoid Robots**|Lijun Zhu Team|[2506.08416](http://arxiv.org/abs/2506.08416)|null|
|**2025-06-11**|**HiBerNAC: Hierarchical Brain-emulated Robotic Neural Agent Collective for Disentangling Complex Manipulation**|Cong Wang Team|[2506.08296](http://arxiv.org/abs/2506.08296)|null|
|**2025-06-09**|**ReCogDrive: A Reinforced Cognitive Framework for End-to-End Autonomous Driving**|Xinggang Wang Team|[2506.08052](http://arxiv.org/abs/2506.08052)|null|
|**2025-06-09**|**BridgeVLA: Input-Output Alignment for Efficient 3D Manipulation Learning with Vision-Language Models**|Tieniu Tan Team|[2506.07961](http://arxiv.org/abs/2506.07961)|null|
|**2025-06-09**|**BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation**|Xilin Chen Team|[2506.07530](http://arxiv.org/abs/2506.07530)|null|
|**2025-06-09**|**Reinforcement Learning via Implicit Imitation Guidance**|Chelsea Finn Team|[2506.07505](http://arxiv.org/abs/2506.07505)|null|
|**2025-06-09**|**RAPID Hand: A Robust, Affordable, Perception-Integrated, Dexterous Manipulation Platform for Generalist Robot Autonomy**|Hui Cheng Team|[2506.07490](http://arxiv.org/abs/2506.07490)|null|
|**2025-06-08**|**CARoL: Context-aware Adaptation for Robot Learning**|Xuan Wang Team|[2506.07006](http://arxiv.org/abs/2506.07006)|null|
|**2025-06-07**|**SpikePingpong: High-Frequency Spike Vision-based Robot Learning for Precise Striking in Table Tennis Game**|Shanghang Zhang Team|[2506.06690](http://arxiv.org/abs/2506.06690)|null|
|**2025-06-07**|**RoboCerebra: A Large-scale Benchmark for Long-horizon Robotic Manipulation Evaluation**|Si Liu Team|[2506.06677](http://arxiv.org/abs/2506.06677)|null|
|**2025-06-07**|**Self-Adapting Improvement Loops for Robotic Learning**|Chen Sun Team|[2506.06658](http://arxiv.org/abs/2506.06658)|null|
|**2025-06-06**|**Enhancing Robot Safety via MLLM-Based Semantic Interpretation of Failure Data**|Somil Bansal Team|[2506.06570](http://arxiv.org/abs/2506.06570)|null|
|**2025-06-06**|**NeSyPack: A Neuro-Symbolic Framework for Bimanual Logistics Packing**|Changliu Liu Team|[2506.06567](http://arxiv.org/abs/2506.06567)|null|
|**2025-06-06**|**MapleGrasp: Mask-guided Feature Pooling for Language-driven Efficient Robotic Grasping**|Farshad Khorrami Team|[2506.06535](http://arxiv.org/abs/2506.06535)|null|
|**2025-06-06**|**3DFlowAction: Learning Cross-Embodiment Manipulation from 3D Flow World Model**|Mingkui Tan Team|[2506.06199](http://arxiv.org/abs/2506.06199)|null|
|**2025-06-06**|**Bridging Perception and Action: Spatially-Grounded Mid-Level Representations for Robot Generalization**|Tingnan Zhang Team|[2506.06196](http://arxiv.org/abs/2506.06196)|null|
|**2025-06-10**|**BEAST: Efficient Tokenization of B-Splines Encoded Action Sequences for Imitation Learning**|Rudolf Lioutikov Team|[2506.06072](http://arxiv.org/abs/2506.06072)|null|
|**2025-06-06**|**Dynamic Mixture of Progressive Parameter-Efficient Expert Library for Lifelong Robot Learning**|Ping Luo Team|[2506.05985](http://arxiv.org/abs/2506.05985)|null|
|**2025-06-06**|**Optimal Robotic Velcro Peeling with Force Feedback**|Volkan Isler Team|[2506.05812](http://arxiv.org/abs/2506.05812)|null|
|**2025-06-06**|**Where Do We Look When We Teach? Analyzing Human Gaze Behavior Across Demonstration Devices in Robot Imitation Learning**|Hiroshi Bito Team|[2506.05808](http://arxiv.org/abs/2506.05808)|null|
|**2025-06-06**|**FlowOE: Imitation Learning with Flow Policy from Ensemble RL Experts for Optimal Execution under Heston Volatility and Concave Market Impacts**|Zhi Chen Team|[2506.05755](http://arxiv.org/abs/2506.05755)|null|
|**2025-06-06**|**You Only Estimate Once: Unified, One-stage, Real-Time Category-level Articulated Object 6D Pose Estimation for Robotic Grasping**|Xiangyang Xue Team|[2506.05719](http://arxiv.org/abs/2506.05719)|null|
|**2025-06-05**|**A Smooth Sea Never Made a Skilled $\texttt{SAILOR}$ : Robust Imitation via Learning to Search**|Gokul Swamy Team|[2506.05294](http://arxiv.org/abs/2506.05294)|null|
|**2025-06-05**|**LiPo: A Lightweight Post-optimization Framework for Smoothing Action Chunks Generated by Learned Policies**|Suhan Park Team|[2506.05165](http://arxiv.org/abs/2506.05165)|null|
|**2025-06-05**|**DemoSpeedup: Accelerating Visuomotor Policies via Entropy-Guided Demonstration Acceleration**|Huazhe Xu Team|[2506.05064](http://arxiv.org/abs/2506.05064)|null|
|**2025-06-06**|**ArtVIP: Articulated Digital Assets of Visual Realism, Modular Interaction, and Physical Fidelity for Robot Learning**|Jian Tang Team|[2506.04941](http://arxiv.org/abs/2506.04941)|null|
|**2025-06-05**|**Learning dissection trajectories from expert surgical videos via imitation learning with equivariant diffusion**|Qi Dou Team|[2506.04716](http://arxiv.org/abs/2506.04716)|null|
|**2025-06-05**|**Advancing Tool-Augmented Large Language Models via Meta-Verification and Reflection Learning**|Wanxiang Che Team|[2506.04625](http://arxiv.org/abs/2506.04625)|null|
|**2025-06-04**|**SGN-CIRL: Scene Graph-based Navigation with Curriculum, Imitation, and Reinforcement Learning**|Aleksandr Panov Team|[2506.04505](http://arxiv.org/abs/2506.04505)|null|
|**2025-06-04**|**Object-centric 3D Motion Field for Robot Learning from Human Videos**|Pieter Abbeel Team|[2506.04227](http://arxiv.org/abs/2506.04227)|null|
|**2025-06-04**|**Splatting Physical Scenes: End-to-End Real-to-Sim from Imperfect Robot Data**|Leonard Hasenclever Team|[2506.04120](http://arxiv.org/abs/2506.04120)|null|
|**2025-06-04**|**STAR: Learning Diverse Robot Skill Abstractions through Rotation-Augmented Vector Quantization**|Liqiang Nie Team|[2506.03863](http://arxiv.org/abs/2506.03863)|**[link](https://github.com/jiutian-vl/star)**|
|**2025-06-04**|**SwitchVLA: Execution-Aware Task Switching for Vision-Language-Action Models**|Jian Tang Team|[2506.03574](http://arxiv.org/abs/2506.03574)|null|
|**2025-06-05**|**Confidence-Guided Human-AI Collaboration: Reinforcement Learning with Distributional Proxy Value Propagation for Autonomous Driving**|Hu Chuan Team|[2506.03568](http://arxiv.org/abs/2506.03568)|**[link](https://github.com/lzqw/c-hac)**|
|**2025-06-03**|**ORV: 4D Occupancy-centric Robot Video Generation**|Hao Zhao Team|[2506.03079](http://arxiv.org/abs/2506.03079)|null|
|**2025-06-03**|**Geometric Visual Servo Via Optimal Transport**|Ashutosh Tiwari Team|[2506.02768](http://arxiv.org/abs/2506.02768)|null|
|**2025-06-03**|**Rodrigues Network for Learning Robot Actions**|Leonidas Guibas Team|[2506.02618](http://arxiv.org/abs/2506.02618)|null|
|**2025-06-03**|**Reachability Weighted Offline Goal-conditioned Resampling**|Joni Pajarinen Team|[2506.02577](http://arxiv.org/abs/2506.02577)|null|
|**2025-06-02**|**Fast-in-Slow: A Dual-System Foundation Model Unifying Fast Manipulation within Slow Reasoning**|Pheng-Ann Heng Team|[2506.01953](http://arxiv.org/abs/2506.01953)|null|
|**2025-06-02**|**Feel the Force: Contact-Driven Learning from Humans**|Lerrel Pinto Team|[2506.01944](http://arxiv.org/abs/2506.01944)|null|
|**2025-06-02**|**Learning Video Generation for Robotic Manipulation with Collaborative Trajectory Control**|Dahua Lin Team|[2506.01943](http://arxiv.org/abs/2506.01943)|null|
|**2025-06-02**|**FreeTacMan: Robot-free Visuo-Tactile Data Collection System for Contact-rich Manipulation**|Hongyang Li Team|[2506.01941](http://arxiv.org/abs/2506.01941)|null|
|**2025-06-02**|**Learning with pyCub: A New Simulation and Exercise Framework for Humanoid Robotics**|Matej Hoffmann Team|[2506.01756](http://arxiv.org/abs/2506.01756)|null|
|**2025-06-02**|**Reasoning-Table: Exploring Reinforcement Learning for Table Reasoning**|Kang Liu Team|[2506.01710](http://arxiv.org/abs/2506.01710)|**[link](https://github.com/MJinXiang/Reasoning-Table)**|
|**2025-06-02**|**WoMAP: World Models For Embodied Open-Vocabulary Object Localization**|Anirudha Majumdar Team|[2506.01600](http://arxiv.org/abs/2506.01600)|null|
|**2025-06-02**|**FreqPolicy: Frequency Autoregressive Visuomotor Policy with Continuous Tokens**|Yuexin Ma Team|[2506.01583](http://arxiv.org/abs/2506.01583)|null|
|**2025-06-02**|**Trajectory First: A Curriculum for Discovering Diverse Policies**|Marc Toussaint Team|[2506.01568](http://arxiv.org/abs/2506.01568)|null|
|**2025-06-02**|**Variational Adaptive Noise and Dropout towards Stable Recurrent Neural Networks**|Shingo Murata Team|[2506.01350](http://arxiv.org/abs/2506.01350)|null|
|**2025-06-01**|**OG-VLA: 3D-Aware Vision Language Action Model via Orthographic Image Generation**|Valts Blukis Team|[2506.01196](http://arxiv.org/abs/2506.01196)|null|
|**2025-06-01**|**HoMeR: Learning In-the-Wild Mobile Manipulation via Hybrid Imitation and Whole-Body Control**|Jeannette Bohg Team|[2506.01185](http://arxiv.org/abs/2506.01185)|null|
|**2025-06-01**|**Jailbreak-R1: Exploring the Jailbreak Capabilities of LLMs via Reinforcement Learning**|Jing Li Team|[2506.00782](http://arxiv.org/abs/2506.00782)|null|
|**2025-05-31**|**XYZ-IBD: High-precision Bin-picking Dataset for Object 6D Pose Estimation Capturing Real-world Industrial Complexity**|Benjamin Busam Team|[2506.00599](http://arxiv.org/abs/2506.00599)|null|
|**2025-05-31**|**Dyna-Think: Synergizing Reasoning, Acting, and World Model Simulation in AI Agents**|Zhou Yu Team|[2506.00320](http://arxiv.org/abs/2506.00320)|null|
|**2025-05-30**|**3D Gaussian Splat Vulnerabilities**|Polo Chau Team|[2506.00280](http://arxiv.org/abs/2506.00280)|null|
|**2025-05-30**|**Bi-Manual Joint Camera Calibration and Scene Representation**|Weiming Zhi Team|[2505.24819](http://arxiv.org/abs/2505.24819)|null|
|**2025-05-30**|**MagicGripper: A Multimodal Sensor-Integrated Gripper for Contact-Rich Robotic Manipulation**|Dandan Zhang Team|[2505.24382](http://arxiv.org/abs/2505.24382)|null|
|**2025-05-30**|**Imitation Learning-Based Path Generation for the Complex Assembly of Deformable Objects**|Christoffer Sloth Team|[2505.24339](http://arxiv.org/abs/2505.24339)|null|
|**2025-05-30**|**SR3D: Unleashing Single-view 3D Reconstruction for Transparent and Specular Object Grasping**|Hao Dong Team|[2505.24305](http://arxiv.org/abs/2505.24305)|null|
|**2025-05-30**|**Safety-Aware Robust Model Predictive Control for Robotic Arms in Dynamic Environments**|Suwoong Lee Team|[2505.24209](http://arxiv.org/abs/2505.24209)|null|
|**2025-05-30**|**Learning Gentle Humanoid Locomotion and End-Effector Stabilization Control**|Guanya Shi Team|[2505.24198](http://arxiv.org/abs/2505.24198)|null|
|**2025-05-29**|**Mobi- $π$ : Mobilizing Your Robot Learning Policy**|Jeannette Bohg Team|[2505.23692](http://arxiv.org/abs/2505.23692)|null|
|**2025-05-30**|**Normalizing Flows are Capable Models for RL**|Benjamin Eysenbach Team|[2505.23527](http://arxiv.org/abs/2505.23527)|null|
|**2025-05-29**|**Optimization-based Posture Generation for Whole-body Contact Motion by Contact Point Search on the Body Surface**|Masayuki Inaba Team|[2505.23501](http://arxiv.org/abs/2505.23501)|null|
|**2025-05-29**|**Agentic Robot: A Brain-Inspired Framework for Vision-Language-Action Models in Embodied Agents**|Lichao Sun Team|[2505.23450](http://arxiv.org/abs/2505.23450)|null|
|**2025-05-29**|**Enhanced DACER Algorithm with High Diffusion Efficiency**|Shengbo Eben Li Team|[2505.23426](http://arxiv.org/abs/2505.23426)|null|
|**2025-05-29**|**RoboTransfer: Geometry-Consistent Video Diffusion for Robotic Visual Policy Transfer**|Zhizhong Su Team|[2505.23171](http://arxiv.org/abs/2505.23171)|null|
|**2025-05-28**|**SCIZOR: A Self-Supervised Approach to Data Curation for Large-Scale Imitation Learning**|Yuke Zhu Team|[2505.22626](http://arxiv.org/abs/2505.22626)|null|
|**2025-05-28**|**Hybrid Learning for Cold-Start-Aware Microservice Scheduling in Dynamic Edge Environments**|Weijia Jia Team|[2505.22424](http://arxiv.org/abs/2505.22424)|**[link](https://github.com/Blacktower27/CSDCRMDE)**|
|**2025-05-28**|**Efficient Precision-Scalable Hardware for Microscaling (MX) Processing in Robotics Learning**|Marian Verhelst Team|[2505.22404](http://arxiv.org/abs/2505.22404)|null|
|**2025-05-28**|**State and Input Constrained Adaptive Tracking Control of Uncertain Euler-Lagrange Systems with Robustness and Feasibility Analysis**|Shubhendu Bhasin Team|[2505.22352](http://arxiv.org/abs/2505.22352)|null|
|**2025-05-28**|**ForceVLA: Enhancing VLA Models with a Force-aware MoE for Contact-rich Manipulation**|Wenqiang Zhang Team|[2505.22159](http://arxiv.org/abs/2505.22159)|null|
|**2025-05-28**|**Learning Compositional Behaviors from Demonstration and Language**|Jiajun Wu Team|[2505.21981](http://arxiv.org/abs/2505.21981)|null|
|**2025-05-29**|**ChatVLA-2: Vision-Language-Action Model with Open-World Embodied Reasoning from Pretrained Knowledge**|Yi Xu Team|[2505.21906](http://arxiv.org/abs/2505.21906)|null|
|**2025-05-28**|**Streaming Flow Policy: Simplifying diffusion $/$ flow-matching policies by treating action trajectories as flow trajectories**|Siddharth Ancha Team|[2505.21851](http://arxiv.org/abs/2505.21851)|null|
|**2025-05-27**|**PartInstruct: Part-level Instruction Following for Fine-grained Robot Manipulation**|Tianmin Shu Team|[2505.21652](http://arxiv.org/abs/2505.21652)|null|
|**2025-05-30**|**Right Side Up? Disentangling Orientation Understanding in MLLMs with Fine-grained Multi-axis Perception Tasks**|Bryan A. Plummer Team|[2505.21649](http://arxiv.org/abs/2505.21649)|null|
|**2025-05-27**|**CLAMP: Crowdsourcing a LArge-scale in-the-wild haptic dataset with an open-source device for Multimodal robot Perception**|Tapomayukh Bhattacharjee Team|[2505.21495](http://arxiv.org/abs/2505.21495)|null|
|**2025-05-27**|**EquAct: An SE(3)-Equivariant Multi-Task Transformer for Open-Loop Robotic Manipulation**|Robert Platt Team|[2505.21351](http://arxiv.org/abs/2505.21351)|null|
|**2025-05-27**|**EgoWalk: A Multimodal Dataset for Robot Navigation in the Wild**|Gonzalo Ferrer Team|[2505.21282](http://arxiv.org/abs/2505.21282)|null|
|**2025-05-27**|**Learning What to Do and What Not To Do: Offline Imitation from Expert and Undesirable Demonstrations**|Tanvi Verma Team|[2505.21182](http://arxiv.org/abs/2505.21182)|null|
|**2025-05-27**|**Object-Centric Action-Enhanced Representations for Robot Visuo-Motor Policy Learning**|George Retsinas Team|[2505.20962](http://arxiv.org/abs/2505.20962)|null|
|**2025-05-27**|**Learning Unified Force and Position Control for Legged Loco-Manipulation**|Siyuan Huang Team|[2505.20829](http://arxiv.org/abs/2505.20829)|null|
|**2025-05-27**|**Spatial RoboGrasp: Generalized Robotic Grasping Control Policy**|Luhui Hu Team|[2505.20814](http://arxiv.org/abs/2505.20814)|null|
|**2025-05-27**|**Learning Generalizable Robot Policy with Human Demonstration Video as a Prompt**|Jianyu Chen Team|[2505.20795](http://arxiv.org/abs/2505.20795)|null|
|**2025-05-28**|**ControlTac: Force- and Position-Controlled Tactile Data Augmentation with a Single Reference Image**|Ruohan Gao Team|[2505.20498](http://arxiv.org/abs/2505.20498)|null|
|**2025-05-26**|**OSVI-WM: One-Shot Visual Imitation for Unseen Tasks using World-Model-Guided Trajectory Generation**|Farshad Khorrami Team|[2505.20425](http://arxiv.org/abs/2505.20425)|null|
|**2025-05-26**|**Co-Design of Soft Gripper with Neural Physics**|Xiaolong Wang Team|[2505.20404](http://arxiv.org/abs/2505.20404)|null|
|**2025-05-26**|**EgoZero: Robot Learning from Smart Glasses**|Lerrel Pinto Team|[2505.20290](http://arxiv.org/abs/2505.20290)|null|
|**2025-05-26**|**URPlanner: A Universal Paradigm For Collision-Free Robotic Motion Planning Based on Deep Reinforcement Learning**|Marcelo H. Ang Jr Team|[2505.20175](http://arxiv.org/abs/2505.20175)|null|
|**2025-05-27**|**MineAnyBuild: Benchmarking Spatial Planning for Open-world AI Agents**|Xiaodan Liang Team|[2505.20148](http://arxiv.org/abs/2505.20148)|**[link](https://github.com/mineanybuild/mineanybuild)**|
|**2025-05-26**|**ReasonPlan: Unified Scene Prediction and Decision Reasoning for Closed-loop Autonomous Driving**|Dongbin Zhao Team|[2505.20024](http://arxiv.org/abs/2505.20024)|**[link](https://github.com/liuxueyi/reasonplan)**|
|**2025-05-26**|**Inverse Q-Learning Done Right: Offline Imitation Learning in $Q^π$ -Realizable MDPs**|Luca Viano Team|[2505.19946](http://arxiv.org/abs/2505.19946)|null|
|**2025-05-26**|**TeViR: Text-to-Video Reward with Diffusion Models for Efficient Reinforcement Learning**|Dongbin Zhao Team|[2505.19769](http://arxiv.org/abs/2505.19769)|null|
|**2025-05-26**|**Extremum Flow Matching for Offline Goal Conditioned Reinforcement Learning**|Jean-Baptiste Mouret Team|[2505.19717](http://arxiv.org/abs/2505.19717)|null|
|**2025-05-25**|**Structured Reinforcement Learning for Combinatorial Decision-Making**|Maximilian Schiffer Team|[2505.19053](http://arxiv.org/abs/2505.19053)|**[link](https://github.com/tumbais/structured-rl)**|
|**2025-05-25**|**WorldEval: World Model as Real-World Robot Policies Evaluator**|Yi Xu Team|[2505.19017](http://arxiv.org/abs/2505.19017)|null|
|**2025-05-25**|**Online Knowledge Distillation with Reward Guidance**|Chen Jia Team|[2505.18952](http://arxiv.org/abs/2505.18952)|null|
|**2025-05-24**|**Guided by Guardrails: Control Barrier Functions as Safety Instructors for Robotic Learning**|Giovanni Beltrame Team|[2505.18858](http://arxiv.org/abs/2505.18858)|null|
|**2025-05-24**|**On the Dual-Use Dilemma in Physical Reasoning and Force**|Nikolaus Correll Team|[2505.18792](http://arxiv.org/abs/2505.18792)|null|
|**2025-05-24**|**VLA-RL: Towards Masterful and General Robotic Manipulation with Scalable Reinforcement Learning**|Ziwei Wang Team|[2505.18719](http://arxiv.org/abs/2505.18719)|null|
|**2025-05-24**|**MisoDICE: Multi-Agent Imitation from Unlabeled Mixed-Quality Demonstrations**|Hong Thanh Nguyen Team|[2505.18595](http://arxiv.org/abs/2505.18595)|null|
|**2025-05-24**|**Grounding Bodily Awareness in Visual Representations for Efficient Policy Learning**|Zhiyun Lin Team|[2505.18487](http://arxiv.org/abs/2505.18487)|null|
|**2025-05-24**|**Canonical Policy: Learning Canonical 3D Representation for Equivariant Policy**|Yu She Team|[2505.18474](http://arxiv.org/abs/2505.18474)|null|
|**2025-05-24**|**ManiFeel: Benchmarking and Understanding Visuotactile Manipulation Policy Learning**|Yu She Team|[2505.18472](http://arxiv.org/abs/2505.18472)|null|
|**2025-05-23**|**ProgRM: Build Better GUI Agents with Progress Rewards**|Kai Yu Team|[2505.18121](http://arxiv.org/abs/2505.18121)|null|
|**2025-05-23**|**Classification of assembly tasks combining multiple primitive actions using Transformers and xLSTMs**|Pedro Neto Team|[2505.18012](http://arxiv.org/abs/2505.18012)|null|
|**2025-05-23**|**Is Single-View Mesh Reconstruction Ready for Robotics?**|Ingmar Posner Team|[2505.17966](http://arxiv.org/abs/2505.17966)|null|
|**2025-05-23**|**SynRES: Towards Referring Expression Segmentation in the Wild via Synthetic Data**|Donghyun Kim Team|[2505.17695](http://arxiv.org/abs/2505.17695)|null|
|**2025-05-23**|**Learning Equilibria from Data: Provably Efficient Multi-Agent Imitation Learning**|Giorgia Ramponi Team|[2505.17610](http://arxiv.org/abs/2505.17610)|null|
|**2025-05-23**|**Dynamic Manipulation of Deformable Objects in 3D: Simulation, Benchmark and Learning Strategy**|Bin Zhao Team|[2505.17434](http://arxiv.org/abs/2505.17434)|null|
|**2025-05-23**|**Bootstrapping Imitation Learning for Long-horizon Manipulation via Hierarchical Data Collection Space**|Hui Cheng Team|[2505.17389](http://arxiv.org/abs/2505.17389)|null|
|**2025-05-22**|**ScanBot: Towards Intelligent Surface Scanning in Embodied Robotic Systems**|Farhad Imani Team|[2505.17295](http://arxiv.org/abs/2505.17295)|null|
|**2025-05-22**|**CoMo: Learning Continuous Latent Motion from Internet Videos for Scalable Robot Learning**|Limin Wang Team|[2505.17006](http://arxiv.org/abs/2505.17006)|null|
|**2025-05-22**|**3D Equivariant Visuomotor Policy Learning via Spherical Projection**|Robin Walters Team|[2505.16969](http://arxiv.org/abs/2505.16969)|null|
|**2025-05-22**|**Efficient Online RL Fine Tuning with Offline Pre-trained Policy Only**|Donglin Wang Team|[2505.16856](http://arxiv.org/abs/2505.16856)|null|
|**2025-05-22**|**Find the Fruit: Designing a Zero-Shot Sim2Real Deep RL Planner for Occlusion Aware Plant Manipulation**|Soumik Sarkar Team|[2505.16547](http://arxiv.org/abs/2505.16547)|null|
|**2025-05-24**|**ManipLVM-R1: Reinforcement Learning for Reasoning in Embodied Manipulation with Large Vision-Language Models**|Xiuying Chen Team|[2505.16517](http://arxiv.org/abs/2505.16517)|null|
|**2025-05-22**|**Raw2Drive: Reinforcement Learning with Aligned World Models for End-to-End Autonomous Driving (in CARLA v2)**|Junchi Yan Team|[2505.16394](http://arxiv.org/abs/2505.16394)|null|
|**2025-05-22**|**TacCompress: A Benchmark for Multi-Point Tactile Data Compression in Dexterous Manipulation**|Hengdi Zhang Team|[2505.16289](http://arxiv.org/abs/2505.16289)|null|
|**2025-05-22**|**SEM: Enhancing Spatial Understanding for Robust Robot Manipulation**|Zhizhong Su Team|[2505.16196](http://arxiv.org/abs/2505.16196)|null|
|**2025-05-22**|**Tactile-based Reinforcement Learning for Adaptive Grasping under Observation Uncertainties**|Yang Ye Team|[2505.16167](http://arxiv.org/abs/2505.16167)|null|
|**2025-05-21**|**WaveTouch: Active Tactile Sensing Using Vibro-Feedback for Classification of Variable Stiffness and Infill Density Objects**|Bakhtiyar Orazbayev Team|[2505.16062](http://arxiv.org/abs/2505.16062)|null|
|**2025-05-25**|**Proactive Hierarchical Control Barrier Function-Based Safety Prioritization in Close Human-Robot Interaction Scenarios**|Prashanth Krishnamurthy Team|[2505.16055](http://arxiv.org/abs/2505.16055)|null|
|**2025-05-21**|**UAV-Flow Colosseo: A Real-World Benchmark for Flying-on-a-Word UAV Imitation Learning**|Si Liu Team|[2505.15725](http://arxiv.org/abs/2505.15725)|null|
|**2025-05-21**|**Exploring the Limits of Vision-Language-Action Manipulations in Cross-task Generalization**|Junwei Liang Team|[2505.15660](http://arxiv.org/abs/2505.15660)|null|
|**2025-05-21**|**FLARE: Robot Learning with Implicit World Modeling**|Linxi Fan Team|[2505.15659](http://arxiv.org/abs/2505.15659)|null|
|**2025-05-21**|**Robo2VLM: Visual Question Answering from Large-Scale In-the-Wild Robot Manipulation Datasets**|Ken Goldberg Team|[2505.15517](http://arxiv.org/abs/2505.15517)|null|
|**2025-05-21**|**Guided Policy Optimization under Partial Observability**|Zongqing Lu Team|[2505.15418](http://arxiv.org/abs/2505.15418)|**[link](https://github.com/liyheng/GPO)**|
|**2025-05-21**|**Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control**|Jungwook Choi Team|[2505.15304](http://arxiv.org/abs/2505.15304)|null|
|**2025-05-21**|**Learning-based Autonomous Oversteer Control and Collision Avoidance**|Seung-Hyun Kong Team|[2505.15275](http://arxiv.org/abs/2505.15275)|null|
|**2025-05-21**|**Filtering Learning Histories Enhances In-Context Reinforcement Learning**|Santiago Paternain Team|[2505.15143](http://arxiv.org/abs/2505.15143)|null|
|**2025-05-21**|**Object-Focus Actor for Data-efficient Robot Generalization Dexterous Manipulation**|Xiaodong He Team|[2505.15098](http://arxiv.org/abs/2505.15098)|null|
|**2025-05-20**|**RoboCulture: A Robotics Platform for Automated Biological Experimentation**|Milica Radisic Team|[2505.14941](http://arxiv.org/abs/2505.14941)|null|
|**2025-05-20**|**Imitation Learning via Focused Satisficing**|Brian Ziebart Team|[2505.14820](http://arxiv.org/abs/2505.14820)|null|
|**2025-05-20**|**DORA: Object Affordance-Guided Reinforcement Learning for Dexterous Robotic Manipulation**|Jianwei Zhang Team|[2505.14819](http://arxiv.org/abs/2505.14819)|null|
|**2025-05-20**|**Vid2World: Crafting Video Diffusion Models to Interactive World Models**|Mingsheng Long Team|[2505.14357](http://arxiv.org/abs/2505.14357)|null|
|**2025-05-20**|**AutoBio: A Simulation and Benchmark for Robotic Automation in Digital Biology Laboratory**|Ping Luo Team|[2505.14030](http://arxiv.org/abs/2505.14030)|null|
|**2025-05-20**|**RLVR-World: Training World Models with Reinforcement Learning**|Mingsheng Long Team|[2505.13934](http://arxiv.org/abs/2505.13934)|**[link](https://github.com/thuml/RLVR-World)**|
|**2025-05-20**|**Time Reversal Symmetry for Efficient Robotic Manipulations in Deep Reinforcement Learning**|Yutong Ban Team|[2505.13925](http://arxiv.org/abs/2505.13925)|null|
|**2025-05-20**|**Learning to Insert for Constructive Neural Vehicle Routing Solver**|Qingfu Zhang Team|[2505.13904](http://arxiv.org/abs/2505.13904)|null|
|**2025-05-20**|**Structured Agent Distillation for Large Language Model**|Yanzhi Wang Team|[2505.13820](http://arxiv.org/abs/2505.13820)|null|
|**2025-05-21**|**Adaptive Diffusion Constrained Sampling for Bimanual Robot Manipulation**|Georgia Chalvatzaki Team|[2505.13667](http://arxiv.org/abs/2505.13667)|null|
|**2025-05-19**|**TD-GRPC: Temporal Difference Learning with Group Relative Policy Constraint for Humanoid Locomotion**|Minh Nhat Vu Team|[2505.13549](http://arxiv.org/abs/2505.13549)|null|
|**2025-05-19**|**GraspMolmo: Generalizable Task-Oriented Grasping via Large-Scale Synthetic Data Generation**|Rose Hendrix Team|[2505.13441](http://arxiv.org/abs/2505.13441)|null|
|**2025-05-19**|**KinTwin: Imitation Learning with Torque and Muscle Driven Biomechanical Models Enables Precise Replication of Able-Bodied and Impaired Movement from Markerless Motion Capture**|R. James Cotton Team|[2505.13436](http://arxiv.org/abs/2505.13436)|null|
|**2025-05-19**|**TeleOpBench: A Simulator-Centric Benchmark for Dual-Arm Dexterous Teleoperation**|Jiangmiao Pang Team|[2505.12748](http://arxiv.org/abs/2505.12748)|null|
|**2025-05-19**|**Incentivizing Multimodal Reasoning in Large Models for Direct Robot Manipulation**|Chi-Wing Fu Team|[2505.12744](http://arxiv.org/abs/2505.12744)|null|
|**2025-05-19**|**Option-aware Temporally Abstracted Value for Offline Goal-Conditioned Reinforcement Learning**|Taesup Moon Team|[2505.12737](http://arxiv.org/abs/2505.12737)|null|
|**2025-05-19**|**DreamGen: Unlocking Generalization in Robot Learning through Neural Trajectories**|Linxi Fan Team|[2505.12705](http://arxiv.org/abs/2505.12705)|null|
|**2025-05-19**|**Dribble Master: Learning Agile Humanoid Dribbling Through Legged Locomotion**|Qi Wu Team|[2505.12679](http://arxiv.org/abs/2505.12679)|null|
|**2025-05-19**|**HIL: Hybrid Imitation Learning of Diverse Parkour Skills from Videos**|Xue Bin Peng Team|[2505.12619](http://arxiv.org/abs/2505.12619)|null|
|**2025-05-18**|**MTIL: Encoding Full History with Mamba for Temporal Imitation Learning**|Zhouping Yin Team|[2505.12410](http://arxiv.org/abs/2505.12410)|**[link](https://github.com/yulinzhouzyl/mtil)**|
|**2025-05-18**|**PartDexTOG: Generating Dexterous Task-Oriented Grasping via Language-driven Part Analysis**|Zhipong Cai Team|[2505.12294](http://arxiv.org/abs/2505.12294)|null|
|**2025-05-20**|**RoboFAC: A Comprehensive Framework for Robotic Failure Analysis and Correction**|Bo Zhao Team|[2505.12224](http://arxiv.org/abs/2505.12224)|null|
|**2025-05-20**|**Learning Impact-Rich Rotational Maneuvers via Centroidal Velocity Rewards and Sim-to-Real Techniques: A One-Leg Hopper Flip Case Study**|Hae-Won Park Team|[2505.12222](http://arxiv.org/abs/2505.12222)|null|
|**2025-05-17**|**L2D2: Robot Learning from 2D Drawings**|Dylan P. Losey Team|[2505.12072](http://arxiv.org/abs/2505.12072)|null|
|**2025-05-17**|**H2R: A Human-to-Robot Data Augmentation for Robot Pre-training from Videos**|Shanghang Zhang Team|[2505.11920](http://arxiv.org/abs/2505.11920)|null|
|**2025-05-17**|**GLOVER++: Unleashing the Potential of Affordance Learning from Human Behaviors for Robotic Manipulation**|Junwei Liang Team|[2505.11865](http://arxiv.org/abs/2505.11865)|null|
|**2025-05-17**|**Learning IMU Bias with Diffusion Model**|Guoquan Huang Team|[2505.11763](http://arxiv.org/abs/2505.11763)|null|
|**2025-05-16**|**Zero-Shot Visual Generalization in Robot Manipulation**|Gaurav Sukhatme Team|[2505.11719](http://arxiv.org/abs/2505.11719)|null|
|**2025-05-16**|**Employing Laban Shape for Generating Emotionally and Functionally Expressive Trajectories in Robotic Manipulators**|Alessandro Roncone Team|[2505.11716](http://arxiv.org/abs/2505.11716)|null|
|**2025-05-16**|**EgoDex: Learning Dexterous Manipulation from Large-Scale Egocentric Video**|Jian Zhang Team|[2505.11709](http://arxiv.org/abs/2505.11709)|null|
|**2025-05-16**|**Grounded Task Axes: Zero-Shot Semantic Skill Generalization via Task-Axis Controllers and Visual Foundation Models**|Oliver Kroemer Team|[2505.11680](http://arxiv.org/abs/2505.11680)|null|
|**2025-05-16**|**SHIELD: Safety on Humanoids via CBFs In Expectation on Learned Dynamics**|Aaron D. Ames Team|[2505.11494](http://arxiv.org/abs/2505.11494)|null|
|**2025-05-16**|**Exploiting Radiance Fields for Grasp Generation on Novel Synthetic Views**|Todor Stoyanov Team|[2505.11467](http://arxiv.org/abs/2505.11467)|null|
|**2025-05-16**|**ReWiND: Language-Guided Rewards Teach Robot Policies without New Demonstrations**|Jesse Zhang Team|[2505.10911](http://arxiv.org/abs/2505.10911)|null|
|**2025-05-16**|**Counterfactual Behavior Cloning: Offline Imitation Learning from Imperfect Human Demonstrations**|Dylan P. Losey Team|[2505.10760](http://arxiv.org/abs/2505.10760)|null|
|**2025-05-15**|**Infinigen-Sim: Procedural Generation of Articulated Simulation Assets**|Jia Deng Team|[2505.10755](http://arxiv.org/abs/2505.10755)|null|
|**2025-05-15**|**Knowledge capture, adaptation and composition (KCAC): A framework for cross-task curriculum learning in robotic manipulation**|Yan Jin Team|[2505.10522](http://arxiv.org/abs/2505.10522)|null|
|**2025-05-15**|**IN-RIL: Interleaved Reinforcement and Imitation Learning for Policy Fine-Tuning**|Junshan Zhang Team|[2505.10442](http://arxiv.org/abs/2505.10442)|null|
|**2025-05-15**|**NVSPolicy: Adaptive Novel-View Synthesis for Generalizable Language-Conditioned Policy Learning**|Chengyuan Chen Team|[2505.10359](http://arxiv.org/abs/2505.10359)|null|
|**2025-05-15**|**SRT-H: A Hierarchical Framework for Autonomous Surgery via Language Conditioned Imitation Learning**|Axel Krieger Team|[2505.10251](http://arxiv.org/abs/2505.10251)|null|
|**2025-05-15**|**Training People to Reward Robots**|Matthew Howard Team|[2505.10151](http://arxiv.org/abs/2505.10151)|null|
|**2025-05-15**|**EmbodiedMAE: A Unified 3D Multi-Modal Representation for Robot Manipulation**|Jianye Hao Team|[2505.10105](http://arxiv.org/abs/2505.10105)|null|
|**2025-05-15**|**FlowDreamer: A RGB-D World Model with Flow-based Motion Representations for Robot Manipulation**|Qing Li Team|[2505.10075](http://arxiv.org/abs/2505.10075)|null|
|**2025-05-15**|**APEX: Action Priors Enable Efficient Exploration for Skill Imitation on Articulated Robots**|Guillaume Sartoretti Team|[2505.10022](http://arxiv.org/abs/2505.10022)|null|
|**2025-05-15**|**ImagineBench: Evaluating Reinforcement Learning with Large Language Model Rollouts**|Yang Yu Team|[2505.10010](http://arxiv.org/abs/2505.10010)|**[link](https://github.com/lamda-rl/imaginebench)**|
|**2025-05-16**|**PointArena: Probing Multimodal Grounding Through Language-Guided Pointing**|Ranjay Krishna Team|[2505.09990](http://arxiv.org/abs/2505.09990)|null|
|**2025-05-15**|**Learning Diverse Natural Behaviors for Enhancing the Agility of Quadrupedal Robots**|Chunlin Chen Team|[2505.09979](http://arxiv.org/abs/2505.09979)|null|
|**2025-05-14**|**Learning Rock Pushability on Rough Planetary Terrain**|Cagri Kilic Team|[2505.09833](http://arxiv.org/abs/2505.09833)|null|
|**2025-05-14**|**Trailblazer: Learning offroad costmaps for long range planning**|Srikanth Saripalli Team|[2505.09739](http://arxiv.org/abs/2505.09739)|null|
|**2025-05-14**|**EnerVerse-AC: Envisioning Embodied Environments with Action Condition**|Guanghui Ren Team|[2505.09723](http://arxiv.org/abs/2505.09723)|null|
|**2025-05-14**|**ManipBench: Benchmarking Vision-Language Models for Low-Level Robot Manipulation**|Daniel Seita Team|[2505.09698](http://arxiv.org/abs/2505.09698)|null|
|**2025-05-14**|**DataMIL: Selecting Data for Robot Imitation Learning with Datamodels**|Roberto Martín-Martín Team|[2505.09603](http://arxiv.org/abs/2505.09603)|null|
|**2025-05-14**|**Real2Render2Real: Scaling Robot Data Without Dynamics Simulation or Robot Hardware**|Ken Goldberg Team|[2505.09601](http://arxiv.org/abs/2505.09601)|null|
|**2025-05-14**|**VTLA: Vision-Tactile-Language-Action Model with Preference Learning for Insertion Manipulation**|Shuo Wang Team|[2505.09577](http://arxiv.org/abs/2505.09577)|null|
|**2025-05-14**|**Learning Long-Context Diffusion Policies via Past-Token Prediction**|Chelsea Finn Team|[2505.09561](http://arxiv.org/abs/2505.09561)|null|
|**2025-05-14**|**Distilling Realizable Students from Unrealizable Teachers**|Sanjiban Choudhury Team|[2505.09546](http://arxiv.org/abs/2505.09546)|null|
|**2025-05-14**|**Exploring Pose-Guided Imitation Learning for Robotic Precise Insertion**|Qixin Cao Team|[2505.09424](http://arxiv.org/abs/2505.09424)|null|
|**2025-05-14**|**Neural Multivariate Regression: Qualitative Insights from the Unconstrained Feature Model**|Keith Ross Team|[2505.09308](http://arxiv.org/abs/2505.09308)|null|
|**2025-05-14**|**Latent Theory of Mind: A Decentralized Diffusion Architecture for Cooperative Manipulation**|Guillaume Sartoretti Team|[2505.09144](http://arxiv.org/abs/2505.09144)|null|
|**2025-05-14**|**FoldNet: Learning Generalizable Closed-Loop Policy for Garment Folding via Keypoint-Driven Asset and Demonstration Synthesis**|He Wang Team|[2505.09109](http://arxiv.org/abs/2505.09109)|null|
|**2025-05-14**|**Imitation Learning for Adaptive Control of a Virtual Soft Exoglove**|Letizia Gionfrida Team|[2505.09099](http://arxiv.org/abs/2505.09099)|null|
|**2025-05-13**|**ChicGrasp: Imitation-Learning based Customized Dual-Jaw Gripper Control for Delicate, Irregular Bio-products Manipulation**|Dongyi Wang Team|[2505.08986](http://arxiv.org/abs/2505.08986)|null|
|**2025-05-13**|**Augmented Reality for RObots (ARRO): Pointing Visuomotor Policies Towards Visual Robustness**|Wolfram Burgard Team|[2505.08627](http://arxiv.org/abs/2505.08627)|null|
|**2025-05-13**|**Beyond Predefined Actions: Integrating Behavior Trees and Dynamic Movement Primitives for Robot Learning from Demonstration**|Todor Stoyanov Team|[2505.08625](http://arxiv.org/abs/2505.08625)|null|
|**2025-05-13**|**From Seeing to Doing: Bridging Reasoning and Decision for Robotic Manipulation**|Jianye Hao Team|[2505.08548](http://arxiv.org/abs/2505.08548)|null|
|**2025-05-13**|**Parameter Estimation using Reinforcement Learning Causal Curiosity: Limits and Challenges**|Weisi Guo Team|[2505.08453](http://arxiv.org/abs/2505.08453)|null|
|**2025-05-13**|**Adaptive Diffusion Policy Optimization for Robotic Manipulation**|Zhuang Yang Team|[2505.08376](http://arxiv.org/abs/2505.08376)|null|
|**2025-05-13**|**Learning Like Humans: Advancing LLM Reasoning Capabilities via Adaptive Difficulty Curriculum Learning and Expert-Guided Self-Reformulation**|Qianchun Lu Team|[2505.08364](http://arxiv.org/abs/2505.08364)|null|
|**2025-05-13**|**Modeling Unseen Environments with Language-guided Composable Causal Components in Reinforcement Learning**|Biwei Huang Team|[2505.08361](http://arxiv.org/abs/2505.08361)|null|
|**2025-05-13**|**HandCept: A Visual-Inertial Fusion Framework for Accurate Proprioception in Dexterous Hands**|Yunhui Liu Team|[2505.08213](http://arxiv.org/abs/2505.08213)|null|
|**2025-05-13**|**CLTP: Contrastive Language-Tactile Pre-training for 3D Contact Geometry Understanding**|Shuo Wang Team|[2505.08194](http://arxiv.org/abs/2505.08194)|null|
|**2025-05-12**|**What Matters for Batch Online Reinforcement Learning in Robotics?**|Chelsea Finn Team|[2505.08078](http://arxiv.org/abs/2505.08078)|null|
|**2025-05-12**|**H $^{\mathbf{3}}$ DP: Triply-Hierarchical Diffusion Policy for Visuomotor Learning**|Huazhe Xu Team|[2505.07819](http://arxiv.org/abs/2505.07819)|null|
|**2025-05-12**|**Imagine, Verify, Execute: Memory-Guided Agentic Exploration with Vision-Language Models**|Jia-Bin Huang Team|[2505.07815](http://arxiv.org/abs/2505.07815)|null|
|**2025-05-12**|**Improving Trajectory Stitching with Flow Models**|Ioannis Havoutis Team|[2505.07802](http://arxiv.org/abs/2505.07802)|null|
|**2025-05-12**|**Guiding Data Collection via Factored Scaling Curves**|Anirudha Majumdar Team|[2505.07728](http://arxiv.org/abs/2505.07728)|null|
|**2025-05-12**|**GelFusion: Enhancing Robotic Manipulation under Visual Constraints via Visuotactile Fusion**|Peng Yin Team|[2505.07455](http://arxiv.org/abs/2505.07455)|null|
|**2025-05-12**|**ReinboT: Amplifying Robot Visual-Language Manipulation with Reinforcement Learning**|Donglin Wang Team|[2505.07395](http://arxiv.org/abs/2505.07395)|null|
|**2025-05-11**|**X-Sim: Cross-Embodiment Learning via Real-to-Sim-to-Real**|Sanjiban Choudhury Team|[2505.07096](http://arxiv.org/abs/2505.07096)|null|
|**2025-05-11**|**YOPOv2-Tracker: An End-to-End Agile Tracking and Navigation Framework from Perception to Action**|Bailing Tian Team|[2505.06923](http://arxiv.org/abs/2505.06923)|null|
|**2025-05-10**|**JaxRobotarium: Training and Deploying Multi-Robot Policies in 10 Minutes**|Harish Ravichandar Team|[2505.06771](http://arxiv.org/abs/2505.06771)|null|
|**2025-05-10**|**Learned IMU Bias Prediction for Invariant Visual Inertial Odometry**|Nikolay Atanasov Team|[2505.06748](http://arxiv.org/abs/2505.06748)|null|
|**2025-05-10**|**ACORN: Adaptive Contrastive Optimization for Safe and Robust Fine-Grained Robotic Manipulation**|Zixian Yue Team|[2505.06628](http://arxiv.org/abs/2505.06628)|null|
|**2025-05-10**|**Video-Enhanced Offline Reinforcement Learning: A Model-Based Approach**|Xiaokang Yang Team|[2505.06482](http://arxiv.org/abs/2505.06482)|null|
|**2025-05-09**|**Adaptive Wiping: Adaptive contact-rich manipulation through few-shot imitation learning with Force-Torque feedback and pre-trained object representations**|Gentiane Venture Team|[2505.06451](http://arxiv.org/abs/2505.06451)|null|
|**2025-05-09**|**VIN-NBV: A View Introspection Network for Next-Best-View Selection for Resource-Efficient 3D Reconstruction**|Roni Sengupta Team|[2505.06219](http://arxiv.org/abs/2505.06219)|null|
|**2025-05-09**|**Neuro-Symbolic Concepts**|Jiajun Wu Team|[2505.06191](http://arxiv.org/abs/2505.06191)|null|
|**2025-05-07**|**Efficient Sensorimotor Learning for Open-world Robot Manipulation**|Yifeng Zhu Team|[2505.06136](http://arxiv.org/abs/2505.06136)|null|
|**2025-05-09**|**Robot Learning Using Multi-Coordinate Elastic Maps**|Reza Azadeh Team|[2505.06092](http://arxiv.org/abs/2505.06092)|null|
|**2025-05-09**|**TREND: Tri-teaching for Robust Preference-based Reinforcement Learning with Demonstrations**|Abhinav Shrivastava Team|[2505.06079](http://arxiv.org/abs/2505.06079)|null|
|**2025-05-09**|**3D CAVLA: Leveraging Depth and 3D Context to Generalize Vision Language Action Models for Unseen Tasks**|Farshad Khorrami Team|[2505.05800](http://arxiv.org/abs/2505.05800)|null|
|**2025-05-09**|**Demystifying Diffusion Policies: Action Memorization and Simple Lookup Table Alternatives**|Mac Schwager Team|[2505.05787](http://arxiv.org/abs/2505.05787)|null|
|**2025-05-09**|**FlowHFT: Flow Policy Induced Optimal High-Frequency Trading under Diverse Market Conditions**|Steve Yang Team|[2505.05784](http://arxiv.org/abs/2505.05784)|null|
|**2025-05-08**|**CLAM: Continuous Latent Action Models for Robot Learning from Unlabeled Demonstrations**|Stephen Tu Team|[2505.04999](http://arxiv.org/abs/2505.04999)|null|
|**2025-05-08**|**CubeDAgger: Improved Robustness of Interactive Imitation Learning without Violation of Dynamic Stability**|Taisuke Kobayashi Team|[2505.04897](http://arxiv.org/abs/2505.04897)|null|
|**2025-05-08**|**D-CODA: Diffusion for Coordinated Dual-Arm Data Augmentation**|Daniel Seita Team|[2505.04860](http://arxiv.org/abs/2505.04860)|null|
|**2025-05-07**|**Steerable Scene Generation with Post Training and Inference-Time Search**|Russ Tedrake Team|[2505.04831](http://arxiv.org/abs/2505.04831)|null|
|**2025-05-07**|**Primal-dual algorithm for contextual stochastic combinatorial optimization**|Axel Parmentier Team|[2505.04757](http://arxiv.org/abs/2505.04757)|null|
|**2025-05-07**|**Merging and Disentangling Views in Visual Reinforcement Learning for Robotic Manipulation**|Henrik I. Christensen Team|[2505.04619](http://arxiv.org/abs/2505.04619)|null|
|**2025-05-06**|**OpenHelix: A Short Survey, Empirical Analysis, and Open-Source Dual-System VLA Model for Robotic Manipulation**|Donglin Wang Team|[2505.03912](http://arxiv.org/abs/2505.03912)|null|
|**2025-05-06**|**AMO: Adaptive Motion Optimization for Hyper-Dexterous Humanoid Whole-Body Control**|Xiaolong Wang Team|[2505.03738](http://arxiv.org/abs/2505.03738)|null|
|**2025-05-06**|**Meta-Optimization and Program Search using Language Models for Task and Motion Planning**|Marc Toussaint Team|[2505.03725](http://arxiv.org/abs/2505.03725)|null|
|**2025-05-06**|**Ergodic Generative Flows**|Yinchuan Li Team|[2505.03561](http://arxiv.org/abs/2505.03561)|null|
|**2025-05-06**|**RIFT: Closed-Loop RL Fine-Tuning for Realistic and Controllable Traffic Simulation**|Sifa Zheng Team|[2505.03344](http://arxiv.org/abs/2505.03344)|null|
|**2025-05-06**|**The Unreasonable Effectiveness of Discrete-Time Gaussian Process Mixtures for Robot Policy Learning**|Abhinav Valada Team|[2505.03296](http://arxiv.org/abs/2505.03296)|null|
|**2025-05-05**|**Sim2Real Transfer for Vision-Based Grasp Verification**|Markus Vincze Team|[2505.03046](http://arxiv.org/abs/2505.03046)|**[link](https://github.com/pauamargant/hsr-graspsynth)**|
|**2025-05-05**|**Zero-shot Sim2Real Transfer for Magnet-Based Tactile Sensor on Insertion Tasks**|Jia Deng Team|[2505.02915](http://arxiv.org/abs/2505.02915)|null|
|**2025-05-05**|**Re-purposing a modular origami manipulator into an adaptive physical computer for machine learning and robotic perception**|Suyi Li Team|[2505.02744](http://arxiv.org/abs/2505.02744)|null|
|**2025-05-05**|**Spatiotemporal Non-Uniformity-Aware Online Task Scheduling in Collaborative Edge Computing for Industrial Internet of Things**|Bo Lei Team|[2505.02597](http://arxiv.org/abs/2505.02597)|null|
|**2025-05-05**|**Automated Hybrid Reward Scheduling via Large Language Models for Robotic Skill Learning**|Jianqiang Li Team|[2505.02483](http://arxiv.org/abs/2505.02483)|null|
|**2025-05-05**|**MetaScenes: Towards Automated Replica Creation for Real-world 3D Scans**|Siyuan Huang Team|[2505.02388](http://arxiv.org/abs/2505.02388)|null|
|**2025-05-04**|**Coupled Distributional Random Expert Distillation for World Model Online Imitation Learning**|Hao Su Team|[2505.02228](http://arxiv.org/abs/2505.02228)|null|
|**2025-05-04**|**CrayonRobo: Object-Centric Prompt-Driven Vision-Language-Action Model for Robotic Manipulation**|Hao Dong Team|[2505.02166](http://arxiv.org/abs/2505.02166)|null|
|**2025-05-04**|**Interleave-VLA: Enhancing Robot Manipulation with Interleaved Image-Text Instructions**|Mingyu Ding Team|[2505.02152](http://arxiv.org/abs/2505.02152)|null|
|**2025-05-03**|**Act Natural! Extending Naturalistic Projection to Multimodal Behavior Scenarios**|David Fridovich-Keil Team|[2505.01945](http://arxiv.org/abs/2505.01945)|null|
|**2025-05-07**|**RoBridge: A Hierarchical Architecture Bridging Cognition and Execution for General Robotic Manipulation**|Xiaodan Liang Team|[2505.01709](http://arxiv.org/abs/2505.01709)|null|
|**2025-05-02**|**FalconWing: An Open-Source Platform for Ultra-Light Fixed-Wing Aircraft Research**|Sayan Mitra Team|[2505.01383](http://arxiv.org/abs/2505.01383)|null|
|**2025-05-06**|**Robotic Visual Instruction**|Xianzheng Ma Team|[2505.00693](http://arxiv.org/abs/2505.00693)|null|
|**2025-05-01**|**Towards Autonomous Micromobility through Scalable Urban Simulation**|Bolei Zhou Team|[2505.00690](http://arxiv.org/abs/2505.00690)|null|
|**2025-05-01**|**DeCo: Task Decomposition and Skill Composition for Zero-Shot Generalization in Long-Horizon 3D Manipulation**|Yang Gao Team|[2505.00527](http://arxiv.org/abs/2505.00527)|null|
|**2025-05-01**|**Optimal Interactive Learning on the Job via Facility Location Planning**|George Konidaris Team|[2505.00490](http://arxiv.org/abs/2505.00490)|null|
|**2025-04-30**|**LLM-based Interactive Imitation Learning for Robotic Manipulation**|Stefan Wermter Team|[2504.21769](http://arxiv.org/abs/2504.21769)|null|
|**2025-04-30**|**RoboGround: Robotic Manipulation with Grounded Vision-Language Priors**|Zhou Zhao Team|[2504.21530](http://arxiv.org/abs/2504.21530)|null|
|**2025-04-30**|**Provably-Safe, Online System Identification**|Ram Vasudevan Team|[2504.21486](http://arxiv.org/abs/2504.21486)|null|
|**2025-04-29**|**TesserAct: Learning 4D Embodied World Models**|Chuang Gan Team|[2504.20995](http://arxiv.org/abs/2504.20995)|null|
|**2025-04-29**|**XPG-RL: Reinforcement Learning with Explainable Priority Guidance for Efficiency-Boosted Mechanical Search**|Elena Shrestha Team|[2504.20969](http://arxiv.org/abs/2504.20969)|null|
|**2025-04-29**|**PRISM: Projection-based Reward Integration for Scene-Aware Real-to-Sim-to-Real Transfer with Few Demonstrations**|Xuguang Lan Team|[2504.20520](http://arxiv.org/abs/2504.20520)|null|
|**2025-04-29**|**SPARK Hand: Scooping-Pinching Adaptive Robotic Hand with Kempe Mechanism for Vertical Passive Grasp in Environmental Constraints**|Wenzeng Zhang Team|[2504.20506](http://arxiv.org/abs/2504.20506)|null|
|**2025-04-28**|**UTTG_ A Universal Teleoperation Approach via Online Trajectory Generation**|Hesheng Wang Team|[2504.19736](http://arxiv.org/abs/2504.19736)|null|
|**2025-04-28**|**GPA-RAM: Grasp-Pretraining Augmented Robotic Attention Mamba for Spatial Task Learning**|Mengyuan Liu Team|[2504.19683](http://arxiv.org/abs/2504.19683)|null|
|**2025-04-27**|**PolyTouch: A Robust Multi-Modal Tactile Sensor for Contact-rich Manipulation Using Tactile-Diffusion Policies**|Edward Adelson Team|[2504.19341](http://arxiv.org/abs/2504.19341)|null|
|**2025-04-29**|**Learned Perceptive Forward Dynamics Model for Safe and Platform-aware Robotic Navigation**|Marco Hutter Team|[2504.19322](http://arxiv.org/abs/2504.19322)|**[link](https://github.com/leggedrobotics/fdm)**|
|**2025-04-27**|**Learning to Drive from a World Model**|Yassine Yousfi Team|[2504.19077](http://arxiv.org/abs/2504.19077)|null|
|**2025-04-26**|**RoboVerse: Towards a Unified Platform, Dataset and Benchmark for Scalable and Generalizable Robot Learning**|Pieter Abbeel Team|[2504.18904](http://arxiv.org/abs/2504.18904)|null|
|**2025-04-26**|**Imitation Learning for Autonomous Driving: Insights from Real-World Testing**|Tufan Kumbasar Team|[2504.18847](http://arxiv.org/abs/2504.18847)|null|
|**2025-04-26**|**Hierarchical Reinforcement Learning in Multi-Goal Spatial Navigation with Autonomous Mobile Robots**|Alfredo Weitzenfeld Team|[2504.18794](http://arxiv.org/abs/2504.18794)|null|
|**2025-04-26**|**STDArm: Transferring Visuomotor Policies From Static Data Training to Dynamic Robot Manipulation**|Yanyong Zhang Team|[2504.18792](http://arxiv.org/abs/2504.18792)|null|
|**2025-04-25**|**Generalization Capability for Imitation Learning**|Yixiao Wang Team|[2504.18538](http://arxiv.org/abs/2504.18538)|null|
|**2025-04-25**|**Instrumentation for Better Demonstrations: A Case Study**|Francis wyffels Team|[2504.18481](http://arxiv.org/abs/2504.18481)|null|
|**2025-04-25**|**Action Flow Matching for Continual Robot Learning**|Lantao Liu Team|[2504.18471](http://arxiv.org/abs/2504.18471)|null|
|**2025-04-25**|**Design and Evaluation of a UGV-Based Robotic Platform for Precision Soil Moisture Remote Sensing**|George Nikolakopoulos Team|[2504.18284](http://arxiv.org/abs/2504.18284)|null|
|**2025-04-28**|**Implementation Analysis of Collaborative Robot Digital Twins in Physics Engines**|Hans D. Schotten Team|[2504.18200](http://arxiv.org/abs/2504.18200)|null|
|**2025-04-25**|**Offline Learning of Controllable Diverse Behaviors**|Ludovic Denoyer Team|[2504.18160](http://arxiv.org/abs/2504.18160)|null|
|**2025-04-24**|**CIVIL: Causal and Intuitive Visual Imitation Learning**|Dylan P. Losey Team|[2504.17959](http://arxiv.org/abs/2504.17959)|null|
|**2025-04-24**|**Collaborating Action by Action: A Multi-agent LLM Framework for Embodied Reasoning**|Prithviraj Ammanabrolu Team|[2504.17950](http://arxiv.org/abs/2504.17950)|null|
|**2025-04-24**|**Learning Attentive Neural Processes for Planning with Pushing Actions**|Nicholas Roy Team|[2504.17924](http://arxiv.org/abs/2504.17924)|null|
|**2025-04-24**|**CaRL: Learning Scalable Planning Policies with Simple Rewards**|Andreas Geiger Team|[2504.17838](http://arxiv.org/abs/2504.17838)|null|
|**2025-04-23**|**Learning Underwater Active Perception in Simulation**|Donald G. Dansereau Team|[2504.17817](http://arxiv.org/abs/2504.17817)|null|
|**2025-04-24**|**Gripper Keypose and Object Pointflow as Interfaces for Bimanual Robotic Manipulation**|Jiangmiao Pang Team|[2504.17784](http://arxiv.org/abs/2504.17784)|null|
|**2025-04-24**|**Integrating Learning-Based Manipulation and Physics-Based Locomotion for Whole-Body Badminton Robot Control**|Dong Xuan Team|[2504.17771](http://arxiv.org/abs/2504.17771)|null|
|**2025-04-24**|**Robotic Grinding Skills Learning Based on Geodesic Length Dynamic Motion Primitives**|Han Ding Team|[2504.17216](http://arxiv.org/abs/2504.17216)|null|
|**2025-04-23**|**Geometric Formulation of Unified Force-Impedance Control on SE(3) for Robotic Manipulators**|Roberto Horowitz Team|[2504.17080](http://arxiv.org/abs/2504.17080)|null|
|**2025-04-23**|**A Systematic Approach to Design Real-World Human-in-the-Loop Deep Reinforcement Learning: Salient Features, Challenges and Trade-offs**|Younes Zerouali Team|[2504.17006](http://arxiv.org/abs/2504.17006)|null|
|**2025-04-23**|**Latent Diffusion Planning for Imitation Learning**|Chelsea Finn Team|[2504.16925](http://arxiv.org/abs/2504.16925)|null|
|**2025-04-23**|**MOSAIC: A Skill-Centric Algorithmic Framework for Long-Horizon Manipulation Planning**|Maxim Likhachev Team|[2504.16738](http://arxiv.org/abs/2504.16738)|null|
|**2025-04-23**|**ManipDreamer: Boosting Robotic Manipulation World Model with Action Tree and Visual Guidance**|Shanghang Zhang Team|[2504.16464](http://arxiv.org/abs/2504.16464)|null|
|**2025-04-22**|**Mass-Adaptive Admittance Control for Robotic Manipulators**|Logan E. Beaver Team|[2504.16224](http://arxiv.org/abs/2504.16224)|null|
|**2025-04-22**|**$π_{0.5}$ : a Vision-Language-Action Model with Open-World Generalization**|Ury Zhilinsky Team|[2504.16054](http://arxiv.org/abs/2504.16054)|null|
|**2025-04-22**|**SPECI: Skill Prompts based Hierarchical Continual Imitation Learning for Robot Manipulation**|Xiangli Nie Team|[2504.15561](http://arxiv.org/abs/2504.15561)|null|
|**2025-04-22**|**VibeCheck: Using Active Acoustic Tactile Sensing for Contact-Rich Manipulation**|Matei Ciocarlie Team|[2504.15535](http://arxiv.org/abs/2504.15535)|null|
|**2025-04-22**|**Few-Shot Vision-Language Action-Incremental Policy Learning**|Weili Guan Team|[2504.15517](http://arxiv.org/abs/2504.15517)|null|
|**2025-04-21**|**LAPP: Large Language Model Feedback for Preference-Driven Reinforcement Learning**|Boyuan Chen Team|[2504.15472](http://arxiv.org/abs/2504.15472)|null|
|**2025-04-23**|**Advancing Embodied Intelligence in Robotic-Assisted Endovascular Procedures: A Systematic Review of AI Solutions**|Peng Qi Team|[2504.15327](http://arxiv.org/abs/2504.15327)|null|
|**2025-04-21**|**Immersive Teleoperation Framework for Locomanipulation Tasks**|Dimitrios Kanoulas Team|[2504.15229](http://arxiv.org/abs/2504.15229)|null|
|**2025-04-21**|**A Genetic Fuzzy-Enabled Framework on Robotic Manipulation for In-Space Servicing**|Kelly Cohen Team|[2504.15226](http://arxiv.org/abs/2504.15226)|null|
|**2025-04-21**|**A General Infrastructure and Workflow for Quadrotor Deep Reinforcement Learning and Reality Deployment**|Huaping Liu Team|[2504.15129](http://arxiv.org/abs/2504.15129)|null|
|**2025-04-21**|**SuFIA-BC: Generating High Quality Demonstration Data for Visuomotor Policy Learning in Surgical Subtasks**|Animesh Garg Team|[2504.14857](http://arxiv.org/abs/2504.14857)|null|
|**2025-04-20**|**Exposing the Copycat Problem of Imitation-based Planner: A Novel Closed-Loop Simulator, Causal Benchmark and Joint IL-RL Baseline**|Hongsheng Li Team|[2504.14709](http://arxiv.org/abs/2504.14709)|null|
|**2025-04-24**|**Latent Representations for Visual Proprioception in Inexpensive Robots**|Ladislau Bölöni Team|[2504.14634](http://arxiv.org/abs/2504.14634)|null|
|**2025-04-18**|**DiffOG: Differentiable Policy Trajectory Optimization with Generalizability**|Yu She Team|[2504.13807](http://arxiv.org/abs/2504.13807)|null|
|**2025-04-18**|**Imitation Learning with Precisely Labeled Human Demonstrations**|Yilong Song Team|[2504.13803](http://arxiv.org/abs/2504.13803)|null|
|**2025-04-21**|**SLAM&Render: A Benchmark for the Intersection Between Neural Rendering, Gaussian Splatting and SLAM**|Javier Civera Team|[2504.13713](http://arxiv.org/abs/2504.13713)|**[link](https://github.com/samuel-cerezo/SLAM-Render)**|
|**2025-04-18**|**Self-Mixing Laser Interferometry: In Search of an Ambient Noise-Resilient Alternative to Acoustic Sensing**|Francis wyffels Team|[2504.13711](http://arxiv.org/abs/2504.13711)|null|
|**2025-04-18**|**On the Importance of Tactile Sensing for Imitation Learning: A Case Study on Robotic Match Lighting**|Jan Peters Team|[2504.13618](http://arxiv.org/abs/2504.13618)|null|
|**2025-04-18**|**A Model-Based Approach to Imitation Learning through Multi-Step Predictions**|Na Li Team|[2504.13413](http://arxiv.org/abs/2504.13413)|null|
|**2025-04-17**|**RoboTwin: Dual-Arm Robot Benchmark with Generative Digital Twins**|Ping Luo Team|[2504.13059](http://arxiv.org/abs/2504.13059)|null|
|**2025-04-17**|**Adaptive Task Space Non-Singular Terminal Super-Twisting Sliding Mode Control of a 7-DOF Robotic Manipulator**|E. Witrant Team|[2504.13056](http://arxiv.org/abs/2504.13056)|null|
|**2025-04-17**|**Krysalis Hand: A Lightweight, High-Payload, 18-DoF Anthropomorphic End-Effector for Robotic Learning and Dexterous Manipulation**|Iman Soltani Team|[2504.12967](http://arxiv.org/abs/2504.12967)|null|
|**2025-04-17**|**TSGS: Improving Gaussian Splatting for Transparent Surface Reconstruction via Normal and De-lighting Priors**|Yi Yang Team|[2504.12799](http://arxiv.org/abs/2504.12799)|null|
|**2025-04-17**|**Trajectory Adaptation using Large Language Models**|Ravi Prakash Team|[2504.12755](http://arxiv.org/abs/2504.12755)|null|
|**2025-04-17**|**Embodied Neuromorphic Control Applied on a 7-DOF Robotic Manipulator**|Lei Wang Team|[2504.12702](http://arxiv.org/abs/2504.12702)|**[link](https://bitbucket.org/icubdataset/inverse-dynamic)**|
|**2025-04-21**|**A0: An Affordance-Aware Hierarchical Model for General Robotic Manipulation**|Xiaodan Liang Team|[2504.12636](http://arxiv.org/abs/2504.12636)|null|
|**2025-04-17**|**Crossing the Human-Robot Embodiment Gap with Sim-to-Real RL using One Human Demonstration**|Jeannette Bohg Team|[2504.12609](http://arxiv.org/abs/2504.12609)|null|
|**2025-04-16**|**Adapting a World Model for Trajectory Following in a 3D Game**|Raluca Georgescu Team|[2504.12299](http://arxiv.org/abs/2504.12299)|null|
|**2025-04-16**|**Towards Forceful Robotic Foundation Models: a Literature Survey**|Nikolaus Correll Team|[2504.11827](http://arxiv.org/abs/2504.11827)|null|
|**2025-04-17**|**Toward Aligning Human and Robot Actions via Multi-Modal Demonstration Learning**|Fei Liu Team|[2504.11493](http://arxiv.org/abs/2504.11493)|null|
|**2025-04-15**|**Next-Future: Sample-Efficient Policy Learning for Robotic-Arm Tasks**|Suryansh Kumar Team|[2504.11247](http://arxiv.org/abs/2504.11247)|null|
|**2025-04-17**|**CAP-Net: A Unified Network for 6D Pose and Size Estimation of Categorical Articulated Parts from a Single RGB-D Image**|Yi Zhu Team|[2504.11230](http://arxiv.org/abs/2504.11230)|null|
|**2025-04-15**|**Superfast Configuration-Space Convex Set Computation on GPUs for Online Motion Planning**|Daniela Rus Team|[2504.10783](http://arxiv.org/abs/2504.10783)|**[link](https://github.com/wernerpe/csdecomp)**|
|**2025-04-14**|**Improving In-Context Learning with Reasoning Distillation**|Xiang Gao Team|[2504.10647](http://arxiv.org/abs/2504.10647)|null|
|**2025-04-14**|**Flying Hand: End-Effector-Centric Framework for Versatile Aerial Manipulation Teleoperation and Policy Learning**|Guanya Shi Team|[2504.10334](http://arxiv.org/abs/2504.10334)|null|
|**2025-04-14**|**Look-to-Touch: A Vision-Enhanced Proximity and Tactile Sensor for Distance and Geometry Perception in Robotic Manipulation**|Guoying Gu Team|[2504.10280](http://arxiv.org/abs/2504.10280)|null|
|**2025-04-14**|**Prior Does Matter: Visual Navigation via Denoising Diffusion Bridge Models**|Hui Cheng Team|[2504.10041](http://arxiv.org/abs/2504.10041)|**[link](https://github.com/hren20/naivibridger)**|
|**2025-04-14**|**Efficient Task-specific Conditional Diffusion Policies: Shortcut Model Acceleration and SO(3) Optimization**|Wei Sui Team|[2504.09927](http://arxiv.org/abs/2504.09927)|null|
|**2025-04-12**|**Compliant Explicit Reference Governor for Contact Friendly Robotic Manipulators**|Marco M. Nicotra Team|[2504.09188](http://arxiv.org/abs/2504.09188)|null|
|**2025-04-11**|**BiFlex: A Passive Bimodal Stiffness Flexible Wrist for Manipulation in Unstructured Environments**|Roberto Martín-Martín Team|[2504.08706](http://arxiv.org/abs/2504.08706)|null|
|**2025-04-11**|**Diffusion Models for Robotic Manipulation: A Survey**|Rania Rayyes Team|[2504.08438](http://arxiv.org/abs/2504.08438)|null|
|**2025-04-10**|**Echo: An Open-Source, Low-Cost Teleoperation System with Force Feedback for Dataset Collection in Robot Learning**|Dzmitry Tsetserukou Team|[2504.07939](http://arxiv.org/abs/2504.07939)|null|
|**2025-04-10**|**TOCALib: Optimal control library with interpolation for bimanual manipulation and obstacles avoidance**|Aleksandr Panov Team|[2504.07708](http://arxiv.org/abs/2504.07708)|null|
|**2025-04-10**|**Novel Diffusion Models for Multimodal 3D Hand Trajectory Prediction**|Hesheng Wang Team|[2504.07375](http://arxiv.org/abs/2504.07375)|**[link](https://github.com/irmvlab/mmtwin)**|
|**2025-04-09**|**Adaptive Vision-Guided Robotic Arm Control for Precision Pruning in Dynamic Orchard Environments**|Manoj Karkee Team|[2504.07309](http://arxiv.org/abs/2504.07309)|null|
|**2025-04-09**|**AssistanceZero: Scalably Solving Assistance Games**|Anca Dragan Team|[2504.07091](http://arxiv.org/abs/2504.07091)|**[link](https://github.com/cassidylaidlaw/minecraft-building-assistance-game)**|
|**2025-04-09**|**Two by Two: Learning Multi-Task Pairwise Objects Assembly for Generalizable Robot Manipulation**|Huazhe Xu Team|[2504.06961](http://arxiv.org/abs/2504.06961)|null|
|**2025-04-09**|**Developing Modular Grasping and Manipulation Pipeline Infrastructure to Streamline Performance Benchmarking**|Holly Yanco Team|[2504.06819](http://arxiv.org/abs/2504.06819)|null|
|**2025-04-09**|**Interactive Expressive Motion Generation Using Dynamic Movement Primitives**|Kai O. Arras Team|[2504.06735](http://arxiv.org/abs/2504.06735)|null|
|**2025-04-09**|**Overcoming Dynamic Environments: A Hybrid Approach to Motion Planning for Manipulators**|Gavin Paul Team|[2504.06596](http://arxiv.org/abs/2504.06596)|null|
|**2025-04-09**|**CAFE-AD: Cross-Scenario Adaptive Feature Enhancement for Trajectory Planning in Autonomous Driving**|Yanyong Zhang Team|[2504.06584](http://arxiv.org/abs/2504.06584)|**[link](https://github.com/alniyatrui/cafe-ad)**|
|**2025-04-09**|**OPAL: Encoding Causal Understanding of Physical Systems for Robot Learning**|Tyler Fenstermaker Team|[2504.06538](http://arxiv.org/abs/2504.06538)|null|
|**2025-04-08**|**ViTaMIn: Learning Contact-Rich Tasks Through Robot-Free Visuo-Tactile Manipulation Interface**|Rui Chen Team|[2504.06156](http://arxiv.org/abs/2504.06156)|null|
|**2025-04-08**|**MAPLE: Encoding Dexterous Robotic Manipulation Priors Learned From Egocentric Videos**|Marc Pollefeys Team|[2504.06084](http://arxiv.org/abs/2504.06084)|null|
|**2025-04-08**|**Learning-enhanced electronic skin for tactile sensing on deformable surface based on electrical impedance tomography**|Yunjie Yang Team|[2504.05987](http://arxiv.org/abs/2504.05987)|null|
|**2025-04-08**|**Stratified Expert Cloning with Adaptive Selection for User Retention in Large-Scale Recommender Systems**|Yongqi Liu Team|[2504.05628](http://arxiv.org/abs/2504.05628)|null|
|**2025-04-08**|**TW-CRL: Time-Weighted Contrastive Reward Learning for Efficient Inverse Reinforcement Learning**|Stephen Xia Team|[2504.05585](http://arxiv.org/abs/2504.05585)|null|
|**2025-04-07**|**SPARK-Remote: A Cost-Effective System for Remote Bimanual Robot Teleoperation**|Karthik Desingh Team|[2504.05488](http://arxiv.org/abs/2504.05488)|null|
|**2025-04-07**|**RobustDexGrasp: Robust Dexterous Grasping of General Objects from Single-view Perception**|Jie Song Team|[2504.05287](http://arxiv.org/abs/2504.05287)|null|
|**2025-04-07**|**Vision-Language Model Predictive Control for Manipulation Planning and Trajectory Generation**|Wei Zhang Team|[2504.05225](http://arxiv.org/abs/2504.05225)|**[link](https://github.com/ppjmchen/vlmpc)**|
|**2025-04-07**|**Wavelet Policy: Imitation Policy Learning in Frequency Domain with Wavelet Transforms**|Hongrui Zhu Team|[2504.04991](http://arxiv.org/abs/2504.04991)|null|
|**2025-04-07**|**Embodied Perception for Test-time Grasping Detection Adaptation with Knowledge Infusion**|Fengyu Zhou Team|[2504.04795](http://arxiv.org/abs/2504.04795)|null|
|**2025-04-06**|**Tool-as-Interface: Learning Robot Policies from Human Tool Usage through Imitation Learning**|Katherine Driggs-Campbell Team|[2504.04612](http://arxiv.org/abs/2504.04612)|null|
|**2025-04-06**|**Diffusion-Based Approximate MPC: Fast and Consistent Imitation of Multi-Modal Action Distributions**|Katherine J. Kuchenbecker Team|[2504.04603](http://arxiv.org/abs/2504.04603)|null|
|**2025-04-06**|**DexTOG: Learning Task-Oriented Dexterous Grasp with Language**|Cewu Lu Team|[2504.04573](http://arxiv.org/abs/2504.04573)|null|
|**2025-04-06**|**DexSinGrasp: Learning a Unified Policy for Dexterous Object Singulation and Grasping in Cluttered Environments**|Lin Shao Team|[2504.04516](http://arxiv.org/abs/2504.04516)|null|
|**2025-04-06**|**Human-Level Competitive Pokémon via Scalable Offline Reinforcement Learning with Transformers**|Yuke Zhu Team|[2504.04395](http://arxiv.org/abs/2504.04395)|null|
|**2025-04-05**|**ORCA: An Open-Source, Reliable, Cost-Effective, Anthropomorphic Robotic Hand for Uninterrupted Dexterous Task Learning**|Robert K. Katzschmann Team|[2504.04259](http://arxiv.org/abs/2504.04259)|null|
|**2025-04-09**|**Digital Gene: Learning about the Physical World through Analytic Concepts**|Cewu Lu Team|[2504.04170](http://arxiv.org/abs/2504.04170)|null|
|**2025-04-04**|**Dexterous Manipulation through Imitation Learning: A Survey**|Hong Zhang Team|[2504.03515](http://arxiv.org/abs/2504.03515)|null|
|**2025-04-04**|**GraphSeg: Segmented 3D Representations via Graph Edge Addition and Contraction**|Weiming Zhi Team|[2504.03129](http://arxiv.org/abs/2504.03129)|null|
|**2025-04-03**|**Unified World Models: Coupling Video and Action Diffusion for Pretraining on Large Robotic Datasets**|Abhishek Gupta Team|[2504.02792](http://arxiv.org/abs/2504.02792)|null|
|**2025-04-03**|**Multimodal Fusion and Vision-Language Models: A Survey for Robot Vision**|Shibiao Xu Team|[2504.02477](http://arxiv.org/abs/2504.02477)|null|
|**2025-04-02**|**RoboAct-CLIP: Video-Driven Pre-training of Atomic Action Understanding for Robotics**|Qiang Nie Team|[2504.02069](http://arxiv.org/abs/2504.02069)|null|
|**2025-04-02**|**Slot-Level Robotic Placement via Visual Imitation from Single Human Video**|Arsalan Mousavian Team|[2504.01959](http://arxiv.org/abs/2504.01959)|null|
|**2025-04-02**|**Learning with Imperfect Models: When Multi-step Prediction Mitigates Compounding Error**|Nikolai Matni Team|[2504.01766](http://arxiv.org/abs/2504.01766)|null|
|**2025-04-02**|**TransforMerger: Transformer-based Voice-Gesture Fusion for Robust Human-Robot Communication**|Karla Stepanova Team|[2504.01708](http://arxiv.org/abs/2504.01708)|null|
|**2025-04-02**|**8-DoFs Cable Driven Parallel Robots for Bimanual Teleportation**|Josie Hughes Team|[2504.01554](http://arxiv.org/abs/2504.01554)|null|
|**2025-04-02**|**Bi-LAT: Bilateral Control-Based Imitation Learning via Natural Language and Action Chunking with Transformers**|Yuki Uranishi Team|[2504.01301](http://arxiv.org/abs/2504.01301)|null|
|**2025-04-02**|**The Social Life of Industrial Arms: How Arousal and Attention Shape Human-Robot Interaction**|Matthew K. X. J Pan Team|[2504.01260](http://arxiv.org/abs/2504.01260)|null|
|**2025-04-01**|**Energy Weighted Learning Progress Guided Interleaved Multi-Task Learning**|Erhan Oztop Team|[2504.00707](http://arxiv.org/abs/2504.00707)|null|
|**2025-04-01**|**Learning Bipedal Locomotion on Gear-Driven Humanoid Robot Using Foot-Mounted IMUs**|Masaya Kinoshita Team|[2504.00614](http://arxiv.org/abs/2504.00614)|null|
|**2025-04-01**|**Think Small, Act Big: Primitive Prompt Learning for Lifelong Robot Manipulation**|Dong Wang Team|[2504.00420](http://arxiv.org/abs/2504.00420)|null|
|**2025-03-31**|**CBIL: Collective Behavior Imitation Learning for Fish from Real Videos**|Taku Komura Team|[2504.00234](http://arxiv.org/abs/2504.00234)|null|
|**2025-04-02**|**Sim-and-Real Co-Training: A Simple Recipe for Vision-Based Robotic Manipulation**|Yuke Zhu Team|[2503.24361](http://arxiv.org/abs/2503.24361)|null|
|**2025-04-02**|**AutoEval: Autonomous Evaluation of Generalist Robot Manipulation Policies in the Real World**|Sergey Levine Team|[2503.24278](http://arxiv.org/abs/2503.24278)|**[link](https://github.com/zhouzypaul/auto_eval)**|
|**2025-03-31**|**HACTS: a Human-As-Copilot Teleoperation System for Robot Learning**|Jian Tang Team|[2503.24070](http://arxiv.org/abs/2503.24070)|null|
|**2025-03-31**|**Learning 3D-Gaussian Simulators from RGB Videos**|Georg Martius Team|[2503.24009](http://arxiv.org/abs/2503.24009)|null|
|**2025-03-31**|**ZeroMimic: Distilling Robotic Manipulation Skills from Web Videos**|Dinesh Jayaraman Team|[2503.23877](http://arxiv.org/abs/2503.23877)|**[link](https://github.com/everloom-129/rekep)**|
|**2025-03-31**|**Disambiguate Gripper State in Grasp-Based Tasks: Pseudo-Tactile as Feedback Enables Pure Simulation Learning**|Yue Wang Team|[2503.23835](http://arxiv.org/abs/2503.23835)|null|
|**2025-03-30**|**Can Visuo-motor Policies Benefit from Random Exploration Data? A Case Study on Stacking**|Florian T. Pokorny Team|[2503.23571](http://arxiv.org/abs/2503.23571)|null|
|**2025-08-26**|**BEHAVIOR Robot Suite: Streamlining Real-World Whole-Body Manipulation for Everyday Household Activities**|Li Fei-Fei Team|[2503.05652](http://arxiv.org/abs/2503.05652)|**[link](https://behavior-robot-suite.github.io/)**|
|**2024-12-17**|**TidyBot++: An Open-Source Holonomic Mobile Manipulator for Robot Learning**|Jeannette Bohg Team|[2412.10447](http://arxiv.org/abs/2412.10447)|**[link](https://tidybot2.github.io)**|
|**2025-01-08**|**3D-ViTac: Learning Fine-Grained Manipulation with Visuo-Tactile Sensing**|Yunzhu Li Team|[2410.24091](http://arxiv.org/abs/2410.24091)|null|
|**2024-10-24**|**SPIRE: Synergistic Planning, Imitation, and Reinforcement Learning for Long-Horizon Manipulation**|Ajay Mandlekar Team|[2410.18065](http://arxiv.org/abs/2410.18065)|null|
|**2024-11-05**|**ManiWAV: Learning Robot Manipulation from In-the-Wild Audio-Visual Data**|Shuran Song Team|[2406.19464](http://arxiv.org/abs/2406.19464)|**[link](https://maniwav.github.io/)**|
|**2023-10-31**|**Learning Robot Manipulation from Cross-Morphology Demonstration**|Gaurav Sukhatme Team|[2304.03833](http://arxiv.org/abs/2304.03833)|null|
|**2022-11-17**|**ToolFlowNet: Robotic Manipulation with Tools via Predicting Tool Flow from Point Clouds**|David Held Team|[2211.09006](http://arxiv.org/abs/2211.09006)|**[link](https://sites.google.com/view/point-cloud-policy/home)**|
|**2022-11-16**|**Learning and Retrieval from Prior Data for Skill-based Imitation Learning**|Yuke Zhu Team|[2210.11435](http://arxiv.org/abs/2210.11435)|null|
|**2023-03-09**|**VIOLA: Imitation Learning for Vision-Based Manipulation with Object Proposal Priors**|Yuke Zhu Team|[2210.11339](http://arxiv.org/abs/2210.11339)|null|
|**2022-10-12**|**Self-Supervised Learning of Multi-Object Keypoints for Robotic Manipulation**|Abhinav Valada Team|[2205.08316](http://arxiv.org/abs/2205.08316)|null|
|**2022-11-21**|**R3M: A Universal Visual Representation for Robot Manipulation**|Abhinav Gupta Team|[2203.12601](http://arxiv.org/abs/2203.12601)|null|
|**2022-02-07**|**BC-Z: Zero-Shot Task Generalization with Robotic Imitation Learning**|Chelsea Finn Team|[2202.02005](http://arxiv.org/abs/2202.02005)|null|
|**2021-11-02**|**Learning Language-Conditioned Robot Behavior from Offline Data and Crowd-Sourced Annotation**|Chelsea Finn Team|[2109.01115](http://arxiv.org/abs/2109.01115)|null|
|**2021-06-11**|**Coarse-to-Fine Imitation Learning: Robot Manipulation from a Single Demonstration**|Edward Johns Team|[2105.06411](http://arxiv.org/abs/2105.06411)|**[link](https://www.robot-learning.uk/coarse-to-fine-imitation-learning)**|
|**2022-03-09**|**Interactive Imitation Learning in State-Space**|Jens Kober Team|[2008.00524](http://arxiv.org/abs/2008.00524)|null|
|**2020-05-19**|**On-Policy Robot Imitation Learning from a Converging Supervisor**|Ken Goldberg Team|[1907.03423](http://arxiv.org/abs/1907.03423)|null|
|**2018-11-08**|**RoboTurk: A Crowdsourcing Platform for Robotic Skill Learning through Imitation**|Li Fei-Fei Team|[1811.02790](http://arxiv.org/abs/1811.02790)|null|
|**2018-10-09**|**Robustness via Retrying: Closed-Loop Robotic Manipulation with Self-Supervised Learning**|Chelsea Finn Team|[1810.03043](http://arxiv.org/abs/1810.03043)|null|
|**2017-10-27**|**Learning Robotic Manipulation of Granular Media**|Sergey Levine Team|[1709.02833](http://arxiv.org/abs/1709.02833)|null|

<p align=right>(<a href=#updated-on-20251217>back to top</a>)</p>

## VLM

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-12-12**|**Extending a Parliamentary Corpus with MPs' Tweets: Automatic Annotation and Evaluation Using MultiParTweet**|Alexander Mehler Team|[2512.11567](http://arxiv.org/abs/2512.11567)|null|
|**2025-12-12**|**VLM2GeoVec: Toward Universal Multimodal Embeddings for Remote Sensing**|Michael Felsberg Team|[2512.11490](http://arxiv.org/abs/2512.11490)|null|
|**2025-12-12**|**Exploring MLLM-Diffusion Information Transfer with MetaCanvas**|Chu Wang Team|[2512.11464](http://arxiv.org/abs/2512.11464)|**[link](https://metacanvas.github.io)**|
|**2025-12-12**|**Minimal Clips, Maximum Salience: Long Video Summarization via Key Moment Extraction**|Nancy F. Chen Team|[2512.11399](http://arxiv.org/abs/2512.11399)|null|
|**2025-12-12**|**The N-Body Problem: Parallel Execution from Single-Person Egocentric Video**|Dima Damen Team|[2512.11393](http://arxiv.org/abs/2512.11393)|**[link](https://zhifanzhu.github.io/ego-nbody)**|
|**2025-12-12**|**Surveillance Video-Based Traffic Accident Detection Using Transformer Architecture**|Long T. Truong Team|[2512.11350](http://arxiv.org/abs/2512.11350)|null|
|**2025-12-12**|**AMBER: An Adaptive Multimodal Mask Transformer for Beam Prediction with Missing Modalities**|Jiangzhou Wang Team|[2512.11331](http://arxiv.org/abs/2512.11331)|null|
|**2025-12-12**|**Benchmarking the Generality of Vision-Language-Action Models**|Yangyue Wang Team|[2512.11315](http://arxiv.org/abs/2512.11315)|null|
|**2025-12-12**|**Towards Logic-Aware Manipulation: A Knowledge Primitive for VLM-Based Assistants in Smart Manufacturing**|Daqiang Guo Team|[2512.11275](http://arxiv.org/abs/2512.11275)|null|
|**2025-12-12**|**Seeing to Act, Prompting to Specify: A Bayesian Factorization of Vision Language Action Policy**|Yue Wang Team|[2512.11218](http://arxiv.org/abs/2512.11218)|null|
|**2025-12-11**|**Image Tiling for High-Resolution Reasoning: Balancing Local Detail with Global Context**|Irina Rish Team|[2512.11167](http://arxiv.org/abs/2512.11167)|null|
|**2025-12-11**|**Limits and Gains of Test-Time Scaling in Vision-Language Reasoning**|Mahdieh Soleymani Baghshah Team|[2512.11109](http://arxiv.org/abs/2512.11109)|null|
|**2025-12-11**|**Vision-Language Models for Infrared Industrial Sensing in Additive Manufacturing Scene Description**|Vinh Nguyen Team|[2512.11098](http://arxiv.org/abs/2512.11098)|null|
|**2025-12-11**|**VDAWorld: World Modelling via VLM-Directed Abstraction and Simulation**|Ayush Tewari Team|[2512.11061](http://arxiv.org/abs/2512.11061)|**[link](https://felixomahony.github.io/vdaworld/)**|
|**2025-12-11**|**Synthetic Vasculature and Pathology Enhance Vision-Language Model Reasoning**|Johannes C. Paetzold Team|[2512.11060](http://arxiv.org/abs/2512.11060)|null|
|**2025-12-11**|**VL-JEPA: Joint Embedding Predictive Architecture for Vision-language**|Pascale Fung Team|[2512.10942](http://arxiv.org/abs/2512.10942)|null|
|**2025-12-11**|**BabyVLM-V2: Toward Developmentally Grounded Pretraining and Benchmarking of Vision Foundation Models**|Boqing Gong Team|[2512.10932](http://arxiv.org/abs/2512.10932)|null|
|**2025-12-11**|**DuetSVG: Unified Multimodal SVG Generation with Internal Visual Guidance**|Difan Liu Team|[2512.10894](http://arxiv.org/abs/2512.10894)|**[link](https://intchous.github.io/DuetSVG-site)**|
|**2025-12-11**|**PubTables-v2: A new large-scale dataset for full-page and multi-page table extraction**|Maury Courtland Team|[2512.10888](http://arxiv.org/abs/2512.10888)|null|
|**2025-12-11**|**From Macro to Micro: Benchmarking Microscopic Spatial Intelligence on Molecules via Vision-Language Models**|Wenbing Huang Team|[2512.10867](http://arxiv.org/abs/2512.10867)|null|
|**2025-12-11**|**SpaceDrive: Infusing Spatial Awareness into VLM-based Autonomous Driving**|Andreas Zell Team|[2512.10719](http://arxiv.org/abs/2512.10719)|null|
|**2025-12-11**|**Enhancing Radiology Report Generation and Visual Grounding using Reinforcement Learning**|Michael Krauthammer Team|[2512.10691](http://arxiv.org/abs/2512.10691)|null|
|**2025-12-11**|**DOCR-Inspector: Fine-Grained and Automated Evaluation of Document Parsing with VLM**|Wentao Zhang Team|[2512.10619](http://arxiv.org/abs/2512.10619)|null|
|**2025-12-11**|**Beyond Pixels: A Training-Free, Text-to-Text Framework for Remote Sensing Image Retrieval**|M. Prasad Team|[2512.10596](http://arxiv.org/abs/2512.10596)|null|
|**2025-12-11**|**Boosting RL-Based Visual Reasoning with Selective Adversarial Entropy Intervention**|Xiaomeng Li Team|[2512.10414](http://arxiv.org/abs/2512.10414)|null|
|**2025-12-11**|**Towards Fine-Grained Recognition with Large Visual Language Models: Benchmark and Optimization Strategies**|Xin Lou Team|[2512.10384](http://arxiv.org/abs/2512.10384)|null|
|**2025-12-11**|**CoSPlan: Corrective Sequential Planning via Scene Graph Incremental Updates**|Yogesh S Rawat Team|[2512.10342](http://arxiv.org/abs/2512.10342)|null|
|**2025-12-11**|**Multilingual VLM Training: Adapting an English-Trained VLM to French**|Alexis Roger Team|[2512.10336](http://arxiv.org/abs/2512.10336)|null|
|**2025-12-11**|**ConStruct: Structural Distillation of Foundation Models for Prototype-Based Weakly Supervised Histopathology Segmentation**|Hien Van Nguyen Team|[2512.10316](http://arxiv.org/abs/2512.10316)|null|
|**2025-12-11**|**Investigating The Functional Roles of Attention Heads in Vision Language Models: Evidence for Reasoning Modules**|Krista A. Ehinger Team|[2512.10300](http://arxiv.org/abs/2512.10300)|null|
|**2025-12-11**|**Solving Semi-Supervised Few-Shot Learning from an Auto-Annotation Perspective**|Shu Kong Team|[2512.10244](http://arxiv.org/abs/2512.10244)|**[link](https://tian1327.github.io/SWIFT)**|
|**2025-12-10**|**Independent Density Estimation**|Jiahao Liu Team|[2512.10067](http://arxiv.org/abs/2512.10067)|null|
|**2025-12-10**|**SimWorld-Robotics: Synthesizing Photorealistic and Dynamic Urban Environments for Multimodal Robot Navigation and Collaboration**|Tianmin Shu Team|[2512.10046](http://arxiv.org/abs/2512.10046)|null|
|**2025-12-06**|**Echo-CoPilot: A Multi-View, Multi-Task Agent for Echocardiography Interpretation and Reporting**|Ilker Hacihaliloglu Team|[2512.09944](http://arxiv.org/abs/2512.09944)|null|
|**2025-12-10**|**ReViSE: Towards Reason-Informed Video Editing in Unified Models with Self-Reflective Learning**|Yike Guo Team|[2512.09924](http://arxiv.org/abs/2512.09924)|**[link](https://github.com/Liuxinyv/ReViSE))**|
|**2025-12-10**|**VisualActBench: Can VLMs See and Act like a Human?**|Jiebo Luo Team|[2512.09907](http://arxiv.org/abs/2512.09907)|null|
|**2025-12-10**|**Benchmarking Document Parsers on Mathematical Formula Extraction from PDFs**|Janis Keuper Team|[2512.09874](http://arxiv.org/abs/2512.09874)|null|
|**2025-12-10**|**An Automated Tip-and-Cue Framework for Optimized Satellite Tasking and Visual Intelligence**|Israel Cohen Team|[2512.09670](http://arxiv.org/abs/2512.09670)|null|
|**2025-12-10**|**Building Reasonable Inference for Vision-Language Models in Blind Image Quality Assessment**|Shin'ya Nishida Team|[2512.09555](http://arxiv.org/abs/2512.09555)|null|
|**2025-12-10**|**Defect-aware Hybrid Prompt Optimization via Progressive Tuning for Zero-Shot Multi-type Anomaly Detection and Segmentation**|Steffen Staab Team|[2512.09446](http://arxiv.org/abs/2512.09446)|null|
|**2025-12-10**|**Representation Calibration and Uncertainty Guidance for Class-Incremental Learning based on Vision Language Model**|Ruixuan Wang Team|[2512.09441](http://arxiv.org/abs/2512.09441)|null|
|**2025-12-10**|**COVLM-RL: Critical Object-Oriented Reasoning for Autonomous Driving Using VLM-Guided Reinforcement Learning**|Chen Lv Team|[2512.09349](http://arxiv.org/abs/2512.09349)|null|
|**2025-12-10**|**View-on-Graph: Zero-shot 3D Visual Grounding via Vision-Language Reasoning on Scene Graphs**|Xin Yang Team|[2512.09215](http://arxiv.org/abs/2512.09215)|null|
|**2025-12-09**|**Prompt-Based Continual Compositional Zero-Shot Learning**|Mohsen Ali Team|[2512.09172](http://arxiv.org/abs/2512.09172)|null|
|**2025-12-09**|**ConceptPose: Training-Free Zero-Shot Object Pose Estimation using Concept Vectors**|Benjamin Busam Team|[2512.09056](http://arxiv.org/abs/2512.09056)|null|
|**2025-12-05**|**Mitigating Bias with Words: Inducing Demographic Ambiguity in Face Recognition Templates by Text Encoding**|Fadi Boutros Team|[2512.08981](http://arxiv.org/abs/2512.08981)|null|
|**2025-12-09**|**Unified Diffusion Transformer for High-fidelity Text-Aware Image Restoration**|Seungryong Kim Team|[2512.08922](http://arxiv.org/abs/2512.08922)|null|
|**2025-12-09**|**SATGround: A Spatially-Aware Approach for Visual Grounding in Remote Sensing**|Jiankang Deng Team|[2512.08881](http://arxiv.org/abs/2512.08881)|null|
|**2025-12-09**|**Tri-Bench: Stress-Testing VLM Reliability on Spatial Reasoning under Camera Tilt and Object Interference**|Amit Bendkhale Team|[2512.08860](http://arxiv.org/abs/2512.08860)|**[link](https://github.com/Amiton7/Tri-Bench.)**|
|**2025-12-09**|**InfiniteVL: Synergizing Linear and Sparse Attention for Highly-Efficient, Unlimited-Input Vision-Language Models**|Xinggang Wang Team|[2512.08829](http://arxiv.org/abs/2512.08829)|null|
|**2025-12-09**|**Training-Free Dual Hyperbolic Adapters for Better Cross-Modal Reasoning**|Angelica I. Aviles-Rivero Team|[2512.08820](http://arxiv.org/abs/2512.08820)|null|
|**2025-12-09**|**Trajectory Densification and Depth from Perspective-based Blur**|Yueting Chen Team|[2512.08627](http://arxiv.org/abs/2512.08627)|null|
|**2025-12-09**|**Mind to Hand: Purposeful Robotic Control via Embodied Reasoning**|Jianan Wang Team|[2512.08580](http://arxiv.org/abs/2512.08580)|null|
|**2025-12-09**|**Beyond Real Weights: Hypercomplex Representations for Stable Quantization**|Shafin Rahman Team|[2512.08524](http://arxiv.org/abs/2512.08524)|null|
|**2025-12-09**|**OpenSubject: Leveraging Video-Derived Identity and Diversity Priors for Subject-driven Image Generation and Manipulation**|Harry Yang Team|[2512.08294](http://arxiv.org/abs/2512.08294)|null|
|**2025-12-09**|**PAVAS: Physics-Aware Video-to-Audio Synthesis**|Yuki Mitsufuji Team|[2512.08282](http://arxiv.org/abs/2512.08282)|null|
|**2025-12-09**|**HybridToken-VLM: Hybrid Token Compression for Vision-Language Models**|Keze Wang Team|[2512.08240](http://arxiv.org/abs/2512.08240)|null|
|**2025-12-09**|**Semantic-Metric Bayesian Risk Fields: Learning Robot Safety from Human Videos with a VLM Prior**|Mac Schwager Team|[2512.08233](http://arxiv.org/abs/2512.08233)|null|
|**2025-12-09**|**MM-CoT:A Benchmark for Probing Visual Chain-of-Thought Reasoning in Multimodal Models**|Keze Wang Team|[2512.08228](http://arxiv.org/abs/2512.08228)|null|
|**2025-12-09**|**Ground Slow, Move Fast: A Dual-System Foundation Model for Generalizable Vision-and-Language Navigation**|Xihui Liu Team|[2512.08186](http://arxiv.org/abs/2512.08186)|null|
|**2025-12-08**|**CAMO: Causality-Guided Adversarial Multimodal Domain Generalization for Crisis Classification**|Huan Liu Team|[2512.08071](http://arxiv.org/abs/2512.08071)|null|
|**2025-12-08**|**FRIEDA: Benchmarking Multi-Step Cartographic Reasoning in Vision-Language Models**|Yao-Yi Chiang Team|[2512.08016](http://arxiv.org/abs/2512.08016)|null|
|**2025-12-08**|**Relational Visual Similarity**|Yuheng Li Team|[2512.07833](http://arxiv.org/abs/2512.07833)|**[link](https://thaoshibe.github.io/relsim)**|
|**2025-12-08**|**Unison: A Fully Automatic, Task-Universal, and Low-Cost Framework for Unified Understanding and Generation**|Kwan-Yee K. Wong Team|[2512.07747](http://arxiv.org/abs/2512.07747)|null|
|**2025-12-08**|**Toward More Reliable Artificial Intelligence: Reducing Hallucinations in Vision-Language Models**|Renzo Ardiccioni Team|[2512.07564](http://arxiv.org/abs/2512.07564)|**[link](https://github.com/kassoumsanogo1/self-correcting-vlm-re-Attention.git)**|
|**2025-12-08**|**From Show Programmes to Data: Designing a Workflow to Make Performing Arts Ephemera Accessible Through Language Models**|Jeanne Fras Team|[2512.07452](http://arxiv.org/abs/2512.07452)|null|
|**2025-12-08**|**Structure-Aware Feature Rectification with Region Adjacency Graphs for Training-Free Open-Vocabulary Semantic Segmentation**|Jianbo Jiao Team|[2512.07360](http://arxiv.org/abs/2512.07360)|null|
|**2025-12-08**|**Venus: An Efficient Edge Memory-and-Retrieval System for VLM-based Online Video Understanding**|Xu Chen Team|[2512.07344](http://arxiv.org/abs/2512.07344)|null|
|**2025-12-08**|**Towards Accurate UAV Image Perception: Guiding Vision-Language Models with Stronger Task Prompts**|Chao Tao Team|[2512.07302](http://arxiv.org/abs/2512.07302)|null|
|**2025-12-08**|**Geo3DVQA: Evaluating Vision-Language Models for 3D Geospatial Reasoning from Aerial Imagery**|Naoto Yokoya Team|[2512.07276](http://arxiv.org/abs/2512.07276)|null|
|**2025-12-08**|**RVLF: A Reinforcing Vision-Language Framework for Gloss-Free Sign Language Translation**|Jun Wan Team|[2512.07273](http://arxiv.org/abs/2512.07273)|null|
|**2025-12-08**|**Zero-Shot Textual Explanations via Translating Decision-Critical Features**|Kazuhiko Kawamoto Team|[2512.07245](http://arxiv.org/abs/2512.07245)|null|
|**2025-12-08**|**Dropout Prompt Learning: Towards Robust and Adaptive Vision-Language Models**|Yuchen Wang Team|[2512.07234](http://arxiv.org/abs/2512.07234)|null|
|**2025-12-08**|**Pay Less Attention to Function Words for Free Robustness of Vision-Language Models**|Chao Shen Team|[2512.07222](http://arxiv.org/abs/2512.07222)|null|
|**2025-12-08**|**VFM-VLM: Vision Foundation Model and Vision Language Model based Visual Comparison for 3D Pose Estimation**|Sungho Kim Team|[2512.07215](http://arxiv.org/abs/2512.07215)|null|
|**2025-12-08**|**MMRPT: MultiModal Reinforcement Pre-Training via Masked Vision-Dependent Reasoning**|Yichao Wu Team|[2512.07203](http://arxiv.org/abs/2512.07203)|null|
|**2025-12-08**|**Using Vision-Language Models as Proxies for Social Intelligence in Human-Robot Interaction**|Wendy Ju Team|[2512.07177](http://arxiv.org/abs/2512.07177)|null|
|**2025-12-08**|**CHIMERA: Adaptive Cache Injection and Semantic Anchor Prompting for Zero-shot Image Morphing with Morphing-oriented Metrics**|Jihyong Oh Team|[2512.07155](http://arxiv.org/abs/2512.07155)|**[link](https://cmlab-korea.github.io/CHIMERA/)**|
|**2025-12-08**|**Think-Reflect-Revise: A Policy-Guided Reflective Framework for Safety Alignment in Large Vision Language Models**|Wenjie Wang Team|[2512.07141](http://arxiv.org/abs/2512.07141)|null|
|**2025-12-08**|**A Large-Scale Multimodal Dataset and Benchmarks for Human Activity Scene Understanding and Reasoning**|Guoliang Xing Team|[2512.07136](http://arxiv.org/abs/2512.07136)|null|
|**2025-12-08**|**DART: Leveraging Multi-Agent Disagreement for Tool Recruitment in Multimodal Reasoning**|Mohit Bansal Team|[2512.07132](http://arxiv.org/abs/2512.07132)|**[link](https://github.com/nsivaku/dart)**|
|**2025-12-08**|**MulCLIP: A Multi-level Alignment Framework for Enhancing Fine-grained Long-context CLIP**|Dung D. Le Team|[2512.07128](http://arxiv.org/abs/2512.07128)|null|
|**2025-12-07**|**Structural and Disentangled Adaptation of Large Vision Language Models for Multimodal Recommendation**|Nan Tang Team|[2512.06883](http://arxiv.org/abs/2512.06883)|null|
|**2025-12-07**|**Pseudo Anomalies Are All You Need: Diffusion-Based Generation for Weakly-Supervised Video Anomaly Detection**|Mori Kurokawa Team|[2512.06845](http://arxiv.org/abs/2512.06845)|null|
|**2025-12-07**|**Decouple to Generalize: Context-First Self-Evolving Learning for Data-Scarce Vision-Language Reasoning**|Cheng Tan Team|[2512.06835](http://arxiv.org/abs/2512.06835)|null|
|**2025-12-07**|**RMAdapter: Reconstruction-based Multi-Modal Adapter for Vision-Language Models**|Di Huang Team|[2512.06811](http://arxiv.org/abs/2512.06811)|null|
|**2025-12-07**|**Stitch and Tell: A Structured Multimodal Data Augmentation Method for Spatial Understanding**|Kan Li Team|[2512.06769](http://arxiv.org/abs/2512.06769)|null|
|**2025-12-07**|**VisChainBench: A Benchmark for Multi-Turn, Multi-Image Visual Reasoning Beyond Language Priors**|Ling Shao Team|[2512.06759](http://arxiv.org/abs/2512.06759)|null|
|**2025-12-07**|**UARE: A Unified Vision-Language Model for Image Quality Assessment, Restoration, and Enhancement**|Shijie Zhao Team|[2512.06750](http://arxiv.org/abs/2512.06750)|null|
|**2025-12-07**|**Task-Model Alignment: A Simple Path to Generalizable AI-Generated Image Detection**|Shouhong Ding Team|[2512.06746](http://arxiv.org/abs/2512.06746)|null|
|**2025-12-07**|**A Novel Multimodal RUL Framework for Remaining Useful Life Estimation with Layer-wise Explanations**|Yun-Bo Zhao Team|[2512.06708](http://arxiv.org/abs/2512.06708)|null|
|**2025-12-07**|**CoT4Det: A Chain-of-Thought Framework for Perception-Oriented Vision-Language Tasks**|Jingdong Wang Team|[2512.06663](http://arxiv.org/abs/2512.06663)|null|
|**2025-12-07**|**Personalized Image Descriptions from Attention Sequences**|Dimitris Samaras Team|[2512.06662](http://arxiv.org/abs/2512.06662)|null|
|**2025-12-07**|**MIND-V: Hierarchical Video Generation for Long-Horizon Robotic Manipulation with RL-based Physical Alignment**|Xiu Li Team|[2512.06628](http://arxiv.org/abs/2512.06628)|null|
|**2025-12-06**|**MedGRPO: Multi-Task Reinforcement Learning for Heterogeneous Medical Video Understanding**|Ziyan Wu Team|[2512.06581](http://arxiv.org/abs/2512.06581)|null|
|**2025-12-06**|**Are AI-Generated Driving Videos Ready for Autonomous Driving? A Diagnostic Evaluation Framework**|Jiawei Zhang Team|[2512.06376](http://arxiv.org/abs/2512.06376)|null|
|**2025-12-06**|**ReCAD: Reinforcement Learning Enhanced Parametric CAD Model Generation with Vision-Language Models**|Xiangdong Zhou Team|[2512.06328](http://arxiv.org/abs/2512.06328)|null|
|**2025-12-06**|**Knowing the Answer Isn't Enough: Fixing Reasoning Path Failures in LVLMs**|Huaxiu Yao Team|[2512.06258](http://arxiv.org/abs/2512.06258)|null|
|**2025-12-06**|**Language-driven Fine-grained Retrieval**|Zi Huang Team|[2512.06255](http://arxiv.org/abs/2512.06255)|null|
|**2025-12-05**|**BeLLA: End-to-End Birds Eye View Large Language Assistant for Autonomous Driving**|Amit Arvind Kale Team|[2512.06096](http://arxiv.org/abs/2512.06096)|null|
|**2025-12-04**|**DreamFoley: Scalable VLMs for High-Fidelity Video-to-Audio Generation**|Dongliang He Team|[2512.06022](http://arxiv.org/abs/2512.06022)|null|
|**2025-12-03**|**Training-Free Robot Pose Estimation using Off-the-Shelf Foundational Models**|Laurence Liang Team|[2512.06017](http://arxiv.org/abs/2512.06017)|null|
|**2025-12-05**|**Training-Time Action Conditioning for Efficient Real-Time Chunking**|Sergey Levine Team|[2512.05964](http://arxiv.org/abs/2512.05964)|null|
|**2025-12-05**|**M4-RAG: A Massive-Scale Multilingual Multi-Cultural Multimodal RAG**|Genta Indra Winata Team|[2512.05959](http://arxiv.org/abs/2512.05959)|null|
|**2025-12-05**|**SIMPACT: Simulation-Enabled Action Planning using Vision-Language Models**|Yilun Du Team|[2512.05955](http://arxiv.org/abs/2512.05955)|null|
|**2025-12-05**|**Impugan: Learning Conditional Generative Models for Robust Data Imputation**|Aritran Piplai Team|[2512.05950](http://arxiv.org/abs/2512.05950)|null|
|**2025-12-05**|**TRACE: A Framework for Analyzing and Enhancing Stepwise Reasoning in Vision-Language Models**|Babak Damavandi Team|[2512.05943](http://arxiv.org/abs/2512.05943)|null|
|**2025-12-05**|**Zoom in, Click out: Unlocking and Evaluating the Potential of Zooming for GUI Grounding**|Shilong Liu Team|[2512.05941](http://arxiv.org/abs/2512.05941)|**[link](https://github.com/Princeton-AI2-Lab/ZoomClick)**|
|**2025-12-05**|**PRiSM: An Agentic Multimodal Benchmark for Scientific Reasoning via Python-Grounded Evaluation**|Babak Damavandi Team|[2512.05930](http://arxiv.org/abs/2512.05930)|null|
|**2025-12-05**|**VRSA: Jailbreaking Multimodal Large Language Models through Visual Reasoning Sequential Attack**|Xingxing Wei Team|[2512.05853](http://arxiv.org/abs/2512.05853)|null|
|**2025-12-05**|**Probing the effectiveness of World Models for Spatial Reasoning through Test-time Scaling**|Sarath Chandar Team|[2512.05809](http://arxiv.org/abs/2512.05809)|null|
|**2025-12-05**|**Distilling Expert Surgical Knowledge: How to train local surgical VLMs for anatomy explanation in Complete Mesocolic Excision**|Alexander Schlaefer Team|[2512.05740](http://arxiv.org/abs/2512.05740)|null|
|**2025-12-05**|**HiMoE-VLA: Hierarchical Mixture-of-Experts for Generalist Vision-Language-Action Policies**|Yu-Gang Jiang Team|[2512.05693](http://arxiv.org/abs/2512.05693)|null|
|**2025-12-05**|**MedTutor-R1: Socratic Personalized Medical Teaching with Multi-Agent Simulation**|Yi R Fung Team|[2512.05671](http://arxiv.org/abs/2512.05671)|null|
|**2025-12-05**|**Interleaved Latent Visual Reasoning with Selective Perceptual Modeling**|Zhongyu Wei Team|[2512.05665](http://arxiv.org/abs/2512.05665)|**[link](https://github.com/XD111ds/ILVR)**|
|**2025-12-05**|**Fast SceneScript: Accurate and Efficient Structured Language Model via Multi-Token Prediction**|Theo Gevers Team|[2512.05597](http://arxiv.org/abs/2512.05597)|null|
|**2025-12-05**|**Learning High-Fidelity Cloth Animation via Skinning-Free Image Transfer**|Hongdong Li Team|[2512.05593](http://arxiv.org/abs/2512.05593)|null|
|**2025-12-05**|**Machine and Deep Learning Regression for Compact Object Equations of State**|Ch. C. Moustakidis Team|[2512.05566](http://arxiv.org/abs/2512.05566)|null|
|**2025-12-05**|**ProPhy: Progressive Physical Alignment for Dynamic World Simulation**|Xiaodan Liang Team|[2512.05564](http://arxiv.org/abs/2512.05564)|null|
|**2025-12-05**|**Conscious Gaze: Adaptive Attention Mechanisms for Hallucination Mitigation in Vision-Language Models**|Guixian Zhang Team|[2512.05546](http://arxiv.org/abs/2512.05546)|null|
|**2025-12-05**|**MIND: Multi-rationale INtegrated Discriminative Reasoning Framework for Multi-modal Large Models**|Xiangyu Yue Team|[2512.05530](http://arxiv.org/abs/2512.05530)|null|
|**2025-12-05**|**Poodle: Seamlessly Scaling Down Large Language Models with Just-in-Time Model Replacement**|Tilmann Rabl Team|[2512.05525](http://arxiv.org/abs/2512.05525)|null|
|**2025-12-05**|**VOST-SGG: VLM-Aided One-Stage Spatio-Temporal Scene Graph Generation**|Basura Fernando Team|[2512.05524](http://arxiv.org/abs/2512.05524)|null|
|**2025-12-05**|**DashFusion: Dual-stream Alignment with Hierarchical Bottleneck Fusion for Multimodal Sentiment Analysis**|Ya Li Team|[2512.05515](http://arxiv.org/abs/2512.05515)|null|
|**2025-12-05**|**Lyrics Matter: Exploiting the Power of Learnt Representations for Music Popularity Prediction**|Pushpak Bhattacharyya Team|[2512.05508](http://arxiv.org/abs/2512.05508)|null|
|**2025-12-05**|**Concept-based Explainable Data Mining with VLM for 3D Detection**|Mai Tsujimoto Team|[2512.05482](http://arxiv.org/abs/2512.05482)|**[link](https://github.com/mm1129/concept_based_rare_detector_2025)**|
|**2025-12-05**|**ArtistMus: A Globally Diverse, Artist-Centric Benchmark for Retrieval-Augmented Music Question Answering**|Juhan Nam Team|[2512.05430](http://arxiv.org/abs/2512.05430)|null|
|**2025-12-05**|**ParaUni: Enhance Generation in Unified Multimodal Model with Reinforcement-driven Hierarchical Parallel Information Interaction**|Feng Zhao Team|[2512.05422](http://arxiv.org/abs/2512.05422)|null|
|**2025-12-05**|**The Dynamic Prior: Understanding 3D Structures for Casual Dynamic Videos**|Jun Gao Team|[2512.05398](http://arxiv.org/abs/2512.05398)|**[link](https://github.com/wuzy2115/DYNAPO)**|
|**2025-12-05**|**LoC-Path: Learning to Compress for Pathology Multimodal Large Language Models**|Chao Chen Team|[2512.05391](http://arxiv.org/abs/2512.05391)|null|
|**2025-12-05**|**ShaRP: SHAllow-LayeR Pruning for Video Large Language Models Acceleration**|Xi Wang Team|[2512.05385](http://arxiv.org/abs/2512.05385)|null|
|**2025-12-05**|**SpaceControl: Introducing Test-Time Spatial Control to 3D Generative Modeling**|Leonidas Guibas Team|[2512.05343](http://arxiv.org/abs/2512.05343)|**[link](https://spacecontrol3d.github.io/)**|
|**2025-12-04**|**From Segments to Scenes: Temporal Understanding in Autonomous Driving via Vision-Language Model**|Mohammad Akbari Team|[2512.05277](http://arxiv.org/abs/2512.05277)|null|
|**2025-12-04**|**Semore: VLM-guided Enhanced Semantic Motion Representations for Visual Reinforcement Learning**|Yan Wang Team|[2512.05172](http://arxiv.org/abs/2512.05172)|null|
|**2025-12-04**|**DraCo: Draft as CoT for Text-to-Image Preview and Rare Concept Generation**|Hongsheng Li Team|[2512.05112](http://arxiv.org/abs/2512.05112)|**[link](https://github.com/CaraJ7/DraCo)**|
|**2025-12-04**|**ARM-Thinker: Reinforcing Multimodal Generative Reward Models with Agentic Tool Use and Visual Reasoning**|Jiaqi Wang Team|[2512.05111](http://arxiv.org/abs/2512.05111)|null|
|**2025-12-04**|**STARE-VLA: Progressive Stage-Aware Reinforcement for Fine-Tuning Vision-Language-Action Models**|Benjamin Busam Team|[2512.05107](http://arxiv.org/abs/2512.05107)|null|
|**2025-12-04**|**TV2TV: A Unified Framework for Interleaved Language and Video Generation**|Emily Dinan Team|[2512.05103](http://arxiv.org/abs/2512.05103)|null|
|**2025-12-04**|**Visual Reasoning Tracer: Object-Level Grounded Reasoning Benchmark**|Ming-Hsuan Yang Team|[2512.05091](http://arxiv.org/abs/2512.05091)|**[link](https://harboryuan.github.io/visual-reasoning-tracer)**|
|**2025-12-04**|**Aligned but Stereotypical? The Hidden Influence of System Prompts on Social Bias in LVLM-Based Text-to-Image Models**|Hyunjung Shim Team|[2512.04981](http://arxiv.org/abs/2512.04981)|**[link](https://fairpro-t2i.github.io)**|
|**2025-12-04**|**FASTer: Toward Efficient Autoregressive Vision Language Action Modeling via neural Action Tokenization**|Hang Zhao Team|[2512.04952](http://arxiv.org/abs/2512.04952)|null|
|**2025-12-04**|**Chameleon: Adaptive Adversarial Agents for Scaling-Based Visual Prompt Injection in Multimodal AI Systems**|Saud Satti Team|[2512.04895](http://arxiv.org/abs/2512.04895)|null|
|**2025-12-04**|**ASTRIDE: A Security Threat Modeling Platform for Agentic-AI Applications**|Nilaan Loganathan Team|[2512.04785](http://arxiv.org/abs/2512.04785)|null|
|**2025-12-04**|**MemLoRA: Distilling Expert Adapters for On-Device Memory Systems**|Taha Ceritli Team|[2512.04763](http://arxiv.org/abs/2512.04763)|null|
|**2025-12-04**|**E3AD: An Emotion-Aware Vision-Language-Action Model for Human-Centric End-to-End Autonomous Driving**|Chengzhong Xu Team|[2512.04733](http://arxiv.org/abs/2512.04733)|null|
|**2025-12-04**|**Measuring the Unspoken: A Disentanglement Model and Benchmark for Psychological Analysis in the Wild**|Jie Liu Team|[2512.04728](http://arxiv.org/abs/2512.04728)|null|
|**2025-12-04**|**Towards Cross-View Point Correspondence in Vision-Language Models**|Xiaolong Zheng Team|[2512.04686](http://arxiv.org/abs/2512.04686)|null|
|**2025-12-04**|**Reward Forcing: Efficient Streaming Video Generation with Rewarded Distribution Matching Distillation**|Min Zhang Team|[2512.04678](http://arxiv.org/abs/2512.04678)|null|
|**2025-12-04**|**SEASON: Mitigating Temporal Hallucination in Video Large Language Models via Self-Diagnostic Contrastive Decoding**|Yu-Chiang Frank Wang Team|[2512.04643](http://arxiv.org/abs/2512.04643)|null|
|**2025-12-04**|**Turbo-Muon: Accelerating Orthogonality-Based Optimization with Pre-Conditioning**|Mathieu Serrurier Team|[2512.04632](http://arxiv.org/abs/2512.04632)|null|
|**2025-12-04**|**Neural Decoding of Overt Speech from ECoG Using Vision Transformers and Contrastive Representation Learning**|Blaise Yvert Team|[2512.04618](http://arxiv.org/abs/2512.04618)|null|
|**2025-12-04**|**Malicious Image Analysis via Vision-Language Segmentation Fusion: Detection, Element, and Location in One-shot**|Shuo Wang Team|[2512.04599](http://arxiv.org/abs/2512.04599)|null|
|**2025-12-04**|**When Robots Should Say "I Don't Know": Benchmarking Abstention in Embodied Question Answering**|Jianfei Yang Team|[2512.04597](http://arxiv.org/abs/2512.04597)|null|
|**2025-12-04**|**SAM3-I: Segment Anything with Instructions**|Li Cheng Team|[2512.04585](http://arxiv.org/abs/2512.04585)|null|
|**2025-12-04**|**VideoMem: Enhancing Ultra-Long Video Understanding via Adaptive Memory Management**|Sijie Cheng Team|[2512.04540](http://arxiv.org/abs/2512.04540)|null|
|**2025-12-04**|**dVLM-AD: Enhance Diffusion Vision-Language-Model for Driving via Controllable Reasoning**|Chaowei Xiao Team|[2512.04459](http://arxiv.org/abs/2512.04459)|null|
|**2025-12-04**|**MindDrive: An All-in-One Framework Bridging World Models and Vision-Language Model for End-to-End Autonomous Driving**|Ziying Song Team|[2512.04441](http://arxiv.org/abs/2512.04441)|null|
|**2025-12-04**|**Fourier-Attentive Representation Learning: A Fourier-Guided Framework for Few-Shot Generalization in Vision-Language Models**|Cuong Tuan Nguyen Team|[2512.04395](http://arxiv.org/abs/2512.04395)|null|
|**2025-12-03**|**How (Mis)calibrated is Your Federated CLIP and What To Do About It?**|Subhankar Roy Team|[2512.04305](http://arxiv.org/abs/2512.04305)|null|
|**2025-12-03**|**6 Fingers, 1 Kidney: Natural Adversarial Medical Images Reveal Critical Weaknesses of Vision-Language Models**|Lena Maier-Hein Team|[2512.04238](http://arxiv.org/abs/2512.04238)|null|
|**2025-12-03**|**SpaceTools: Tool-Augmented Spatial Reasoning via Double Interactive RL**|Jonathan Tremblay Team|[2512.04069](http://arxiv.org/abs/2512.04069)|null|
|**2025-12-03**|**Stable Signer: Hierarchical Sign Language Generative Model**|Dimitris N. Metaxas Team|[2512.04048](http://arxiv.org/abs/2512.04048)|**[link](https://stablesigner.github.io)**|
|**2025-12-03**|**Jina-VLM: Small Multilingual Vision Language Model**|Han Xiao Team|[2512.04032](http://arxiv.org/abs/2512.04032)|null|
|**2025-12-03**|**DIQ-H: Evaluating Hallucination Persistence in VLMs Under Temporal Visual Degradation**|Xiaoqiang Team|[2512.03992](http://arxiv.org/abs/2512.03992)|null|
|**2025-12-03**|**TempR1: Improving Temporal Understanding of MLLMs via Temporal-Aware Multi-Task Reinforcement Learning**|Limin Wang Team|[2512.03963](http://arxiv.org/abs/2512.03963)|null|
|**2025-12-03**|**Hierarchical Vision Language Action Model Using Success and Failure Demonstrations**|Sungjoon Choi Team|[2512.03913](http://arxiv.org/abs/2512.03913)|**[link](https://vine-vla.github.io/)**|
|**2025-12-03**|**OmniDexVLG: Learning Dexterous Grasp Generation from Vision Language Model-Guided Grasp Semantics, Taxonomy and Functional Affordance**|Jianwei Zhang Team|[2512.03874](http://arxiv.org/abs/2512.03874)|**[link](https://sites.google.com/view/omnidexvlg)**|
|**2025-12-03**|**PULSE: A Unified Multi-Task Architecture for Cardiac Segmentation, Diagnosis, and Few-Shot Cross-Modality Clinical Adaptation**|Muzammil Behzad Team|[2512.03848](http://arxiv.org/abs/2512.03848)|null|
|**2025-12-03**|**AdaptVision: Efficient Vision-Language Models via Adaptive Visual Acquisition**|Deheng Ye Team|[2512.03794](http://arxiv.org/abs/2512.03794)|null|
|**2025-12-03**|**Universally Converging Representations of Matter Across Scientific Foundation Models**|Rafael Gómez-Bombarelli Team|[2512.03750](http://arxiv.org/abs/2512.03750)|null|
|**2025-12-03**|**Thinking with Programming Vision: Towards a Unified View for Thinking with Images**|Tao Jin Team|[2512.03746](http://arxiv.org/abs/2512.03746)|null|
|**2025-12-03**|**PosA-VLA: Enhancing Action Generation via Pose-Conditioned Anchor Attention**|Mingming Gong Team|[2512.03724](http://arxiv.org/abs/2512.03724)|null|
|**2025-12-03**|**ConvRot: Rotation-Based Plug-and-Play 4-bit Quantization for Diffusion Transformers**|Haoqian Wang Team|[2512.03673](http://arxiv.org/abs/2512.03673)|null|
|**2025-12-03**|**Colon-X: Advancing Intelligent Colonoscopy from Multimodal Understanding to Clinical Reasoning**|Nick Barnes Team|[2512.03667](http://arxiv.org/abs/2512.03667)|null|
|**2025-12-03**|**Optical Context Compression Is Just (Bad) Autoencoding**|Taylor Berg-Kirkpatrick Team|[2512.03643](http://arxiv.org/abs/2512.03643)|null|
|**2025-12-03**|**MemVerse: Multimodal Memory for Lifelong Learning Agents**|Ding Wang Team|[2512.03627](http://arxiv.org/abs/2512.03627)|null|
|**2025-12-03**|**The promising potential of vision language models for the generation of textual weather forecasts**|Charles Ewen Team|[2512.03623](http://arxiv.org/abs/2512.03623)|null|
|**2025-12-03**|**LAMP: Language-Assisted Motion Planning for Controllable Video Generation**|Duygu Ceylan Team|[2512.03619](http://arxiv.org/abs/2512.03619)|null|
|**2025-12-03**|**CartoMapQA: A Fundamental Benchmark Dataset Evaluating Vision-Language Models on Cartographic Map Understanding**|Yan Liu Team|[2512.03558](http://arxiv.org/abs/2512.03558)|null|
|**2025-12-03**|**Dynamic Content Moderation in Livestreams: Combining Supervised Classification with MLLM-Boosted Similarity Matching**|Danhui Guan Team|[2512.03553](http://arxiv.org/abs/2512.03553)|null|
|**2025-12-02**|**OneThinker: All-in-one Reasoning Model for Image and Video**|Xiangyu Yue Team|[2512.03043](http://arxiv.org/abs/2512.03043)|**[link](https://github.com/tulerfeng/OneThinker)**|
|**2025-12-02**|**InEx: Hallucination Mitigation via Introspection and Cross-Modal Multi-Agent Collaboration**|Wei Pang Team|[2512.02981](http://arxiv.org/abs/2512.02981)|null|
|**2025-12-02**|**Contextual Image Attack: How Visual Context Exposes Multimodal Safety Vulnerabilities**|Jing Shao Team|[2512.02973](http://arxiv.org/abs/2512.02973)|null|
|**2025-12-02**|**Lumos: Let there be Language Model System Certification**|Gagandeep Singh Team|[2512.02966](http://arxiv.org/abs/2512.02966)|null|
|**2025-12-02**|**AutoNeural: Co-Designing Vision-Language Models for NPU Inference**|Han Yang Team|[2512.02924](http://arxiv.org/abs/2512.02924)|null|
|**2025-12-02**|**MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding**|Kaihao Zhang Team|[2512.02906](http://arxiv.org/abs/2512.02906)|null|
|**2025-12-02**|**VLA Models Are More Generalizable Than You Think: Revisiting Physical and Spatial Modeling**|Guangrun Wang Team|[2512.02902](http://arxiv.org/abs/2512.02902)|null|
|**2025-12-02**|**MindGPT-4ov: An Enhanced MLLM via a Multi-Stage Post-Training Paradigm**|Xuhan Zhu Team|[2512.02895](http://arxiv.org/abs/2512.02895)|null|
|**2025-12-02**|**Action Anticipation at a Glimpse: To What Extent Can Multimodal Cues Replace Video?**|Jose Garcia-Rodriguez Team|[2512.02846](http://arxiv.org/abs/2512.02846)|null|
|**2025-12-02**|**VLM as Strategist: Adaptive Generation of Safety-critical Testing Scenarios via Guided Diffusion**|Yong Shen Team|[2512.02844](http://arxiv.org/abs/2512.02844)|null|
|**2025-12-02**|**ReVSeg: Incentivizing the Reasoning Chain for Video Segmentation with Reinforcement Learning**|Yanwei Fu Team|[2512.02835](http://arxiv.org/abs/2512.02835)|null|
|**2025-12-02**|**Steering Vision-Language-Action Models as Anti-Exploration: A Test-Time Scaling Approach**|Xuelong Li Team|[2512.02834](http://arxiv.org/abs/2512.02834)|null|
|**2025-12-02**|**Radiologist Copilot: An Agentic Assistant with Orchestrated Tools for Radiology Reporting with Quality Control**|Xiaofan Zhang Team|[2512.02814](http://arxiv.org/abs/2512.02814)|null|
|**2025-12-02**|**Diagnose, Correct, and Learn from Manipulation Failures via Visual Symbols**|Yong-Lu Li Team|[2512.02787](http://arxiv.org/abs/2512.02787)|null|
|**2025-12-02**|**Reasoning-Aware Multimodal Fusion for Hateful Video Detection**|Zeyu Fu Team|[2512.02743](http://arxiv.org/abs/2512.02743)|null|
|**2025-12-02**|**RoboWheel: A Data Engine from Real-World Human Demonstrations for Cross-Embodiment Robotic Learning**|Haoqian Wang Team|[2512.02729](http://arxiv.org/abs/2512.02729)|null|
|**2025-12-02**|**Emergent Bayesian Behaviour and Optimal Cue Combination in LLMs**|Zafeirios Fountas Team|[2512.02719](http://arxiv.org/abs/2512.02719)|null|
|**2025-12-02**|**GeoViS: Geospatially Rewarded Visual Search for Remote Sensing Visual Grounding**|Lei Wang Team|[2512.02715](http://arxiv.org/abs/2512.02715)|null|
|**2025-12-02**|**VLM-Pruner: Buffering for Spatial Sparsity in an Efficient VLM Centrifugal Token Pruning Paradigm**|Xinghao Chen Team|[2512.02700](http://arxiv.org/abs/2512.02700)|null|
|**2025-12-02**|**GeoBridge: A Semantic-Anchored Multi-View Foundation Model Bridging Images and Text for Geo-Localization**|Bo Du Team|[2512.02697](http://arxiv.org/abs/2512.02697)|null|
|**2025-12-01**|**ManualVLA: A Unified VLA Model for Chain-of-Thought Manual Generation and Robotic Manipulation**|Shanghang Zhang Team|[2512.02013](http://arxiv.org/abs/2512.02013)|null|
|**2025-12-01**|**PAI-Bench: A Comprehensive Benchmark For Physical AI**|Humphrey Shi Team|[2512.01989](http://arxiv.org/abs/2512.01989)|null|
|**2025-12-01**|**Low-Rank Prehab: Preparing Neural Networks for SVD Compression**|Soheil Kolouri Team|[2512.01980](http://arxiv.org/abs/2512.01980)|null|
|**2025-12-01**|**Chain-of-Ground: Improving GUI Grounding via Iterative Reasoning and Reference Feedback**|Shilong Liu Team|[2512.01979](http://arxiv.org/abs/2512.01979)|null|
|**2025-12-01**|**GrndCtrl: Grounding World Models via Self-Supervised Reward Alignment**|Sebastian Scherer Team|[2512.01952](http://arxiv.org/abs/2512.01952)|null|
|**2025-12-01**|**Script: Graph-Structured and Query-Conditioned Semantic Token Pruning for Multimodal Large Language Models**|Yingfang Yuan Team|[2512.01949](http://arxiv.org/abs/2512.01949)|**[link](https://01yzzyu.github.io/script.github.io/)**|
|**2025-12-01**|**Guardian: Detecting Robotic Planning and Execution Errors with Vision-Language Models**|Cordelia Schmid Team|[2512.01946](http://arxiv.org/abs/2512.01946)|null|
|**2025-12-01**|**Med-VCD: Mitigating Hallucination for Medical Large Vision Language Models through Visual Contrastive Decoding**|Omid Nejati Manzari Team|[2512.01922](http://arxiv.org/abs/2512.01922)|null|
|**2025-12-01**|**PhyDetEx: Detecting and Explaining the Physical Plausibility of T2V Models**|Lei Zhang Team|[2512.01843](http://arxiv.org/abs/2512.01843)|null|
|**2025-12-01**|**OpenREAD: Reinforced Open-Ended Reasoing for End-to-End Autonomous Driving with LLM-as-Critic**|Chen Lv Team|[2512.01830](http://arxiv.org/abs/2512.01830)|null|
|**2025-12-01**|**CauSight: Learning to Supersense for Visual Causal Discovery**|Chaochao Lu Team|[2512.01827](http://arxiv.org/abs/2512.01827)|**[link](https://github.com/OpenCausaLab/CauSight)**|
|**2025-12-01**|**Seeing through Imagination: Learning Scene Geometry via Implicit Spatial World Modeling**|Xiaodan Liang Team|[2512.01821](http://arxiv.org/abs/2512.01821)|null|
|**2025-12-01**|**Generative Action Tell-Tales: Assessing Human Motion in Synthesized Videos**|Deepti Ghadiyaram Team|[2512.01803](http://arxiv.org/abs/2512.01803)|null|
|**2025-12-01**|**GR-RL: Going Dexterous and Precise for Long-Horizon Robotic Manipulation**|Yonghui Wu Team|[2512.01801](http://arxiv.org/abs/2512.01801)|null|
|**2025-12-01**|**IGen: Scalable Data Generation for Robot Learning from Open-World Images**|Zhi Wang Team|[2512.01773](http://arxiv.org/abs/2512.01773)|null|
|**2025-12-01**|**VideoScoop: A Non-Traditional Domain-Independent Framework For Video Analysis**|Hafsa Billah Team|[2512.01769](http://arxiv.org/abs/2512.01769)|null|
|**2025-12-01**|**FreqEdit: Preserving High-Frequency Features for Robust Multi-Turn Image Editing**|Xudong Mao Team|[2512.01755](http://arxiv.org/abs/2512.01755)|null|
|**2025-12-01**|**DiG-Flow: Discrepancy-Guided Flow Matching for Robust VLA Models**|Zongqing Lu Team|[2512.01715](http://arxiv.org/abs/2512.01715)|null|
|**2025-12-01**|**StreamGaze: Gaze-Guided Temporal Reasoning and Proactive Understanding in Streaming Videos**|Mohit Bansal Team|[2512.01707](http://arxiv.org/abs/2512.01707)|**[link](https://streamgaze.github.io/)**|
|**2025-12-01**|**DreamingComics: A Story Visualization Pipeline via Subject and Layout Customized Generation using Video Models**|Chen Chen Team|[2512.01686](http://arxiv.org/abs/2512.01686)|null|
|**2025-11-28**|**Video-R2: Reinforcing Consistent and Grounded Reasoning in Multimodal Language Models**|Salman Khan Team|[2511.23478](http://arxiv.org/abs/2511.23478)|null|
|**2025-11-28**|**Video-CoM: Interactive Video Reasoning via Chain of Manipulations**|Salman Khan Team|[2511.23477](http://arxiv.org/abs/2511.23477)|null|
|**2025-11-28**|**Visual Generation Tuning**|Xinggang Wang Team|[2511.23469](http://arxiv.org/abs/2511.23469)|null|
|**2025-11-28**|**Hunyuan-GameCraft-2: Instruction-following Interactive Game World Model**|Qinglin Lu Team|[2511.23429](http://arxiv.org/abs/2511.23429)|**[link](https://hunyuan-gamecraft-2.github.io/)**|
|**2025-11-28**|**LFM2 Technical Report**|Neehal Tumma Team|[2511.23404](http://arxiv.org/abs/2511.23404)|null|
|**2025-11-28**|**DEAL-300K: Diffusion-based Editing Area Localization with a 300K-Scale Dataset and Frequency-Prompted Baseline**|Qiang Zeng Team|[2511.23377](http://arxiv.org/abs/2511.23377)|null|
|**2025-11-28**|**Optimizing Multimodal Language Models through Attention-based Interpretability**|Evgeny Kotelnikov Team|[2511.23375](http://arxiv.org/abs/2511.23375)|null|
|**2025-11-28**|**Toward Automatic Safe Driving Instruction: A Large-Scale Vision Language Model Approach**|Taro Watanabe Team|[2511.23311](http://arxiv.org/abs/2511.23311)|null|
|**2025-11-28**|**SafeHumanoid: VLM-RAG-driven Control of Upper Body Impedance for Humanoid Robot**|Dzmitry Tsetserukou Team|[2511.23300](http://arxiv.org/abs/2511.23300)|null|
|**2025-11-28**|**Transformer-Driven Triple Fusion Framework for Enhanced Multimodal Author Intent Classification in Low-Resource Bangla**|Md Rifat Hossen Team|[2511.23287](http://arxiv.org/abs/2511.23287)|null|
|**2025-11-28**|**OctoMed: Data Recipes for State-of-the-Art Multimodal Medical Reasoning**|Hoifung Poon Team|[2511.23269](http://arxiv.org/abs/2511.23269)|null|
|**2025-11-28**|**Adapting Like Humans: A Metacognitive Agent with Test-time Reasoning**|Jun Wang Team|[2511.23262](http://arxiv.org/abs/2511.23262)|null|
|**2025-11-28**|**AgriCoT: A Chain-of-Thought Benchmark for Evaluating Reasoning in Vision-Language Models for Agriculture**|Juepeng Zheng Team|[2511.23253](http://arxiv.org/abs/2511.23253)|null|
|**2025-11-28**|**Unlocking Multilingual Reasoning Capability of LLMs and LVLMs through Representation Engineering**|Bing Qin Team|[2511.23231](http://arxiv.org/abs/2511.23231)|null|
|**2025-11-28**|**TWEO: Transformers Without Extreme Outliers Enables FP8 Training And Quantization For Dummies**|Jianxin Wu Team|[2511.23225](http://arxiv.org/abs/2511.23225)|null|
|**2025-11-28**|**Instruction Tuning of Large Language Models for Tabular Data Generation-in One Day**|Biplab Sikdar Team|[2511.23220](http://arxiv.org/abs/2511.23220)|null|
|**2025-11-28**|**Obstruction reasoning for robotic grasping**|Fabio Poiesi Team|[2511.23186](http://arxiv.org/abs/2511.23186)|null|
|**2025-11-28**|**Learning to Refuse: Refusal-Aware Reinforcement Fine-Tuning for Hard-Irrelevant Queries in Video Temporal Grounding**|Jee-Hyong Lee Team|[2511.23151](http://arxiv.org/abs/2511.23151)|null|
|**2025-11-28**|**Analyzing Image Beyond Visual Aspect: Image Emotion Classification via Multiple-Affective Captioning**|Hansen Yang Team|[2511.23115](http://arxiv.org/abs/2511.23115)|null|
|**2025-11-28**|**MathSight: A Benchmark Exploring Have Vision-Language Models Really Seen in University-Level Mathematical Reasoning?**|Zhenzhou Shao Team|[2511.23112](http://arxiv.org/abs/2511.23112)|**[link](https://cnu-bot-group.github.io/MathSight/)**|
|**2025-11-26**|**G $^2$ VLM: Geometry Grounded Vision Language Model with Unified 3D Reconstruction and Spatial Reasoning**|Jiangmiao Pang Team|[2511.21688](http://arxiv.org/abs/2511.21688)|**[link](https://github.com/InternRobotics/G2VLM)**|
|**2025-11-26**|**Attention-Guided Patch-Wise Sparse Adversarial Attacks on Vision-Language-Action Models**|Nan Zhang Team|[2511.21663](http://arxiv.org/abs/2511.21663)|null|
|**2025-11-26**|**Qwen3-VL Technical Report**|Ke Zhu Team|[2511.21631](http://arxiv.org/abs/2511.21631)|null|
|**2025-11-26**|**Automated Protein Motif Localization using Concept Activation Vectors in Protein Language Model Embedding Space**|Claire D. McWhite Team|[2511.21614](http://arxiv.org/abs/2511.21614)|null|
|**2025-11-26**|**VacuumVLA: Boosting VLA Capabilities via a Unified Suction and Gripping Tool for Complex Robotic Manipulation**|Shaoshuai Shi Team|[2511.21557](http://arxiv.org/abs/2511.21557)|null|
|**2025-11-26**|**$\mathcal{E}_0$ : Enhancing Generalization and Fine-Grained Control in VLA Models via Continuized Discrete Diffusion**|Guangrun Wang Team|[2511.21542](http://arxiv.org/abs/2511.21542)|null|
|**2025-11-26**|**Video Generation Models Are Good Latent Reward Models**|Fan Tang Team|[2511.21541](http://arxiv.org/abs/2511.21541)|null|
|**2025-11-26**|**EoS-FM: Can an Ensemble of Specialist Models act as a Generalist Feature Extractor?**|Sébastien Lefèvre Team|[2511.21523](http://arxiv.org/abs/2511.21523)|null|
|**2025-11-26**|**IntAttention: A Fully Integer Attention Pipeline for Efficient Edge Inference**|Shiqi Yu Team|[2511.21513](http://arxiv.org/abs/2511.21513)|null|
|**2025-11-26**|**From Observation to Action: Latent Action-based Primitive Segmentation for VLA Pre-training in Industrial Settings**|Alexander Kleiner Team|[2511.21428](http://arxiv.org/abs/2511.21428)|null|
|**2025-11-26**|**SAM Guided Semantic and Motion Changed Region Mining for Remote Sensing Change Captioning**|Jin Tang Team|[2511.21420](http://arxiv.org/abs/2511.21420)|null|
|**2025-11-26**|**Do Reasoning Vision-Language Models Inversely Scale in Test-Time Compute? A Distractor-centric Empirical Analysis**|Jaeho Lee Team|[2511.21397](http://arxiv.org/abs/2511.21397)|null|
|**2025-11-26**|**Monet: Reasoning in Latent Visual Space Beyond Images and Language**|Yisen Wang Team|[2511.21395](http://arxiv.org/abs/2511.21395)|null|
|**2025-11-26**|**Thinking With Bounding Boxes: Enhancing Spatio-Temporal Video Grounding via Reinforcement Fine-Tuning**|Sijie Zhu Team|[2511.21375](http://arxiv.org/abs/2511.21375)|null|
|**2025-11-26**|**SurgMLLMBench: A Multimodal Large Language Model Benchmark Dataset for Surgical Scene Understanding**|Juyoun Park Team|[2511.21339](http://arxiv.org/abs/2511.21339)|null|
|**2025-11-26**|**Co-Training Vision Language Models for Remote Sensing Multi-task Learning**|Junchi Yan Team|[2511.21272](http://arxiv.org/abs/2511.21272)|null|
|**2025-11-26**|**Multi-Reward GRPO for Stable and Prosodic Single-Codebook TTS LLMs at Scale**|Zhisheng Wang Team|[2511.21270](http://arxiv.org/abs/2511.21270)|null|
|**2025-11-26**|**AVFakeBench: A Comprehensive Audio-Video Forgery Detection Benchmark for AV-LMMs**|Zekun Li Team|[2511.21251](http://arxiv.org/abs/2511.21251)|null|
|**2025-11-26**|**Towards an Effective Action-Region Tracking Framework for Fine-grained Video Action Recognition**|Zhiyong Wang Team|[2511.21202](http://arxiv.org/abs/2511.21202)|null|
|**2025-11-26**|**When Robots Obey the Patch: Universal Transferable Patch Attacks on Vision-Language-Action Models**|Xudong Jiang Team|[2511.21192](http://arxiv.org/abs/2511.21192)|null|
|**2025-11-25**|**LocateAnything3D: Vision-Language 3D Detection with Chain-of-Sight**|Zhiding Yu Team|[2511.20648](http://arxiv.org/abs/2511.20648)|**[link](https://nvlabs.github.io/LocateAnything3D/)**|
|**2025-11-25**|**Vision-Language Memory for Spatial Reasoning**|Chen Wang Team|[2511.20644](http://arxiv.org/abs/2511.20644)|null|
|**2025-11-25**|**Concept-Aware Batch Sampling Improves Language-Image Pretraining**|Matthias Bethge Team|[2511.20643](http://arxiv.org/abs/2511.20643)|null|
|**2025-11-25**|**Unleashing the Power of Vision-Language Models for Long-Tailed Multi-Label Visual Recognition**|Min-Ling Zhang Team|[2511.20641](http://arxiv.org/abs/2511.20641)|null|
|**2025-11-25**|**Reinforcing Action Policies by Prophesying**|Li Zhang Team|[2511.20633](http://arxiv.org/abs/2511.20633)|**[link](https://LogosRoboticsGroup.github.io/ProphRL)**|
|**2025-11-25**|**MapReduce LoRA: Advancing the Pareto Front in Multi-Preference Optimization for Generative Models**|Humphrey Shi Team|[2511.20629](http://arxiv.org/abs/2511.20629)|null|
|**2025-11-25**|**Fighting AI with AI: Leveraging Foundation Models for Assuring AI-Enabled Safety-Critical Systems**|Corina S. Păsăreanu Team|[2511.20627](http://arxiv.org/abs/2511.20627)|null|
|**2025-11-25**|**Does Understanding Inform Generation in Unified Multimodal Models? From Analysis to Path Forward**|Li Yuan Team|[2511.20561](http://arxiv.org/abs/2511.20561)|null|
|**2025-11-25**|**Beyond Generation: Multi-Hop Reasoning for Factual Accuracy in Vision-Language Models**|Shamima Hossain Team|[2511.20531](http://arxiv.org/abs/2511.20531)|null|
|**2025-11-25**|**Adam Simplified: Bias Correction Simplified**|Antonio Orvieto Team|[2511.20516](http://arxiv.org/abs/2511.20516)|null|
|**2025-11-25**|**DesignPref: Capturing Personal Preferences in Visual Design Generation**|Jason Wu Team|[2511.20513](http://arxiv.org/abs/2511.20513)|null|
|**2025-11-25**|**NVIDIA Nemotron Parse 1.1**|Bryan Catanzaro Team|[2511.20478](http://arxiv.org/abs/2511.20478)|null|
|**2025-11-25**|**Object-Centric Vision Token Pruning for Vision Language Models**|Joni Pajarinen Team|[2511.20439](http://arxiv.org/abs/2511.20439)|null|
|**2025-11-25**|**VibraVerse: A Large-Scale Geometry-Acoustics Alignment Dataset for Physically-Consistent Multimodal Learning**|Sheng Li Team|[2511.20422](http://arxiv.org/abs/2511.20422)|null|
|**2025-11-25**|**NNGPT: Rethinking AutoML with Large Language Models**|Radu Timofte Team|[2511.20333](http://arxiv.org/abs/2511.20333)|null|
|**2025-11-25**|**Bootstrapping Physics-Grounded Video Generation through VLM-Guided Iterative Self-Refinement**|Qingming Huang Team|[2511.20280](http://arxiv.org/abs/2511.20280)|null|
|**2025-11-25**|**ScenarioCLIP: Pretrained Transferable Visual Language Models and Action-Genome Dataset for Natural Scene Analysis**|Abhijit Das Team|[2511.20274](http://arxiv.org/abs/2511.20274)|null|
|**2025-11-25**|**VKnowU: Evaluating Visual Knowledge Understanding in Multimodal LLMs**|Yi Wang Team|[2511.20272](http://arxiv.org/abs/2511.20272)|null|
|**2025-11-25**|**Rectified Flow for Vision-Aided mmWave V2I Beam Prediction**|Henk Wymeersch Team|[2511.20265](http://arxiv.org/abs/2511.20265)|null|
|**2025-11-25**|**V-Attack: Targeting Disentangled Value Features for Controllable Adversarial Attacks on LVLMs**|Xilin Chen Team|[2511.20223](http://arxiv.org/abs/2511.20223)|null|
|**2025-11-24**|**Mixture of Horizons in Action Chunking**|Mingyu Ding Team|[2511.19433](http://arxiv.org/abs/2511.19433)|null|
|**2025-11-24**|**Cook and Clean Together: Teaching Embodied Agents for Parallel Task Execution**|Xiang Bai Team|[2511.19430](http://arxiv.org/abs/2511.19430)|**[link](https://github.com/H-EmbodVis/GRANT})**|
|**2025-11-24**|**Chain-of-Visual-Thought: Teaching VLMs to See and Think Better with Continuous Visual Tokens**|Xudong Wang Team|[2511.19418](http://arxiv.org/abs/2511.19418)|**[link](https://wakalsprojectpage.github.io/comt-website/)**|
|**2025-11-24**|**Be My Eyes: Extending Large Language Models to New Modalities Through Multi-Agent Collaboration**|Hoifung Poon Team|[2511.19417](http://arxiv.org/abs/2511.19417)|null|
|**2025-11-24**|**UISearch: Graph-Based Embeddings for Multimodal Enterprise UI Screenshots Retrieval**|Rima Kilany Team|[2511.19380](http://arxiv.org/abs/2511.19380)|null|
|**2025-11-24**|**Rethinking Intermediate Representation for VLM-based Robot Manipulation**|Chi-Wing Fu Team|[2511.19315](http://arxiv.org/abs/2511.19315)|null|
|**2025-11-24**|**LAST: LeArning to Think in Space and Time for Generalist Vision-Language Models**|Jiaheng Wei Team|[2511.19261](http://arxiv.org/abs/2511.19261)|null|
|**2025-11-24**|**Medusa: Cross-Modal Transferable Adversarial Attacks on Multimodal Medical Retrieval-Augmented Generation**|Yefeng Zheng Team|[2511.19257](http://arxiv.org/abs/2511.19257)|null|
|**2025-11-24**|**Percept-WAM: Perception-Enhanced World-Awareness-Action Model for Robust End-to-End Autonomous Driving**|Hang Xu Team|[2511.19221](http://arxiv.org/abs/2511.19221)|null|
|**2025-11-24**|**Are Large Vision Language Models Truly Grounded in Medical Images? Evidence from Italian Clinical Visual Question Answering**|Marcello Di Pumpo Team|[2511.19220](http://arxiv.org/abs/2511.19220)|null|
|**2025-11-24**|**Can Modern Vision Models Understand the Difference Between an Object and a Look-alike?**|Amir Rosenfeld Team|[2511.19200](http://arxiv.org/abs/2511.19200)|null|
|**2025-11-24**|**EEG-VLM: A Hierarchical Vision-Language Model with Multi-Level Feature Alignment and Visually Enhanced Language-Guided Reasoning for EEG Image-Based Sleep Stage Prediction**|Shuo Li Team|[2511.19155](http://arxiv.org/abs/2511.19155)|null|
|**2025-11-24**|**From Pixels to Posts: Retrieval-Augmented Fashion Captioning and Hashtag Generation**|Asma Ahmad Farhan Team|[2511.19149](http://arxiv.org/abs/2511.19149)|null|
|**2025-11-24**|**ABM-LoRA: Activation Boundary Matching for Fast Convergence in Low-Rank Adaptation**|Junseok Kwon Team|[2511.19145](http://arxiv.org/abs/2511.19145)|null|
|**2025-11-24**|**MonoSR: Open-Vocabulary Spatial Reasoning from Monocular Images**|Shijie Li Team|[2511.19119](http://arxiv.org/abs/2511.19119)|null|
|**2025-11-24**|**DiffSeg30k: A Multi-Turn Diffusion Editing Benchmark for Localized AIGC Detection**|Mike Zheng Shou Team|[2511.19111](http://arxiv.org/abs/2511.19111)|null|
|**2025-11-24**|**LLMAID: Identifying AI Capabilities in Android Apps with LLMs**|Hongyu Zhang Team|[2511.19059](http://arxiv.org/abs/2511.19059)|null|
|**2025-11-24**|**MedSAM3: Delving into Segment Anything with Medical Concepts**|Jintai Chen Team|[2511.19046](http://arxiv.org/abs/2511.19046)|null|
|**2025-11-24**|**Benchmarking Corruption Robustness of LVLMs: A Discriminative Benchmark and Robustness Alignment Metric**|Xin Sun Team|[2511.19032](http://arxiv.org/abs/2511.19032)|null|
|**2025-11-24**|**Rethinking Plant Disease Diagnosis: Bridging the Academic-Practical Gap with Vision Transformers and Zero-Shot Learning**|Bilal Fortas Team|[2511.18989](http://arxiv.org/abs/2511.18989)|null|
|**2025-11-21**|**RynnVLA-002: A Unified Vision-Language-Action and World Model**|Hao Chen Team|[2511.17502](http://arxiv.org/abs/2511.17502)|null|
|**2025-11-21**|**Downscaling Intelligence: Exploring Perception and Reasoning Bottlenecks in Small Multimodal Models**|Serena Yeung-Levy Team|[2511.17487](http://arxiv.org/abs/2511.17487)|**[link](https://web.stanford.edu/~markendo/projects/downscaling_intelligence)**|
|**2025-11-21**|**Counterfactual World Models via Digital Twin-conditioned Video Diffusion**|Mathias Unberath Team|[2511.17481](http://arxiv.org/abs/2511.17481)|null|
|**2025-11-21**|**MMT-ARD: Multimodal Multi-Teacher Adversarial Distillation for Robust Vision-Language Models**|Yew-Soon Ong Team|[2511.17448](http://arxiv.org/abs/2511.17448)|null|
|**2025-11-21**|**REMSA: An LLM Agent for Foundation Model Selection in Remote Sensing**|Begüm Demir Team|[2511.17442](http://arxiv.org/abs/2511.17442)|**[link](https://github.com/be-chen/REMSA)**|
|**2025-11-21**|**SMILE: A Composite Lexical-Semantic Metric for Question-Answering Evaluation**|Juan Carlos Niebles Team|[2511.17432](http://arxiv.org/abs/2511.17432)|null|
|**2025-11-21**|**SPEAR-1: Scaling Beyond Robot Demonstrations via 3D Understanding**|Danda Pani Paudel Team|[2511.17411](http://arxiv.org/abs/2511.17411)|null|
|**2025-11-21**|**IndustryNav: Exploring Spatial Reasoning of Embodied Agents in Dynamic Industrial Navigation**|Yu Kong Team|[2511.17384](http://arxiv.org/abs/2511.17384)|null|
|**2025-11-21**|**METIS: Multi-Source Egocentric Training for Integrated Dexterous Vision-Language-Action Model**|Shanghang Zhang Team|[2511.17366](http://arxiv.org/abs/2511.17366)|null|
|**2025-11-21**|**UAM: A Unified Attention-Mamba Backbone of Multimodal Framework for Tumor Cell Classification**|Nancy Guo Team|[2511.17355](http://arxiv.org/abs/2511.17355)|null|
|**2025-11-21**|**Agentic Program Verification**|Abhik Roychoudhury Team|[2511.17330](http://arxiv.org/abs/2511.17330)|null|
|**2025-11-21**|**SpatialGeo:Boosting Spatial Reasoning in Multimodal LLMs via Geometry-Semantics Fusion**|Weida Wang Team|[2511.17308](http://arxiv.org/abs/2511.17308)|null|
|**2025-11-21**|**MolSight: Optical Chemical Structure Recognition with SMILES Pretraining, Multi-Granularity Learning and Reinforcement Learning**|Wenyu Liu Team|[2511.17300](http://arxiv.org/abs/2511.17300)|null|
|**2025-11-21**|**Where Culture Fades: Revealing the Cultural Gap in Text-to-Image Generation**|Tat-Seng Chua Team|[2511.17282](http://arxiv.org/abs/2511.17282)|null|
|**2025-11-21**|**A Little More Like This: Text-to-Image Retrieval with Vision-Language Models Using Relevance Feedback**|Nava Tintarev Team|[2511.17255](http://arxiv.org/abs/2511.17255)|null|
|**2025-11-21**|**Intervene-All-Paths: Unified Mitigation of LVLM Hallucinations across Alignment Formats**|Sibei Yang Team|[2511.17254](http://arxiv.org/abs/2511.17254)|**[link](https://github.com/SooLab/AllPath)**|
|**2025-11-21**|**Lost in Translation and Noise: A Deep Dive into the Failure Modes of VLMs on Real-World Tables**|Abhay Kumary Team|[2511.17238](http://arxiv.org/abs/2511.17238)|null|
|**2025-11-21**|**Scaling Self-Supervised and Cross-Modal Pretraining for Volumetric CT Transformers**|Fons van der Sommen Team|[2511.17209](http://arxiv.org/abs/2511.17209)|null|
|**2025-11-21**|**VLA-4D: Embedding 4D Awareness into Vision-Language-Action Models for SpatioTemporally Coherent Robotic Manipulation**|Gim Hee Lee Team|[2511.17199](http://arxiv.org/abs/2511.17199)|null|
|**2025-11-21**|**Device-Guided Music Transfer**|Dong Ma Team|[2511.17136](http://arxiv.org/abs/2511.17136)|null|
|**2025-11-20**|**Learning to Think Fast and Slow for Visual Language Models**|Kaiyang Zhou Team|[2511.16670](http://arxiv.org/abs/2511.16670)|null|
|**2025-11-20**|**Video-as-Answer: Predict and Generate Next Video Event with Joint-GRPO**|Jing Liao Team|[2511.16669](http://arxiv.org/abs/2511.16669)|**[link](https://video-as-answer.github.io/)**|
|**2025-11-20**|**Cognitive Foundations for Reasoning and Their Manifestation in LLMs**|Yulia Tsvetkov Team|[2511.16660](http://arxiv.org/abs/2511.16660)|null|
|**2025-11-20**|**InternData-A1: Pioneering High-Fidelity Synthetic Data for Pre-training Generalist Policy**|Jiangmiao Pang Team|[2511.16651](http://arxiv.org/abs/2511.16651)|null|
|**2025-11-20**|**Bridging VLMs and Embodied Intelligence with Deliberate Practice Policy Optimization**|Xiaozhu Ju Team|[2511.16602](http://arxiv.org/abs/2511.16602)|null|
|**2025-11-20**|**TimeViper: A Hybrid Mamba-Transformer Vision-Language Model for Efficient Long Video Understanding**|Qin Jin Team|[2511.16595](http://arxiv.org/abs/2511.16595)|**[link](https://xuboshen.github.io/TimeViper)**|
|**2025-11-20**|**Contrastive vision-language learning with paraphrasing and negation**|Artur d'Avila Garcez Team|[2511.16527](http://arxiv.org/abs/2511.16527)|null|
|**2025-11-20**|**MiMo-Embodied: X-Embodied Foundation Model Technical Report**|Long Chen Team|[2511.16518](http://arxiv.org/abs/2511.16518)|**[link](https://github.com/XiaomiMiMo/MiMo-Embodied)**|
|**2025-11-20**|**Arctic-Extract Technical Report**|Wojciech Jaśkowski Team|[2511.16470](http://arxiv.org/abs/2511.16470)|null|
|**2025-11-20**|**LLaVA $^3$ : Representing 3D Scenes like a Cubist Painter to Boost 3D Scene Understanding of VLMs**|Loïc Barthe Team|[2511.16454](http://arxiv.org/abs/2511.16454)|null|
|**2025-11-20**|**VLA-Pruner: Temporal-Aware Dual-Level Visual Token Pruning for Efficient Vision-Language-Action Inference**|Bo Zhao Team|[2511.16449](http://arxiv.org/abs/2511.16449)|null|
|**2025-11-20**|**Beyond Visual Cues: Leveraging General Semantics as Support for Few-Shot Segmentation**|Weifeng Liu Team|[2511.16435](http://arxiv.org/abs/2511.16435)|null|
|**2025-11-20**|**TOFA: Training-Free One-Shot Federated Adaptation for Vision-Language Models**|Chaochao Chen Team|[2511.16423](http://arxiv.org/abs/2511.16423)|null|
|**2025-11-20**|**The Shawshank Redemption of Embodied AI: Understanding and Benchmarking Indirect Environmental Jailbreaks**|Jianfeng Ma Team|[2511.16347](http://arxiv.org/abs/2511.16347)|null|
|**2025-11-20**|**FT-NCFM: An Influence-Aware Data Distillation Framework for Efficient VLA Models**|Mingsheng Shang Team|[2511.16233](http://arxiv.org/abs/2511.16233)|null|
|**2025-11-20**|**Can MLLMs Read the Room? A Multimodal Benchmark for Assessing Deception in Multi-Party Social Interactions**|Yoichi Sato Team|[2511.16221](http://arxiv.org/abs/2511.16221)|null|
|**2025-11-20**|**FlipVQA-Miner: Cross-Page Visual Question-Answer Mining from Textbooks**|Wentao Zhang Team|[2511.16216](http://arxiv.org/abs/2511.16216)|null|
|**2025-11-20**|**When Alignment Fails: Multimodal Adversarial Attacks on Vision-Language-Action Models**|Yaochu Jin Team|[2511.16203](http://arxiv.org/abs/2511.16203)|null|
|**2025-11-20**|**From Performance to Understanding: A Vision for Explainable Automated Algorithm Design**|Thomas Bäck Team|[2511.16201](http://arxiv.org/abs/2511.16201)|null|
|**2025-11-20**|**Mantis: A Versatile Vision-Language-Action Model with Disentangled Visual Foresight**|Zhijie Deng Team|[2511.16175](http://arxiv.org/abs/2511.16175)|null|
|**2025-11-19**|**Think Visually, Reason Textually: Vision-Language Synergy in ARC**|Jiaqi Wang Team|[2511.15703](http://arxiv.org/abs/2511.15703)|null|
|**2025-11-19**|**MoDES: Accelerating Mixture-of-Experts Multimodal Large Language Models via Dynamic Expert Skipping**|Jun Zhang Team|[2511.15690](http://arxiv.org/abs/2511.15690)|null|
|**2025-11-19**|**Walrus: A Cross-Domain Foundation Model for Continuum Dynamics**|Shirley Ho Team|[2511.15684](http://arxiv.org/abs/2511.15684)|null|
|**2025-11-19**|**VisPlay: Self-Evolving Vision-Language Models from Images**|Yonghui Yang Team|[2511.15661](http://arxiv.org/abs/2511.15661)|null|
|**2025-11-19**|**Hierarchical Semantic Tree Anchoring for CLIP-Based Class-Incremental Learning**|Da-Wei Zhou Team|[2511.15633](http://arxiv.org/abs/2511.15633)|null|
|**2025-11-19**|**The SA-FARI Dataset: Segment Anything in Footage of Animals for Recognition and Identification**|Didac Suris Team|[2511.15622](http://arxiv.org/abs/2511.15622)|null|
|**2025-11-19**|**When to Think and When to Look: Uncertainty-Guided Lookback**|Chenliang Xu Team|[2511.15613](http://arxiv.org/abs/2511.15613)|null|
|**2025-11-19**|**SRPO: Self-Referential Policy Optimization for Vision-Language-Action Models**|Xipeng Qiu Team|[2511.15605](http://arxiv.org/abs/2511.15605)|null|
|**2025-11-19**|**AVATAAR: Agentic Video Answering via Temporal Adaptive Alignment and Reasoning**|Chinmay Gondhalekar Team|[2511.15578](http://arxiv.org/abs/2511.15578)|null|
|**2025-11-19**|**Computer-Use Agents as Judges for Generative User Interface**|Mike Zheng Shou Team|[2511.15567](http://arxiv.org/abs/2511.15567)|**[link](https://showlab.github.io/AUI)**|
|**2025-11-19**|**Multimodal Evaluation of Russian-language Architectures**|Alena Fenogenova Team|[2511.15552](http://arxiv.org/abs/2511.15552)|null|
|**2025-11-19**|**Learning to Expand Images for Efficient Visual Autoregressive Modeling**|Tao Huang Team|[2511.15499](http://arxiv.org/abs/2511.15499)|null|
|**2025-11-19**|**SIGMMA: Hierarchical Graph-Based Multi-Scale Multi-modal Contrastive Alignment of Histopathology Image and Spatial Transcriptome**|Mohammad Lotfollahi Team|[2511.15464](http://arxiv.org/abs/2511.15464)|null|
|**2025-11-19**|**D4C: Data-free Quantization for Contrastive Language-Image Pre-training Models**|Kentaro Yoshioka Team|[2511.15411](http://arxiv.org/abs/2511.15411)|null|
|**2025-11-19**|**Breaking Expert Knowledge Limits: Self-Pruning for Large Language Models**|Hao Wang Team|[2511.15390](http://arxiv.org/abs/2511.15390)|null|
|**2025-11-19**|**Zero-Shot Open-Vocabulary Human Motion Grounding with Test-Time Training**|Jianfei Yang Team|[2511.15379](http://arxiv.org/abs/2511.15379)|null|
|**2025-11-19**|**C2F-Space: Coarse-to-Fine Space Grounding for Spatial Instructions using Vision-Language Models**|Daehyung Park Team|[2511.15333](http://arxiv.org/abs/2511.15333)|null|
|**2025-11-19**|**What Your Features Reveal: Data-Efficient Black-Box Feature Inversion Attack for Split DNNs**|Fan Li Team|[2511.15316](http://arxiv.org/abs/2511.15316)|null|
|**2025-11-19**|**Adapt-As-You-Walk Through the Clouds: Training-Free Online Test-Time Adaptation of 3D Vision-Language Foundation Models**|Morteza Saberi Team|[2511.15311](http://arxiv.org/abs/2511.15311)|null|
|**2025-11-19**|**Text2Loc++: Generalizing 3D Point Cloud Localization from Natural Language**|Daniel Cremers Team|[2511.15308](http://arxiv.org/abs/2511.15308)|null|
|**2025-11-18**|**ARC Is a Vision Problem!**|Kaiming He Team|[2511.14761](http://arxiv.org/abs/2511.14761)|**[link](https://github.com/lillian039/VARC)**|
|**2025-11-18**|**UniGen-1.5: Enhancing Image Generation and Editing through Reward Unification in Reinforcement Learning**|Afshin Dehghan Team|[2511.14760](http://arxiv.org/abs/2511.14760)|null|
|**2025-11-18**|**$π^{*}_{0.6}$ : a VLA That Learns From Experience**|Zhiyuan Zhou Team|[2511.14759](http://arxiv.org/abs/2511.14759)|null|
|**2025-11-18**|**Vision Large Language Models Are Good Noise Handlers in Engagement Analysis**|Xiaobai Li Team|[2511.14749](http://arxiv.org/abs/2511.14749)|null|
|**2025-11-18**|**Measuring AI Progress in Drug Discovery: A Reproducible Leaderboard for the Tox21 Challenge**|Günter Klambauer Team|[2511.14744](http://arxiv.org/abs/2511.14744)|null|
|**2025-11-18**|**Attention via Synaptic Plasticity is All You Need: A Biologically Inspired Spiking Neuromorphic Transformer**|Ankush Kumar Team|[2511.14691](http://arxiv.org/abs/2511.14691)|null|
|**2025-11-18**|**NORA-1.5: A Vision-Language-Action Model Trained using World Model- and Action-based Preference Rewards**|Soujanya Poria Team|[2511.14659](http://arxiv.org/abs/2511.14659)|**[link](https://declare-lab.github.io/nora-1.5)**|
|**2025-11-18**|**Enhancing Agentic Autonomous Scientific Discovery with Vision-Language Model Capabilities**|Inigo Zubeldia Team|[2511.14631](http://arxiv.org/abs/2511.14631)|null|
|**2025-11-18**|**Is Your VLM for Autonomous Driving Safety-Ready? A Comprehensive Benchmark for Evaluating External and In-Cabin Risks**|Xiaoshuai Hao Team|[2511.14592](http://arxiv.org/abs/2511.14592)|null|
|**2025-11-18**|**OmniZip: Audio-Guided Dynamic Token Compression for Fast Omnimodal Large Language Models**|Huan Wang Team|[2511.14582](http://arxiv.org/abs/2511.14582)|**[link](https://github.com/KD-TAO/OmniZip)**|
|**2025-11-18**|**Task Addition and Weight Disentanglement in Closed-Vocabulary Models**|Pascal Frossard Team|[2511.14569](http://arxiv.org/abs/2511.14569)|null|
|**2025-11-18**|**Enhancing End-to-End Autonomous Driving with Risk Semantic Distillaion from VLM**|Siyuan Cheng Team|[2511.14499](http://arxiv.org/abs/2511.14499)|null|
|**2025-11-18**|**Agentic Video Intelligence: A Flexible Framework for Advanced Video Exploration and Understanding**|Min-Ling Zhang Team|[2511.14446](http://arxiv.org/abs/2511.14446)|null|
|**2025-11-18**|**Watchdogs and Oracles: Runtime Verification Meets Large Language Models for Autonomous Systems**|Angelo Ferrando Team|[2511.14435](http://arxiv.org/abs/2511.14435)|null|
|**2025-11-18**|**Enhancing LLM-based Autonomous Driving with Modular Traffic Light and Sign Recognition**|Abhinav Valada Team|[2511.14391](http://arxiv.org/abs/2511.14391)|null|
|**2025-11-18**|**O3SLM: Open Weight, Open Data, and Open Vocabulary Sketch-Language Model**|Anirban Chakraborty Team|[2511.14368](http://arxiv.org/abs/2511.14368)|null|
|**2025-11-18**|**ArchMap: Arch-Flattening and Knowledge-Guided Vision Language Model for Tooth Counting and Structured Dental Understanding**|Jionglong Su Team|[2511.14336](http://arxiv.org/abs/2511.14336)|null|
|**2025-11-18**|**When Words Change the Model: Sensitivity of LLMs for Constraint Programming Modelling**|Jacopo Mauro Team|[2511.14334](http://arxiv.org/abs/2511.14334)|null|
|**2025-11-18**|**Step by Step Network**|Gao Huang Team|[2511.14329](http://arxiv.org/abs/2511.14329)|null|
|**2025-11-18**|**Segmentwise Pruning in Audio-Language Models**|Jean-François Bonastre Team|[2511.14293](http://arxiv.org/abs/2511.14293)|null|
|**2025-11-17**|**Scaling Spatial Intelligence with Multimodal Foundation Models**|Lei Yang Team|[2511.13719](http://arxiv.org/abs/2511.13719)|**[link](https://huggingface.co/collections/sensenova/sensenova-si)**|
|**2025-11-17**|**TiViBench: Benchmarking Think-in-Video Reasoning for Video Generative Models**|Ying-Cong Chen Team|[2511.13704](http://arxiv.org/abs/2511.13704)|**[link](https://haroldchen19.github.io/TiViBench-Page/)**|
|**2025-11-17**|**Crossing Borders: A Multimodal Challenge for Indian Poetry Translation and Image Generation**|Joseph K J Team|[2511.13689](http://arxiv.org/abs/2511.13689)|null|
|**2025-11-17**|**Training-Free Multi-View Extension of IC-Light for Textual Position-Aware Scene Relighting**|Haoji Hu Team|[2511.13684](http://arxiv.org/abs/2511.13684)|null|
|**2025-11-17**|**Part-X-MLLM: Part-aware 3D Multimodal Large Language Model**|Chunchao Guo Team|[2511.13647](http://arxiv.org/abs/2511.13647)|null|
|**2025-11-17**|**CacheFlow: Compressive Streaming Memory for Efficient Long-Form Video Understanding**|Daivik Patel Team|[2511.13644](http://arxiv.org/abs/2511.13644)|null|
|**2025-11-17**|**CreBench: Human-Aligned Creativity Evaluation from Idea to Process to Product**|Jiayi Cen Team|[2511.13626](http://arxiv.org/abs/2511.13626)|null|
|**2025-11-17**|**FreeAskWorld: An Interactive and Closed-Loop Simulator for Human-Centric Embodied AI**|Jiangtao Gong Team|[2511.13524](http://arxiv.org/abs/2511.13524)|null|
|**2025-11-17**|**Language-Guided Invariance Probing of Vision-Language Models**|Jae Joong Lee Team|[2511.13494](http://arxiv.org/abs/2511.13494)|null|
|**2025-11-17**|**Semantic Document Derendering: SVG Reconstruction via Vision-Language Modeling**|Pascal Frossard Team|[2511.13478](http://arxiv.org/abs/2511.13478)|null|
|**2025-11-17**|**Trust in Vision-Language Models: Insights from a Participatory User Workshop**|Viola Schiaffonati Team|[2511.13458](http://arxiv.org/abs/2511.13458)|null|
|**2025-11-17**|**Unlocking the Forgery Detection Potential of Vanilla MLLMs: A Novel Training-Free Pipeline**|Ziqian Lu Team|[2511.13442](http://arxiv.org/abs/2511.13442)|null|
|**2025-11-17**|**VOPE: Revisiting Hallucination of Vision-Language Models in Voluntary Imagination Task**|Xilin Chen Team|[2511.13420](http://arxiv.org/abs/2511.13420)|null|
|**2025-11-17**|**Attention Grounded Enhancement for Visual Document Retrieval**|Keping Bi Team|[2511.13415](http://arxiv.org/abs/2511.13415)|null|
|**2025-11-17**|**Descriptor: Distance-Annotated Traffic Perception Question Answering (DTPQA)**|Ciaran Eising Team|[2511.13397](http://arxiv.org/abs/2511.13397)|null|
|**2025-11-17**|**Generalized Denoising Diffusion Codebook Models (gDDCM): Tokenizing images using a pre-trained diffusion model**|Fei Kong Team|[2511.13387](http://arxiv.org/abs/2511.13387)|null|
|**2025-11-17**|**Moving Pictures of Thought: Extracting Visual Knowledge in Charles S. Peirce's Manuscripts with Vision-Language Models**|Dario Rodighiero Team|[2511.13378](http://arxiv.org/abs/2511.13378)|null|
|**2025-11-17**|**Tab-PET: Graph-Based Positional Encodings for Tabular Transformers**|Mehul Motani Team|[2511.13338](http://arxiv.org/abs/2511.13338)|null|
|**2025-11-17**|**TabFlash: Efficient Table Understanding with Progressive Question Conditioning and Token Focusing**|Hyunwoo J. Kim Team|[2511.13283](http://arxiv.org/abs/2511.13283)|null|
|**2025-11-17**|**Is your VLM Sky-Ready? A Comprehensive Spatial Intelligence Benchmark for UAV Navigation**|Wenbo Ding Team|[2511.13269](http://arxiv.org/abs/2511.13269)|null|
|**2025-11-14**|**DocLens : A Tool-Augmented Multi-Agent Framework for Long Visual Document Understanding**|Jinsung Yoon Team|[2511.11552](http://arxiv.org/abs/2511.11552)|null|
|**2025-11-14**|**Bridging Hidden States in Vision-Language Models**|Jacob Fein-Ashley Team|[2511.11526](http://arxiv.org/abs/2511.11526)|null|
|**2025-11-14**|**Collaborative Representation Learning for Alignment of Tactile, Language, and Vision Modalities**|Jingyuan Chen Team|[2511.11512](http://arxiv.org/abs/2511.11512)|null|
|**2025-11-14**|**PAS : Prelim Attention Score for Detecting Object Hallucinations in Large Vision--Language Models**|Manish Bhattarai Team|[2511.11502](http://arxiv.org/abs/2511.11502)|null|
|**2025-11-14**|**Rethinking Progression of Memory State in Robotic Manipulation: An Object-Centric Perspective**|Ngan Le Team|[2511.11478](http://arxiv.org/abs/2511.11478)|null|
|**2025-11-14**|**Benchmarking Visual LLMs Resilience to Unanswerable Questions on Visually Rich Documents**|Fabrizio Battiloro Team|[2511.11468](http://arxiv.org/abs/2511.11468)|null|
|**2025-11-14**|**VoxTell: Free-Text Promptable Universal 3D Medical Image Segmentation**|Klaus Maier-Hein Team|[2511.11450](http://arxiv.org/abs/2511.11450)|null|
|**2025-11-14**|**From Synthetic Scenes to Real Performance: Enhancing Spatial Reasoning in VLMs**|Giuseppe Riccardi Team|[2511.11440](http://arxiv.org/abs/2511.11440)|null|
|**2025-11-14**|**VP-Bench: A Comprehensive Benchmark for Visual Prompting in Multimodal Large Language Models**|Wenqiang Lei Team|[2511.11438](http://arxiv.org/abs/2511.11438)|null|
|**2025-11-14**|**Comprehension of Multilingual Expressions Referring to Target Objects in Visual Inputs**|Bruno Martins Team|[2511.11427](http://arxiv.org/abs/2511.11427)|null|
|**2025-11-14**|**BOFA: Bridge-Layer Orthogonal Low-Rank Fusion for CLIP-Based Class-Incremental Learning**|De-Chuan Zhan Team|[2511.11421](http://arxiv.org/abs/2511.11421)|null|
|**2025-11-14**|**Q-Doc: Benchmarking Document Image Quality Assessment Capabilities in Multi-modal Large Language Models**|Baoliang Chen Team|[2511.11410](http://arxiv.org/abs/2511.11410)|null|
|**2025-11-14**|**MicroVQA++: High-Quality Microscopy Reasoning Dataset with Weakly Supervised Graphs for Multimodal Large Language Model**|Bo Yan Team|[2511.11407](http://arxiv.org/abs/2511.11407)|null|
|**2025-11-14**|**DocSLM: A Small Vision-Language Model for Long Multimodal Document Understanding**|Sunando Sengupta Team|[2511.11313](http://arxiv.org/abs/2511.11313)|null|
|**2025-11-14**|**EcoAlign: An Economically Rational Framework for Efficient LVLM Alignment**|Hongyi Zhang Team|[2511.11301](http://arxiv.org/abs/2511.11301)|null|
|**2025-11-14**|**AUVIC: Adversarial Unlearning of Visual Concepts for Multi-modal Large Language Models**|Volker Tresp Team|[2511.11299](http://arxiv.org/abs/2511.11299)|**[link](https://github.com/HaokunChen245/AUVIC)**|
|**2025-11-14**|**Experiences from Benchmarking Vision-Language-Action Models for Robotic Manipulation**|Xi Zheng Team|[2511.11298](http://arxiv.org/abs/2511.11298)|null|
|**2025-11-14**|**GraphPilot: Grounded Scene Graph Conditioning for Language-Based Autonomous Driving**|Abhinav Valada Team|[2511.11266](http://arxiv.org/abs/2511.11266)|null|
|**2025-11-14**|**Discovering Meaningful Units with Visually Grounded Semantics from Image Captions**|James Henderson Team|[2511.11262](http://arxiv.org/abs/2511.11262)|null|
|**2025-11-14**|**CountSteer: Steering Attention for Object Counting in Diffusion Models**|Hyunsoo Cho Team|[2511.11253](http://arxiv.org/abs/2511.11253)|null|
|**2025-11-13**|**Enhancing the Outcome Reward-based RL Training of MLLMs with Self-Consistency Sampling**|Jinguo Zhu Team|[2511.10648](http://arxiv.org/abs/2511.10648)|null|
|**2025-11-13**|**Querying Labeled Time Series Data with Scenario Programs**|Sanjit A Seshia Team|[2511.10627](http://arxiv.org/abs/2511.10627)|null|
|**2025-11-13**|**Towards Blind and Low-Vision Accessibility of Lightweight VLMs and Custom LLM-Evals**|Pawan Goyal Team|[2511.10615](http://arxiv.org/abs/2511.10615)|null|
|**2025-11-13**|**Impact of Layer Norm on Memorization and Generalization in Transformers**|Jung-Eun Kim Team|[2511.10566](http://arxiv.org/abs/2511.10566)|null|
|**2025-11-13**|**OmniVGGT: Omni-Modality Driven Visual Geometry Grounded**|Ziwei Liu Team|[2511.10560](http://arxiv.org/abs/2511.10560)|**[link](https://livioni.github.io/OmniVGGT-offcial/)**|
|**2025-11-13**|**SemanticVLA: Semantic-Aligned Sparsification and Enhancement for Efficient Robotic Manipulation**|Liqiang Nie Team|[2511.10518](http://arxiv.org/abs/2511.10518)|**[link](https://github.com/JiuTian-VL/SemanticVLA)**|
|**2025-11-13**|**LLM-YOLOMS: Large Language Model-based Semantic Interpretation and Fault Diagnosis for Wind Turbine Components**|Jianbo Feng Team|[2511.10394](http://arxiv.org/abs/2511.10394)|null|
|**2025-11-13**|**MonkeyOCR v1.5 Technical Report: Unlocking Robust Document Parsing for Complex Patterns**|Xiang Bai Team|[2511.10390](http://arxiv.org/abs/2511.10390)|null|
|**2025-11-13**|**Rethinking Visual Information Processing in Multimodal LLMs**|Amit Kumar K C Team|[2511.10301](http://arxiv.org/abs/2511.10301)|null|
|**2025-11-13**|**Adaptive Residual-Update Steering for Low-Overhead Hallucination Mitigation in Large Vision Language Models**|Pekka Marttinen Team|[2511.10292](http://arxiv.org/abs/2511.10292)|null|
|**2025-11-13**|**PROPA: Toward Process-level Optimization in Visual Reasoning via Reinforcement Learning**|Jey Han Lau Team|[2511.10279](http://arxiv.org/abs/2511.10279)|null|
|**2025-11-13**|**Causal-HalBench: Uncovering LVLMs Object Hallucinations Through Causal Intervention**|Xiang Wang Team|[2511.10268](http://arxiv.org/abs/2511.10268)|null|
|**2025-11-13**|**Facial-R1: Aligning Reasoning and Recognition for Facial Emotion Analysis**|Min Cao Team|[2511.10254](http://arxiv.org/abs/2511.10254)|null|
|**2025-11-13**|**TubeRMC: Tube-conditioned Reconstruction with Mutual Constraints for Weakly-supervised Spatio-Temporal Video Grounding**|Beihao Xia Team|[2511.10241](http://arxiv.org/abs/2511.10241)|null|
|**2025-11-13**|**Intilligence Foundation Model: A New Perspective to Approach Artificial General Intelligence**|Yao Zhao Team|[2511.10119](http://arxiv.org/abs/2511.10119)|null|
|**2025-11-13**|**MTAttack: Multi-Target Backdoor Attacks against Large Vision-Language Models**|Xiao Bai Team|[2511.10098](http://arxiv.org/abs/2511.10098)|null|
|**2025-11-13**|**How does My Model Fail? Automatic Identification and Interpretation of Physical Plausibility Failure Modes with Matryoshka Transcoders**|Dianbo Liu Team|[2511.10094](http://arxiv.org/abs/2511.10094)|null|
|**2025-11-13**|**SUGAR: Learning Skeleton Representation with Visual-Motion Knowledge for Action Recognition**|Zitong Yu Team|[2511.10091](http://arxiv.org/abs/2511.10091)|null|
|**2025-11-13**|**GridPrune: From "Where to Look" to "What to Select" in Visual Token Pruning for MLLMs**|Pengwei Wang Team|[2511.10081](http://arxiv.org/abs/2511.10081)|null|
|**2025-11-13**|**VLF-MSC: Vision-Language Feature-Based Multimodal Semantic Communication System**|Joonhyuk Kang Team|[2511.10074](http://arxiv.org/abs/2511.10074)|null|
|**2025-11-10**|**Using Vision Language Models as Closed-Loop Symbolic Planners for Robotic Applications: A Control-Theoretic Perspective**|Somil Bansal Team|[2511.07410](http://arxiv.org/abs/2511.07410)|null|
|**2025-11-10**|**CAMP-VQA: Caption-Embedded Multimodal Perception for No-Reference Quality Assessment of Compressed Video**|David Bull Team|[2511.07290](http://arxiv.org/abs/2511.07290)|null|
|**2025-11-10**|**Leveraging Text-Driven Semantic Variation for Robust OOD Segmentation**|Jaekoo Lee Team|[2511.07238](http://arxiv.org/abs/2511.07238)|null|
|**2025-11-10**|**Federated Learning for Video Violence Detection: Complementary Roles of Lightweight CNNs and Vision-Language Models for Energy-Efficient Use**|Rachid Chelouah Team|[2511.07171](http://arxiv.org/abs/2511.07171)|null|
|**2025-11-10**|**ClusterMine: Robust Label-Free Visual Out-Of-Distribution Detection via Concept Mining from Text Corpora**|Markus Kollmann Team|[2511.07068](http://arxiv.org/abs/2511.07068)|**[link](https://github.com/HHU-MMBS/clustermine_wacv_official)**|
|**2025-11-10**|**CoLM: Collaborative Large Models via A Client-Server Paradigm**|Hongyuan Zhang Team|[2511.06991](http://arxiv.org/abs/2511.06991)|null|
|**2025-11-10**|**RPTS: Tree-Structured Reasoning Process Scoring for Faithful Multimodal Evaluation**|Yu Zhang Team|[2511.06899](http://arxiv.org/abs/2511.06899)|null|
|**2025-11-10**|**Flexible Concept Bottleneck Model**|Rui Zhang Team|[2511.06678](http://arxiv.org/abs/2511.06678)|null|
|**2025-11-10**|**HiMo-CLIP: Modeling Semantic Hierarchy and Monotonicity in Vision-Language Alignment**|Shiguo Lian Team|[2511.06653](http://arxiv.org/abs/2511.06653)|null|
|**2025-11-10**|**NOVO: Bridging LLaVA and SAM with Visual-only Prompts for Reasoning Segmentation**|Yeong-Jun Cho Team|[2511.06651](http://arxiv.org/abs/2511.06651)|null|
|**2025-11-10**|**How Do VLAs Effectively Inherit from VLMs?**|Jiang Bian Team|[2511.06619](http://arxiv.org/abs/2511.06619)|null|
|**2025-11-09**|**A Low-Rank Method for Vision Language Model Hallucination Mitigation in Autonomous Driving**|Xiaopeng Li Team|[2511.06496](http://arxiv.org/abs/2511.06496)|null|
|**2025-11-09**|**Zooming into Comics: Region-Aware RL Improves Fine-Grained Comic Understanding in Vision-Language Models**|Sabine Süsstrunk Team|[2511.06490](http://arxiv.org/abs/2511.06490)|null|
|**2025-11-09**|**GazeVLM: A Vision-Language Model for Multi-Task Gaze Understanding**|Riad Souissi Team|[2511.06348](http://arxiv.org/abs/2511.06348)|null|
|**2025-11-09**|**ALIGN: A Vision-Language Framework for High-Accuracy Accident Location Inference through Geo-Spatial Neural Reasoning**|Moazzem Hossain Team|[2511.06316](http://arxiv.org/abs/2511.06316)|null|
|**2025-11-09**|**TinyChemVL: Advancing Chemical Vision-Language Models via Efficient Visual Token Reduction and Complex Reaction Tasks**|Bo Xu Team|[2511.06283](http://arxiv.org/abs/2511.06283)|null|
|**2025-11-09**|**WebVIA: A Web-based Vision-Language Agentic Framework for Interactive and Verifiable UI-to-Code Generation**|Jie Tang Team|[2511.06251](http://arxiv.org/abs/2511.06251)|null|
|**2025-11-09**|**Affordance-Guided Coarse-to-Fine Exploration for Base Placement in Open-Vocabulary Mobile Manipulation**|Winston H. Hsu Team|[2511.06240](http://arxiv.org/abs/2511.06240)|null|
|**2025-11-09**|**MoRA: Missing Modality Low-Rank Adaptation for Visual Recognition**|Vijaykrishnan Narayanan Team|[2511.06225](http://arxiv.org/abs/2511.06225)|null|
|**2025-11-09**|**Scene-Aware Urban Design: A Human-AI Recommendation Framework Using Co-Occurrence Embeddings and Vision-Language Models**|Alexander Htet Kyaw Team|[2511.06201](http://arxiv.org/abs/2511.06201)|null|
|**2025-11-07**|**Visual Spatial Tuning**|Hengshuang Zhao Team|[2511.05491](http://arxiv.org/abs/2511.05491)|null|
|**2025-11-07**|**Turning Adversaries into Allies: Reversing Typographic Attacks for Multimodal E-Commerce Product Retrieval**|Hongda Shen Team|[2511.05325](http://arxiv.org/abs/2511.05325)|null|
|**2025-11-07**|**Towards Mitigating Hallucinations in Large Vision-Language Models by Refining Textual Embeddings**|Furong Huang Team|[2511.05017](http://arxiv.org/abs/2511.05017)|null|
|**2025-11-07**|**iFlyBot-VLM Technical Report**|Jia Pan Team|[2511.04976](http://arxiv.org/abs/2511.04976)|null|
|**2025-11-07**|**A benchmark multimodal oro-dental dataset for large vision-language models**|Muhammad Saqib Team|[2511.04948](http://arxiv.org/abs/2511.04948)|null|
|**2025-11-06**|**Conformalized Non-uniform Sampling Strategies for Accelerated Sampling-based Motion Planning**|Yiannis Kantaros Team|[2511.04835](http://arxiv.org/abs/2511.04835)|null|
|**2025-11-06**|**IndicVisionBench: Benchmarking Cultural and Multilingual Understanding in VLMs**|Shubham Agarwal Team|[2511.04727](http://arxiv.org/abs/2511.04727)|null|
|**2025-11-05**|**SWAP: Towards Copyright Auditing of Soft Prompts via Sequential Watermarking**|Dacheng Tao Team|[2511.04711](http://arxiv.org/abs/2511.04711)|null|
|**2025-11-06**|**SAFe-Copilot: Unified Shared Autonomy Framework**|Daniela Rus Team|[2511.04664](http://arxiv.org/abs/2511.04664)|null|
|**2025-11-06**|**Thinking with Video: Video Generation as a Promising Multimodal Reasoning Paradigm**|Xipeng Qiu Team|[2511.04570](http://arxiv.org/abs/2511.04570)|null|
|**2025-11-06**|**Evo-1: Lightweight Vision-Language-Action Model with Preserved Semantic Alignment**|Bo Zhao Team|[2511.04555](http://arxiv.org/abs/2511.04555)|**[link](https://github.com/MINT-SJTU/Evo-1)**|
|**2025-11-07**|**ThaiOCRBench: A Task-Diverse Benchmark for Vision-Language Understanding in Thai**|Kunat Pipatanakul Team|[2511.04479](http://arxiv.org/abs/2511.04479)|null|
|**2025-11-06**|**GUI-360: A Comprehensive Dataset and Benchmark for Computer-Using Agents**|Dongmei Zhang Team|[2511.04307](http://arxiv.org/abs/2511.04307)|null|
|**2025-11-07**|**On the Brittleness of CLIP Text Encoders**|Luca Rossetto Team|[2511.04247](http://arxiv.org/abs/2511.04247)|**[link](https://github.com/allie-tran/clip-brittleness)**|
|**2025-11-06**|**Text to Sketch Generation with Multi-Styles**|Lei Xu Team|[2511.04123](http://arxiv.org/abs/2511.04123)|null|
|**2025-11-05**|**Context informs pragmatic interpretation in vision-language models**|Michael C. Frank Team|[2511.03908](http://arxiv.org/abs/2511.03908)|null|
|**2025-11-05**|**Contamination Detection for VLMs using Multi-Modal Semantic Perturbation**|Yong Jae Lee Team|[2511.03774](http://arxiv.org/abs/2511.03774)|null|
|**2025-11-05**|**GUIDES: Guidance Using Instructor-Distilled Embeddings for Pre-trained Robot Policy Enhancement**|Jiachen Li Team|[2511.03400](http://arxiv.org/abs/2511.03400)|null|
|**2025-11-05**|**Decoupling Augmentation Bias in Prompt Learning for Vision-Language Models**|Seokju Lee Team|[2511.03367](http://arxiv.org/abs/2511.03367)|null|
|**2025-11-04**|**LEGO-Eval: Towards Fine-Grained Evaluation on Synthesizing 3D Embodied Environments with Tool Augmentation**|Jinyoung Yeo Team|[2511.03001](http://arxiv.org/abs/2511.03001)|null|
|**2025-11-04**|**SCALE-VLP: Soft-Weighted Contrastive Volumetric Vision-Language Pre-training with Spatial-Knowledge Semantics**|Leonid Sigal Team|[2511.02996](http://arxiv.org/abs/2511.02996)|null|
|**2025-11-04**|**XR-1: Towards Versatile Vision-Language-Action Models via Learning Unified Vision-Motion Representations**|Jian Tang Team|[2511.02776](http://arxiv.org/abs/2511.02776)|null|
|**2025-11-04**|**Adapting General-Purpose Foundation Models for X-ray Ptychography in Low-Data Regimes**|Yi Jiang Team|[2511.02503](http://arxiv.org/abs/2511.02503)|null|
|**2025-11-04**|**RxnCaption: Reformulating Reaction Diagram Parsing as Visual Prompt Guided Captioning**|Conghui He Team|[2511.02384](http://arxiv.org/abs/2511.02384)|null|
|**2025-11-04**|**The Pervasive Blind Spot: Benchmarking VLM Inference Risks on Everyday Personal Videos**|Hewu Li Team|[2511.02367](http://arxiv.org/abs/2511.02367)|null|
|**2025-11-04**|**CoCoVa: Chain of Continuous Vision-Language Thought for Latent Space Reasoning**|Han Yan Team|[2511.02360](http://arxiv.org/abs/2511.02360)|null|
|**2025-11-04**|**LACY: A Vision-Language Model-based Language-Action Cycle for Self-Improving Robotic Manipulation**|Changhyun Choi Team|[2511.02239](http://arxiv.org/abs/2511.02239)|**[link](https://vla2026.github.io/LACY/)**|
|**2025-11-04**|**Text to Robotic Assembly of Multi Component Objects using 3D Generative AI and Vision Language Models**|Randall Davis Team|[2511.02162](http://arxiv.org/abs/2511.02162)|null|
|**2025-11-03**|**Enhancing Multimodal Recommendations with Vision-Language Models and Information-Aware Fusion**|Dung D. Le Team|[2511.02113](http://arxiv.org/abs/2511.02113)|null|
|**2025-11-03**|**TRACE: Textual Reasoning for Affordance Coordinate Extraction**|Matthew S. Brown Team|[2511.01999](http://arxiv.org/abs/2511.01999)|null|
|**2025-11-03**|**Black-Box Membership Inference Attack for LVLMs via Prior Knowledge-Calibrated Memory Probing**|Tao Qi Team|[2511.01952](http://arxiv.org/abs/2511.01952)|null|
|**2025-11-04**|**Dynamic Routing Between Experts: A Data-Efficient Approach to Continual Learning in Vision-Language Models**|Mingwei Shen Team|[2511.01831](http://arxiv.org/abs/2511.01831)|null|
|**2025-11-03**|**SciTextures: Collecting and Connecting Visual Patterns, Models, and Code Across Science and Art**|Alona Strugatski Team|[2511.01817](http://arxiv.org/abs/2511.01817)|null|
|**2025-11-03**|**GenDexHand: Generative Simulation for Dexterous Hands**|Yi Ma Team|[2511.01791](http://arxiv.org/abs/2511.01791)|null|
|**2025-11-03**|**3EED: Ground Everything Everywhere in 3D**|Ziwei Liu Team|[2511.01755](http://arxiv.org/abs/2511.01755)|**[link](https://project-3eed.github.io/)**|
|**2025-11-03**|**UniLumos: Fast and Unified Image and Video Relighting with Physics-Plausible Feedback**|Fan Wang Team|[2511.01678](http://arxiv.org/abs/2511.01678)|null|
|**2025-11-03**|**Vote-in-Context: Turning VLMs into Zero-Shot Rank Fusers**|Naeemullah Khan Team|[2511.01617](http://arxiv.org/abs/2511.01617)|null|
|**2025-11-03**|**Analyzing Sustainability Messaging in Large-Scale Corporate Social Media**|Marcel Worring Team|[2511.01550](http://arxiv.org/abs/2511.01550)|null|
|**2025-11-03**|**AERMANI-VLM: Structured Prompting and Reasoning for Aerial Manipulation with Vision Language Models**|Spandan Roy Team|[2511.01472](http://arxiv.org/abs/2511.01472)|null|
|**2025-11-03**|**HMVLM: Human Motion-Vision-Lanuage Model via MoE LoRA**|Shihong Xia Team|[2511.01463](http://arxiv.org/abs/2511.01463)|null|
|**2025-11-03**|**When to Trust the Answer: Question-Aligned Semantic Nearest Neighbor Entropy for Safer Surgical VQA**|Mobarak I. Hoque Team|[2511.01458](http://arxiv.org/abs/2511.01458)|null|
|**2025-10-31**|**PETAR: Localized Findings Generation with Mask-Aware Vision-Language Modeling for PET Automated Reporting**|Tyler J. Bradshaw Team|[2510.27680](http://arxiv.org/abs/2510.27680)|null|
|**2025-10-31**|**Spatial-SSRL: Enhancing Spatial Understanding via Self-Supervised Reinforcement Learning**|Jiaqi Wang Team|[2510.27606](http://arxiv.org/abs/2510.27606)|null|
|**2025-10-31**|**From Pixels to Paths: A Multi-Agent Framework for Editable Scientific Illustration**|Kaipeng Zhang Team|[2510.27452](http://arxiv.org/abs/2510.27452)|null|
|**2025-10-31**|**Modality Alignment across Trees on Heterogeneous Hyperbolic Manifolds**|Mehrtash Harandi Team|[2510.27391](http://arxiv.org/abs/2510.27391)|null|
|**2025-10-31**|**FOCUS: Efficient Keyframe Selection for Long Video Understanding**|Yang You Team|[2510.27280](http://arxiv.org/abs/2510.27280)|null|
|**2025-10-31**|**T3: Test-Time Model Merging in VLMs for Zero-Shot Medical Imaging Analysis**|Mohammad Yaqub Team|[2510.27265](http://arxiv.org/abs/2510.27265)|null|
|**2025-10-31**|**ECVL-ROUTER: Scenario-Aware Routing for Vision-Language Models**|Tengxiang Zhang Team|[2510.27256](http://arxiv.org/abs/2510.27256)|null|
|**2025-11-03**|**Enhancing Spatio-Temporal Zero-shot Action Recognition with Language-driven Description Attributes**|Seong-Whan Lee Team|[2510.27255](http://arxiv.org/abs/2510.27255)|null|
|**2025-10-31**|**Generating Accurate and Detailed Captions for High-Resolution Images**|Jiyoung Jung Team|[2510.27164](http://arxiv.org/abs/2510.27164)|null|
|**2025-10-30**|**MoME: Mixture of Visual Language Medical Experts for Medical Imaging Segmentation**|Xiaohui Xie Team|[2510.26996](http://arxiv.org/abs/2510.26996)|null|
|**2025-10-30**|**MM-OPERA: Benchmarking Open-ended Association Reasoning for Large Vision-Language Models**|Ziliang Chen Team|[2510.26937](http://arxiv.org/abs/2510.26937)|null|
|**2025-10-30**|**NaviTrace: Evaluating Embodied Navigation of Vision-Language Models**|Jonas Frey Team|[2510.26909](http://arxiv.org/abs/2510.26909)|null|
|**2025-10-30**|**Cognition Envelopes for Bounded AI Reasoning in Autonomous UAS Operations**|Jane Cleland-Huang Team|[2510.26905](http://arxiv.org/abs/2510.26905)|null|
|**2025-10-30**|**Do Vision-Language Models Measure Up? Benchmarking Visual Measurement Reading with MeasureBench**|Xi Yang Team|[2510.26865](http://arxiv.org/abs/2510.26865)|**[link](https://flageval-baai.github.io/MeasureBenchPage/)**|
|**2025-11-03**|**ChartAB: A Benchmark for Chart Grounding & Dense Alignment**|Tianyi Zhou Team|[2510.26781](http://arxiv.org/abs/2510.26781)|null|
|**2025-10-30**|**SteerVLM: Robust Model Control through Lightweight Activation Steering for Vision Language Models**|Chris Thomas Team|[2510.26769](http://arxiv.org/abs/2510.26769)|null|
|**2025-10-30**|**All You Need for Object Detection: From Pixels, Points, and Prompts to Next-Gen Fusion and Multimodal LLMs/VLMs in Autonomous Vehicles**|Abolfazl Razi Team|[2510.26641](http://arxiv.org/abs/2510.26641)|null|
|**2025-10-30**|**Counteracting Matthew Effect in Self-Improvement of LVLMs through Head-Tail Re-balancing**|Xuanjing Huang Team|[2510.26474](http://arxiv.org/abs/2510.26474)|null|
|**2025-11-03**|**Representation-Level Counterfactual Calibration for Debiased Zero-Shot Recognition**|ShengJun Huang Team|[2510.26466](http://arxiv.org/abs/2510.26466)|null|
|**2025-10-30**|**Towards Fine-Grained Vision-Language Alignment for Few-Shot Anomaly Detection**|Chengjie Wang Team|[2510.26464](http://arxiv.org/abs/2510.26464)|null|
|**2025-10-30**|**A-TPT: Angular Diversity Calibration Properties for Test-Time Prompt Tuning of Vision-Language Models**|Muhammad Haris Khan Team|[2510.26441](http://arxiv.org/abs/2510.26441)|null|
|**2025-10-30**|**MedSAE: Dissecting MedCLIP Representations with Sparse Autoencoders**|Marco Grangetto Team|[2510.26411](http://arxiv.org/abs/2510.26411)|null|
|**2025-10-30**|**Distilling Multilingual Vision-Language Models: When Smaller Models Stay Multilingual**|Peerat Limkonchotiwat Team|[2510.26271](http://arxiv.org/abs/2510.26271)|null|
|**2025-10-30**|**Which Way Does Time Flow? A Psychophysics-Grounded Evaluation for Vision-Language Models**|Shigeru Kitazawa Team|[2510.26241](http://arxiv.org/abs/2510.26241)|null|
|**2025-10-30**|**MV-MLM: Bridging Multi-View Mammography and Language for Breast Cancer Diagnosis and Risk Prediction**|Ali Diba Team|[2510.26151](http://arxiv.org/abs/2510.26151)|null|
|**2025-10-30**|**GUI Knowledge Bench: Revealing the Knowledge Gap Behind VLM Failures in GUI Tasks**|Qing Li Team|[2510.26098](http://arxiv.org/abs/2510.26098)|null|
|**2025-10-30**|**Dynamic VLM-Guided Negative Prompting for Diffusion Models**|Yoonseok Choi Team|[2510.26052](http://arxiv.org/abs/2510.26052)|null|
|**2025-10-29**|**CAVE: Detecting and Explaining Commonsense Anomalies in Visual Environments**|Antoine Bosselut Team|[2510.26006](http://arxiv.org/abs/2510.26006)|null|
|**2025-10-30**|**PairUni: Pairwise Training for Unified Multimodal Language Models**|Zhuochen Wang Team|[2510.25682](http://arxiv.org/abs/2510.25682)|null|
|**2025-10-29**|**ALDEN: Reinforcement Learning for Active Navigation and Evidence Gathering in Long Documents**|Bela Gipp Team|[2510.25668](http://arxiv.org/abs/2510.25668)|null|
|**2025-10-29**|**Don't Blind Your VLA: Aligning Visual Representations for OOD Generalization**|Aleksandr I. Panov Team|[2510.25616](http://arxiv.org/abs/2510.25616)|null|
|**2025-10-29**|**Using VLM Reasoning to Constrain Task and Motion Planning**|Zachary Kingston Team|[2510.25548](http://arxiv.org/abs/2510.25548)|null|
|**2025-10-29**|**Seeing, Signing, and Saying: A Vision-Language Model-Assisted Pipeline for Sign Language Data Acquisition and Curation from Social Media**|Josef van Genabith Team|[2510.25413](http://arxiv.org/abs/2510.25413)|null|
|**2025-10-29**|**SoraNav: Adaptive UAV Task-Centric Navigation via Zeroshot VLM Reasoning**|Wei Pan Team|[2510.25191](http://arxiv.org/abs/2510.25191)|null|
|**2025-10-29**|**Agentic Moderation: Multi-Agent Design for Safer Vision-Language Models**|Usman Naseem Team|[2510.25179](http://arxiv.org/abs/2510.25179)|null|
|**2025-10-29**|**Learning Spatial-Aware Manipulation Ordering**|Jian Pu Team|[2510.25138](http://arxiv.org/abs/2510.25138)|null|
|**2025-10-29**|**NanoVLA: Routing Decoupled Vision-Language Understanding for Nano-sized Generalist Robotic Policies**|Jinghui Lu Team|[2510.25122](http://arxiv.org/abs/2510.25122)|null|
|**2025-10-29**|**Visual Diversity and Region-aware Prompt Learning for Zero-shot HOI Detection**|Hyunwoo J. Kim Team|[2510.25094](http://arxiv.org/abs/2510.25094)|null|
|**2025-10-29**|**DRIP: Dynamic patch Reduction via Interpretable Pooling**|Sachin Kumar Team|[2510.25067](http://arxiv.org/abs/2510.25067)|null|
|**2025-10-28**|**Efficient License Plate Recognition via Pseudo-Labeled Supervision with Grounding DINO and YOLOv8**|Ching Yee Suen Team|[2510.25032](http://arxiv.org/abs/2510.25032)|null|
|**2025-10-28**|**SCOUT: A Lightweight Framework for Scenario Coverage Assessment in Autonomous Driving**|Mykel J. Kochenderfer Team|[2510.24949](http://arxiv.org/abs/2510.24949)|null|
|**2025-10-28**|**Finding Culture-Sensitive Neurons in Vision-Language Models**|Ivan Titov Team|[2510.24942](http://arxiv.org/abs/2510.24942)|null|
|**2025-10-28**|**Advancing site-specific disease and pest management in precision agriculture: From reasoning-driven foundation models to adaptive, feedback-based learning**|Arnold W. Schumann Team|[2510.24650](http://arxiv.org/abs/2510.24650)|null|
|**2025-10-28**|**OS-Sentinel: Towards Safety-Enhanced Mobile GUI Agents via Hybrid Validation in Realistic Workflows**|Lingpeng Kong Team|[2510.24411](http://arxiv.org/abs/2510.24411)|null|
|**2025-10-28**|**What do vision-language models see in the context? Investigating multimodal in-context learning**|Sandra Avila Team|[2510.24331](http://arxiv.org/abs/2510.24331)|null|
|**2025-10-28**|**Few-Shot Remote Sensing Image Scene Classification with CLIP and Prompt Learning**|Ivan Kitanovski Team|[2510.24321](http://arxiv.org/abs/2510.24321)|null|
|**2025-10-28**|**ViPER: Empowering the Self-Evolution of Visual Perception Abilities in Vision-Language Model**|Rui Yan Team|[2510.24285](http://arxiv.org/abs/2510.24285)|null|
|**2025-10-28**|**Enabling Near-realtime Remote Sensing via Satellite-Ground Collaboration of Large Vision-Language Models**|Yue Gao Team|[2510.24242](http://arxiv.org/abs/2510.24242)|null|
|**2025-10-28**|**V-SAT: Video Subtitle Annotation Tool**|Vishwanathan Raman Team|[2510.24180](http://arxiv.org/abs/2510.24180)|null|
|**2025-10-28**|**Enhancing Vision-Language Models for Autonomous Driving through Task-Specific Prompting and Spatial Reasoning**|Xubo Luo Team|[2510.24152](http://arxiv.org/abs/2510.24152)|null|
|**2025-10-28**|**Compositional Image Synthesis with Inference-Time Scaling**|Namhyuk Ahn Team|[2510.24133](http://arxiv.org/abs/2510.24133)|**[link](https://github.com/gcl-inha/ReFocus)**|
|**2025-10-28**|**HistoLens: An Interactive XAI Toolkit for Verifying and Mitigating Flaws in Vision-Language Models for Histopathology**|Vandita Singh Team|[2510.24115](http://arxiv.org/abs/2510.24115)|null|
|**2025-10-28**|**PFEA: An LLM-based High-Level Natural Language Planning and Feedback Embodied Agent for Human-Centered AI**|Philip Dames Team|[2510.24109](http://arxiv.org/abs/2510.24109)|null|
|**2025-10-28**|**Enhancing CLIP Robustness via Cross-Modality Alignment**|Hanwang Zhang Team|[2510.24038](http://arxiv.org/abs/2510.24038)|null|
|**2025-10-28**|**Mars-Bench: A Benchmark for Evaluating Foundation Models for Mars Science Tasks**|Hannah Kerner Team|[2510.24010](http://arxiv.org/abs/2510.24010)|null|
|**2025-10-28**|**Reasoning Visual Language Model for Chest X-Ray Analysis**|Daguang Xu Team|[2510.23968](http://arxiv.org/abs/2510.23968)|null|
|**2025-10-27**|**Latent Chain-of-Thought for Visual Reasoning**|Zhiqiang Tao Team|[2510.23925](http://arxiv.org/abs/2510.23925)|null|
|**2025-10-27**|**Explainable Detection of AI-Generated Images with Artifact Localization Using Faster-Than-Lies and Vision-Language Models for Edge Devices**|Madesh Kuppusamy Team|[2510.23775](http://arxiv.org/abs/2510.23775)|null|
|**2025-10-27**|**RobotArena $\infty$ : Scalable Robot Benchmarking via Real-to-Sim Translation**|Katerina Fragkiadaki Team|[2510.23571](http://arxiv.org/abs/2510.23571)|**[link](https://robotarenainf.github.io)**|
|**2025-10-28**|**VOLD: Reasoning Transfer from LLMs to Vision-Language Models via On-Policy Distillation**|Cordelia Schmid Team|[2510.23497](http://arxiv.org/abs/2510.23497)|null|
|**2025-10-27**|**On the Faithfulness of Visual Thinking: Measurement and Enhancement**|Guisong Xia Team|[2510.23482](http://arxiv.org/abs/2510.23482)|null|
|**2025-10-27**|**A Video Is Not Worth a Thousand Words**|Michael Wray Team|[2510.23253](http://arxiv.org/abs/2510.23253)|null|
|**2025-10-27**|**Process Reward Models for Sentence-Level Verification of LVLM Radiology Reports**|Curtis P. Langlotz Team|[2510.23217](http://arxiv.org/abs/2510.23217)|null|
|**2025-10-27**|**DecoDINO: 3D Human-Scene Contact Prediction with Semantic Classification**|Angelo Broere Team|[2510.23203](http://arxiv.org/abs/2510.23203)|null|
|**2025-10-27**|**Evaluation of Vision-LLMs in Surveillance Video**|Jelte P. Mense Team|[2510.23190](http://arxiv.org/abs/2510.23190)|null|
|**2025-10-27**|**Finding 3D Scene Analogies with Multimodal Foundation Models**|Young Min Kim Team|[2510.23184](http://arxiv.org/abs/2510.23184)|null|
|**2025-10-27**|**Revisiting Multimodal Positional Encoding in Vision-Language Models**|Shuai Bai Team|[2510.23095](http://arxiv.org/abs/2510.23095)|null|
|**2025-10-27**|**Multi-Stage Field Extraction of Financial Documents with OCR and Compact Vision-Language Models**|Donald MacDonald Team|[2510.23066](http://arxiv.org/abs/2510.23066)|null|
|**2025-10-27**|**VoMP: Predicting Volumetric Mechanical Property Fields**|Maria Shugrina Team|[2510.22975](http://arxiv.org/abs/2510.22975)|**[link](https://research.nvidia.com/labs/sil/projects/vomp)**|
|**2025-10-28**|**HyPerNav: Hybrid Perception for Object-Oriented Navigation in Unknown Environment**|Zhen Li Team|[2510.22917](http://arxiv.org/abs/2510.22917)|null|
|**2025-10-26**|**Seeing the Unseen: Towards Zero-Shot Inspection for Wind Turbine Blades using Knowledge-Augmented Vision Language Models**|Jiong Tang Team|[2510.22868](http://arxiv.org/abs/2510.22868)|null|
|**2025-10-26**|**Semantic-Preserving Cross-Style Visual Reasoning for Robust Multi-Modal Understanding in Large Vision-Language Models**|Kaito Tanaka Team|[2510.22838](http://arxiv.org/abs/2510.22838)|null|
|**2025-10-26**|**VEHME: A Vision-Language Model For Evaluating Handwritten Mathematics Expressions**|Taehwan Kim Team|[2510.22798](http://arxiv.org/abs/2510.22798)|**[link](https://vehme.github.io/)**|
|**2025-10-26**|**Self-Calibrated Consistency can Fight Back for Adversarial Robustness in Vision-Language Models**|Mingkun Xu Team|[2510.22785](http://arxiv.org/abs/2510.22785)|null|
|**2025-10-26**|**MMPersuade: A Dataset and Evaluation Framework for Multimodal Persuasion**|Chien-Sheng Wu Team|[2510.22768](http://arxiv.org/abs/2510.22768)|null|
|**2025-10-26**|**Jarvis: Towards Personalized AI Assistant via Personal KV-Cache Retrieval**|Wentao Zhang Team|[2510.22765](http://arxiv.org/abs/2510.22765)|null|
|**2025-10-26**|**S-Chain: Structured Visual Chain-of-Thought For Medicine**|Anh Totti Nguyen Team|[2510.22728](http://arxiv.org/abs/2510.22728)|null|
|**2025-10-26**|**Atlas Urban Index: A VLM-Based Approach for Spatially and Temporally Calibrated Urban Development Monitoring**|Prathamesh Mayekar Team|[2510.22702](http://arxiv.org/abs/2510.22702)|null|
|**2025-10-24**|**A Multimodal Benchmark for Framing of Oil & Gas Advertising and Potential Greenwashing Detection**|Peter Henderson Team|[2510.21679](http://arxiv.org/abs/2510.21679)|null|
|**2025-10-24**|**Modest-Align: Data-Efficient Alignment for Vision-Language Models**|Zuozhu Liu Team|[2510.21606](http://arxiv.org/abs/2510.21606)|null|
|**2025-10-24**|**Head Pursuit: Probing Attention Specialization in Multimodal Transformers**|Alberto Cazzaniga Team|[2510.21518](http://arxiv.org/abs/2510.21518)|null|
|**2025-10-24**|**MoniTor: Exploiting Large Language Models with Instruction for Online Video Anomaly Detection**|Jie Qin Team|[2510.21449](http://arxiv.org/abs/2510.21449)|null|
|**2025-10-24**|**Vision Language Models for Dynamic Human Activity Recognition in Healthcare Settings**|Fakhri Karray Team|[2510.21424](http://arxiv.org/abs/2510.21424)|null|
|**2025-10-24**|**Bridging the gap to real-world language-grounded visual concept learning**|Seunghoon Hong Team|[2510.21412](http://arxiv.org/abs/2510.21412)|null|
|**2025-10-24**|**VL-SAE: Interpreting and Enhancing Vision-Language Alignment with a Unified Concept Set**|Shuhui Wang Team|[2510.21323](http://arxiv.org/abs/2510.21323)|null|
|**2025-10-24**|**Memory-Free Continual Learning with Null Space Adaptation for Zero-Shot Vision-Language Models**|Taesup Kim Team|[2510.21175](http://arxiv.org/abs/2510.21175)|null|
|**2025-10-24**|**Generalizable Hierarchical Skill Learning via Object-Centric Representation**|Robert Platt Team|[2510.21121](http://arxiv.org/abs/2510.21121)|null|
|**2025-10-24**|**SafetyPairs: Isolating Safety Critical Image Features with Counterfactual Image Generation**|Joseph Yitan Cheng Team|[2510.21120](http://arxiv.org/abs/2510.21120)|null|
|**2025-10-24**|**MedAlign: A Synergistic Framework of Multimodal Preference Optimization and Federated Meta-Cognitive Reasoning**|Dong In Kim Team|[2510.21093](http://arxiv.org/abs/2510.21093)|null|
|**2025-10-24**|**Knowledge-Driven Vision-Language Model for Plexus Detection in Hirschsprung's Disease**|Adrian D. C. Chan Team|[2510.21083](http://arxiv.org/abs/2510.21083)|null|
|**2025-10-24**|**ZING-3D: Zero-shot Incremental 3D Scene Graphs via Vision-Language Models**|Jimmy Chiun Team|[2510.21069](http://arxiv.org/abs/2510.21069)|null|
|**2025-10-23**|**3DReasonKnee: Advancing Grounded Reasoning in Medical Vision Language Models**|Pranav Rajpurkar Team|[2510.20967](http://arxiv.org/abs/2510.20967)|null|
|**2025-10-23**|**Small Drafts, Big Verdict: Information-Intensive Visual Reasoning via Speculation**|Shengjie Wang Team|[2510.20812](http://arxiv.org/abs/2510.20812)|null|
|**2025-10-23**|**Mixing Importance with Diversity: Joint Optimization for KV Cache Compression in Large Vision-Language Models**|Linfeng Zhang Team|[2510.20707](http://arxiv.org/abs/2510.20707)|**[link](https://github.com/xuyang-liu16/MixKV)**|
|**2025-10-23**|**Diagnosing Visual Reasoning: Challenges, Insights, and a Path Forward**|Chenliang Xu Team|[2510.20696](http://arxiv.org/abs/2510.20696)|null|
|**2025-10-23**|**Better Tokens for Better 3D: Advancing Vision-Language Modeling in 3D Medical Imaging**|Bjoern Menze Team|[2510.20639](http://arxiv.org/abs/2510.20639)|null|
|**2025-10-23**|**Bi-CoG: Bi-Consistency-Guided Self-Training for Vision-Language Models**|Lan-Zhe Guo Team|[2510.20477](http://arxiv.org/abs/2510.20477)|null|
|**2025-10-23**|**GhostEI-Bench: Do Mobile Agents Resilience to Environmental Injection in Dynamic On-Device Environments?**|Yingchun Wang Team|[2510.20333](http://arxiv.org/abs/2510.20333)|null|
|**2025-10-23**|**Breakdance Video classification in the age of Generative AI**|Michelle Munson Team|[2510.20287](http://arxiv.org/abs/2510.20287)|null|
|**2025-10-23**|**Empower Words: DualGround for Structured Phrase and Sentence-Level Temporal Grounding**|Sangyoun Lee Team|[2510.20244](http://arxiv.org/abs/2510.20244)|null|
|**2025-10-23**|**Why LVLMs Are More Prone to Hallucinations in Longer Responses: The Role of Context**|Sibei Yang Team|[2510.20229](http://arxiv.org/abs/2510.20229)|null|
|**2025-10-24**|**Surfer 2: The Next Generation of Cross-Platform Computer Use Agents**|Jevgenij Zubovskij Team|[2510.19949](http://arxiv.org/abs/2510.19949)|null|
|**2025-10-22**|**Semantic World Models**|Abhishek Gupta Team|[2510.19818](http://arxiv.org/abs/2510.19818)|null|
|**2025-10-22**|**olmOCR 2: Unit Test Rewards for Document OCR**|Kyle Lo Team|[2510.19817](http://arxiv.org/abs/2510.19817)|**[link](https://olmocr.allen.ai/)**|
|**2025-10-22**|**Class-Aware Prototype Learning with Negative Contrast for Test-Time Adaptation of Vision-Language Models**|Xuelong Li Team|[2510.19802](http://arxiv.org/abs/2510.19802)|null|
|**2025-10-22**|**MedReason-R1: Learning to Reason for CT Diagnosis with Reinforcement Learning and Local Zoom**|Shaohua Kevin Zhou Team|[2510.19626](http://arxiv.org/abs/2510.19626)|**[link](https://github.com/Leevan001/MedReason-R1)**|
|**2025-10-22**|**XBench: A Comprehensive Benchmark for Visual-Language Explanations in Chest Radiography**|Mauricio Reyes Team|[2510.19599](http://arxiv.org/abs/2510.19599)|null|
|**2025-10-22**|**Can You Trust What You See? Alpha Channel No-Box Attacks on Video Object Detection**|Qiben Yan Team|[2510.19574](http://arxiv.org/abs/2510.19574)|null|
|**2025-10-22**|**A Matter of Time: Revealing the Structure of Time in Vision-Language Models**|Matthias Zeppelzauer Team|[2510.19559](http://arxiv.org/abs/2510.19559)|null|
|**2025-10-22**|**[De|Re]constructing VLMs' Reasoning in Counting**|Giuseppe Riccardi Team|[2510.19555](http://arxiv.org/abs/2510.19555)|null|
|**2025-10-22**|**CARES: Context-Aware Resolution Selector for VLMs**|Eli Schwartz Team|[2510.19496](http://arxiv.org/abs/2510.19496)|null|
|**2025-10-22**|**Seeing Across Views: Benchmarking Spatial Reasoning of Vision-Language Models in Robotic Scenes**|Baining Guo Team|[2510.19400](http://arxiv.org/abs/2510.19400)|**[link](https://github.com/microsoft/MV-RoboBench)**|
|**2025-10-22**|**A Training-Free Framework for Open-Vocabulary Image Segmentation and Recognition with EfficientNet and CLIP**|Wei Yu Chen Team|[2510.19333](http://arxiv.org/abs/2510.19333)|null|
|**2025-10-22**|**Unified Reinforcement and Imitation Learning for Vision-Language Models**|Yueh-Hua Wu Team|[2510.19307](http://arxiv.org/abs/2510.19307)|**[link](https://byungkwanlee.github.io/RIL-page)**|
|**2025-10-22**|**Hierarchical DLO Routing with Reinforcement Learning and In-Context Vision-language Models**|Changhyun Choi Team|[2510.19268](http://arxiv.org/abs/2510.19268)|null|
|**2025-10-22**|**Preliminary Use of Vision Language Model Driven Extraction of Mouse Behavior Towards Understanding Fear Expression**|Evangelos E. Papalexakis Team|[2510.19160](http://arxiv.org/abs/2510.19160)|null|
|**2025-10-21**|**PoSh: Using Scene Graphs To Guide LLMs-as-a-Judge For Detailed Image Descriptions**|Kathleen McKeown Team|[2510.19060](http://arxiv.org/abs/2510.19060)|**[link](https://github.com/amith-ananthram/posh)**|
|**2025-10-21**|**Robust Driving QA through Metadata-Grounded Context and Task-Specific Prompts**|Hyunjung Shim Team|[2510.19001](http://arxiv.org/abs/2510.19001)|null|
|**2025-10-21**|**DSI-Bench: A Benchmark for Dynamic Spatial Intelligence**|Zhou Zhao Team|[2510.18873](http://arxiv.org/abs/2510.18873)|null|
|**2025-10-21**|**FedDEAP: Adaptive Dual-Prompt Tuning for Multi-Domain Federated Learning**|Jagath C. Rajapakse Team|[2510.18837](http://arxiv.org/abs/2510.18837)|null|
|**2025-10-21**|**Seg the HAB: Language-Guided Geospatial Algae Bloom Reasoning and Segmentation**|Elvis Hsieh Team|[2510.18751](http://arxiv.org/abs/2510.18751)|null|
|**2025-10-21**|**Exploring a Unified Vision-Centric Contrastive Alternatives on Multi-Modal Web Documents**|Mike Zheng Shou Team|[2510.18703](http://arxiv.org/abs/2510.18703)|**[link](https://linyq17.github.io/VC2L/)**|
|**2025-10-21**|**Think with 3D: Geometric Imagination Grounded Spatial Reasoning from Limited Views**|Ruqi Huang Team|[2510.18632](http://arxiv.org/abs/2510.18632)|null|
|**2025-10-21**|**CUARewardBench: A Benchmark for Evaluating Reward Models on Computer-using Agent**|Xing Sun Team|[2510.18596](http://arxiv.org/abs/2510.18596)|null|
|**2025-10-21**|**CovMatch: Cross-Covariance Guided Multimodal Dataset Distillation with Trainable Text Encoder**|Hye Won Chung Team|[2510.18583](http://arxiv.org/abs/2510.18583)|null|
|**2025-10-21**|**Zero-Shot Vehicle Model Recognition via Text-Based Retrieval-Augmented Generation**|Yan-Ann Chen Team|[2510.18502](http://arxiv.org/abs/2510.18502)|null|
|**2025-10-21**|**StarBench: A Turn-Based RPG Benchmark for Agentic Multimodal Decision-Making and Information Seeking**|Donglin Yu Team|[2510.18483](http://arxiv.org/abs/2510.18483)|null|
|**2025-10-21**|**Grounding or Guessing? Visual Signals for Detecting Hallucinations in Sign Language Translation**|Cristina España-Bonet Team|[2510.18439](http://arxiv.org/abs/2510.18439)|null|
|**2025-10-21**|**ImageGem: In-the-wild Generative Image Interaction Dataset for Generative Model Personalization**|Hongyi Wen Team|[2510.18433](http://arxiv.org/abs/2510.18433)|null|
|**2025-10-21**|**Beyond Single Models: Mitigating Multimodal Hallucinations via Adaptive Token Ensemble Decoding**|Xian Wu Team|[2510.18321](http://arxiv.org/abs/2510.18321)|null|
|**2025-10-21**|**StreamingTOM: Streaming Token Compression for Efficient Video Understanding**|Huan Wang Team|[2510.18269](http://arxiv.org/abs/2510.18269)|null|
|**2025-10-21**|**UWBench: A Comprehensive Vision-Language Benchmark for Underwater Understanding**|Xuelong Li Team|[2510.18262](http://arxiv.org/abs/2510.18262)|null|
|**2025-10-21**|**RadDiagSeg-M: A Vision Language Model for Joint Diagnosis and Multi-Target Segmentation in Radiology**|Bjoern Menze Team|[2510.18188](http://arxiv.org/abs/2510.18188)|null|
|**2025-10-20**|**Online In-Context Distillation for Low-Resource Vision Language Models**|Karteek Alahari Team|[2510.18117](http://arxiv.org/abs/2510.18117)|null|
|**2025-10-20**|**HouseTour: A Virtual Real Estate A(I)gent**|Iro Armeni Team|[2510.18054](http://arxiv.org/abs/2510.18054)|null|
|**2025-10-20**|**SAVANT: Semantic Analysis with Vision-Augmented Anomaly deTection**|Johannes Betz Team|[2510.18034](http://arxiv.org/abs/2510.18034)|null|
|**2025-10-21**|**Glyph: Scaling Context Windows via Visual-Text Compression**|Minlie Huang Team|[2510.17800](http://arxiv.org/abs/2510.17800)|null|
|**2025-10-20**|**SparseVILA: Decoupling Visual Sparsity for Efficient VLM Inference**|Zhijian Liu Team|[2510.17777](http://arxiv.org/abs/2510.17777)|null|
|**2025-10-20**|**Seeing but Not Believing: Probing the Disconnect Between Visual Attention and Answer Correctness in VLMs**|Hanghang Tong Team|[2510.17771](http://arxiv.org/abs/2510.17771)|null|
|**2025-10-20**|**VERA-V: Variational Inference Framework for Jailbreaking Vision-Language Models**|Ruqi Zhang Team|[2510.17759](http://arxiv.org/abs/2510.17759)|null|
|**2025-10-20**|**Frugal Federated Learning for Violence Detection: A Comparison of LoRA-Tuned VLMs and Personalized CNNs**|Rachid Chelouah Team|[2510.17651](http://arxiv.org/abs/2510.17651)|null|
|**2025-10-20**|**SARSteer: Safeguarding Large Audio Language Models via Safe-Ablated Refusal Steering**|Li Liu Team|[2510.17633](http://arxiv.org/abs/2510.17633)|null|
|**2025-10-20**|**MIRAGE: Agentic Framework for Multimodal Misinformation Detection with Web-Grounded Reasoning**|Adiba Mahbub Proma Team|[2510.17590](http://arxiv.org/abs/2510.17590)|null|
|**2025-10-20**|**Towards Mixed-Modal Retrieval for Universal Retrieval-Augmented Generation**|Zhicheng Dou Team|[2510.17354](http://arxiv.org/abs/2510.17354)|null|
|**2025-10-20**|**Disentanglement Beyond Static vs. Dynamic: A Benchmark and Evaluation Framework for Multi-Factor Sequential Representations**|Omri Azencot Team|[2510.17313](http://arxiv.org/abs/2510.17313)|null|
|**2025-10-20**|**FineVision: Open Data Is All You Need**|Andrés Marafioti Team|[2510.17269](http://arxiv.org/abs/2510.17269)|null|
|**2025-10-20**|**ZSPAPrune: Zero-Shot Prompt-Aware Token Pruning for Vision-Language Models**|Guoming Tang Team|[2510.17197](http://arxiv.org/abs/2510.17197)|null|
|**2025-10-20**|**SimpleVSF: VLM-Scoring Fusion for Trajectory Prediction of End-to-End Autonomous Driving**|Shaohua Wu Team|[2510.17191](http://arxiv.org/abs/2510.17191)|null|
|**2025-10-20**|**OmniVIC: A Self-Improving Variable Impedance Controller with Vision-Language In-Context Learning for Safe Robotic Manipulation**|Arash Ajoudani Team|[2510.17150](http://arxiv.org/abs/2510.17150)|**[link](https://sites.google.com/view/omni-vic})**|
|**2025-10-20**|**Efficient Vision-Language-Action Models for Embodied Manipulation: A Systematic Survey**|Jian Cheng Team|[2510.17111](http://arxiv.org/abs/2510.17111)|null|
|**2025-10-19**|**Where, Not What: Compelling Video LLMs to Learn Geometric Causality for 3D-Grounding**|Yutong Zhong Team|[2510.17034](http://arxiv.org/abs/2510.17034)|null|
|**2025-10-19**|**Does Visual Grounding Enhance the Understanding of Embodied Knowledge in Large Language Models?**|Renfen Hu Team|[2510.16924](http://arxiv.org/abs/2510.16924)|null|
|**2025-10-19**|**VAGEN: Reinforcing World Model Reasoning for Multi-Turn VLM Agents**|Manling Li Team|[2510.16907](http://arxiv.org/abs/2510.16907)|null|
|**2025-10-19**|**Uncovering Brain-Like Hierarchical Patterns in Vision-Language Models through fMRI-Based Neural Encoding**|Xiaowei He Team|[2510.16870](http://arxiv.org/abs/2510.16870)|null|
|**2025-10-19**|**Region in Context: Text-condition Image editing with Human-like semantic reasoning**|Phan Xuan Tan Team|[2510.16772](http://arxiv.org/abs/2510.16772)|null|
|**2025-10-19**|**See or Say Graphs: Agent-Driven Scalable Graph Understanding with Vision-Language Models**|Xike Xie Team|[2510.16769](http://arxiv.org/abs/2510.16769)|null|
|**2025-10-17**|**BiomedXPro: Prompt Optimization for Explainable Diagnosis with Biomedical Vision Language Models**|Damayanthi Herath Team|[2510.15866](http://arxiv.org/abs/2510.15866)|null|
|**2025-10-17**|**Neuro-Symbolic Spatial Reasoning in Segmentation**|Shaogang Gong Team|[2510.15841](http://arxiv.org/abs/2510.15841)|null|
|**2025-10-17**|**Learning to Detect Unknown Jailbreak Attacks in Large Vision-Language Models**|Xiting Wang Team|[2510.15430](http://arxiv.org/abs/2510.15430)|null|
|**2025-10-17**|**Fine-Tuning MedGemma for Clinical Captioning to Enhance Multimodal RAG over Malaysia CPGs**|Goh Man Fye Team|[2510.15418](http://arxiv.org/abs/2510.15418)|null|
|**2025-10-17**|**Infinity Parser: Layout Aware Reinforcement Learning for Scanned Document Parsing**|Yuan Qi Team|[2510.15349](http://arxiv.org/abs/2510.15349)|null|
|**2025-10-16**|**From Pixels to Words -- Towards Native Vision-Language Primitives at Scale**|Ziwei Liu Team|[2510.14979](http://arxiv.org/abs/2510.14979)|null|
|**2025-10-16**|**Learning an Image Editing Model without Image Editing Pairs**|Xun Huang Team|[2510.14978](http://arxiv.org/abs/2510.14978)|**[link](https://nupurkmr9.github.io/npedit/)**|
|**2025-10-16**|**RDD: Retrieval-Based Demonstration Decomposer for Planner Alignment in Long-Horizon Tasks**|Jiachen Li Team|[2510.14968](http://arxiv.org/abs/2510.14968)|null|
|**2025-10-16**|**RoboGPT-R1: Enhancing Robot Planning with Reinforcement Learning**|Haoran Li Team|[2510.14828](http://arxiv.org/abs/2510.14828)|null|
|**2025-10-16**|**CoT-PL: Visual Chain-of-Thought Reasoning Meets Pseudo-Labeling for Open-Vocabulary Object Detection**|Hyunjung Shim Team|[2510.14792](http://arxiv.org/abs/2510.14792)|null|
|**2025-10-16**|**Free-Grained Hierarchical Recognition**|Stella X. Yu Team|[2510.14737](http://arxiv.org/abs/2510.14737)|null|
|**2025-10-16**|**Efficient Video Sampling: Pruning Temporally Redundant Tokens for Faster VLM Inference**|Andrew Tao Team|[2510.14624](http://arxiv.org/abs/2510.14624)|null|
|**2025-10-16**|**Talking Points: Describing and Localizing Pixels**|Shai Avidan Team|[2510.14583](http://arxiv.org/abs/2510.14583)|null|
|**2025-10-16**|**Exploring Cross-Modal Flows for Few-Shot Learning**|Long Chen Team|[2510.14543](http://arxiv.org/abs/2510.14543)|null|
|**2025-10-17**|**PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model**|Yanjun Ma Team|[2510.14528](http://arxiv.org/abs/2510.14528)|**[link](https://github.com/PaddlePaddle/PaddleOCR)**|
|**2025-10-16**|**Noise Projection: Closing the Prompt-Agnostic Gap Behind Text-to-Image Misalignment in Diffusion Models**|Ziyu Zhao Team|[2510.14526](http://arxiv.org/abs/2510.14526)|null|
|**2025-10-16**|**Hi-Agent: Hierarchical Vision-Language Agents for Mobile Device Control**|Yuanchun Shi Team|[2510.14388](http://arxiv.org/abs/2510.14388)|null|
|**2025-10-16**|**Watermarking for Factuality: Guiding Vision-Language Models Toward Truth via Tri-layer Contrastive Decoding**|Jinkyu Kim Team|[2510.14304](http://arxiv.org/abs/2510.14304)|**[link](https://github.com/KR-0822/TCD)**|
|**2025-10-15**|**Efficient Few-Shot Learning in Remote Sensing: Fusing Vision and Vision-Language Models**|Miguel Arana-Catania Team|[2510.13993](http://arxiv.org/abs/2510.13993)|null|
|**2025-10-15**|**VisCoP: Visual Probing for Video Domain Adaptation of Vision Language Models**|Srijan Das Team|[2510.13808](http://arxiv.org/abs/2510.13808)|null|
|**2025-10-15**|**Generative Universal Verifier as Multimodal Meta-Reasoner**|Yujiu Yang Team|[2510.13804](http://arxiv.org/abs/2510.13804)|null|
|**2025-10-15**|**Spatial-DISE: A Unified Benchmark for Evaluating Spatial Reasoning in Vision-Language Models**|Xiaowei Huang Team|[2510.13394](http://arxiv.org/abs/2510.13394)|null|
|**2025-10-15**|**DepthVLA: Enhancing Vision-Language-Action Models with Depth-Aware Spatial Reasoning**|Hang Zhao Team|[2510.13375](http://arxiv.org/abs/2510.13375)|null|
|**2025-10-15**|**Language as a Label: Zero-Shot Multimodal Classification of Everyday Postures under Data Scarcity**|Jubal Chandy Jacob Team|[2510.13364](http://arxiv.org/abs/2510.13364)|null|
|**2025-10-15**|**Improving Visual Recommendation on E-commerce Platforms Using Vision-Language Models**|Andre Rusli Team|[2510.13359](http://arxiv.org/abs/2510.13359)|null|
|**2025-10-15**|**Self-Augmented Visual Contrastive Decoding**|Vivek Gupta Team|[2510.13315](http://arxiv.org/abs/2510.13315)|null|
|**2025-10-15**|**MMLongCite: A Benchmark for Evaluating Fidelity of Long-Context Vision-Language Models**|Min Zhang Team|[2510.13276](http://arxiv.org/abs/2510.13276)|null|
|**2025-10-15**|**Map the Flow: Revealing Hidden Pathways of Information in VideoLLMs**|Bohyung Han Team|[2510.13251](http://arxiv.org/abs/2510.13251)|null|
|**2025-10-15**|**What "Not" to Detect: Negation-Aware VLMs via Structured Reasoning and Token Merging**|Hyunjung Shim Team|[2510.13232](http://arxiv.org/abs/2510.13232)|null|
|**2025-10-15**|**SHIELD: Classifier-Guided Prompting for Robust and Safer LVLMs**|Usman Naseem Team|[2510.13190](http://arxiv.org/abs/2510.13190)|null|
|**2025-10-15**|**DriveCritic: Towards Context-Aware, Human-Aligned Evaluation for Autonomous Driving with Vision-Language Models**|Jose M. Alvarez Team|[2510.13108](http://arxiv.org/abs/2510.13108)|null|
|**2025-10-15**|**VLA-0: Building State-of-the-Art VLAs with Zero Modification**|Fabio Ramos Team|[2510.13054](http://arxiv.org/abs/2510.13054)|null|
|**2025-10-14**|**SVAG-Bench: A Large-Scale Benchmark for Multi-Instance Spatio-temporal Video Action Grounding**|Thomas Seidl Team|[2510.13016](http://arxiv.org/abs/2510.13016)|null|
|**2025-10-14**|**UNCAP: Uncertainty-Guided Planning Using Natural Language Communication for Cooperative Autonomous Vehicles**|Ufuk Topcu Team|[2510.12992](http://arxiv.org/abs/2510.12992)|null|
|**2025-10-14**|**Scope: Selective Cross-modal Orchestration of Visual Perception Experts**|Perouz Taslakian Team|[2510.12974](http://arxiv.org/abs/2510.12974)|null|
|**2025-10-14**|**Epistemic-aware Vision-Language Foundation Model for Fetal Ultrasound Interpretation**|Bo Du Team|[2510.12953](http://arxiv.org/abs/2510.12953)|null|
|**2025-10-14**|**Unifying Vision-Language Latents for Zero-label Image Caption Enhancement**|Woo Seong Chung Team|[2510.12931](http://arxiv.org/abs/2510.12931)|null|
|**2025-10-14**|**UniFusion: Vision-Language Model as Unified Encoder in Image Generation**|Ajinkya Kale Team|[2510.12789](http://arxiv.org/abs/2510.12789)|**[link](https://thekevinli.github.io/unifusion/)**|
|**2025-10-15**|**SAIL-Embedding Technical Report: Omni-modal Embedding Foundation Model**|Chao Feng Team|[2510.12709](http://arxiv.org/abs/2510.12709)|null|
|**2025-10-14**|**ERA: Transforming VLMs into Embodied Agents via Embodied Prior Learning and Online Reinforcement Learning**|Tong Zhang Team|[2510.12693](http://arxiv.org/abs/2510.12693)|null|
|**2025-10-14**|**VISaGE: Understanding Visual Generics and Exceptions**|Emily Allaway Team|[2510.12548](http://arxiv.org/abs/2510.12548)|null|
|**2025-10-14**|**A Review of Longitudinal Radiology Report Generation: Dataset Composition, Methods, and Performance Evaluation**|Luping Zhou Team|[2510.12444](http://arxiv.org/abs/2510.12444)|null|
|**2025-10-14**|**Towards General Urban Monitoring with Vision-Language Models: A Review, Evaluation, and a Research Agenda**|Nuno F. Rodrigues Team|[2510.12400](http://arxiv.org/abs/2510.12400)|null|
|**2025-10-14**|**Vision Language Models Map Logos to Text via Semantic Entanglement in the Visual Projector**|Yiwei Wang Team|[2510.12287](http://arxiv.org/abs/2510.12287)|null|
|**2025-10-14**|**Spatial Forcing: Implicit Spatial Representation Alignment for Vision-language-action Model**|Haoang Li Team|[2510.12276](http://arxiv.org/abs/2510.12276)|null|
|**2025-10-14**|**HoneyBee: Data Recipes for Vision-Language Reasoners**|Ramakanth Pasunuru Team|[2510.12225](http://arxiv.org/abs/2510.12225)|null|
|**2025-10-14**|**Hierarchical Reasoning with Vision-Language Models for Incident Reports from Dashcam Videos**|Yu Yamaguchi Team|[2510.12190](http://arxiv.org/abs/2510.12190)|null|
|**2025-10-14**|**ImageSentinel: Protecting Visual Datasets from Unauthorized Retrieval-Augmented Image Generation**|Renjie Wan Team|[2510.12119](http://arxiv.org/abs/2510.12119)|null|
|**2025-10-13**|**Embedding the Teacher: Distilling vLLM Preferences for Scalable Image Retrieval**|Vyas Raina Team|[2510.12014](http://arxiv.org/abs/2510.12014)|null|
|**2025-10-13**|**Learning Dynamics of VLM Finetuning**|Keze Wang Team|[2510.11978](http://arxiv.org/abs/2510.11978)|null|
|**2025-10-13**|**Evaluating Open-Source Vision-Language Models for Multimodal Sarcasm Detection**|Marcos Zampieri Team|[2510.11852](http://arxiv.org/abs/2510.11852)|**[link](https://icdmw25mmai.github.io/)**|
|**2025-10-13**|**Data or Language Supervision: What Makes CLIP Better than DINO?**|Serena Yeung-Levy Team|[2510.11835](http://arxiv.org/abs/2510.11835)|null|
|**2025-10-13**|**CodePlot-CoT: Mathematical Visual Reasoning by Thinking with Code-Driven Images**|Xihui Liu Team|[2510.11718](http://arxiv.org/abs/2510.11718)|null|
|**2025-10-13**|**Phys2Real: Fusing VLM Priors with Interactive Online Adaptation for Uncertainty-Aware Sim-to-Real Manipulation**|Mac Schwager Team|[2510.11689](http://arxiv.org/abs/2510.11689)|null|
|**2025-10-13**|**EvoCAD: Evolutionary CAD Code Generation with Vision Language Models**|Niki van Stein Team|[2510.11631](http://arxiv.org/abs/2510.11631)|null|
|**2025-10-13**|**mmWalk: Towards Multi-modal Multi-view Walking Assistance**|Rainer Stiefelhagen Team|[2510.11520](http://arxiv.org/abs/2510.11520)|**[link](https://github.com/KediYing/mmWalk)**|
|**2025-10-13**|**Coupled Degradation Modeling and Fusion: A VLM-Guided Degradation-Coupled Network for Degradation-Aware Infrared and Visible Image Fusion**|Guangmang Cui Team|[2510.11456](http://arxiv.org/abs/2510.11456)|null|
|**2025-10-13**|**Template-Based Text-to-Image Alignment for Language Accessibility: A Study on Visualizing Text Simplifications**|Yingqiang Gao Team|[2510.11314](http://arxiv.org/abs/2510.11314)|null|
|**2025-10-13**|**When Does Supervised Training Pay Off? The Hidden Economics of Object Detection in the Era of Vision-Language Models**|Samer Al-Hamadani Team|[2510.11302](http://arxiv.org/abs/2510.11302)|null|
|**2025-10-13**|**$Δ\mathrm{Energy}$ : Optimizing Energy Change During Vision-Language Alignment Improves both OOD Detection and OOD Generalization**|Nanyang Ye Team|[2510.11296](http://arxiv.org/abs/2510.11296)|null|
|**2025-10-13**|**Human Uncertainty-Aware Data Selection and Automatic Labeling in Visual Question Answering**|Thomas Seidl Team|[2510.11295](http://arxiv.org/abs/2510.11295)|null|
|**2025-10-13**|**Evaluating Reasoning Faithfulness in Medical Vision-Language Models using Multimodal Perturbations**|Keno K. Bressem Team|[2510.11196](http://arxiv.org/abs/2510.11196)|null|
|**2025-10-13**|**BLEnD-Vis: Benchmarking Multimodal Cultural Understanding in Vision Language Models**|Roy Ka-Wei Lee Team|[2510.11178](http://arxiv.org/abs/2510.11178)|null|
|**2025-10-13**|**Vlaser: Vision-Language-Action Model with Synergistic Embodied Reasoning**|Zhi Hou Team|[2510.11027](http://arxiv.org/abs/2510.11027)|null|
|**2025-10-13**|**GeoVLMath: Enhancing Geometry Reasoning in Vision-Language Models via Cross-Modal Reward for Auxiliary Line Creation**|Jing Zhang Team|[2510.11020](http://arxiv.org/abs/2510.11020)|null|
|**2025-10-13**|**COCO-Tree: Compositional Hierarchical Concept Trees for Enhanced Reasoning in Vision Language Models**|Aidong Zhang Team|[2510.11012](http://arxiv.org/abs/2510.11012)|null|
|**2025-10-13**|**Catch-Only-One: Non-Transferable Examples for Model-Specific Authorization**|Guangdong Bai Team|[2510.10982](http://arxiv.org/abs/2510.10982)|null|
|**2025-10-13**|**Chart-RVR: Reinforcement Learning with Verifiable Rewards for Explainable Chart Reasoning**|Aidong Zhang Team|[2510.10973](http://arxiv.org/abs/2510.10973)|null|
|**2025-10-13**|**IUT-Plug: A Plug-in tool for Interleaved Image-Text Generation**|Jing Tang Team|[2510.10969](http://arxiv.org/abs/2510.10969)|null|
|**2025-10-13**|**MC#: Mixture Compressor for Mixture-of-Experts Large Models**|Xiaojuan Qi Team|[2510.10962](http://arxiv.org/abs/2510.10962)|null|
|**2025-10-13**|**FG-CLIP 2: A Bilingual Fine-grained Vision-Language Alignment Model**|Yuhui Yin Team|[2510.10921](http://arxiv.org/abs/2510.10921)|null|
|**2025-10-13**|**Topological Alignment of Shared Vision-Language Embedding Space**|Jae-Hun Jung Team|[2510.10889](http://arxiv.org/abs/2510.10889)|null|
|**2025-10-10**|**StreamingVLM: Real-Time Understanding for Infinite Video Streams**|Song Han Team|[2510.09608](http://arxiv.org/abs/2510.09608)|null|
|**2025-10-10**|**VITA-VLA: Efficiently Teaching Vision-Language Models to Act via Action Expert Distillation**|Caifeng Shan Team|[2510.09607](http://arxiv.org/abs/2510.09607)|**[link](https://ltbai.github.io/VITA-VLA/)**|
|**2025-10-10**|**Vision Language Models: A Survey of 26K Papers**|Fengming Lin Team|[2510.09586](http://arxiv.org/abs/2510.09586)|null|
|**2025-10-10**|**D-TPT: Dimensional Entropy Maximization for Calibrating Test-Time Prompt Tuning in Vision-Language Models**|Wonjun Hwang Team|[2510.09473](http://arxiv.org/abs/2510.09473)|null|
|**2025-10-10**|**Boosting Multi-modal Keyphrase Prediction with Dynamic Chain-of-Thought in Vision-Language Models**|Jiao Ran Team|[2510.09358](http://arxiv.org/abs/2510.09358)|**[link](https://github.com/bytedance/DynamicCoT)**|
|**2025-10-10**|**Spotlight on Token Perception for Multimodal Reinforcement Learning**|Yu Cheng Team|[2510.09285](http://arxiv.org/abs/2510.09285)|**[link](https://github.com/huaixuheqing/VPPO-RL)**|
|**2025-10-10**|**Hallucination Filtering in Radiology Vision-Language Models Using Discrete Semantic Entropy**|Daniel Truhn Team|[2510.09256](http://arxiv.org/abs/2510.09256)|**[link](https://github.com/TruhnLab/VisionSemanticEntropy)**|
|**2025-10-10**|**Zero-shot image privacy classification with Vision-Language Models**|Andrea Cavallaro Team|[2510.09253](http://arxiv.org/abs/2510.09253)|null|
|**2025-10-10**|**Clear Roads, Clear Vision: Advancements in Multi-Weather Restoration for Smart Transportation**|Subrahmanyam Murala Team|[2510.09228](http://arxiv.org/abs/2510.09228)|null|
|**2025-10-10**|**MCMC: Bridging Rendering, Optimization and Generative AI**|Wenzel Jakob Team|[2510.09078](http://arxiv.org/abs/2510.09078)|null|
|**2025-10-10**|**On Epistemic Uncertainty of Visual Tokens for Object Hallucinations in Large Vision-Language Models**|Se Young Chun Team|[2510.09008](http://arxiv.org/abs/2510.09008)|null|
|**2025-10-10**|**Unleashing Perception-Time Scaling to Multimodal Reasoning Models**|Minghui Qiu Team|[2510.08964](http://arxiv.org/abs/2510.08964)|null|
|**2025-10-10**|**PHyCLIP: $\ell_1$ -Product of Hyperbolic Factors Unifies Hierarchy and Compositionality in Vision-Language Representation Learning**|Takashi Matsubara Team|[2510.08919](http://arxiv.org/abs/2510.08919)|null|
|**2025-10-09**|**CDE: Concept-Driven Exploration for Reinforcement Learning**|Joseph Campbell Team|[2510.08851](http://arxiv.org/abs/2510.08851)|null|
|**2025-10-09**|**FOLK: Fast Open-Vocabulary 3D Instance Segmentation via Label-guided Knowledge Distillation**|Zhihua Wei Team|[2510.08849](http://arxiv.org/abs/2510.08849)|null|
|**2025-10-09**|**D-CoDe: Scaling Image-Pretrained VLMs to Video via Dynamic Compression and Question Decomposition**|Yun Fu Team|[2510.08818](http://arxiv.org/abs/2510.08818)|null|
|**2025-10-09**|**Q-Router: Agentic Video Quality Assessment with Expert Model Routing and Artifact Localization**|Zhengzhong Tu Team|[2510.08789](http://arxiv.org/abs/2510.08789)|null|
|**2025-10-09**|**MATRIX: Multimodal Agent Tuning for Robust Tool-Use Reasoning**|Salman Khan Team|[2510.08567](http://arxiv.org/abs/2510.08567)|null|
|**2025-10-09**|**SpatialLadder: Progressive Training for Spatial Reasoning in Vision-Language Models**|Yueting Zhuang Team|[2510.08531](http://arxiv.org/abs/2510.08531)|**[link](https://zju-real.github.io/SpatialLadder/)**|
|**2025-10-09**|**To Sink or Not to Sink: Visual Information Pathways in Large Vision-Language Models**|Leonid Sigal Team|[2510.08510](http://arxiv.org/abs/2510.08510)|**[link](https://davidhalladay.github.io/diysink_demo)**|
|**2025-10-09**|**MoA-VR: A Mixture-of-Agents System Towards All-in-One Video Restoration**|Guangtao Zhai Team|[2510.08508](http://arxiv.org/abs/2510.08508)|null|
|**2025-10-09**|**The Visual Iconicity Challenge: Evaluating Vision-Language Models on Sign Language Form-Meaning Mapping**|Esam Ghaleb Team|[2510.08482](http://arxiv.org/abs/2510.08482)|null|
|**2025-10-09**|**Looking to Learn: Token-wise Dynamic Gating for Low-Resource Vision-Language Modelling**|Paula Buttery Team|[2510.08470](http://arxiv.org/abs/2510.08470)|null|
|**2025-10-09**|**VideoVerse: How Far is Your T2V Generator from a World Model?**|Lei Zhang Team|[2510.08398](http://arxiv.org/abs/2510.08398)|null|
|**2025-10-09**|**Evaluating Small Vision-Language Models on Distance-Dependent Traffic Perception**|Ciaran Eising Team|[2510.08352](http://arxiv.org/abs/2510.08352)|null|
|**2025-10-09**|**Chain-of-Trigger: An Agentic Backdoor that Paradoxically Enhances Agentic Robustness**|Hai Zhao Team|[2510.08238](http://arxiv.org/abs/2510.08238)|null|
|**2025-10-09**|**Approximate Domain Unlearning for Vision-Language Models**|Go Irie Team|[2510.08132](http://arxiv.org/abs/2510.08132)|null|
|**2025-10-09**|**CIR-CoT: Towards Interpretable Composed Image Retrieval via End-to-End Chain-of-Thought Reasoning**|Rongrong Ji Team|[2510.08003](http://arxiv.org/abs/2510.08003)|null|
|**2025-10-09**|**Executable Analytic Concepts as the Missing Link Between VLM Insight and Precise Manipulation**|Jianhua Sun Team|[2510.07975](http://arxiv.org/abs/2510.07975)|null|
|**2025-10-09**|**Effective and Stealthy One-Shot Jailbreaks on Deployed Mobile Vision-Language Agents**|Jun Zhu Team|[2510.07809](http://arxiv.org/abs/2510.07809)|null|
|**2025-10-09**|**GTR-Bench: Evaluating Geo-Temporal Reasoning in Vision-Language Models**|Long Zeng Team|[2510.07791](http://arxiv.org/abs/2510.07791)|null|
|**2025-10-09**|**IntentionVLA: Generalizable and Efficient Embodied Intention Reasoning for Human-Robot Interaction**|Liqiang Nie Team|[2510.07778](http://arxiv.org/abs/2510.07778)|null|
|**2025-10-09**|**Multimodal Safety Evaluation in Generative Agent Social Simulations**|Bernard Ghanem Team|[2510.07709](http://arxiv.org/abs/2510.07709)|null|
|**2025-10-09**|**Test-Time Matching: Unlocking Compositional Reasoning in Multimodal Models**|Fuzhi Tang Team|[2510.07632](http://arxiv.org/abs/2510.07632)|null|
|**2025-10-08**|**Cross-Modal Attention Guided Unlearning in Vision-Language Models**|Xintao Wu Team|[2510.07567](http://arxiv.org/abs/2510.07567)|null|
|**2025-10-08**|**Deploying Tiny LVLM Judges for Real-World Evaluation of Chart Models: Lessons Learned and Best Practices**|Jimmy Huang Team|[2510.07545](http://arxiv.org/abs/2510.07545)|null|
|**2025-10-09**|**TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics**|Shanghang Zhang Team|[2510.07181](http://arxiv.org/abs/2510.07181)|null|
|**2025-10-08**|**Few-Shot Adaptation Benchmark for Remote Sensing Vision-Language Models**|Benoit Macq Team|[2510.07135](http://arxiv.org/abs/2510.07135)|null|
|**2025-10-08**|**TALENT: Table VQA via Augmented Language-Enhanced Natural-text Transcription**|Haoyu Wang Team|[2510.07098](http://arxiv.org/abs/2510.07098)|null|
|**2025-10-08**|**Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications**|Yuke Zhu Team|[2510.07077](http://arxiv.org/abs/2510.07077)|**[link](https://vla-survey.github.io)**|
|**2025-10-08**|**Unified Molecule Pre-training with Flexible 2D and 3D Modalities: Single and Paired Modality Integration**|Yuan Fang Team|[2510.07035](http://arxiv.org/abs/2510.07035)|null|
|**2025-10-08**|**Get RICH or Die Scaling: Profitably Trading Inference Compute for Robustness**|Brian Bartoldson Team|[2510.06790](http://arxiv.org/abs/2510.06790)|null|
|**2025-10-08**|**TTRV: Test-Time Reinforcement Learning for Vision Language Models**|M. Jehanzeb Mirza Team|[2510.06783](http://arxiv.org/abs/2510.06783)|null|
|**2025-10-08**|**ToolMem: Enhancing Multimodal Agents with Learnable Tool Capability Memory**|Zora Zhiruo Wang Team|[2510.06664](http://arxiv.org/abs/2510.06664)|null|
|**2025-10-08**|**VUGEN: Visual Understanding priors for GENeration**|Jakob Verbeek Team|[2510.06529](http://arxiv.org/abs/2510.06529)|null|
|**2025-10-07**|**ChainMPQ: Interleaved Text-Image Reasoning Chains for Mitigating Relation Hallucinations**|Yujun Cai Team|[2510.06292](http://arxiv.org/abs/2510.06292)|null|
|**2025-10-06**|**Surgeons Are Indian Males and Speech Therapists Are White Females: Auditing Biases in Vision-Language Models for Healthcare Professionals**|Beenish Moalla Chaudhry Team|[2510.06280](http://arxiv.org/abs/2510.06280)|null|
|**2025-10-07**|**Reasoning under Vision: Understanding Visual-Spatial Cognition in Vision-Language Models for CAPTCHA**|Junfeng Yang Team|[2510.06067](http://arxiv.org/abs/2510.06067)|null|
|**2025-10-07**|**Medical Vision Language Models as Policies for Robotic Surgery**|Martin Radfar Team|[2510.06064](http://arxiv.org/abs/2510.06064)|null|
|**2025-10-07**|**Data Factory with Minimal Human Effort Using VLMs**|Andrew Markham Team|[2510.05722](http://arxiv.org/abs/2510.05722)|null|
|**2025-10-07**|**Activation-Informed Pareto-Guided Low-Rank Compression for Efficient LLM/VLM**|Zheng Zhang Team|[2510.05544](http://arxiv.org/abs/2510.05544)|null|
|**2025-10-06**|**Guided Query Refinement: Multimodal Hybrid Retrieval with Test-Time Optimization**|Ariel Gera Team|[2510.05038](http://arxiv.org/abs/2510.05038)|null|
|**2025-10-06**|**Efficient Navigation in Unknown Indoor Environments with Vision-Language Models**|J. P. How Team|[2510.04991](http://arxiv.org/abs/2510.04991)|null|
|**2025-10-06**|**ViTs: Teaching Machines to See Time Series Anomalies Like Human Experts**|Dan Pei Team|[2510.04710](http://arxiv.org/abs/2510.04710)|null|
|**2025-10-06**|**Conditional Representation Learning for Customized Tasks**|Xi Peng Team|[2510.04564](http://arxiv.org/abs/2510.04564)|null|
|**2025-10-06**|**More Than Meets the Eye? Uncovering the Reasoning-Planning Disconnect in Training Vision-Language Driving Models**|Jun Luo Team|[2510.04532](http://arxiv.org/abs/2510.04532)|null|
|**2025-10-06**|**VaseVQA-3D: Benchmarking 3D VLMs on Ancient Greek Pottery**|Hao Tang Team|[2510.04479](http://arxiv.org/abs/2510.04479)|null|
|**2025-10-06**|**MedCLM: Learning to Localize and Reason via a CoT-Curriculum in Medical Vision-Language Models**|Gyeongyeon Hwang Team|[2510.04477](http://arxiv.org/abs/2510.04477)|null|
|**2025-10-06**|**A.I.R.: Enabling Adaptive, Iterative, and Reasoning-based Frame Selection For Video Question Answering**|Chen Chen Team|[2510.04428](http://arxiv.org/abs/2510.04428)|null|
|**2025-10-06**|**Your Vision-Language Model Can't Even Count to 20: Exposing the Failures of VLMs in Compositional Counting**|Jiahao Zhang Team|[2510.04401](http://arxiv.org/abs/2510.04401)|null|
|**2025-10-05**|**AgentTypo: Adaptive Typographic Prompt Injection Attacks against Black-box Multimodal Agents**|Bin Xiao Team|[2510.04257](http://arxiv.org/abs/2510.04257)|null|
|**2025-10-05**|**ContextVLA: Vision-Language-Action Model with Amortized Multi-Frame Context**|Jinwoo Shin Team|[2510.04246](http://arxiv.org/abs/2510.04246)|**[link](https://huiwon-jang.github.io/contextvla)**|
|**2025-10-05**|**Zoom-In to Sort AI-Generated Images Out**|Jianfu Zhang Team|[2510.04225](http://arxiv.org/abs/2510.04225)|null|
|**2025-10-05**|**Automating construction safety inspections using a multi-modal vision-language RAG framework**|Daniel Dias-da-Costa Team|[2510.04145](http://arxiv.org/abs/2510.04145)|null|
|**2025-10-07**|**AgriGPT-VL: Agricultural Vision-Language Understanding Suite**|Shijian Li Team|[2510.04002](http://arxiv.org/abs/2510.04002)|null|
|**2025-10-04**|**No Tokens Wasted: Leveraging Long Context in Biomedical Vision-Language Models**|Serena Yeung-Levy Team|[2510.03978](http://arxiv.org/abs/2510.03978)|null|
|**2025-10-04**|**Zero-Shot Fine-Grained Image Classification Using Large Vision-Language Models**|Chris Thomas Team|[2510.03903](http://arxiv.org/abs/2510.03903)|null|
|**2025-10-04**|**Bridge Thinking and Acting: Unleashing Physical Potential of VLM with Generalizable Action Expert**|Chunhua Shen Team|[2510.03896](http://arxiv.org/abs/2510.03896)|null|
|**2025-10-04**|**Mirage: Unveiling Hidden Artifacts in Synthetic Images with Large Vision-Language Models**|Durga Toshniwal Team|[2510.03840](http://arxiv.org/abs/2510.03840)|null|
|**2025-10-04**|**Person-Centric Annotations of LAION-400M: Auditing Bias and Its Transfer to Models**|Zeynep Akata Team|[2510.03721](http://arxiv.org/abs/2510.03721)|null|
|**2025-10-04**|**MonitorVLM:A Vision Language Framework for Safety Violation Detection in Mining Operations**|Jingliang Duan Team|[2510.03666](http://arxiv.org/abs/2510.03666)|null|
|**2025-10-03**|**Simulation to Rules: A Dual-VLM Framework for Formal Visual Planning**|Yang Zhang Team|[2510.03182](http://arxiv.org/abs/2510.03182)|null|
|**2025-10-03**|**SpineBench: A Clinically Salient, Level-Aware Benchmark Powered by the SpineMed-450k Corpus**|Caifeng Shan Team|[2510.03160](http://arxiv.org/abs/2510.03160)|null|
|**2025-10-03**|**Multimodal Carotid Risk Stratification with Large Vision-Language Models: Benchmarking, Fine-Tuning, and Clinical Insights**|Konstantina Nikita Team|[2510.02922](http://arxiv.org/abs/2510.02922)|null|
|**2025-10-03**|**Zero-Shot Robustness of Vision Language Models Via Confidence-Aware Weighting**|Mostafa Tavassolipour Team|[2510.02913](http://arxiv.org/abs/2510.02913)|null|
|**2025-10-03**|**Med-K2N: Flexible K-to-N Modality Translation for Medical Image Synthesis**|Xin Gao Team|[2510.02815](http://arxiv.org/abs/2510.02815)|null|
|**2025-10-03**|**MaskCD: Mitigating LVLM Hallucinations by Image Head Masked Contrastive Decoding**|Yujiu Yang Team|[2510.02790](http://arxiv.org/abs/2510.02790)|null|
|**2025-10-03**|**OTR: Synthesizing Overlay Text Dataset for Text Removal**|Kota Yamaguchi Team|[2510.02787](http://arxiv.org/abs/2510.02787)|**[link](https://doi.org/10.1145/3746027.3758297)**|
|**2025-10-03**|**Reasoning Riddles: How Explainability Reveals Cognitive Limits in Vision-Language Models**|Prahitha Movva Team|[2510.02780](http://arxiv.org/abs/2510.02780)|null|
|**2025-10-03**|**AdaRD-key: Adaptive Relevance-Diversity Keyframe Sampling for Long-form Video understanding**|Mohammed Bennamoun Team|[2510.02778](http://arxiv.org/abs/2510.02778)|null|
|**2025-10-03**|**Bayesian Test-time Adaptation for Object Recognition and Detection with Vision-language Models**|Zhen Lei Team|[2510.02750](http://arxiv.org/abs/2510.02750)|null|
|**2025-10-03**|**Team Xiaomi EV-AD VLA: Caption-Guided Retrieval System for Cross-Modal Drone Navigation -- Technical Report for IROS 2025 RoboSense Challenge Track 4**|Xiaoshuai Hao Team|[2510.02728](http://arxiv.org/abs/2510.02728)|null|
|**2025-10-03**|**ARMs: Adaptive Red-Teaming Agent against Multimodal Models with Plug-and-Play Attacks**|Bo Li Team|[2510.02677](http://arxiv.org/abs/2510.02677)|null|
|**2025-10-02**|**Exploring OCR-augmented Generation for Bilingual VQA**|Sunho Park Team|[2510.02543](http://arxiv.org/abs/2510.02543)|null|
|**2025-10-02**|**Multimodal Function Vectors for Spatial Relations**|Hongjing Lu Team|[2510.02528](http://arxiv.org/abs/2510.02528)|null|
|**2025-10-02**|**From Behavioral Performance to Internal Competence: Interpreting Vision-Language Models with VLM-Lens**|Freda Shi Team|[2510.02292](http://arxiv.org/abs/2510.02292)|**[link](https://github.com/compling-wat/vlm-lens)**|
|**2025-10-02**|**microCLIP: Unsupervised CLIP Adaptation via Coarse-Fine Token Fusion for Fine-Grained Image Classification**|Muhammad Haris Khan Team|[2510.02270](http://arxiv.org/abs/2510.02270)|null|
|**2025-10-02**|**Say One Thing, Do Another? Diagnosing Reasoning-Execution Gaps in VLM-Powered Mobile-Use Agents**|Zhuosheng Zhang Team|[2510.02204](http://arxiv.org/abs/2510.02204)|null|
|**2025-10-02**|**GeoPurify: A Data-Efficient Geometric Distillation Framework for Open-Vocabulary 3D Segmentation**|Heng Tao Shen Team|[2510.02186](http://arxiv.org/abs/2510.02186)|null|
|**2025-10-02**|**Unlocking Vision-Language Models for Video Anomaly Detection via Fine-Grained Prompting**|Jing Zhang Team|[2510.02155](http://arxiv.org/abs/2510.02155)|null|
|**2025-10-02**|**Nav-EE: Navigation-Guided Early Exiting for Efficient Vision-Language Models in Autonomous Driving**|Chun Jason Xue Team|[2510.01795](http://arxiv.org/abs/2510.01795)|null|
|**2025-10-02**|**Accelerating Attention with Basis Decomposition**|Jialin Zhao Team|[2510.01718](http://arxiv.org/abs/2510.01718)|null|
|**2025-10-02**|**Contrastive Representation Regularization for Vision-Language-Action Models**|Jinwoo Shin Team|[2510.01711](http://arxiv.org/abs/2510.01711)|null|
|**2025-10-02**|**VaPR -- Vision-language Preference alignment for Reasoning**|Nanyun Peng Team|[2510.01700](http://arxiv.org/abs/2510.01700)|null|
|**2025-10-02**|**Look Less, Reason More: Rollout-Guided Adaptive Pixel-Space Reasoning**|Wentao Zhang Team|[2510.01681](http://arxiv.org/abs/2510.01681)|null|
|**2025-10-02**|**Source-Free Cross-Domain Continual Learning**|Kutluyil Dogancay Team|[2510.01649](http://arxiv.org/abs/2510.01649)|null|
|**2025-10-02**|**FailSafe: Reasoning and Recovery from Failures in Vision-Language-Action Models**|Bihan Wen Team|[2510.01642](http://arxiv.org/abs/2510.01642)|**[link](https://jimntu.github.io/FailSafe/)**|
|**2025-10-02**|**ImageNet-Think-250K: A Large-Scale Synthetic Dataset for Multimodal Reasoning for Vision Language Models**|Murali Emani Team|[2510.01582](http://arxiv.org/abs/2510.01582)|null|
|**2025-10-03**|**Understanding Adversarial Transfer: Why Representation-Space Attacks Fail Where Data-Space Attacks Succeed**|Sanmi Koyejo Team|[2510.01494](http://arxiv.org/abs/2510.01494)|null|
|**2025-10-01**|**VL-KnG: Visual Scene Understanding for Navigation Goal Identification using Spatiotemporal Knowledge Graphs**|Gonzalo Ferrer Team|[2510.01483](http://arxiv.org/abs/2510.01483)|null|
|**2025-10-01**|**Data Selection for Fine-tuning Vision Language Models via Cross Modal Alignment Trajectories**|Baharan Mirzasoleiman Team|[2510.01454](http://arxiv.org/abs/2510.01454)|**[link](https://bigml-cs-ucla.github.io/XMAS-project-page/)**|
|**2025-10-01**|**GeoSURGE: Geo-localization using Semantic Fusion with Hierarchy of Geographic Embeddings**|Rakesh Kumar Team|[2510.01448](http://arxiv.org/abs/2510.01448)|null|
|**2025-10-01**|**VENTURA: Adapting Image Diffusion Models for Unified Task Conditioned Navigation**|Amirreza Shaban Team|[2510.01388](http://arxiv.org/abs/2510.01388)|null|
|**2025-10-01**|**Agentic Jigsaw Interaction Learning for Enhancing Visual Perception and Reasoning in Vision-Language Models**|Feng Zhao Team|[2510.01304](http://arxiv.org/abs/2510.01304)|null|
|**2025-10-01**|**Dirichlet-Prior Shaping: Guiding Expert Specialization in Upcycled MoEs**|Paul Whatmough Team|[2510.01185](http://arxiv.org/abs/2510.01185)|null|
|**2025-09-30**|**MLA: A Multisensory Language-Action Model for Multimodal Understanding and Forecasting in Robotic Manipulation**|Shanghang Zhang Team|[2509.26642](http://arxiv.org/abs/2509.26642)|null|
|**2025-09-30**|**Query-Kontext: An Unified Multimodal Model for Image Generation and Editing**|Jingdong Wang Team|[2509.26641](http://arxiv.org/abs/2509.26641)|null|
|**2025-09-30**|**Clarification as Supervision: Reinforcement Learning for Vision-Language Interfaces**|Ivan Titov Team|[2509.26594](http://arxiv.org/abs/2509.26594)|null|
|**2025-09-30**|**The Invisible Mentor: Inferring User Actions from Screen Recordings to Recommend Better Workflows**|Emerson Murphy-Hill Team|[2509.26557](http://arxiv.org/abs/2509.26557)|null|
|**2025-09-30**|**Stable Cinemetrics : Structured Taxonomy and Evaluation for Professional Video Generation**|Varun Jampani Team|[2509.26555](http://arxiv.org/abs/2509.26555)|**[link](https://stable-cinemetrics.github.io/)**|
|**2025-09-30**|**Zero-Shot Decentralized Federated Learning**|Giovanni Bellitto Team|[2509.26462](http://arxiv.org/abs/2509.26462)|**[link](https://github.com/perceivelab/ZeroDFL)**|
|**2025-09-30**|**SQUARE: Semantic Query-Augmented Fusion and Efficient Batch Reranking for Training-free Zero-Shot Composed Image Retrieval**|Huei-Fang Yang Team|[2509.26330](http://arxiv.org/abs/2509.26330)|null|
|**2025-09-30**|**ProfVLM: A Lightweight Video-Language Model for Multi-View Proficiency Estimation**|Antonio Liotta Team|[2509.26278](http://arxiv.org/abs/2509.26278)|null|
|**2025-09-30**|**Interpret, prune and distill Donut : towards lightweight VLMs for VQA on document**|David Naccache Team|[2509.26235](http://arxiv.org/abs/2509.26235)|null|
|**2025-09-30**|**TSalV360: A Method and Dataset for Text-driven Saliency Detection in 360-Degrees Videos**|Vasileios Mezaris Team|[2509.26208](http://arxiv.org/abs/2509.26208)|**[link](https://ieeexplore.ieee.org/)**|
|**2025-09-30**|**SGS: Segmentation-Guided Scoring for Global Scene Inconsistencies**|Xue Li Team|[2509.26039](http://arxiv.org/abs/2509.26039)|null|
|**2025-10-01**|**AgenticIQA: An Agentic Framework for Adaptive and Interpretable Image Quality Assessment**|Weisi Lin Team|[2509.26006](http://arxiv.org/abs/2509.26006)|null|
|**2025-09-30**|**Learning Egocentric In-Hand Object Segmentation through Weak Supervision from Human Narrations**|Antonino Furnari Team|[2509.26004](http://arxiv.org/abs/2509.26004)|null|
|**2025-09-30**|**Towards Unified Multimodal Misinformation Detection in Social Media: A Benchmark Dataset and Baseline**|Zhun Zhong Team|[2509.25991](http://arxiv.org/abs/2509.25991)|null|
|**2025-09-30**|**NuRisk: A Visual Question Answering Dataset for Agent-Level Risk Assessment in Autonomous Driving**|Johannes Betz Team|[2509.25944](http://arxiv.org/abs/2509.25944)|null|
|**2025-09-30**|**VLM-FO1: Bridging the Gap Between High-Level Reasoning and Fine-Grained Perception in VLMs**|Tiancheng Zhao Team|[2509.25916](http://arxiv.org/abs/2509.25916)|null|
|**2025-10-01**|**LLaVAShield: Safeguarding Multimodal Multi-Turn Dialogues in Vision-Language Models**|Yongjun Shen Team|[2509.25896](http://arxiv.org/abs/2509.25896)|null|
|**2025-09-30**|**DeepSketcher: Internalizing Visual Manipulation for Multimodal Reasoning**|Jing Zhang Team|[2509.25866](http://arxiv.org/abs/2509.25866)|null|
|**2025-09-30**|**MAPLE: Multi-scale Attribute-enhanced Prompt Learning for Few-shot Whole Slide Image Classification**|Daoqiang Zhang Team|[2509.25863](http://arxiv.org/abs/2509.25863)|null|
|**2025-09-30**|**Reinforced Embodied Planning with Verifiable Reward for Real-World Robotic Manipulation**|Hao Chen Team|[2509.25852](http://arxiv.org/abs/2509.25852)|null|
|**2025-09-29**|**TemMed-Bench: Evaluating Temporal Medical Image Reasoning in Vision-Language Models**|Nanyun Peng Team|[2509.25143](http://arxiv.org/abs/2509.25143)|null|
|**2025-09-29**|**Visual serial processing deficits explain divergences in human and VLM reasoning**|Thomas L. Griffiths Team|[2509.25142](http://arxiv.org/abs/2509.25142)|null|
|**2025-09-29**|**GeoVLM-R1: Reinforcement Fine-Tuning for Improved Remote Sensing Reasoning**|Salman Khan Team|[2509.25026](http://arxiv.org/abs/2509.25026)|**[link](https://mustansarfiaz.github.io/GeoVLM-R1/)**|
|**2025-09-29**|**World-Env: Leveraging World Model as a Virtual Environment for VLA Post-Training**|Qing Zhang Team|[2509.24948](http://arxiv.org/abs/2509.24948)|null|
|**2025-09-29**|**From Code to Action: Hierarchical Learning of Diffusion-VLM Policies**|Daniel Dijkman Team|[2509.24917](http://arxiv.org/abs/2509.24917)|null|
|**2025-09-29**|**Training-Free Token Pruning via Zeroth-Order Gradient Estimation in Vision-Language Models**|Sungeun Hong Team|[2509.24837](http://arxiv.org/abs/2509.24837)|null|
|**2025-09-29**|**IA-VLA: Input Augmentation for Vision-Language-Action models in settings with semantically complex tasks**|Ville Kyrki Team|[2509.24768](http://arxiv.org/abs/2509.24768)|null|
|**2025-09-29**|**IWR-Bench: Can LVLMs reconstruct interactive webpage from a user interaction video?**|Botian Shi Team|[2509.24709](http://arxiv.org/abs/2509.24709)|null|
|**2025-09-29**|**Can you SPLICE it together? A Human Curated Benchmark for Probing Visual Reasoning in VLMs**|Elia Bruni Team|[2509.24640](http://arxiv.org/abs/2509.24640)|null|
|**2025-09-30**|**Inducing Dyslexia in Vision Language Models**|Martin Schrimpf Team|[2509.24597](http://arxiv.org/abs/2509.24597)|null|
|**2025-09-29**|**TokenSwap: Backdoor Attack on the Compositional Understanding of Large Vision-Language Models**|Joey Tianyi Zhou Team|[2509.24566](http://arxiv.org/abs/2509.24566)|null|
|**2025-09-29**|**CORE-3D: Context-aware Open-vocabulary Retrieval by Embeddings in 3D**|Matin Mirzababaei Team|[2509.24528](http://arxiv.org/abs/2509.24528)|null|
|**2025-09-29**|**PhysiAgent: An Embodied Agent Framework in Physical World**|Xianyuan Zhan Team|[2509.24524](http://arxiv.org/abs/2509.24524)|null|
|**2025-09-29**|**GRPO-MA: Multi-Answer Generation in GRPO for Stable and Efficient Chain-of-Thought Training**|Hao Dong Team|[2509.24494](http://arxiv.org/abs/2509.24494)|null|
|**2025-09-29**|**Euclid's Gift: Enhancing Spatial Perception and Reasoning in Vision-Language Models via Geometric Surrogate Tasks**|Kai Chen Team|[2509.24473](http://arxiv.org/abs/2509.24473)|null|
|**2025-09-29**|**AXIS: Explainable Time Series Anomaly Detection with Large Language Models**|Chen Zhang Team|[2509.24378](http://arxiv.org/abs/2509.24378)|null|
|**2025-09-29**|**SONAR: Semantic-Object Navigation with Aggregated Reasoning through a Cross-Modal Inference Paradigm**|Jiankun Wang Team|[2509.24321](http://arxiv.org/abs/2509.24321)|null|
|**2025-09-30**|**FrameThinker: Learning to Think with Long Videos via Multi-Turn Frame Spotlighting**|Yu Cheng Team|[2509.24304](http://arxiv.org/abs/2509.24304)|null|
|**2025-09-29**|**ViReSkill: Vision-Grounded Replanning with Skill Memory for LLM-Based Planning in Lifelong Robot Learning**|Yang You Team|[2509.24219](http://arxiv.org/abs/2509.24219)|null|
|**2025-09-29**|**Talk in Pieces, See in Whole: Disentangling and Hierarchical Aggregating Representations for Language-based Object Detection**|Donghyun Kim Team|[2509.24192](http://arxiv.org/abs/2509.24192)|null|
|**2025-09-26**|**See, Point, Fly: A Learning-Free VLM Framework for Universal Unmanned Aerial Navigation**|Yu-Lun Liu Team|[2509.22653](http://arxiv.org/abs/2509.22653)|**[link](https://spf-web.pages.dev)**|
|**2025-09-26**|**CapRL: Stimulating Dense Image Caption Capabilities via Reinforcement Learning**|Dahua Lin Team|[2509.22647](http://arxiv.org/abs/2509.22647)|**[link](https://github.com/InternLM/CapRL)**|
|**2025-09-26**|**Hierarchical Representation Matching for CLIP-based Class-Incremental Learning**|Da-Wei Zhou Team|[2509.22645](http://arxiv.org/abs/2509.22645)|null|
|**2025-09-26**|**WoW: Towards a World omniscient World model Through Embodied Interaction**|Jian Tang Team|[2509.22642](http://arxiv.org/abs/2509.22642)|null|
|**2025-09-26**|**SPARK: Synergistic Policy And Reward Co-Evolving Framework**|Jiaqi Wang Team|[2509.22624](http://arxiv.org/abs/2509.22624)|**[link](https://github.com/InternLM/Spark)**|
|**2025-09-26**|**Color Names in Vision-Language Models**|Javier Vazquez-Corral Team|[2509.22524](http://arxiv.org/abs/2509.22524)|null|
|**2025-09-26**|**Guiding Evolution of Artificial Life Using Vision-Language Models**|Frederico Wieser Team|[2509.22447](http://arxiv.org/abs/2509.22447)|null|
|**2025-09-26**|**Chimera: Diagnosing Shortcut Learning in Visual-Language Understanding**|Mrinmaya Sachan Team|[2509.22437](http://arxiv.org/abs/2509.22437)|**[link](https://github.com/CHIzhP/Chimera))**|
|**2025-09-26**|**RAU: Reference-based Anatomical Understanding with Vision Language Models**|Shanhui Sun Team|[2509.22404](http://arxiv.org/abs/2509.22404)|null|
|**2025-09-26**|**Zero-Effort Image-to-Music Generation: An Interpretable RAG-based VLM Approach**|Zijing Zhou Team|[2509.22378](http://arxiv.org/abs/2509.22378)|null|
|**2025-09-26**|**Rule-Based Reinforcement Learning for Document Image Classification with Vision Language Models**|Andreas Fischer Team|[2509.22283](http://arxiv.org/abs/2509.22283)|**[link](https://github.com/jungomi/vision-finetune)**|
|**2025-09-26**|**Beyond Classification Accuracy: Neural-MedBench and the Need for Deeper Reasoning Benchmarks**|Shangyang Li Team|[2509.22258](http://arxiv.org/abs/2509.22258)|null|
|**2025-09-26**|**A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation**|Cheng Deng Team|[2509.22229](http://arxiv.org/abs/2509.22229)|null|
|**2025-09-26**|**Polysemous Language Gaussian Splatting via Matching-based Mask Lifting**|Ge Li Team|[2509.22225](http://arxiv.org/abs/2509.22225)|null|
|**2025-09-26**|**Towards Faithful Reasoning in Remote Sensing: A Perceptually-Grounded GeoSpatial Chain-of-Thought for Vision-Language Models**|Bo Yang Team|[2509.22221](http://arxiv.org/abs/2509.22221)|null|
|**2025-09-26**|**Actions as Language: Fine-Tuning VLMs into VLAs Without Catastrophic Forgetting**|Anirudha Majumdar Team|[2509.22195](http://arxiv.org/abs/2509.22195)|null|
|**2025-09-26**|**MinerU2.5: A Decoupled Vision-Language Model for Efficient High-Resolution Document Parsing**|Conghui He Team|[2509.22186](http://arxiv.org/abs/2509.22186)|**[link](https://github.com/opendatalab/MinerU)**|
|**2025-09-26**|**Multilingual Vision-Language Models, A Survey**|Jindřich Libovický Team|[2509.22123](http://arxiv.org/abs/2509.22123)|null|
|**2025-09-26**|**Lightweight Structured Multimodal Reasoning for Clinical Scene Understanding in Robotics**|Stefan K. Ehrlich Team|[2509.22014](http://arxiv.org/abs/2509.22014)|null|
|**2025-09-26**|**CoFFT: Chain of Foresight-Focus Thought for Visual Language Models**|Mike Zheng Shou Team|[2509.22010](http://arxiv.org/abs/2509.22010)|null|
|**2025-09-25**|**Nova: Real-Time Agentic Vision-Language Model Serving with Adaptive Cross-Stage Parallelization**|Guihai Chen Team|[2509.21301](http://arxiv.org/abs/2509.21301)|null|
|**2025-09-25**|**DisCoCLIP: A Distributional Compositional Tensor Network Encoder for Vision-Language Understanding**|Mehrnoosh Sadrzadeh Team|[2509.21287](http://arxiv.org/abs/2509.21287)|null|
|**2025-09-25**|**Un-Doubling Diffusion: LLM-guided Disambiguation of Homonym Duplication**|Alexander Nagaev Team|[2509.21262](http://arxiv.org/abs/2509.21262)|null|
|**2025-09-25**|**Hallucination as an Upper Bound: A New Perspective on Text-to-Image Evaluation**|Mohammad Hossein Rohban Team|[2509.21257](http://arxiv.org/abs/2509.21257)|null|
|**2025-09-25**|**Learning to Look: Cognitive Attention Alignment with Vision-Language Models**|Nidhi Rastogi Team|[2509.21247](http://arxiv.org/abs/2509.21247)|null|
|**2025-09-25**|**TABLET: A Large-Scale Dataset for Robust Visual Table Understanding**|Mirella Lapata Team|[2509.21205](http://arxiv.org/abs/2509.21205)|null|
|**2025-09-25**|**Human-like Navigation in a World Built for Humans**|Shenlong Wang Team|[2509.21189](http://arxiv.org/abs/2509.21189)|**[link](https://reasonnav.github.io/)**|
|**2025-09-25**|**Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy**|Chokri Mraidha Team|[2509.21173](http://arxiv.org/abs/2509.21173)|null|
|**2025-09-25**|**Teaching RL Agents to Act Better: VLM as Action Advisor for Online Reinforcement Learning**|Mingyu Hu Team|[2509.21126](http://arxiv.org/abs/2509.21126)|null|
|**2025-09-25**|**Cross-Modal Instructions for Robot Motion Generation**|Weiming Zhi Team|[2509.21107](http://arxiv.org/abs/2509.21107)|null|
|**2025-09-25**|**Mammo-CLIP Dissect: A Framework for Analysing Mammography Concepts in Vision-Language Models**|Robert Jenssen Team|[2509.21102](http://arxiv.org/abs/2509.21102)|null|
|**2025-09-25**|**SoM-1K: A Thousand-Problem Benchmark Dataset for Strength of Materials**|Lu Cheng Team|[2509.21079](http://arxiv.org/abs/2509.21079)|null|
|**2025-09-25**|**Unlocking Financial Insights: An advanced Multimodal Summarization with Multimodal Output Framework for Financial Advisory Videos**|Alka Maurya Team|[2509.20961](http://arxiv.org/abs/2509.20961)|null|
|**2025-09-25**|**Decoding the Surgical Scene: A Scoping Review of Scene Graphs in Surgery**|M. Ali Nasseri Team|[2509.20941](http://arxiv.org/abs/2509.20941)|null|
|**2025-09-25**|**MTRDrive: Memory-Tool Synergistic Reasoning for Robust Autonomous Driving in Corner Cases**|Diange Yang Team|[2509.20843](http://arxiv.org/abs/2509.20843)|null|
|**2025-09-25**|**DAC-LoRA: Dynamic Adversarial Curriculum for Efficient and Robust Few-Shot Adaptation**|Ved Umrajkar Team|[2509.20792](http://arxiv.org/abs/2509.20792)|null|
|**2025-09-25**|**Provenance Analysis of Archaeological Artifacts via Multimodal RAG Systems**|Ruiliang Liu Team|[2509.20769](http://arxiv.org/abs/2509.20769)|null|
|**2025-09-25**|**Seeing Through Words, Speaking Through Pixels: Deep Representational Alignment Between Vision and Language Models**|Meenakshi Khosla Team|[2509.20751](http://arxiv.org/abs/2509.20751)|null|
|**2025-09-25**|**Recov-Vision: Linking Street View Imagery and Vision-Language Models for Post-Disaster Recovery**|Ali Mostafavi Team|[2509.20628](http://arxiv.org/abs/2509.20628)|null|
|**2025-09-24**|**InstructVTON: Optimal Auto-Masking and Natural-Language-Guided Interactive Style Control for Inpainting-Based Virtual Try-On**|Karim Bouyarmane Team|[2509.20524](http://arxiv.org/abs/2509.20524)|null|
|**2025-09-24**|**A co-evolving agentic AI system for medical imaging analysis**|Zhi Huang Team|[2509.20279](http://arxiv.org/abs/2509.20279)|null|
|**2025-09-24**|**Universal Camouflage Attack on Vision-Language Models for Autonomous Driving**|Wenqi Ren Team|[2509.20196](http://arxiv.org/abs/2509.20196)|null|
|**2025-09-24**|**EchoBench: Benchmarking Sycophancy in Medical Large Vision-Language Models**|Dacheng Tao Team|[2509.20146](http://arxiv.org/abs/2509.20146)|null|
|**2025-09-24**|**A Simple Data Augmentation Strategy for Text-in-Image Scientific VQA**|Yova Kementchedjhieva Team|[2509.20119](http://arxiv.org/abs/2509.20119)|null|
|**2025-09-24**|**Discrete Diffusion for Reflective Vision-Language-Action Models in Autonomous Driving**|Xianpeng Lang Team|[2509.20109](http://arxiv.org/abs/2509.20109)|null|
|**2025-09-24**|**Queryable 3D Scene Representation: A Multi-Modal Framework for Semantic Reasoning and Robotic Task Planning**|Jiajun Liu Team|[2509.20077](http://arxiv.org/abs/2509.20077)|null|
|**2025-09-25**|**OmniScene: Attention-Augmented Multimodal 4D Scene Understanding for Autonomous Driving**|Jun Ma Team|[2509.19973](http://arxiv.org/abs/2509.19973)|null|
|**2025-09-24**|**Generalist Robot Manipulation beyond Action Labeled Data**|Danda Pani Paudel Team|[2509.19958](http://arxiv.org/abs/2509.19958)|null|
|**2025-09-24**|**Benchmarking Gaslighting Attacks Against Speech Large Language Models**|Pan Zhou Team|[2509.19858](http://arxiv.org/abs/2509.19858)|null|
|**2025-09-24**|**CHURRO: Making History Readable with an Open-Weight Large Vision-Language Model for High-Accuracy, Low-Cost Historical Text Recognition**|Monica S. Lam Team|[2509.19768](http://arxiv.org/abs/2509.19768)|null|
|**2025-09-24**|**Logics-Parsing Technical Report**|Minggang Wu Team|[2509.19760](http://arxiv.org/abs/2509.19760)|null|
|**2025-09-24**|**Formal Safety Verification and Refinement for Generative Motion Planners via Certified Local Stabilization**|Glen Chou Team|[2509.19688](http://arxiv.org/abs/2509.19688)|null|
|**2025-09-24**|**Bias in the Picture: Benchmarking VLMs with Social-Cue News Images and LLM-as-Judge Assessment**|Shaina Raza Team|[2509.19659](http://arxiv.org/abs/2509.19659)|null|
|**2025-09-23**|**Anatomy of a Feeling: Narrating Embodied Emotions via Large Vision-Language Models**|Tianyu Jiang Team|[2509.19595](http://arxiv.org/abs/2509.19595)|null|
|**2025-09-23**|**iFinder: Structured Zero-Shot Vision-Based LLM Grounding for Dash-Cam Video Reasoning**|Abhishek Aich Team|[2509.19552](http://arxiv.org/abs/2509.19552)|null|
|**2025-09-23**|**Score the Steps, Not Just the Goal: VLM-Based Subgoal Evaluation for Robotic Manipulation**|Chi-Guhn Lee Team|[2509.19524](http://arxiv.org/abs/2509.19524)|null|
|**2025-09-23**|**DRISHTIKON: A Multimodal Multilingual Benchmark for Testing Language Models' Understanding on Indian Culture**|Sriparna Saha Team|[2509.19274](http://arxiv.org/abs/2509.19274)|null|
|**2025-09-23**|**Long Story Short: Disentangling Compositionality and Long-Caption Understanding in VLMs**|Yova Kementchedjhieva Team|[2509.19207](http://arxiv.org/abs/2509.19207)|null|
|**2025-09-23**|**Vision-Free Retrieval: Rethinking Multimodal Search with Textual Scene Descriptions**|Georgios Tzimiropoulos Team|[2509.19203](http://arxiv.org/abs/2509.19203)|null|
|**2025-09-23**|**Reading Images Like Texts: Sequential Image Understanding in Vision-Language Models**|Xiaojie Wang Team|[2509.19191](http://arxiv.org/abs/2509.19191)|null|
|**2025-09-23**|**FUNCanon: Learning Pose-Aware Action Primitives via Functional Object Canonicalization for Generalizable Robotic Manipulation**|Jianwei Zhang Team|[2509.19102](http://arxiv.org/abs/2509.19102)|**[link](https://sites.google.com/view/funcanon)**|
|**2025-09-23**|**ColorBlindnessEval: Can Vision-Language Models Pass Color Blindness Tests?**|Jiahao Cui Team|[2509.19070](http://arxiv.org/abs/2509.19070)|null|
|**2025-09-23**|**Pure Vision Language Action (VLA) Models: A Comprehensive Survey**|Qingguo Zhou Team|[2509.19012](http://arxiv.org/abs/2509.19012)|null|
|**2025-09-23**|**Unveiling Chain of Step Reasoning for Vision-Language Models with Fine-grained Rewards**|Xinlong Wang Team|[2509.19003](http://arxiv.org/abs/2509.19003)|null|
|**2025-09-23**|**No Labels Needed: Zero-Shot Image Classification with Collaborative Self-Learning**|Joel Luís Carbonera Team|[2509.18938](http://arxiv.org/abs/2509.18938)|null|
|**2025-09-23**|**How Far are VLMs from Visual Spatial Intelligence? A Benchmark-Driven Perspective**|Huchuan Lu Team|[2509.18905](http://arxiv.org/abs/2509.18905)|null|
|**2025-09-23**|**Benchmarking Vision-Language and Multimodal Large Language Models in Zero-shot and Few-shot Scenarios: A study on Christian Iconography**|Giovanni Colavizza Team|[2509.18839](http://arxiv.org/abs/2509.18839)|null|
|**2025-09-23**|**Bi-VLM: Pushing Ultra-Low Precision Post-Training Quantization Boundaries in Vision-Language Models**|Dinesh Manocha Team|[2509.18763](http://arxiv.org/abs/2509.18763)|null|
|**2025-09-23**|**Knowledge Transfer from Interaction Learning**|Shugong Xu Team|[2509.18733](http://arxiv.org/abs/2509.18733)|null|
|**2025-09-23**|**What Makes You Unique? Attribute Prompt Composition for Object Re-Identification**|Huchuan Lu Team|[2509.18715](http://arxiv.org/abs/2509.18715)|null|
|**2025-09-23**|**RSVG-ZeroOV: Exploring a Training-Free Framework for Zero-Shot Open-Vocabulary Visual Grounding in Remote Sensing Images**|Quan Wang Team|[2509.18711](http://arxiv.org/abs/2509.18711)|null|
|**2025-09-23**|**NaviSense: A Multimodal Assistive Mobile application for Object Retrieval by Persons with Visual Impairment**|Vijaykrishnan Narayanan Team|[2509.18672](http://arxiv.org/abs/2509.18672)|null|
|**2025-09-23**|**Learning neuroimaging models from health system-scale data**|Todd Hollon Team|[2509.18638](http://arxiv.org/abs/2509.18638)|null|
|**2025-09-23**|**SINGER: An Onboard Generalist Vision-Language Navigation Policy for Drones**|Mac Schwager Team|[2509.18610](http://arxiv.org/abs/2509.18610)|null|
|**2025-09-23**|**VLN-Zero: Rapid Exploration and Cache-Enabled Neurosymbolic Vision-Language Planning for Zero-Shot Transfer in Robot Navigation**|Ufuk Topcu Team|[2509.18592](http://arxiv.org/abs/2509.18592)|**[link](https://vln-zero.github.io/)**|
|**2025-09-22**|**Losing the Plot: How VLM responses degrade on imperfect charts**|Mahantesh Halappanavar Team|[2509.18425](http://arxiv.org/abs/2509.18425)|null|
|**2025-09-22**|**NeuS-QA: Grounding Long-Form Video Understanding in Temporal Logic and Neuro-Symbolic Reasoning**|Sandeep Chinchali Team|[2509.18041](http://arxiv.org/abs/2509.18041)|null|
|**2025-09-22**|**Robust and Resilient Soft Robotic Object Insertion with Compliance-Enabled Contact Formation and Failure Recovery**|Yoshitaka Ushiku Team|[2509.17666](http://arxiv.org/abs/2509.17666)|null|
|**2025-09-22**|**SD-VLM: Spatial Measuring and Understanding with Depth-Encoded Vision-Language Models**|Jieping Ye Team|[2509.17664](http://arxiv.org/abs/2509.17664)|null|
|**2025-09-22**|**From Benchmarks to Reality: Advancing Visual Anomaly Detection by the VAND 3.0 Challenge**|Paula Ramos Team|[2509.17615](http://arxiv.org/abs/2509.17615)|null|
|**2025-09-22**|**COLA: Context-aware Language-driven Test-time Adaptation**|Zhihe Lu Team|[2509.17598](http://arxiv.org/abs/2509.17598)|null|
|**2025-09-22**|**Interpreting Attention Heads for Image-to-Text Information Flow in Large Vision-Language Models**|Seong Jae Hwang Team|[2509.17588](http://arxiv.org/abs/2509.17588)|null|
|**2025-09-23**|**Visual Instruction Pretraining for Domain-Specific Foundation Models**|Jian Yang Team|[2509.17562](http://arxiv.org/abs/2509.17562)|null|
|**2025-09-22**|**ChartHal: A Fine-grained Framework Evaluating Hallucination of Large Vision Language Models in Chart Understanding**|Xiaoyu Qin Team|[2509.17481](http://arxiv.org/abs/2509.17481)|null|
|**2025-09-22**|**Training-Free Label Space Alignment for Universal Domain Adaptation**|Donghyun Kim Team|[2509.17452](http://arxiv.org/abs/2509.17452)|null|
|**2025-09-23**|**Multi-scale Temporal Prediction via Incremental Generation and Multi-agent Collaboration**|Yueming Jin Team|[2509.17429](http://arxiv.org/abs/2509.17429)|null|
|**2025-09-22**|**Vision Language Models Are Not (Yet) Spelling Correctors**|Bojun Zhang Team|[2509.17418](http://arxiv.org/abs/2509.17418)|null|
|**2025-09-22**|**Mano Report**|Shuo Wang Team|[2509.17336](http://arxiv.org/abs/2509.17336)|null|
|**2025-09-22**|**UIPro: Unleashing Superior Interaction Capability For GUI Agents**|Zhaoxiang Zhang Team|[2509.17328](http://arxiv.org/abs/2509.17328)|null|
|**2025-09-22**|**OpenGVL - Benchmarking Visual Temporal Progress for Data Curation**|Krzysztof Walas Team|[2509.17321](http://arxiv.org/abs/2509.17321)|null|
|**2025-09-21**|**FlagEval Findings Report: A Preliminary Evaluation of Large Reasoning Models on Automatically Verifiable Textual and Visual Questions**|Zhongyuan Wang Team|[2509.17177](http://arxiv.org/abs/2509.17177)|null|
|**2025-09-21**|**MoCLIP-Lite: Efficient Video Recognition by Fusing CLIP with Motion Vectors**|Soumyabrata Dev Team|[2509.17084](http://arxiv.org/abs/2509.17084)|null|
|**2025-09-21**|**CardiacCLIP: Video-based CLIP Adaptation for LVEF Prediction in a Few-shot Manner**|Xiaomeng Li Team|[2509.17065](http://arxiv.org/abs/2509.17065)|null|
|**2025-09-21**|**AgriDoctor: A Multimodal Intelligent Assistant for Agriculture**|Liang Wang Team|[2509.17044](http://arxiv.org/abs/2509.17044)|null|
|**2025-09-21**|**Orchestrate, Generate, Reflect: A VLM-Based Multi-Agent Collaboration Framework for Automated Driving Policy Learning**|Jun Ma Team|[2509.17042](http://arxiv.org/abs/2509.17042)|null|
|**2025-09-21**|**When Color-Space Decoupling Meets Diffusion for Adverse-Weather Image Restoration**|Jun Li Team|[2509.17024](http://arxiv.org/abs/2509.17024)|null|
|**2025-09-19**|**Robust Vision-Language Models via Tensor Decomposition: A Defense Against Adversarial Attacks**|Evangelos E. Papalexakis Team|[2509.16163](http://arxiv.org/abs/2509.16163)|null|
|**2025-09-19**|**Randomized Smoothing Meets Vision-Language Models**|Chih-Hong Cheng Team|[2509.16088](http://arxiv.org/abs/2509.16088)|null|
|**2025-09-19**|**I-FailSense: Towards General Robotic Failure Detection with Vision-Language Models**|Mohamed Chetouani Team|[2509.16072](http://arxiv.org/abs/2509.16072)|null|
|**2025-09-19**|**Compose by Focus: Scene Graph-based Atomic Skills**|Heng Yang Team|[2509.16053](http://arxiv.org/abs/2509.16053)|null|
|**2025-09-19**|**CIDER: A Causal Cure for Brand-Obsessed Text-to-Image Models**|Wushao Wen Team|[2509.15803](http://arxiv.org/abs/2509.15803)|null|
|**2025-09-19**|**Vision-Language Models as Differentiable Semantic and Spatial Rewards for Text-to-3D Generation**|He Sun Team|[2509.15772](http://arxiv.org/abs/2509.15772)|null|
|**2025-09-19**|**GUI-ReWalk: Massive Data Generation for GUI Agent via Stochastic Exploration and Intent-Aware Reasoning**|Zhaojian Li Team|[2509.15738](http://arxiv.org/abs/2509.15738)|null|
|**2025-09-19**|**Training-Free Pyramid Token Pruning for Efficient Large Vision-Language Models via Region, Token, and Instruction-Guided Importance**|Xiangyang Xue Team|[2509.15704](http://arxiv.org/abs/2509.15704)|null|
|**2025-09-19**|**ORIC: Benchmarking Object Recognition in Incongruous Context for Large Vision-Language Models**|Hao Su Team|[2509.15695](http://arxiv.org/abs/2509.15695)|null|
|**2025-09-19**|**SightSound-R1: Cross-Modal Reasoning Distillation from Vision to Audio Language Models**|Nima Mesgarani Team|[2509.15661](http://arxiv.org/abs/2509.15661)|null|
|**2025-09-19**|**PRIMT: Preference-based Reinforcement Learning with Multimodal Feedback and Trajectory Synthesis from Foundation Models**|Byung-Cheol Min Team|[2509.15607](http://arxiv.org/abs/2509.15607)|null|
|**2025-09-18**|**SmolRGPT: Efficient Spatial Reasoning for Warehouse Environments with 600M Parameters**|Andy Couturier Team|[2509.15490](http://arxiv.org/abs/2509.15490)|null|
|**2025-09-18**|**Comparing Computational Pathology Foundation Models using Representational Similarity Analysis**|William Lotter Team|[2509.15482](http://arxiv.org/abs/2509.15482)|null|
|**2025-09-18**|**ORCA: Agentic Reasoning For Hallucination and Adversarial Robustness in Vision-Language Models**|Nathaniel D. Bastian Team|[2509.15435](http://arxiv.org/abs/2509.15435)|null|
|**2025-09-18**|**SERVAL: Surprisingly Effective Zero-Shot Visual Document Retrieval Powered by Large Vision and Language Models**|Andrew Yates Team|[2509.15432](http://arxiv.org/abs/2509.15432)|null|
|**2025-09-18**|**CoDoL: Conditional Domain Prompt Learning for Out-of-Distribution Generalization**|Xin Lin Team|[2509.15330](http://arxiv.org/abs/2509.15330)|null|
|**2025-09-18**|**Calibration-Aware Prompt Learning for Medical Vision-Language Models**|Muhammad Haris Khan Team|[2509.15226](http://arxiv.org/abs/2509.15226)|null|
|**2025-09-19**|**ScaleCUA: Scaling Open-Source Computer Use Agents with Cross-Platform Data**|Wenhai Wang Team|[2509.15221](http://arxiv.org/abs/2509.15221)|null|
|**2025-09-18**|**What's the Best Way to Retrieve Slides? A Comparative Study of Multimodal, Caption-Based, and Hybrid Retrieval Techniques**|Grigorios Tsoumakas Team|[2509.15211](http://arxiv.org/abs/2509.15211)|null|
|**2025-09-18**|**MedFact-R1: Towards Factual Medical Reasoning via Pseudo-Label Augmentation**|Guodong Ding Team|[2509.15154](http://arxiv.org/abs/2509.15154)|null|
|**2025-09-18**|**Forecasting and Visualizing Air Quality from Sky Images with Vision-Language Models**|Yanqing Zhang Team|[2509.15076](http://arxiv.org/abs/2509.15076)|null|
|**2025-09-18**|**QuizRank: Picking Images by Quizzing VLMs**|Eytan Adar Team|[2509.15059](http://arxiv.org/abs/2509.15059)|null|
|**2025-09-18**|**PRISM: Product Retrieval In Shopping Carts using Hybrid Matching**|Jiajing Chen Team|[2509.14985](http://arxiv.org/abs/2509.14985)|null|
|**2025-09-18**|**EchoVLM: Dynamic Mixture-of-Experts Vision-Language Model for Universal Ultrasound Intelligence**|Qinghua Huang Team|[2509.14977](http://arxiv.org/abs/2509.14977)|null|
|**2025-09-19**|**Affordance-Based Disambiguation of Surgical Instructions for Collaborative Robot-Assisted Surgery**|Yasuhisa Hasegawa Team|[2509.14967](http://arxiv.org/abs/2509.14967)|null|
|**2025-09-18**|**MARIC: Multi-Agent Reasoning for Image Classification**|Seunghyun Lee Team|[2509.14860](http://arxiv.org/abs/2509.14860)|null|
|**2025-09-18**|**V-SEAM: Visual Semantic Editing and Attention Modulating for Causal Interpretability of Vision-Language Models**|Ming Jiang Team|[2509.14837](http://arxiv.org/abs/2509.14837)|null|
|**2025-09-18**|**Frame Sampling Strategies Matter: A Benchmark for small vision language models**|Mounim A. El Yacoubi Team|[2509.14769](http://arxiv.org/abs/2509.14769)|null|
|**2025-09-18**|**Do Vision-Language Models See Urban Scenes as People Do? An Urban Perception Benchmark**|Rashid Mushkani Team|[2509.14574](http://arxiv.org/abs/2509.14574)|null|
|**2025-09-18**|**VisMoDAl: Visual Analytics for Evaluating and Improving Corruption Robustness of Vision-Language Models**|Yuxin Ma Team|[2509.14571](http://arxiv.org/abs/2509.14571)|null|
|**2025-09-17**|**CRAFT: Coaching Reinforcement Learning Autonomously using Foundation Models for Multi-Robot Coordination Tasks**|Negar Mehr Team|[2509.14380](http://arxiv.org/abs/2509.14380)|null|
|**2025-09-17**|**Cinéaste: A Fine-grained Contextual Movie Question Answering Benchmark**|Vishal M. Patel Team|[2509.14227](http://arxiv.org/abs/2509.14227)|null|
|**2025-09-19**|**TGPO: Tree-Guided Preference Optimization for Robust Web Agent Reinforcement Learning**|Guitao Cao Team|[2509.14172](http://arxiv.org/abs/2509.14172)|null|
|**2025-09-17**|**VSE-MOT: Multi-Object Tracking in Low-Quality Video Scenes Guided by Visual Semantic Enhancement**|Fei Richard Yu Team|[2509.14060](http://arxiv.org/abs/2509.14060)|null|
|**2025-09-17**|**Can Current AI Models Count What We Mean, Not What They See? A Benchmark and Systematic Evaluation**|Minh Hoai Team|[2509.13939](http://arxiv.org/abs/2509.13939)|null|
|**2025-09-17**|**Towards Rationale-Answer Alignment of LVLMs via Self-Rationale Calibration**|Xiaoqiang Li Team|[2509.13919](http://arxiv.org/abs/2509.13919)|null|
|**2025-09-17**|**EDITS: Enhancing Dataset Distillation with Implicit Textual Semantics**|Jielei Wang Team|[2509.13858](http://arxiv.org/abs/2509.13858)|null|
|**2025-09-17**|**Diving into Mitigating Hallucinations from a Vision Perspective for Large Vision-Language Models**|Longwen Gao Team|[2509.13836](http://arxiv.org/abs/2509.13836)|null|
|**2025-09-17**|**Iterative Prompt Refinement for Safer Text-to-Image Generation**|Byung-Jun Lee Team|[2509.13760](http://arxiv.org/abs/2509.13760)|null|
|**2025-09-17**|**Reinforcement Learning for Robotic Insertion of Flexible Cables in Industrial Settings**|Changjoo Nam Team|[2509.13731](http://arxiv.org/abs/2509.13731)|null|
|**2025-09-17**|**DREAM: Domain-aware Reasoning for Efficient Autonomous Underwater Monitoring**|Xiaomin Lin Team|[2509.13666](http://arxiv.org/abs/2509.13666)|null|
|**2025-09-16**|**Intelligent Healthcare Imaging Platform An VLM-Based Framework for Automated Medical Image Analysis and Clinical Report Generation**|Samer Al-Hamadani Team|[2509.13590](http://arxiv.org/abs/2509.13590)|null|
|**2025-09-16**|**Using Visual Language Models to Control Bionic Hands: Assessment of Object Perception and Grasp Inference**|Cedomir Stefanovic Team|[2509.13572](http://arxiv.org/abs/2509.13572)|null|
|**2025-09-16**|**EdiVal-Agent: An Object-Centric Framework for Automated, Scalable, Fine-Grained Evaluation of Multi-Turn Editing**|Mingyuan Zhou Team|[2509.13399](http://arxiv.org/abs/2509.13399)|null|
|**2025-09-16**|**3D Aware Region Prompted Vision Language Model**|Sifei Liu Team|[2509.13317](http://arxiv.org/abs/2509.13317)|**[link](https://www.anjiecheng.me/sr3d)**|
|**2025-09-16**|**Image Realness Assessment and Localization with Multimodal Features**|Somdyuti Paul Team|[2509.13289](http://arxiv.org/abs/2509.13289)|null|
|**2025-09-16**|**ChartGaze: Enhancing Chart Understanding in LVLMs with Eye-Tracking Guided Attention Refinement**|Giuseppe Carenini Team|[2509.13282](http://arxiv.org/abs/2509.13282)|null|
|**2025-09-16**|**RadGame: An AI-Powered Platform for Radiology Education**|Pranav Rajpurkar Team|[2509.13270](http://arxiv.org/abs/2509.13270)|null|
|**2025-09-16**|**HERO: Rethinking Visual Token Early Dropping in High-Resolution Large Vision-Language Models**|Xiangyang Xue Team|[2509.13067](http://arxiv.org/abs/2509.13067)|null|
|**2025-09-16**|**Perception Before Reasoning: Two-Stage Reinforcement Learning for Visual Reasoning in Vision-Language Models**|Jingdong Wang Team|[2509.13031](http://arxiv.org/abs/2509.13031)|null|
|**2025-09-16**|**Cross-Layer Vision Smoothing: Enhancing Visual Understanding via Sustained Focus on Key Objects in Large Vision-Language Models**|Chong Feng Team|[2509.12897](http://arxiv.org/abs/2509.12897)|null|
|**2025-09-16**|**Benchmarking and Improving LVLMs on Event Extraction from Multimedia Documents**|Haiyang Zhang Team|[2509.12876](http://arxiv.org/abs/2509.12876)|null|
|**2025-09-16**|**Defense-to-Attack: Bypassing Weak Defenses Enables Stronger Jailbreaks in Vision-Language Models**|Xingjun Ma Team|[2509.12724](http://arxiv.org/abs/2509.12724)|null|
|**2025-09-16**|**AsyMoE: Leveraging Modal Asymmetry for Enhanced Expert Specialization in Large Vision-Language Models**|Jin Huang Team|[2509.12715](http://arxiv.org/abs/2509.12715)|null|
|**2025-09-15**|**Evaluating Robustness of Vision-Language Models Under Noisy Conditions**|Alireza Team|[2509.12492](http://arxiv.org/abs/2509.12492)|null|
|**2025-09-15**|**An integrated process for design and control of lunar robotics using AI and simulation**|Martin Servin Team|[2509.12367](http://arxiv.org/abs/2509.12367)|null|
|**2025-09-15**|**Open-ended Hierarchical Streaming Video Understanding with Vision Language Models**|Seon Joo Kim Team|[2509.12145](http://arxiv.org/abs/2509.12145)|null|
|**2025-09-15**|**Look Again, Think Slowly: Enhancing Visual Reflection in Vision-Language Models**|Jiajun Zhang Team|[2509.12132](http://arxiv.org/abs/2509.12132)|null|
|**2025-09-16**|**Embodied Navigation Foundation Model**|He Wang Team|[2509.12129](http://arxiv.org/abs/2509.12129)|**[link](https://pku-epic.github.io/NavFoM-Web/)**|
|**2025-09-15**|**Lost in Embeddings: Information Loss in Vision-Language Models**|Anders Søgaard Team|[2509.11986](http://arxiv.org/abs/2509.11986)|null|
|**2025-09-15**|**Spec-LLaVA: Accelerating Vision-Language Models with Dynamic Tree-Based Speculative Decoding**|Yijun Chen Team|[2509.11961](http://arxiv.org/abs/2509.11961)|null|
|**2025-09-15**|**Bridging Vision Language Models and Symbolic Grounding for Video Question Answering**|Daisy Zhe Wang Team|[2509.11862](http://arxiv.org/abs/2509.11862)|null|
|**2025-09-15**|**Synthetic Captions for Open-Vocabulary Zero-Shot Segmentation**|Michael Louis Iuzzolino Team|[2509.11840](http://arxiv.org/abs/2509.11840)|null|
|**2025-09-15**|**SpecVLM: Fast Speculative Decoding in Vision-Language Models**|Emad Barsoum Team|[2509.11815](http://arxiv.org/abs/2509.11815)|null|
|**2025-09-15**|**Igniting VLMs toward the Embodied Space**|Zach Xu Team|[2509.11766](http://arxiv.org/abs/2509.11766)|null|
|**2025-09-15**|**EMeRALDS: Electronic Medical Record Driven Automated Lung Nodule Detection and Classification in Thoracic CT Images**|Syed Muhammad Anwar Team|[2509.11714](http://arxiv.org/abs/2509.11714)|null|
|**2025-09-15**|**How Auxiliary Reasoning Unleashes GUI Grounding in VLMs**|Manni Duan Team|[2509.11548](http://arxiv.org/abs/2509.11548)|null|
|**2025-09-15**|**LVLMs are Bad at Overhearing Human Referential Communication**|Susan E. Brennan Team|[2509.11514](http://arxiv.org/abs/2509.11514)|null|
|**2025-09-14**|**CEMTM: Contextual Embedding-based Multimodal Topic Modeling**|Giuseppe Carenini Team|[2509.11465](http://arxiv.org/abs/2509.11465)|null|
|**2025-09-14**|**Enhancing Generalization in Vision-Language-Action Models by Preserving Pretrained Representations**|Xuanlin Li Team|[2509.11417](http://arxiv.org/abs/2509.11417)|**[link](https://gen-vla.github.io/)**|
|**2025-09-14**|**ActivePose: Active 6D Object Pose Estimation and Tracking for Robotic Manipulation**|Yizhao Wang Team|[2509.11364](http://arxiv.org/abs/2509.11364)|null|
|**2025-09-14**|**Mitigating Hallucinations in Large Vision-Language Models by Self-Injecting Hallucinations**|Weiming Hu Team|[2509.11287](http://arxiv.org/abs/2509.11287)|null|
|**2025-09-14**|**The System Description of CPS Team for Track on Driving with Language of CVPR 2024 Autonomous Grand Challenge**|Dehui Du Team|[2509.11071](http://arxiv.org/abs/2509.11071)|null|
|**2025-09-14**|**ViScratch: Using Large Language Models and Gameplay Videos for Automated Feedback in Scratch**|Jialu Zhang Team|[2509.11065](http://arxiv.org/abs/2509.11065)|null|
|**2025-09-13**|**Language-based Color ISP Tuning**|Jiro Takatori Team|[2509.10765](http://arxiv.org/abs/2509.10765)|null|
|**2025-09-12**|**TASC: Task-Aware Shared Control for Teleoperated Manipulation**|Renaud Detry Team|[2509.10416](http://arxiv.org/abs/2509.10416)|null|
|**2025-09-12**|**Towards Understanding Visual Grounding in Visual Language Models**|Eda B. Özyiğit Team|[2509.10345](http://arxiv.org/abs/2509.10345)|null|
|**2025-09-12**|**Detecting Text Manipulation in Images using Vision Language Models**|Sébastien Marcel Team|[2509.10278](http://arxiv.org/abs/2509.10278)|**[link](https://www.idiap.ch/paper/textvlmdet/)**|
|**2025-09-12**|**MagicMirror: A Large-Scale Dataset and Benchmark for Fine-Grained Artifacts Assessment in Text-to-Image Generation**|Xiaoming Wei Team|[2509.10260](http://arxiv.org/abs/2509.10260)|null|
|**2025-09-12**|**Towards Reliable and Interpretable Document Question Answering via VLMs**|Simone Marinai Team|[2509.10129](http://arxiv.org/abs/2509.10129)|null|
|**2025-09-12**|**VARCO-VISION-2.0 Technical Report**|Youngjune Kim Team|[2509.10105](http://arxiv.org/abs/2509.10105)|null|
|**2025-09-12**|**Multimodal Mathematical Reasoning Embedded in Aerial Vehicle Imagery: Benchmarking, Analysis, and Exploration**|Wayne Zhang Team|[2509.10059](http://arxiv.org/abs/2509.10059)|null|
|**2025-09-12**|**LaV-CoT: Language-Aware Visual CoT with Multi-Aspect Reward Optimization for Real-World Multilingual VQA**|Jianshu Li Team|[2509.10026](http://arxiv.org/abs/2509.10026)|null|
|**2025-09-11**|**How well can LLMs provide planning feedback in grounded environments?**|Victor Zhong Team|[2509.09790](http://arxiv.org/abs/2509.09790)|null|
|**2025-09-11**|**FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark**|Hongsheng Li Team|[2509.09680](http://arxiv.org/abs/2509.09680)|**[link](https://flux-reason-6m.github.io/)**|
|**2025-09-11**|**Compositional Concept Generalization with Variational Quantum Circuits**|Mehrnoosh sadrzadeh Team|[2509.09541](http://arxiv.org/abs/2509.09541)|null|
|**2025-09-11**|**Decoupling Clinical and Class-Agnostic Features for Reliable Few-Shot Adaptation under Shift**|Dwarikanath Mahapatra Team|[2509.09397](http://arxiv.org/abs/2509.09397)|null|
|**2025-09-11**|**VLA-Adapter: An Effective Paradigm for Tiny-Scale Vision-Language-Action Model**|Donglin Wang Team|[2509.09372](http://arxiv.org/abs/2509.09372)|null|
|**2025-09-11**|**Curriculum-Based Multi-Tier Semantic Exploration via Deep Reinforcement Learning**|Abderrezzak Debilou Team|[2509.09356](http://arxiv.org/abs/2509.09356)|null|
|**2025-09-11**|**Image Recognition with Vision and Language Embeddings of VLMs**|Jiri Matas Team|[2509.09311](http://arxiv.org/abs/2509.09311)|null|
|**2025-09-11**|**Visual Programmability: A Guide for Code-as-Thought in Chart Understanding**|Ya Zhang Team|[2509.09286](http://arxiv.org/abs/2509.09286)|null|
|**2025-09-11**|**Towards Better Dental AI: A Multimodal Benchmark and Instruction Dataset for Panoramic X-ray Analysis**|Kuo Feng Hung Team|[2509.09254](http://arxiv.org/abs/2509.09254)|null|
|**2025-09-11**|**Bridging the Gap Between Ideal and Real-world Evaluation: Benchmarking AI-Generated Image Detection in Challenging Scenarios**|Yao Zhu Team|[2509.09172](http://arxiv.org/abs/2509.09172)|null|
|**2025-09-11**|**Zero-shot Hierarchical Plant Segmentation via Foundation Segmentation Models and Text-to-image Attention**|Fumio Okura Team|[2509.09116](http://arxiv.org/abs/2509.09116)|null|
|**2025-09-10**|**COCO-Urdu: A Large-Scale Urdu Image-Caption Dataset with Multimodal Quality Estimation**|Umair Hassan Team|[2509.09014](http://arxiv.org/abs/2509.09014)|**[link](https://huggingface.co/datasets/umairhassan02/urdu-translated-coco-captions-subset.)**|
|**2025-09-10**|**Can Vision-Language Models Solve Visual Math Equations?**|Mrinmaya Sachan Team|[2509.09013](http://arxiv.org/abs/2509.09013)|null|
|**2025-09-10**|**Generalized User-Oriented Image Semantic Coding Empowered by Large Vision-Language Model**|Vincent W. S. Wong Team|[2509.08913](http://arxiv.org/abs/2509.08913)|null|
|**2025-09-10**|**Recurrence Meets Transformers for Universal Multimodal Retrieval**|Rita Cucchiara Team|[2509.08897](http://arxiv.org/abs/2509.08897)|null|
|**2025-09-10**|**RewardDance: Reward Scaling in Visual Generation**|Weilin Huang Team|[2509.08826](http://arxiv.org/abs/2509.08826)|null|
|**2025-09-10**|**RoboChemist: Long-Horizon and Safety-Compliant Robotic Chemical Experimentation**|Hao Zhao Team|[2509.08820](http://arxiv.org/abs/2509.08820)|**[link](https://zzongzheng0918.github.io/RoboChemist.github.io/)**|
|**2025-09-10**|**SocialNav-SUB: Benchmarking VLMs for Scene Understanding in Social Robot Navigation**|Peter Stone Team|[2509.08757](http://arxiv.org/abs/2509.08757)|**[link](https://larg.github.io/socialnav-sub)**|
|**2025-09-10**|**TCPO: Thought-Centric Preference Optimization for Effective Embodied Decision-making**|Xiu Li Team|[2509.08500](http://arxiv.org/abs/2509.08500)|null|
|**2025-09-10**|**A Structured Review of Underwater Object Detection Challenges and Solutions: From Traditional to Large Vision Language Models**|Zhou Ni Team|[2509.08490](http://arxiv.org/abs/2509.08490)|null|
|**2025-09-11**|**Adapting Vision-Language Models for Neutrino Event Classification in High-Energy Physics**|Pierre Baldi Team|[2509.08461](http://arxiv.org/abs/2509.08461)|null|
|**2025-09-10**|**Retrieval-Augmented VLMs for Multimodal Melanoma Diagnosis**|Charmgil Hong Team|[2509.08338](http://arxiv.org/abs/2509.08338)|null|
|**2025-09-10**|**Interpretable Physics Reasoning and Performance Taxonomy in Vision-Language Models**|Monali Deshmukh Team|[2509.08270](http://arxiv.org/abs/2509.08270)|null|
|**2025-09-10**|**Examining Vision Language Models through Multi-dimensional Experiments with Vision and Text Features**|Donald E. Brown Team|[2509.08266](http://arxiv.org/abs/2509.08266)|null|
|**2025-09-10**|**Vector embedding of multi-modal texts: a tool for discovery?**|Sachith Withana Team|[2509.08216](http://arxiv.org/abs/2509.08216)|null|
|**2025-09-09**|**Privacy Preserving Semantic Communications Using Vision Language Models: A Segmentation and Generation Approach**|Qianqian Zhang Team|[2509.08142](http://arxiv.org/abs/2509.08142)|null|
|**2025-09-09**|**Visual-TableQA: Open-Domain Benchmark for Reasoning over Table Images**|Marc Haraoui Team|[2509.07966](http://arxiv.org/abs/2509.07966)|null|
|**2025-09-09**|**Data-Efficient Fine-Tuning of Vision-Language Models for Diagnosis of Alzheimer's Disease**|Xiaochen Yang Team|[2509.07613](http://arxiv.org/abs/2509.07613)|null|
|**2025-09-09**|**Fine-Tuning Vision-Language Models for Visual Navigation Assistance**|Xi Wang Team|[2509.07488](http://arxiv.org/abs/2509.07488)|null|
|**2025-09-09**|**DepthVision: Robust Vision-Language Understanding through GAN-Based LiDAR-to-RGB Synthesis**|Alois C. Knoll Team|[2509.07463](http://arxiv.org/abs/2509.07463)|null|
|**2025-09-09**|**SpecifyUI: Supporting Iterative UI Design Intent Expression through Structured Specifications and Generative AI**|Liuqing Chen Team|[2509.07334](http://arxiv.org/abs/2509.07334)|null|
|**2025-09-10**|**LLaDA-VLA: Vision Language Diffusion Action Models**|Xiaoyan Sun Team|[2509.06932](http://arxiv.org/abs/2509.06932)|null|
|**2025-09-08**|**D-HUMOR: Dark Humor Understanding via Multimodal Open-ended Reasoning**|Nagendra Kumar Team|[2509.06771](http://arxiv.org/abs/2509.06771)|null|
|**2025-09-08**|**Embodied Hazard Mitigation using Vision-Language Models for Autonomous Mobile Robots**|Aliasghar Arab Team|[2509.06768](http://arxiv.org/abs/2509.06768)|null|
|**2025-09-08**|**Aligning Large Vision-Language Models by Deep Reinforcement Learning and Direct Preference Optimization**|Janis Dalins Team|[2509.06759](http://arxiv.org/abs/2509.06759)|null|
|**2025-09-08**|**Focusing by Contrastive Attention: Enhancing VLMs' Visual Reasoning**|Xueqi Cheng Team|[2509.06461](http://arxiv.org/abs/2509.06461)|null|
|**2025-09-08**|**When Language Model Guides Vision: Grounding DINO for Cattle Muzzle Detection**|Muhammad Ashad Kabir Team|[2509.06427](http://arxiv.org/abs/2509.06427)|null|
|**2025-09-08**|**Index-Preserving Lightweight Token Pruning for Efficient Document Understanding in Vision-Language Models**|Inyong Yun Team|[2509.06415](http://arxiv.org/abs/2509.06415)|null|
|**2025-09-08**|**Teaching AI Stepwise Diagnostic Reasoning with Report-Guided Chain-of-Thought Learning**|Dong Liang Team|[2509.06409](http://arxiv.org/abs/2509.06409)|null|
|**2025-09-08**|**Multi View Slot Attention Using Paraphrased Texts For Face Anti-Spoofing**|Ha Young Kim Team|[2509.06336](http://arxiv.org/abs/2509.06336)|null|
|**2025-09-08**|**Spatial Reasoning with Vision-Language Models in Ego-Centric Multi-View Scenes**|Mohammad Akbari Team|[2509.06266](http://arxiv.org/abs/2509.06266)|null|
|**2025-09-07**|**PathoHR: Hierarchical Reasoning for Vision-Language Models in Pathology**|Hujun Yin Team|[2509.06105](http://arxiv.org/abs/2509.06105)|null|
|**2025-09-07**|**Analysis of Blood Report Images Using General Purpose Vision-Language Models**|Hamid Beigy Team|[2509.06033](http://arxiv.org/abs/2509.06033)|null|
|**2025-09-07**|**ZLATTE: A Geometry-Aware, Learning-Free Framework for Language-Driven Trajectory Reshaping in Human-Robot Interaction**|Luis Figueredo Team|[2509.06031](http://arxiv.org/abs/2509.06031)|null|
|**2025-09-07**|**Imagining Alternatives: Towards High-Resolution 3D Counterfactual Medical Image Generation via Language Guidance**|Tal Arbel Team|[2509.05978](http://arxiv.org/abs/2509.05978)|null|
|**2025-09-06**|**Towards an Automated Framework to Audit Youth Safety on TikTok**|Francesco Pierri Team|[2509.05838](http://arxiv.org/abs/2509.05838)|null|
|**2025-09-06**|**Do Vision-Language Models See Visualizations Like Humans? Alignment in Chart Categorization**|Torsten Möller Team|[2509.05718](http://arxiv.org/abs/2509.05718)|null|
|**2025-09-06**|**Knowledge-Augmented Vision Language Models for Underwater Bioacoustic Spectrogram Analysis**|Kazuhiro Nakadai Team|[2509.05703](http://arxiv.org/abs/2509.05703)|null|
|**2025-09-05**|**VLSM-Ensemble: Ensembling CLIP-based Vision-Language Models for Enhanced Medical Image Segmentation**|Noel E. O'Connor Team|[2509.05154](http://arxiv.org/abs/2509.05154)|null|
|**2025-09-05**|**GenAI-based test case generation and execution in SDV platform**|Alois Knoll Team|[2509.05112](http://arxiv.org/abs/2509.05112)|null|
|**2025-09-05**|**MM-DREX: Multimodal-Driven Dynamic Routing of LLM Experts for Financial Trading**|Fei Wu Team|[2509.05080](http://arxiv.org/abs/2509.05080)|null|
|**2025-09-05**|**Dual-Domain Perspective on Degradation-Aware Fusion: A VLM-Guided Robust Infrared and Visible Image Fusion Framework**|Guangmang Cui Team|[2509.05000](http://arxiv.org/abs/2509.05000)|null|
|**2025-09-05**|**SynGen-Vision: Synthetic Data Generation for training industrial vision models**|Nitish Bhardwaj Team|[2509.04894](http://arxiv.org/abs/2509.04894)|null|
|**2025-09-05**|**TemporalFlowViz: Parameter-Aware Visual Analytics for Interpreting Scramjet Combustion Evolution**|Guihua Shan Team|[2509.04834](http://arxiv.org/abs/2509.04834)|null|
|**2025-09-05**|**FloodVision: Urban Flood Depth Estimation Using Foundation Vision-Language Models and Domain Knowledge Graph**|John E. Taylor Team|[2509.04772](http://arxiv.org/abs/2509.04772)|null|
|**2025-09-05**|**Dynamic Group Detection using VLM-augmented Temporal Groupness Graph**|Norimichi Ukita Team|[2509.04758](http://arxiv.org/abs/2509.04758)|null|
|**2025-09-04**|**Guideline-Consistent Segmentation via Multi-Agent Refinement**|James Davis Team|[2509.04687](http://arxiv.org/abs/2509.04687)|null|
|**2025-09-04**|**TRUST-VL: An Explainable News Assistant for General Multimodal Misinformation Detection**|Mong Li Lee Team|[2509.04448](http://arxiv.org/abs/2509.04448)|**[link](https://yanzehong.github.io/trust-vl/)**|
|**2025-09-05**|**GeoArena: An Open Platform for Benchmarking Large Vision-language Models on WorldWide Image Geolocalization**|Yixuan Li Team|[2509.04334](http://arxiv.org/abs/2509.04334)|null|
|**2025-09-04**|**Learning Active Perception via Self-Evolving Preference Optimization for GUI Grounding**|Juntao Li Team|[2509.04243](http://arxiv.org/abs/2509.04243)|null|
|**2025-09-04**|**An Automated, Scalable Machine Learning Model Inversion Assessment Pipeline**|Nathaniel D. Bastian Team|[2509.04214](http://arxiv.org/abs/2509.04214)|null|
|**2025-09-04**|**Real Time FPGA Based Transformers & VLMs for Vision Tasks: SOTA Designs and Optimizations**|Ashiyana Abdul Majeed Team|[2509.04162](http://arxiv.org/abs/2509.04162)|null|
|**2025-09-04**|**Multimodal Feature Fusion Network with Text Difference Enhancement for Remote Sensing Change Detection**|C. L. Philip Chen Team|[2509.03961](http://arxiv.org/abs/2509.03961)|null|
|**2025-09-04**|**Attn-Adapter: Attention Is All You Need for Online Few-shot Learner of Vision-Language Model**|Hyunseung Choo Team|[2509.03895](http://arxiv.org/abs/2509.03895)|null|
|**2025-09-04**|**Weakly-Supervised Learning of Dense Functional Correspondences**|Jiajun Wu Team|[2509.03893](http://arxiv.org/abs/2509.03893)|**[link](https://dense-functional-correspondence.github.io/)**|
|**2025-09-04**|**Expedition & Expansion: Leveraging Semantic Representations for Goal-Directed Exploration in Continuous Cellular Automata**|Cédric Colas Team|[2509.03863](http://arxiv.org/abs/2509.03863)|null|
|**2025-09-04**|**Measuring How (Not Just Whether) VLMs Build Common Ground**|Malihe Alikhani Team|[2509.03805](http://arxiv.org/abs/2509.03805)|null|
|**2025-09-04**|**Causality-guided Prompt Learning for Vision-language Models via Visual Granulation**|Qiulei Dong Team|[2509.03803](http://arxiv.org/abs/2509.03803)|null|
|**2025-09-04**|**MedVista3D: Vision-Language Modeling for Reducing Diagnostic Errors in 3D CT Disease Detection, Understanding and Reporting**|Xiaofeng Yang Team|[2509.03800](http://arxiv.org/abs/2509.03800)|null|
|**2025-09-03**|**Singular Value Few-shot Adaptation of Vision-Language Models**|Yiming Xiao Team|[2509.03740](http://arxiv.org/abs/2509.03740)|null|
|**2025-09-03**|**E-ARMOR: Edge case Assessment and Review of Multilingual Optical Character Recognition**|Anupam Purwar Team|[2509.03615](http://arxiv.org/abs/2509.03615)|null|
|**2025-09-05**|**Unveiling the Response of Large Vision-Language Models to Visually Absent Tokens**|Eunho Yang Team|[2509.03025](http://arxiv.org/abs/2509.03025)|null|
|**2025-09-03**|**KEPT: Knowledge-Enhanced Prediction of Trajectories from Consecutive Driving Frames with Vision-Language Models**|Hong Chen Team|[2509.02966](http://arxiv.org/abs/2509.02966)|null|
|**2025-09-02**|**A-SEA3L-QA: A Fully Automated Self-Evolving, Adversarial Workflow for Arabic Long-Context Question-Answer Generation**|Pedro J. Moreno Team|[2509.02864](http://arxiv.org/abs/2509.02864)|null|
|**2025-09-02**|**Challenges in Understanding Modality Conflict in Vision-Language Models**|David Jensen Team|[2509.02805](http://arxiv.org/abs/2509.02805)|null|
|**2025-09-02**|**2nd Place Solution for CVPR2024 E2E Challenge: End-to-End Autonomous Driving Using Vision Language Model**|Yi Yang Team|[2509.02659](http://arxiv.org/abs/2509.02659)|null|
|**2025-08-31**|**Radio Astronomy in the Era of Vision-Language Models: Prompt Sensitivity and Adaptation**|Slava Voloshynovskiy Team|[2509.02615](http://arxiv.org/abs/2509.02615)|null|
|**2025-09-02**|**Language-Guided Long Horizon Manipulation with LLM-based Planning and Visual Perception**|Bin He Team|[2509.02324](http://arxiv.org/abs/2509.02324)|null|
|**2025-09-02**|**RS-OOD: A Vision-Language Augmented Framework for Out-of-Distribution Detection in Remote Sensing**|Yao Zhu Team|[2509.02273](http://arxiv.org/abs/2509.02273)|null|
|**2025-09-02**|**E-THER: A PCT-Grounded Dataset for Benchmarking Empathic AI**|Syed Afaq Ali Shah Team|[2509.02100](http://arxiv.org/abs/2509.02100)|null|
|**2025-09-02**|**Structure-aware Contrastive Learning for Diagram Understanding of Multimodal Models**|Hiroshi Sasaki Team|[2509.01959](http://arxiv.org/abs/2509.01959)|null|
|**2025-09-02**|**RSCC: A Large-Scale Remote Sensing Change Caption Dataset for Disaster Events**|Feng Zhang Team|[2509.01907](http://arxiv.org/abs/2509.01907)|null|
|**2025-09-02**|**Automated Wildfire Damage Assessment from Multi view Ground level Imagery Via Vision Language Models**|Yiming Xiao Team|[2509.01895](http://arxiv.org/abs/2509.01895)|null|
|**2025-09-01**|**MoTo: A Zero-shot Plug-in Interaction-aware Navigation for General Mobile Manipulation**|Haibin Yan Team|[2509.01658](http://arxiv.org/abs/2509.01658)|**[link](https://gary3410.github.io/MoTo/)**|
|**2025-09-01**|**Unified Supervision For Vision-Language Modeling in 3D Computed Tomography**|Xueyan Mei Team|[2509.01554](http://arxiv.org/abs/2509.01554)|null|
|**2025-09-01**|**Variation-aware Vision Token Dropping for Faster Large Vision-Language Models**|Honggang Chen Team|[2509.01552](http://arxiv.org/abs/2509.01552)|**[link](https://github.com/xuyang-liu16/V2Drop})**|
|**2025-09-01**|**Error Notebook-Guided, Training-Free Part Retrieval in 3D CAD Assemblies via Vision-Language Models**|Zhiming Tan Team|[2509.01350](http://arxiv.org/abs/2509.01350)|null|
|**2025-09-03**|**Novel Category Discovery with X-Agent Attention for Open-Vocabulary Semantic Segmentation**|Yanyun Qu Team|[2509.01275](http://arxiv.org/abs/2509.01275)|null|
|**2025-09-01**|**ReCap: Event-Aware Image Captioning with Article Retrieval and Semantic Gaussian Normalization**|Trung-Nghia Le Team|[2509.01259](http://arxiv.org/abs/2509.01259)|null|
|**2025-09-01**|**POINTS-Reader: Distillation-Free Adaptation of Vision-Language Models for Document Conversion**|Jie Zhou Team|[2509.01215](http://arxiv.org/abs/2509.01215)|null|
|**2025-09-01**|**Measuring Image-Relation Alignment: Reference-Free Evaluation of VLMs and Synthetic Pre-training for Open-Vocabulary Scene Graph Generation**|Akihiro Sugimoto Team|[2509.01209](http://arxiv.org/abs/2509.01209)|null|
|**2025-08-29**|**VoCap: Video Object Captioning and Segmentation from Any Prompt**|Cordelia Schmid Team|[2508.21809](http://arxiv.org/abs/2508.21809)|null|
|**2025-08-29**|**CAD2DMD-SET: Synthetic Generation Tool of Digital Measurement Device CAD Model Datasets for fine-tuning Large Vision-Language Models**|Rodrigo Ventura Team|[2508.21732](http://arxiv.org/abs/2508.21732)|null|
|**2025-08-29**|**How Well Do Vision--Language Models Understand Cities? A Comparative Study on Spatial Reasoning from Street-View Images**|Yoonjin Yoon Team|[2508.21565](http://arxiv.org/abs/2508.21565)|null|
|**2025-08-29**|**HCCM: Hierarchical Cross-Granularity Contrastive and Matching Learning for Natural Language-Guided Drones**|Shaozi Li Team|[2508.21539](http://arxiv.org/abs/2508.21539)|null|
|**2025-08-28**|**OneReward: Unified Mask-Guided Image Generation via Multi-Task Human Preference Learning**|Xinglong Wu Team|[2508.21066](http://arxiv.org/abs/2508.21066)|**[link](https://one-reward.github.io)**|
|**2025-08-28**|**CogVLA: Cognition-Aligned Vision-Language-Action Model via Instruction-Driven Routing & Sparsification**|Liqiang Nie Team|[2508.21046](http://arxiv.org/abs/2508.21046)|**[link](https://jiutian-vl.github.io/CogVLA-page)**|
|**2025-08-28**|**Learning Primitive Embodied World Models: Towards Scalable Robotic Learning**|Qinying Gu Team|[2508.20840](http://arxiv.org/abs/2508.20840)|null|
|**2025-08-28**|**Estimating 2D Keypoints of Surgical Tools Using Vision-Language Models with Low-Rank Adaptation**|Binod Bhattarai Team|[2508.20830](http://arxiv.org/abs/2508.20830)|null|
|**2025-08-28**|**Evaluating Compositional Generalisation in VLMs and Diffusion Models**|Martha Lewis Team|[2508.20783](http://arxiv.org/abs/2508.20783)|null|
|**2025-09-02**|**Occlusion Robustness of CLIP for Military Vehicle Classification**|Hugo J. Kuijf Team|[2508.20760](http://arxiv.org/abs/2508.20760)|null|
|**2025-08-28**|**"Humor, Art, or Misinformation?": A Multimodal Dataset for Intent-Aware Synthetic Image Detection**|Panagiotis C. Petrantonakis Team|[2508.20670](http://arxiv.org/abs/2508.20670)|null|
|**2025-08-28**|**Towards Mechanistic Defenses Against Typographic Attacks in CLIP**|Wojciech Samek Team|[2508.20570](http://arxiv.org/abs/2508.20570)|null|
|**2025-08-28**|**MedGR $^2$ : Breaking the Data Barrier for Medical Reasoning via Generative Reward Learning**|Shangyang Li Team|[2508.20549](http://arxiv.org/abs/2508.20549)|null|
|**2025-08-28**|**MedFoundationHub: A Lightweight and Secure Toolkit for Deploying Medical Vision Language Foundation Models**|Yuankai Huo Team|[2508.20345](http://arxiv.org/abs/2508.20345)|null|
|**2025-08-28**|**GUARD: Guideline Upholding Test through Adaptive Role-play and Jailbreak Diagnostics for LLMs**|Haohan Wang Team|[2508.20325](http://arxiv.org/abs/2508.20325)|null|
|**2025-08-27**|**A Novel Framework for Automated Explain Vision Model Using Vision-Language Models**|Truong Son Hy Team|[2508.20227](http://arxiv.org/abs/2508.20227)|null|
|**2025-08-27**|**Segmentation Assisted Incremental Test Time Adaptation in an Open World**|Soma Biswas Team|[2508.20029](http://arxiv.org/abs/2508.20029)|null|
|**2025-08-27**|**SWIRL: A Staged Workflow for Interleaved Reinforcement Learning in Mobile GUI Control**|Ping Luo Team|[2508.20018](http://arxiv.org/abs/2508.20018)|null|
|**2025-08-27**|**GLSim: Detecting Object Hallucinations in LVLMs via Global-Local Similarity**|Yixuan Li Team|[2508.19972](http://arxiv.org/abs/2508.19972)|null|
|**2025-08-27**|**Assessing the Geolocation Capabilities, Limitations and Societal Risks of Generative Vision-Language Models**|Shoaib Ehsan Team|[2508.19967](http://arxiv.org/abs/2508.19967)|null|
|**2025-08-27**|**KRETA: A Benchmark for Korean Reading and Reasoning in Text-Rich VQA Attuned to Diverse Visual Contexts**|Hyunjun Eun Team|[2508.19944](http://arxiv.org/abs/2508.19944)|null|
|**2025-08-28**|**NLKI: A lightweight Natural Language Knowledge Integration Framework for Improving Small VLMs in Commonsense VQA Tasks**|Somak Aditya Team|[2508.19724](http://arxiv.org/abs/2508.19724)|null|
|**2025-08-27**|**InquireMobile: Teaching VLM-based Mobile Agent to Request Human Assistance via Reinforcement Fine-Tuning**|Bo Zheng Team|[2508.19679](http://arxiv.org/abs/2508.19679)|null|
|**2025-08-27**|**Self-Rewarding Vision-Language Model via Reasoning Decomposition**|Dong Yu Team|[2508.19652](http://arxiv.org/abs/2508.19652)|null|
|**2025-08-27**|**FakeSV-VLM: Taming VLM for Detecting Fake Short-Video News via Progressive Mixture-Of-Experts Adapter**|Zhun Zhong Team|[2508.19639](http://arxiv.org/abs/2508.19639)|null|
|**2025-08-26**|**LaVA-Man: Learning Visual Action Representations for Robot Manipulation**|Changjae Oh Team|[2508.19391](http://arxiv.org/abs/2508.19391)|null|
|**2025-08-26**|**Fine-Tuning Vision-Language Models for Neutrino Event Analysis in High-Energy Physics Experiments**|Pierre Baldi Team|[2508.19376](http://arxiv.org/abs/2508.19376)|null|
|**2025-08-26**|**AT-CXR: Uncertainty-Aware Agentic Triage for Chest X-rays**|Yiyu Shi Team|[2508.19322](http://arxiv.org/abs/2508.19322)|null|
|**2025-10-01**|**Object Detection with Multimodal Large Vision-Language Models: An In-depth Review**|Manoj Karkee Team|[2508.19294](http://arxiv.org/abs/2508.19294)|null|
|**2025-08-26**|**Do LVLMs Know What They Know? A Systematic Study of Knowledge Boundary Perception in LVLMs**|Keping Bi Team|[2508.19111](http://arxiv.org/abs/2508.19111)|null|
|**2025-08-26**|**ProPy: Building Interactive Prompt Pyramids upon CLIP for Partially Relevant Video Retrieval**|Xiaoguang Zhao Team|[2508.19024](http://arxiv.org/abs/2508.19024)|null|
|**2025-08-26**|**Ask Me Again Differently: GRAS for Measuring Bias in Vision Language Models on Gender, Race, Age, and Skin Tone**|Amit Sheth Team|[2508.18989](http://arxiv.org/abs/2508.18989)|null|
|**2025-08-28**|**Enhancing Document VQA Models via Retrieval-Augmented Generation**|Ernest Valveny Team|[2508.18984](http://arxiv.org/abs/2508.18984)|null|
|**2025-08-26**|**Toward Robust Medical Fairness: Debiased Dual-Modal Alignment via Text-Guided Attribute-Disentangled Prompt Learning for Vision-Language Models**|Yong Xia Team|[2508.18886](http://arxiv.org/abs/2508.18886)|null|
|**2025-08-26**|**Hidden Tail: Adversarial Image Causing Stealthy Resource Consumption in Vision-Language Models**|Guowen Xu Team|[2508.18805](http://arxiv.org/abs/2508.18805)|null|
|**2025-08-26**|**Rethinking Human-Object Interaction Evaluation for both Vision-Language Models and HOI-Specific Methods**|Robby T. Tan Team|[2508.18753](http://arxiv.org/abs/2508.18753)|null|
|**2025-08-26**|**Knowing or Guessing? Robust Medical Visual Question Answering via Joint Consistency and Contrastive Learning**|Zuozhu Liu Team|[2508.18687](http://arxiv.org/abs/2508.18687)|null|
|**2025-08-26**|**PRISM: Robust VLM Alignment with Principled Reasoning for Integrated Safety in Multimodality**|Chaowei Xiao Team|[2508.18649](http://arxiv.org/abs/2508.18649)|null|
|**2025-08-25**|**CLARIFY: A Specialist-Generalist Framework for Accurate and Lightweight Dermatological Visual Question Answering**|Mohammad Ariful Haque Team|[2508.18430](http://arxiv.org/abs/2508.18430)|null|
|**2025-08-25**|**Language-Specific Layer Matters: Efficient Multilingual Enhancement for Large Vision-Language Models**|Jingbo Zhu Team|[2508.18381](http://arxiv.org/abs/2508.18381)|null|
|**2025-08-25**|**SafeBimanual: Diffusion-based Trajectory Optimization for Safe Bimanual Manipulation**|Ziwei Wang Team|[2508.18268](http://arxiv.org/abs/2508.18268)|**[link](https://denghaoyuan123.github.io/SafeBimanip/)**|
|**2025-08-25**|**MMTok: Multimodal Coverage Maximization for Efficient Inference of VLMs**|Qi Qian Team|[2508.18264](http://arxiv.org/abs/2508.18264)|**[link](https://project.ironieser.cc/mmtok)**|
|**2025-08-25**|**SEAM: Semantically Equivalent Across Modalities Benchmark for Vision-Language Models**|Ashton Anderson Team|[2508.18179](http://arxiv.org/abs/2508.18179)|null|
|**2025-08-25**|**Scene-Aware Vectorized Memory Multi-Agent Framework with Cross-Modal Differentiated Quantization VLMs for Visually Impaired Assistance**|Liyong Ren Team|[2508.18177](http://arxiv.org/abs/2508.18177)|null|
|**2025-08-25**|**ArgusCogito: Chain-of-Thought for Cross-Modal Synergy and Omnidirectional Reasoning in Camouflaged Object Segmentation**|Ye Li Team|[2508.18050](http://arxiv.org/abs/2508.18050)|null|
|**2025-08-25**|**PerPilot: Personalizing VLM-based Mobile Agents via Memory and Exploration**|Zhen Wang Team|[2508.18040](http://arxiv.org/abs/2508.18040)|null|
|**2025-08-25**|**Alternating Training-based Label Smoothing Enhances Prompt Generalization**|Yu Zhang Team|[2508.17846](http://arxiv.org/abs/2508.17846)|null|
|**2025-08-25**|**PoRe: Position-Reweighted Visual Token Pruning for Vision Language Models**|Dan Zeng Team|[2508.17807](http://arxiv.org/abs/2508.17807)|null|
|**2025-08-25**|**F2RVLM: Boosting Fine-grained Fragment Retrieval for Multi-Modal Long-form Dialogue with Vision Language Model**|Jinchao Zhang Team|[2508.17714](http://arxiv.org/abs/2508.17714)|null|
|**2025-08-25**|**Language-Guided Temporal Token Pruning for Efficient VideoLLM Processing**|Yogesh Kumar Team|[2508.17686](http://arxiv.org/abs/2508.17686)|null|
|**2025-08-25**|**Hierarchical Vision-Language Learning for Medical Out-of-Distribution Detection**|Ruixuan Wang Team|[2508.17667](http://arxiv.org/abs/2508.17667)|null|
|**2025-08-25**|**Dynamic Embedding of Hierarchical Visual Features for Efficient Vision-Language Fine-Tuning**|Chunping Qiu Team|[2508.17638](http://arxiv.org/abs/2508.17638)|null|
|**2025-08-25**|**TinyGiantVLM: A Lightweight Vision-Language Architecture for Spatial Reasoning under Resource Constraints**|Xuan-Huong Nguyen Team|[2508.17595](http://arxiv.org/abs/2508.17595)|null|
|**2025-08-25**|**MetaGen: A DSL, Database, and Benchmark for VLM-Assisted Metamaterial Generation**|Wojciech Matusik Team|[2508.17568](http://arxiv.org/abs/2508.17568)|null|
|**2025-08-24**|**MoE-Inference-Bench: Performance Evaluation of Mixture of Expert Large Language and Vision Models**|Venkatram Vishwanath Team|[2508.17467](http://arxiv.org/abs/2508.17467)|null|
|**2025-08-24**|**Multi-Level LVLM Guidance for Untrimmed Video Action Recognition**|Yunjie Guo Team|[2508.17442](http://arxiv.org/abs/2508.17442)|null|
|**2025-08-24**|**Constrained Prompt Enhancement for Improving Zero-Shot Generalization of Vision-Language Models**|Qinghua Hu Team|[2508.17417](http://arxiv.org/abs/2508.17417)|null|
|**2025-08-24**|**Lightweight Joint Optimization of General-Purpose Vision-Language Models and Retrievers for Medical Diagnosis**|Tom Hope Team|[2508.17394](http://arxiv.org/abs/2508.17394)|null|
|**2025-08-26**|**Mind the (Language) Gap: Towards Probing Numerical and Cross-Lingual Limits of LVLMs**|Gaurav Harit Team|[2508.17334](http://arxiv.org/abs/2508.17334)|null|
|**2025-08-24**|**Explain Before You Answer: A Survey on Compositional Visual Reasoning**|Hamid Rezatofighi Team|[2508.17298](http://arxiv.org/abs/2508.17298)|null|
|**2025-08-22**|**Modular Embedding Recomposition for Incremental Learning**|Simone Calderara Team|[2508.16463](http://arxiv.org/abs/2508.16463)|null|
|**2025-08-22**|**Structuring GUI Elements through Vision Language Models: Towards Action Space Generation**|Jingdong Chen Team|[2508.16271](http://arxiv.org/abs/2508.16271)|null|
|**2025-08-22**|**RAGSR: Regional Attention Guided Diffusion for Image Super-Resolution**|Gui-Song Xia Team|[2508.16158](http://arxiv.org/abs/2508.16158)|null|
|**2025-08-22**|**Beyond Human-prompting: Adaptive Prompt Tuning with Semantic Alignment for Anomaly Detection**|Chao-Chun Chen Team|[2508.16157](http://arxiv.org/abs/2508.16157)|null|
|**2025-08-22**|**Prompting with Sign Parameters for Low-resource Sign Language Instruction Generation**|Hasan Mahmud Team|[2508.16076](http://arxiv.org/abs/2508.16076)|null|
|**2025-08-22**|**Less Redundancy: Boosting Practicality of Vision Language Model in Walking Assistants**|Jinchao Zhang Team|[2508.16070](http://arxiv.org/abs/2508.16070)|null|
|**2025-08-21**|**Glo-VLMs: Leveraging Vision-Language Models for Fine-Grained Diseased Glomerulus Classification**|Ruining Deng Team|[2508.15960](http://arxiv.org/abs/2508.15960)|null|
|**2025-08-21**|**Semantic-Aware Ship Detection with Vision-Language Integration**|Xiaomeng Huang Team|[2508.15930](http://arxiv.org/abs/2508.15930)|null|
|**2025-08-21**|**VT-LVLM-AR: A Video-Temporal Large Vision-Language Model Adapter for Fine-Grained Action Recognition in Long-Term Videos**|Zihan Xu Team|[2508.15903](http://arxiv.org/abs/2508.15903)|null|
|**2025-08-21**|**LLM-empowered Dynamic Prompt Routing for Vision-Language Models Tuning under Long-Tailed Distributions**|Yulong Bian Team|[2508.15688](http://arxiv.org/abs/2508.15688)|null|
|**2025-08-21**|**Mind and Motion Aligned: A Joint Evaluation IsaacSim Benchmark for Task Planning and Low-Level Policies in Mobile Manipulation**|Alexey K. Kovalev Team|[2508.15663](http://arxiv.org/abs/2508.15663)|null|
|**2025-08-21**|**DesignCLIP: Multimodal Learning with CLIP for Design Patent Understanding**|Sourav Medya Team|[2508.15297](http://arxiv.org/abs/2508.15297)|null|
|**2025-08-21**|**Normal and Abnormal Pathology Knowledge-Augmented Vision-Language Model for Anomaly Detection in Pathology Images**|Jin Tae Kwak Team|[2508.15256](http://arxiv.org/abs/2508.15256)|null|
|**2025-08-21**|**Pathology-Informed Latent Diffusion Model for Anomaly Detection in Lymph Node Metastasis**|Jin Tae Kwak Team|[2508.15236](http://arxiv.org/abs/2508.15236)|null|
|**2025-08-21**|**See it. Say it. Sorted: Agentic System for Compositional Diagram Generation**|Ed Li Team|[2508.15222](http://arxiv.org/abs/2508.15222)|null|
|**2025-08-21**|**ContextualLVLM-Agent: A Holistic Framework for Multi-Turn Visually-Grounded Dialogue and Complex Instruction Following**|Taeyang Yoon Team|[2508.15164](http://arxiv.org/abs/2508.15164)|null|
|**2025-08-20**|**MoEcho: Exploiting Side-Channel Attacks to Compromise User Privacy in Mixture-of-Experts LLMs**|Yunsi Fei Team|[2508.15036](http://arxiv.org/abs/2508.15036)|null|
|**2025-08-20**|**WISE-FUSE: Efficient Whole Slide Image Encoding via Coarse-to-Fine Patch Selection with VLM and LLM Knowledge Fusion**|Won-Ki Jeong Team|[2508.14537](http://arxiv.org/abs/2508.14537)|null|
|**2025-08-19**|**Multi-Rationale Explainable Object Recognition via Contrastive Conditional Inference**|Simon Gottschalk Team|[2508.14280](http://arxiv.org/abs/2508.14280)|null|
|**2025-08-19**|**CLIPSym: Delving into Symmetry Detection with CLIP**|Raymond A. Yeh Team|[2508.14197](http://arxiv.org/abs/2508.14197)|null|
|**2025-08-19**|**LENS: Learning to Segment Anything with Unified Reinforced Reasoning**|Xinggang Wang Team|[2508.14153](http://arxiv.org/abs/2508.14153)|**[link](https://github.com/hustvl/LENS)**|
|**2025-08-19**|**Embodied-R1: Reinforced Embodied Reasoning for General Robotic Manipulation**|Jianye Hao Team|[2508.13998](http://arxiv.org/abs/2508.13998)|null|
|**2025-08-19**|**Mitigating Cross-Image Information Leakage in LVLMs for Multi-Image Tasks**|Junsuk Choe Team|[2508.13744](http://arxiv.org/abs/2508.13744)|**[link](https://github.com/yejipark-m/FOCUS)**|
|**2025-08-19**|**Enhancing Targeted Adversarial Attacks on Large Vision-Language Models through Intermediate Projector Guidance**|Bin Xiao Team|[2508.13739](http://arxiv.org/abs/2508.13739)|null|
|**2025-08-19**|**Hierarchical Vision-Language Retrieval of Educational Metaverse Content in Agriculture**|Giuseppe Serra Team|[2508.13713](http://arxiv.org/abs/2508.13713)|null|
|**2025-08-19**|**ViExam: Are Vision Language Models Better than Humans on Vietnamese Multimodal Exam Questions?**|Daeyoung Kim Team|[2508.13680](http://arxiv.org/abs/2508.13680)|null|
|**2025-08-19**|**Breaking the SFT Plateau: Multimodal Structured Reinforcement Learning for Chart-to-Code Generation**|Lin Ma Team|[2508.13587](http://arxiv.org/abs/2508.13587)|null|
|**2025-08-21**|**DictAS: A Framework for Class-Generalizable Few-Shot Anomaly Segmentation via Dictionary Lookup**|Guiguang Ding Team|[2508.13560](http://arxiv.org/abs/2508.13560)|**[link](https://github.com/xiaozhen228/DictAS)**|
|**2025-08-19**|**Evaluating Open-Source Vision Language Models for Facial Emotion Recognition against Traditional Deep Learning Models**|Sridevi Bonthu Team|[2508.13524](http://arxiv.org/abs/2508.13524)|null|
|**2025-08-19**|**STER-VLM: Spatio-Temporal With Enhanced Reference Vision-Language Models**|Tien-Huy Nguyen Team|[2508.13470](http://arxiv.org/abs/2508.13470)|null|
|**2025-08-19**|**CAST: Counterfactual Labels Improve Instruction Following in Vision-Language-Action Models**|Sergey Levine Team|[2508.13446](http://arxiv.org/abs/2508.13446)|null|
|**2025-08-19**|**Structured Prompting and Multi-Agent Knowledge Distillation for Traffic Video Interpretation and Risk Inference**|Jidong J. Yang Team|[2508.13439](http://arxiv.org/abs/2508.13439)|null|
|**2025-08-19**|**Mitigating Easy Option Bias in Multiple-Choice Question Answering**|Basura Fernando Team|[2508.13428](http://arxiv.org/abs/2508.13428)|null|
|**2025-08-18**|**Prune2Drive: A Plug-and-Play Framework for Accelerating Vision-Language Models in Autonomous Driving**|Linfeng Zhang Team|[2508.13305](http://arxiv.org/abs/2508.13305)|null|
|**2025-08-18**|**CardAIc-Agents: A Multimodal Framework with Hierarchical Adaptation for Cardiac Care Support**|Jinming Duan Team|[2508.13256](http://arxiv.org/abs/2508.13256)|null|
|**2025-08-18**|**Large VLM-based Vision-Language-Action Models for Robotic Manipulation: A Survey**|Liqiang Nie Team|[2508.13073](http://arxiv.org/abs/2508.13073)|**[link](https://github.com/JiuTian-VL/Large-VLM-based-VLA-for-Robotic-Manipulation)**|
|**2025-08-18**|**IntelliCap: Intelligent Guidance for Consistent View Sampling**|Shohei Mori Team|[2508.13043](http://arxiv.org/abs/2508.13043)|**[link](https://mediated-reality.github.io/projects/yasunaga_ismar25/)**|
|**2025-08-18**|**Breaking Reward Collapse: Adaptive Reinforcement for Open-ended Medical Reasoning with Enhanced Semantic Discrimination**|Lihua Zhang Team|[2508.12957](http://arxiv.org/abs/2508.12957)|null|
|**2025-08-18**|**RoboRetriever: Single-Camera Robot Object Retrieval via Active and Interactive Perception with Dynamic Scene Graph**|Yunquan Sun Team|[2508.12916](http://arxiv.org/abs/2508.12916)|null|
|**2025-08-18**|**Preserve and Sculpt: Manifold-Aligned Fine-tuning of Vision-Language Models for Few-Shot Learning**|Ruixuan Wang Team|[2508.12877](http://arxiv.org/abs/2508.12877)|null|
|**2025-08-18**|**Cross-Domain Few-Shot Learning via Multi-View Collaborative Optimization with Vision-Language Models**|Ruixuan Wang Team|[2508.12861](http://arxiv.org/abs/2508.12861)|null|
|**2025-08-18**|**HeteroRAG: A Heterogeneous Retrieval-Augmented Generation Framework for Medical Vision Language Tasks**|Yu Wang Team|[2508.12778](http://arxiv.org/abs/2508.12778)|null|
|**2025-08-18**|**Drifting Away from Truth: GenAI-Driven News Diversity Challenges LVLM-Based Misinformation Detection**|Wei Zhou Team|[2508.12711](http://arxiv.org/abs/2508.12711)|null|
|**2025-08-18**|**WP-CLIP: Leveraging CLIP to Predict Wölfflin's Principles in Visual Art**|Feng Liu Team|[2508.12668](http://arxiv.org/abs/2508.12668)|**[link](https://github.com/abhijay9/wpclip)**|
|**2025-08-18**|**SpotVLM: Cloud-edge Collaborative Real-time VLM based on Context Transfer**|Zheng Yang Team|[2508.12638](http://arxiv.org/abs/2508.12638)|null|
|**2025-08-18**|**ViLaD: A Large Vision Language Diffusion Framework for End-to-End Autonomous Driving**|Ziran Wang Team|[2508.12603](http://arxiv.org/abs/2508.12603)|null|
|**2025-08-18**|**Multimodal Chain of Continuous Thought for Latent-Space Reasoning in Vision-Language Models**|Chris Ngo Team|[2508.12587](http://arxiv.org/abs/2508.12587)|null|
|**2025-08-18**|**REVEAL -- Reasoning and Evaluation of Visual Evidence through Aligned Language**|Yash Butala Team|[2508.12543](http://arxiv.org/abs/2508.12543)|null|
|**2025-08-17**|**LangVision-LoRA-NAS: Neural Architecture Search for Variable LoRA Rank in Vision Language Models**|Venkatram Vishwanath Team|[2508.12512](http://arxiv.org/abs/2508.12512)|null|
|**2025-08-17**|**Standardization of Neuromuscular Reflex Analysis -- Role of Fine-Tuned Vision-Language Model Consortium and OpenAI gpt-oss Reasoning LLM Enabled Decision Support System**|Kasun De Zoysa Team|[2508.12473](http://arxiv.org/abs/2508.12473)|null|
|**2025-08-17**|**M3PO: Multimodal-Model-Guided Preference Optimization for Visual Instruction Following**|Yanfei Qian Team|[2508.12458](http://arxiv.org/abs/2508.12458)|null|
|**2025-08-17**|**X-Ray-CoT: Interpretable Chest X-ray Diagnosis with Vision-Language Models via Chain-of-Thought Reasoning**|Shaoqing Tang Team|[2508.12455](http://arxiv.org/abs/2508.12455)|null|
|**2025-08-17**|**LMAD: Integrated End-to-End Vision-Language Model for Explainable Autonomous Driving**|Li Zhang Team|[2508.12404](http://arxiv.org/abs/2508.12404)|null|
|**2025-08-17**|**MPCAR: Multi-Perspective Contextual Augmentation for Enhanced Visual Reasoning in Large Vision-Language Models**|Xueying Huang Team|[2508.12400](http://arxiv.org/abs/2508.12400)|null|
|**2025-08-17**|**Federated Cross-Modal Style-Aware Prompt Generation**|Amit Sethi Team|[2508.12399](http://arxiv.org/abs/2508.12399)|null|
|**2025-08-15**|**Reinforcing Video Reasoning Segmentation to Think Before It Segments**|Huchuan Lu Team|[2508.11538](http://arxiv.org/abs/2508.11538)|null|
|**2025-08-15**|**OVSegDT: Segmenting Transformer for Open-Vocabulary Object Goal Navigation**|Aleksandr Panov Team|[2508.11479](http://arxiv.org/abs/2508.11479)|null|
|**2025-08-15**|**ImagiDrive: A Unified Imagination-and-Planning Framework for Autonomous Driving**|Li Zhang Team|[2508.11428](http://arxiv.org/abs/2508.11428)|null|
|**2025-08-15**|**Semantically Guided Adversarial Testing of Vision Models Using Language Models**|Jorge M. Cruz-Duarte Team|[2508.11341](http://arxiv.org/abs/2508.11341)|null|
|**2025-08-15**|**Noise Matters: Optimizing Matching Noise for Diffusion Classifiers**|Long Chen Team|[2508.11330](http://arxiv.org/abs/2508.11330)|null|
|**2025-08-15**|**Logic Unseen: Revealing the Logical Blindspots of Vision-Language Models**|Tat-Seng Chua Team|[2508.11317](http://arxiv.org/abs/2508.11317)|null|
|**2025-08-15**|**Vision-Language Models display a strong gender bias**|Sreedath Panat Team|[2508.11262](http://arxiv.org/abs/2508.11262)|null|
|**2025-08-15**|**Generalized Decoupled Learning for Enhancing Open-Vocabulary Dense Perception**|Zhuotao Tian Team|[2508.11256](http://arxiv.org/abs/2508.11256)|null|
|**2025-08-15**|**UAV-VL-R1: Generalizing Vision-Language Models via Supervised Fine-Tuning and Multi-Stage GRPO for UAV Visual Reasoning**|Yue Zhang Team|[2508.11196](http://arxiv.org/abs/2508.11196)|null|
|**2025-08-15**|**Fine-Grained VLM Fine-tuning via Latent Hierarchical Adapter Learning**|Bin Luo Team|[2508.11176](http://arxiv.org/abs/2508.11176)|null|
|**2025-08-15**|**Better Supervised Fine-tuning for VQA: Integer-Only Loss**|Junhui Cui Team|[2508.11170](http://arxiv.org/abs/2508.11170)|null|
|**2025-08-14**|**Utilizing Vision-Language Models as Action Models for Intent Recognition and Assistance**|Rustam Stolkin Team|[2508.11093](http://arxiv.org/abs/2508.11093)|null|
|**2025-08-14**|**Are Large Pre-trained Vision Language Models Effective Construction Safety Inspectors?**|Zhengbo Zou Team|[2508.11011](http://arxiv.org/abs/2508.11011)|null|
|**2025-08-14**|**Not There Yet: Evaluating Vision Language Models in Simulating the Visual Perception of People with Low Vision**|Anhong Guo Team|[2508.10972](http://arxiv.org/abs/2508.10972)|null|
|**2025-08-14**|**AEGIS: Authenticity Evaluation Benchmark for AI-Generated Video Sequences**|Joey Tianyi Zhou Team|[2508.10771](http://arxiv.org/abs/2508.10771)|null|
|**2025-08-14**|**From Diagnosis to Improvement: Probing Spatio-Physical Reasoning in Vision Language Models**|Wenqi Shao Team|[2508.10770](http://arxiv.org/abs/2508.10770)|null|
|**2025-08-14**|**IADGPT: Unified LVLM for Few-Shot Industrial Anomaly Detection, Localization, and Reasoning via In-Context Learning**|Bin Li Team|[2508.10681](http://arxiv.org/abs/2508.10681)|null|
|**2025-08-14**|**AddressVLM: Cross-view Alignment Tuning for Image Address Localization using Large Vision-Language Models**|Jieping Ye Team|[2508.10667](http://arxiv.org/abs/2508.10667)|null|
|**2025-08-14**|**SemPT: Semantic Prompt Tuning for Vision-Language Models**|Zhenzhong Chen Team|[2508.10645](http://arxiv.org/abs/2508.10645)|null|
|**2025-08-14**|**ChatENV: An Interactive Vision-Language Model for Sensor-Guided Environmental Monitoring and Scenario Simulation**|Mohsen Guizani Team|[2508.10635](http://arxiv.org/abs/2508.10635)|null|
|**2025-08-14**|**Retrieval-Augmented Prompt for OOD Detection**|Changqing Zhang Team|[2508.10556](http://arxiv.org/abs/2508.10556)|null|
|**2025-08-14**|**DiFaR: Enhancing Multimodal Misinformation Detection with Diverse, Factual, and Relevant Rationales**|Zhi Zeng Team|[2508.10444](http://arxiv.org/abs/2508.10444)|null|
|**2025-08-14**|**MM-Food-100K: A 100,000-Sample Multimodal Food Intelligence Dataset with Verifiable Provenance**|Yi Zhang Team|[2508.10429](http://arxiv.org/abs/2508.10429)|**[link](https://huggingface.co/datasets/Codatta/MM-Food-100K)**|
|**2025-08-14**|**STRIDE-QA: Visual Question Answering Dataset for Spatiotemporal Reasoning in Urban Driving Scenes**|Yu Yamaguchi Team|[2508.10427](http://arxiv.org/abs/2508.10427)|**[link](https://turingmotors.github.io/stride-qa/)**|
|**2025-08-14**|**PQ-DAF: Pose-driven Quality-controlled Data Augmentation for Data-scarce Driver Distraction Detection**|Xinghui Song Team|[2508.10397](http://arxiv.org/abs/2508.10397)|null|
|**2025-08-14**|**Contrast Sensitivity Function of Multimodal Vision-Language Models**|Valero Laparra Team|[2508.10367](http://arxiv.org/abs/2508.10367)|null|
|**2025-08-14**|**JRDB-Reasoning: A Difficulty-Graded Benchmark for Visual Reasoning in Robotics**|Hamid Rezatofighi Team|[2508.10287](http://arxiv.org/abs/2508.10287)|null|
|**2025-08-14**|**MRFD: Multi-Region Fusion Decoding with Self-Consistency for Mitigating Hallucinations in LVLMs**|Yujun Cai Team|[2508.10264](http://arxiv.org/abs/2508.10264)|null|
|**2025-08-13**|**Efficient Forward-Only Data Valuation for Pretrained LLMs and VLMs**|Xiaoxiao Li Team|[2508.10180](http://arxiv.org/abs/2508.10180)|null|
|**2025-08-13**|**SynSpill: Improved Industrial Spill Detection With Synthetic Data**|Shruti Vyas Team|[2508.10171](http://arxiv.org/abs/2508.10171)|null|
|**2025-08-13**|**Interpretable Oracle Bone Script Decipherment through Radical and Pictographic Analysis with LVLMs**|Bin Li Team|[2508.10113](http://arxiv.org/abs/2508.10113)|null|
|**2025-08-13**|**LLMC+: Benchmarking Vision-Language Model Compression with a Plug-and-play Toolkit**|Wenya Wang Team|[2508.09981](http://arxiv.org/abs/2508.09981)|null|
|**2025-08-13**|**January Food Benchmark (JFB): A Public Benchmark Dataset and Evaluation Suite for Multimodal Food Analysis**|Mark Woodward Team|[2508.09966](http://arxiv.org/abs/2508.09966)|null|
|**2025-08-14**|**Prototype-Guided Diffusion: Visual Conditioning without External Memory**|Mustapha Lebbah Team|[2508.09922](http://arxiv.org/abs/2508.09922)|null|
|**2025-08-12**|**OpenCUA: Open Foundations for Computer-Use Agents**|Tao Yu Team|[2508.09123](http://arxiv.org/abs/2508.09123)|null|
|**2025-08-12**|**Bridging Formal Language with Chain-of-Thought Reasoning to Geometry Problem Solving**|Tian Ding Team|[2508.09099](http://arxiv.org/abs/2508.09099)|null|
|**2025-08-12**|**Addressing Bias in VLMs for Glaucoma Detection Without Protected Attribute Supervision**|Prashnna Gyawali Team|[2508.09087](http://arxiv.org/abs/2508.09087)|null|
|**2025-08-13**|**GeoVLA: Empowering 3D Representations in Vision-Language-Action Models**|Jiale Cao Team|[2508.09071](http://arxiv.org/abs/2508.09071)|**[link](https://linsun449.github.io/GeoVLA/)**|
|**2025-08-12**|**VLM-3D:End-to-End Vision-Language Models for Open-World 3D Perception**|Lei He Team|[2508.09061](http://arxiv.org/abs/2508.09061)|null|
|**2025-08-12**|**MVISU-Bench: Benchmarking Mobile Agents for Real-World Tasks by Multi-App, Vague, Interactive, Single-App and Unethical Instructions**|Jin Xu Team|[2508.09057](http://arxiv.org/abs/2508.09057)|null|
|**2025-08-12**|**Rational Inverse Reasoning**|Leslie Pack Kaelbling Team|[2508.08983](http://arxiv.org/abs/2508.08983)|null|
|**2025-08-12**|**How Does a Virtual Agent Decide Where to Look? -- Symbolic Cognitive Reasoning for Embodied Head Rotation**|Hyeongyeop Kang Team|[2508.08930](http://arxiv.org/abs/2508.08930)|null|
|**2025-08-12**|**Safe Semantics, Unsafe Interpretations: Tackling Implicit Reasoning Safety in Large Vision-Language Models**|Xuelong Li Team|[2508.08926](http://arxiv.org/abs/2508.08926)|null|
|**2025-08-12**|**3DFroMLLM: 3D Prototype Generation only from Pretrained Multimodal LLMs**|Eddy Ilg Team|[2508.08821](http://arxiv.org/abs/2508.08821)|null|
|**2025-08-12**|**SafeFix: Targeted Model Repair via Controlled Image Generation**|Yunhui Guo Team|[2508.08701](http://arxiv.org/abs/2508.08701)|null|
|**2025-08-12**|**STELAR-VISION: Self-Topology-Aware Efficient Learning for Aligned Reasoning in Vision**|Marios Savvides Team|[2508.08688](http://arxiv.org/abs/2508.08688)|null|
|**2025-08-12**|**AME: Aligned Manifold Entropy for Robust Vision-Language Distillation**|Yuming Ou Team|[2508.08644](http://arxiv.org/abs/2508.08644)|null|
|**2025-08-13**|**Transferable Model-agnostic Vision-Language Model Adaptation for Efficient Weak-to-Strong Generalization**|Hyunwoo J. Kim Team|[2508.08604](http://arxiv.org/abs/2508.08604)|null|
|**2025-08-12**|**Superclass-Guided Representation Disentanglement for Spurious Correlation Mitigation**|Qi Lei Team|[2508.08570](http://arxiv.org/abs/2508.08570)|null|
|**2025-08-11**|**VISOR: Visual Input-based Steering for Output Redirection in Vision-Language Models**|Ravikumar Balakrishnan Team|[2508.08521](http://arxiv.org/abs/2508.08521)|null|
|**2025-08-11**|**Re:Verse -- Can Your VLM Read a Manga?**|Shruti Vyas Team|[2508.08508](http://arxiv.org/abs/2508.08508)|null|
|**2025-08-11**|**ODYSSEY: Open-World Quadrupeds Exploration and Manipulation for Long-Horizon Tasks**|Chunhua Shen Team|[2508.08240](http://arxiv.org/abs/2508.08240)|null|
|**2025-08-11**|**Spatial-ORMLLM: Improve Spatial Relation Understanding in the Operating Room with Multimodal Large Language Model**|Shaoliang Peng Team|[2508.08199](http://arxiv.org/abs/2508.08199)|null|
|**2025-08-11**|**BadPromptFL: A Novel Backdoor Threat to Prompt-based Federated Learning in Multimodal Models**|Bo Wang Team|[2508.08040](http://arxiv.org/abs/2508.08040)|null|
|**2025-08-11**|**TRIDE: A Text-assisted Radar-Image weather-aware fusion network for Depth Estimation**|Robert Wille Team|[2508.08038](http://arxiv.org/abs/2508.08038)|null|
|**2025-08-11**|**TAG: A Simple Yet Effective Temporal-Aware Approach for Zero-Shot Video Temporal Grounding**|Jee-Hyong Lee Team|[2508.07925](http://arxiv.org/abs/2508.07925)|null|
|**2025-08-11**|**RSVLM-QA: A Benchmark Dataset for Remote Sensing Vision Language Model-based Question Answering**|Mukesh Prasad Team|[2508.07918](http://arxiv.org/abs/2508.07918)|null|
|**2025-08-11**|**CATP: Contextually Adaptive Token Pruning for Efficient and Enhanced Multimodal In-Context Learning**|Ruixiang Tang Team|[2508.07871](http://arxiv.org/abs/2508.07871)|null|
|**2025-08-11**|**Effortless Vision-Language Model Specialization in Histopathology without Annotation**|Katharina Breininger Team|[2508.07835](http://arxiv.org/abs/2508.07835)|null|
|**2025-08-11**|**MIMIC: Multimodal Inversion for Model Interpretation and Conceptualization**|Alexandros Stergiou Team|[2508.07833](http://arxiv.org/abs/2508.07833)|**[link](https://anaekin.github.io/MIMIC)**|
|**2025-08-11**|**Architectural Co-Design for Zero-Shot Anomaly Detection: Decoupling Representation and Dynamically Fusing Features in CLIP**|Yueyi Luo Team|[2508.07819](http://arxiv.org/abs/2508.07819)|null|
|**2025-08-11**|**SwarmVLM: VLM-Guided Impedance Control for Autonomous Navigation of Heterogeneous Robots in Dynamic Warehousing**|Dzmitry Tsetserukou Team|[2508.07814](http://arxiv.org/abs/2508.07814)|null|
|**2025-08-11**|**Grasp-HGN: Grasping the Unexpected**|Gunar Schirner Team|[2508.07648](http://arxiv.org/abs/2508.07648)|null|
|**2025-08-11**|**Breaking Down and Building Up: Mixture of Skill-Based Vision-and-Language Navigation Agents**|Parisa Kordjamshidi Team|[2508.07642](http://arxiv.org/abs/2508.07642)|null|
|**2025-08-11**|**InterChart: Benchmarking Visual Reasoning Across Decomposed and Distributed Chart Information**|Vivek Gupta Team|[2508.07630](http://arxiv.org/abs/2508.07630)|null|
|**2025-08-11**|**AR-VRM: Imitating Human Motions for Visual Robot Manipulation with Analogical Reasoning**|Yang Liu Team|[2508.07626](http://arxiv.org/abs/2508.07626)|null|
|**2025-08-11**|**Adaptive Cache Enhancement for Test-Time Adaptation of Vision-Language Models**|Duc Thanh Nguyen Team|[2508.07570](http://arxiv.org/abs/2508.07570)|null|
|**2025-08-10**|**FormCoach: Lift Smarter, Not Harder**|Lingjie Liu Team|[2508.07501](http://arxiv.org/abs/2508.07501)|null|
|**2025-08-10**|**Freeze and Reveal: Exposing Modality Bias in Vision-Language Models**|Ponnurangam Kumaraguru Team|[2508.07432](http://arxiv.org/abs/2508.07432)|null|
|**2025-08-10**|**AgriVLN: Vision-and-Language Navigation for Agricultural Robots**|Xiang Li Team|[2508.07406](http://arxiv.org/abs/2508.07406)|null|
|**2025-08-10**|**Small-Large Collaboration: Training-efficient Concept Personalization for Large VLM using a Meta Personalized Small VLM**|Wentao Zhang Team|[2508.07260](http://arxiv.org/abs/2508.07260)|null|
|**2025-08-08**|**Uncertainty-quantified Rollout Policy Adaptation for Unlabelled Cross-domain Temporal Grounding**|Kun Shao Team|[2508.06317](http://arxiv.org/abs/2508.06317)|null|
|**2025-08-08**|**Real-Time 3D Vision-Language Embedding Mapping**|Elmar Rueckert Team|[2508.06291](http://arxiv.org/abs/2508.06291)|null|
|**2025-08-08**|**InfoCausalQA:Can Models Perform Non-explicit Causal Reasoning Based on Infographic?**|Youngjae Yu Team|[2508.06220](http://arxiv.org/abs/2508.06220)|null|
|**2025-08-08**|**VISTAR:A User-Centric and Role-Driven Benchmark for Text-to-Image Evaluation**|ChengSheng Deng Team|[2508.06152](http://arxiv.org/abs/2508.06152)|null|
|**2025-08-08**|**Q-CLIP: Unleashing the Power of Vision-Language Models for Video Quality Assessment through Unified Cross-Modal Adaptation**|Shaohui Liu Team|[2508.06092](http://arxiv.org/abs/2508.06092)|null|
|**2025-08-08**|**AdaptInfer: Adaptive Token Pruning for Vision-Language Model Inference with Dynamical Text Guidance**|Yunhao Liu Team|[2508.06084](http://arxiv.org/abs/2508.06084)|null|
|**2025-08-08**|**Fourier-VLM: Compressing Vision Tokens in the Frequency Domain for Large Vision-Language Models**|Zhouhan Lin Team|[2508.06038](http://arxiv.org/abs/2508.06038)|null|
|**2025-08-08**|**More Is Better: A MoE-Based Emotion Recognition Framework with Human Preference Alignment**|Zhepeng Wang Team|[2508.06036](http://arxiv.org/abs/2508.06036)|null|
|**2025-08-08**|**Mediator-Guided Multi-Agent Collaboration among Open-Source Models for Medical Decision-Making**|Xiaosong Wang Team|[2508.05996](http://arxiv.org/abs/2508.05996)|null|
|**2025-08-08**|**PASG: A Closed-Loop Framework for Automated Geometric Primitive Extraction and Semantic Anchoring in Robotic Manipulation**|Yao Mu Team|[2508.05976](http://arxiv.org/abs/2508.05976)|null|
|**2025-08-07**|**HOLODECK 2.0: Vision-Language-Guided 3D World Generation with Editing**|Chris Callison-Burch Team|[2508.05899](http://arxiv.org/abs/2508.05899)|null|
|**2025-08-07**|**ETTA: Efficient Test-Time Adaptation for Vision-Language Models through Dynamic Embedding Updates**|Ali cheraghian Team|[2508.05898](http://arxiv.org/abs/2508.05898)|null|
|**2025-08-07**|**Follow-Your-Instruction: A Comprehensive MLLM Agent for World Data Synthesis**|Zeyu Wang Team|[2508.05580](http://arxiv.org/abs/2508.05580)|null|
|**2025-08-07**|**Adapting Vision-Language Models Without Labels: A Comprehensive Survey**|Olga Fink Team|[2508.05547](http://arxiv.org/abs/2508.05547)|**[link](https://github.com/tim-learn/Awesome-LabelFree-VLMs})**|
|**2025-08-07**|**Explaining Similarity in Vision-Language Encoders with Weighted Banzhaf Interactions**|Przemyslaw Biecek Team|[2508.05430](http://arxiv.org/abs/2508.05430)|null|
|**2025-08-07**|**From Detection to Correction: Backdoor-Resilient Face Recognition via Vision-Language Trigger Detection and Noise-Based Neutralization**|Ibrahim Khalil Team|[2508.05409](http://arxiv.org/abs/2508.05409)|null|
|**2025-08-07**|**DeepPHY: Benchmarking Agentic VLMs on Physical Reasoning**|Bo Zheng Team|[2508.05405](http://arxiv.org/abs/2508.05405)|null|
|**2025-08-07**|**StructVRM: Aligning Multimodal Reasoning with Structured and Verifiable Reward Models**|Youqiang Zhou Team|[2508.05383](http://arxiv.org/abs/2508.05383)|null|
|**2025-08-07**|**Textual Inversion for Efficient Adaptation of Open-Vocabulary Object Detectors Without Forgetting**|Hugo Kuijf Team|[2508.05323](http://arxiv.org/abs/2508.05323)|null|
|**2025-08-07**|**Towards Embodied Agentic AI: Review and Classification of LLM- and VLM-Driven Robot Autonomy and Interaction**|Jorge Peña Queralta Team|[2508.05294](http://arxiv.org/abs/2508.05294)|null|
|**2025-08-07**|**RegionMed-CLIP: A Region-Aware Multimodal Contrastive Learning Pre-trained Model for Medical Image Understanding**|Guiru Liu Team|[2508.05244](http://arxiv.org/abs/2508.05244)|null|
|**2025-08-07**|**Navigating the Trade-off: A Synthesis of Defensive Strategies for Zero-Shot Adversarial Robustness in Vision-Language Models**|Jason Sun Team|[2508.05237](http://arxiv.org/abs/2508.05237)|null|
|**2025-08-07**|**ReasoningTrack: Chain-of-Thought Reasoning for Long-term Vision-Language Tracking**|Zhipeng Zhang Team|[2508.05221](http://arxiv.org/abs/2508.05221)|null|
|**2025-08-07**|**SPEX: A Vision-Language Model for Land Cover Extraction on Spectral Remote Sensing Images**|Liangpei Zhang Team|[2508.05202](http://arxiv.org/abs/2508.05202)|null|
|**2025-08-07**|**Chemist Eye: A Visual Language Model-Powered System for Safety Monitoring and Robot Decision-Making in Self-Driving Laboratories**|Andrew I. Cooper Team|[2508.05148](http://arxiv.org/abs/2508.05148)|null|
|**2025-08-07**|**Multimodal Causal-Driven Representation Learning for Generalizable Medical Image Segmentation**|Zhen Lei Team|[2508.05008](http://arxiv.org/abs/2508.05008)|null|
|**2025-08-07**|**Attribute Guidance With Inherent Pseudo-label For Occluded Person Re-identification**|Haiyang Zhang Team|[2508.04998](http://arxiv.org/abs/2508.04998)|null|
|**2025-08-07**|**Unified modality separation: A vision-language framework for unsupervised domain adaptation**|Heng Tao Shen Team|[2508.04987](http://arxiv.org/abs/2508.04987)|null|
|**2025-08-07**|**Accelerating Conditional Prompt Learning via Masked Image Modeling for Vision-Language Models**|Hyunseung Choo Team|[2508.04942](http://arxiv.org/abs/2508.04942)|null|
|**2025-08-06**|**INTENTION: Inferring Tendencies of Humanoid Robot Motion Through Interactive Intuition and Grounded VLM**|Nikos Tsagarakis Team|[2508.04931](http://arxiv.org/abs/2508.04931)|**[link](https://robo-intention.github.io)**|
|**2025-08-06**|**Automated Bug Frame Retrieval from Gameplay Videos Using Vision-Language Models**|Cor-Paul Bezemer Team|[2508.04895](http://arxiv.org/abs/2508.04895)|null|
|**2025-08-06**|**Dual-Stream Attention with Multi-Modal Queries for Object Detection in Transportation Applications**|Wassim Bouachir Team|[2508.04868](http://arxiv.org/abs/2508.04868)|null|
|**2025-08-01**|**MMRAG-DocQA: A Multi-Modal Retrieval-Augmented Generation Method for Document Question-Answering with Hierarchical Index and Multi-Granularity Retrieval**|Chengcheng Mai Team|[2508.00579](http://arxiv.org/abs/2508.00579)|null|
|**2025-08-01**|**Training-Free Class Purification for Open-Vocabulary Semantic Segmentation**|Xiaohua Xie Team|[2508.00557](http://arxiv.org/abs/2508.00557)|null|
|**2025-08-01**|**HiPrune: Training-Free Visual Token Pruning via Hierarchical Attention in Vision-Language Models**|Bin Chen Team|[2508.00553](http://arxiv.org/abs/2508.00553)|null|
|**2025-08-01**|**Your other Left! Vision-Language Models Fail to Identify Relative Positions in Medical Images**|Timo Ropinski Team|[2508.00549](http://arxiv.org/abs/2508.00549)|null|
|**2025-08-01**|**EFlat-LoRA: Efficiently Seeking Flat Minima for Better Generalization in Fine-Tuning Large Language Models and Beyond**|Baochang Zhang Team|[2508.00522](http://arxiv.org/abs/2508.00522)|null|
|**2025-08-01**|**When Vision-Language Model (VLM) Meets Beam Prediction: A Multimodal Contrastive Learning Framework**|Tony Q. S. Quek Team|[2508.00456](http://arxiv.org/abs/2508.00456)|null|
|**2025-08-01**|**CLIPTime: Time-Aware Multimodal Representation Learning from Images and Text**|Petar Durdevic Team|[2508.00447](http://arxiv.org/abs/2508.00447)|null|
|**2025-08-01**|**AutoDebias: Automated Framework for Debiasing Text-to-Image Models**|Yang Liu Team|[2508.00445](http://arxiv.org/abs/2508.00445)|null|
|**2025-08-01**|**Sari Sandbox: A Virtual Retail Store Environment for Embodied AI Agents**|Rowel O. Atienza Team|[2508.00400](http://arxiv.org/abs/2508.00400)|null|
|**2025-08-01**|**iSafetyBench: A video-language benchmark for safety in industrial environment**|Shruti Vyas Team|[2508.00399](http://arxiv.org/abs/2508.00399)|null|
|**2025-08-01**|**Decouple before Align: Visual Disentanglement Enhances Prompt Tuning**|Yanfeng Wang Team|[2508.00395](http://arxiv.org/abs/2508.00395)|null|
|**2025-08-01**|**SA-GCS: Semantic-Aware Gaussian Curriculum Scheduling for UAV Vision-Language Navigation**|Renxin Zhong Team|[2508.00390](http://arxiv.org/abs/2508.00390)|null|
|**2025-08-01**|**CoRGI: Verified Chain-of-Thought Reasoning with Visual Grounding**|Lin Shang Team|[2508.00378](http://arxiv.org/abs/2508.00378)|null|
|**2025-08-01**|**Analyze-Prompt-Reason: A Collaborative Agent-Based Framework for Multi-Image Vision-Language Reasoning**|Athanasios Voulodimos Team|[2508.00356](http://arxiv.org/abs/2508.00356)|null|
|**2025-08-01**|**Evaluating the Efficacy of Large Language Models for Generating Fine-Grained Visual Privacy Policies in Homes**|Hewu Li Team|[2508.00321](http://arxiv.org/abs/2508.00321)|null|
|**2025-08-01**|**DocTron-Formula: Generalized Formula Recognition in Complex and Structured Scenarios**|Lin Ma Team|[2508.00311](http://arxiv.org/abs/2508.00311)|null|
|**2025-08-01**|**Instruction-Grounded Visual Projectors for Continual Learning of Generative Vision-Language Models**|Eunwoo Kim Team|[2508.00260](http://arxiv.org/abs/2508.00260)|null|
|**2025-08-01**|**Towards Higher Effective Rank in Parameter-efficient Fine-tuning using Khatri--Rao Product**|Ehsan Abbasnejad Team|[2508.00230](http://arxiv.org/abs/2508.00230)|null|
|**2025-07-31**|**On the Risk of Misleading Reports: Diagnosing Textual Biases in Multimodal Clinical AI**|Enzo Ferrante Team|[2508.00171](http://arxiv.org/abs/2508.00171)|null|
|**2025-07-31**|**ART: Adaptive Relation Tuning for Generalized Relation Prediction**|Stefan Roth Team|[2507.23543](http://arxiv.org/abs/2507.23543)|null|
|**2025-07-23**|**BetterCheck: Towards Safeguarding VLMs for Automotive Perception Systems**|Christian Berger Team|[2507.17722](http://arxiv.org/abs/2507.17722)|null|
|**2025-07-23**|**InstructVLA: Vision-Language-Action Instruction Tuning from Understanding to Manipulation**|Jiangmiao Pang Team|[2507.17520](http://arxiv.org/abs/2507.17520)|null|
|**2025-07-23**|**Dynamic Scoring with Enhanced Semantics for Training-Free Human-Object Interaction Detection**|Elisa Ricci Team|[2507.17456](http://arxiv.org/abs/2507.17456)|null|
|**2025-07-23**|**VLM-Guided Visual Place Recognition for Planet-Scale Geo-Localization**|Shoaib Ehsan Team|[2507.17455](http://arxiv.org/abs/2507.17455)|null|
|**2025-07-23**|**Dynamic-DINO: Fine-Grained Mixture of Experts Tuning for Real-time Open-Vocabulary Object Detection**|Xi Li Team|[2507.17436](http://arxiv.org/abs/2507.17436)|null|
|**2025-07-23**|**Language-Conditioned Open-Vocabulary Mobile Manipulation with Pretrained Models**|Guanghui Sun Team|[2507.17379](http://arxiv.org/abs/2507.17379)|null|
|**2025-07-23**|**RoadBench: A Vision-Language Foundation Model and Benchmark for Road Damage Understanding**|Tianyang Wang Team|[2507.17353](http://arxiv.org/abs/2507.17353)|null|
|**2025-07-23**|**HySafe-AI: Hybrid Safety Architectural Analysis Framework for AI Systems: A Case Study**|Maria Spence Team|[2507.17118](http://arxiv.org/abs/2507.17118)|null|
|**2025-07-23**|**FedVLM: Scalable Personalized Vision-Language Models through Federated Learning**|Habeeb Olufowobi Team|[2507.17088](http://arxiv.org/abs/2507.17088)|null|
|**2025-07-22**|**VL-CLIP: Enhancing Multimodal Recommendations via Visual Grounding and LLM-Augmented CLIP Embeddings**|Kannan Achan Team|[2507.17080](http://arxiv.org/abs/2507.17080)|null|
|**2025-07-22**|**Controllable Hybrid Captioner for Improved Long-form Video Understanding**|Arun Reddy Team|[2507.17047](http://arxiv.org/abs/2507.17047)|null|
|**2025-07-22**|**Semi-off-Policy Reinforcement Learning for Vision-Language Slow-thinking Reasoning**|Kai Chen Team|[2507.16814](http://arxiv.org/abs/2507.16814)|null|
|**2025-07-22**|**Cooling Matters: Benchmarking Large Language Models and Vision-Language Models on Liquid-Cooled Versus Air-Cooled H100 GPU Systems**|Arslan Munir Team|[2507.16781](http://arxiv.org/abs/2507.16781)|null|
|**2025-07-22**|**Enhancing Remote Sensing Vision-Language Models Through MLLM and LLM-Based High-Quality Image-Text Dataset Generation**|Ke Yang Team|[2507.16716](http://arxiv.org/abs/2507.16716)|null|
|**2025-07-22**|**Experience is the Best Teacher: Grounding VLMs for Robotics through Self-Generated Memory**|Marco Hutter Team|[2507.16713](http://arxiv.org/abs/2507.16713)|null|
|**2025-07-22**|**Spatial 3D-LLM: Exploring Spatial Awareness in 3D Vision-Language Models**|Chao Zhang Team|[2507.16524](http://arxiv.org/abs/2507.16524)|null|
|**2025-07-22**|**SceneLoom: Communicating Data with Scene Context**|Siming Chen Team|[2507.16466](http://arxiv.org/abs/2507.16466)|null|
|**2025-07-22**|**Quality Text, Robust Vision: The Role of Language in Enhancing Visual Robustness of Vision-Language Models**|Isao Echizen Team|[2507.16257](http://arxiv.org/abs/2507.16257)|null|
|**2025-07-22**|**SeC: Advancing Complex Video Object Segmentation via Progressive Concept Construction**|Jiaqi Wang Team|[2507.15852](http://arxiv.org/abs/2507.15852)|null|
|**2025-07-21**|**Can Your Model Separate Yolks with a Water Bottle? Benchmarking Physical Commonsense Understanding in Video Generation Models**|Erkut Erdem Team|[2507.15824](http://arxiv.org/abs/2507.15824)|null|
|**2025-07-23**|**Visual-Language Model Knowledge Distillation Method for Image Quality Assessment**|Jiarun Song Team|[2507.15680](http://arxiv.org/abs/2507.15680)|null|
|**2025-07-21**|**Smart Eyes for Silent Threats: VLMs and In-Context Learning for THz Imaging**|Margret Keuper Team|[2507.15576](http://arxiv.org/abs/2507.15576)|null|
|**2025-07-21**|**HOLa: Zero-Shot HOI Detection with Low-Rank Decomposed VLM Feature Adaptation**|Robby T. Tan Team|[2507.15542](http://arxiv.org/abs/2507.15542)|null|
|**2025-07-21**|**Chart-R1: Chain-of-Thought Supervision and Reinforcement for Advanced Chart Reasoner**|Lin Ma Team|[2507.15509](http://arxiv.org/abs/2507.15509)|null|
|**2025-07-21**|**One Last Attention for Your Vision-Language Model**|Zhiqiang Shen Team|[2507.15480](http://arxiv.org/abs/2507.15480)|null|
|**2025-07-21**|**EgoPrune: Efficient Token Pruning for Egomotion Video Reasoning in Embodied Agent**|Xinlei Chen Team|[2507.15428](http://arxiv.org/abs/2507.15428)|null|
|**2025-07-21**|**In-context Learning of Vision Language Models for Detection of Physical and Digital Attacks against Face Recognition Systems**|Christoph Busch Team|[2507.15285](http://arxiv.org/abs/2507.15285)|null|
|**2025-07-21**|**VLM-UDMC: VLM-Enhanced Unified Decision-Making and Motion Control for Urban Autonomous Driving**|Tong Heng Lee Team|[2507.15266](http://arxiv.org/abs/2507.15266)|null|
|**2025-07-20**|**Survey of GenAI for Automotive Software Development: From Requirements to Executable Code**|Alois Knoll Team|[2507.15025](http://arxiv.org/abs/2507.15025)|null|
|**2025-07-20**|**Hierarchical Cross-modal Prompt Learning for Vision-Language Models**|Zhenhua Huang Team|[2507.14976](http://arxiv.org/abs/2507.14976)|null|
|**2025-07-20**|**FinChart-Bench: Benchmarking Financial Chart Comprehension in Vision-Language Models**|Mengnan Du Team|[2507.14823](http://arxiv.org/abs/2507.14823)|null|
|**2025-07-19**|**IRGPT: Understanding Real-world Infrared Image with Bi-cross-modal Curriculum on Large-scale Benchmark**|Ruiheng Zhang Team|[2507.14449](http://arxiv.org/abs/2507.14449)|null|
|**2025-07-18**|**CLIPTTA: Robust Contrastive Vision-Language Test-Time Adaptation**|Nicolas Thome Team|[2507.14312](http://arxiv.org/abs/2507.14312)|null|
|**2025-07-18**|**In-Depth and In-Breadth: Pre-training Multimodal Language Models Customized for Comprehensive Chart Understanding**|Leonid Sigal Team|[2507.14298](http://arxiv.org/abs/2507.14298)|null|
|**2025-07-18**|**VLA-Mark: A cross modal watermark for large vision-language alignment model**|Xuming Hu Team|[2507.14067](http://arxiv.org/abs/2507.14067)|null|
|**2025-07-18**|**EdgeVLA: Efficient Vision-Language-Action Models**|Benjamin Bolte Team|[2507.14049](http://arxiv.org/abs/2507.14049)|null|
|**2025-07-18**|**Moodifier: MLLM-Enhanced Emotion-Driven Image Editing**|Sharon X. Huang Team|[2507.14024](http://arxiv.org/abs/2507.14024)|null|
|**2025-07-18**|**When Seeing Overrides Knowing: Disentangling Knowledge Conflicts in Vision-Language Models**|Alberto Cazzaniga Team|[2507.13868](http://arxiv.org/abs/2507.13868)|null|
|**2025-07-18**|**Teaching Vision-Language Models to Ask: Resolving Ambiguity in Visual Questions**|Jiajun Zhang Team|[2507.13773](http://arxiv.org/abs/2507.13773)|null|
|**2025-07-17**|**LoRA-Loop: Closing the Synthetic Replay Cycle for Continual VLM Learning**|Margrit Betke Team|[2507.13568](http://arxiv.org/abs/2507.13568)|null|
|**2025-07-17**|**COREVQA: A Crowd Observation and Reasoning Entailment Visual Question Answering Benchmark**|Vasu Sharma Team|[2507.13405](http://arxiv.org/abs/2507.13405)|null|
|**2025-07-17**|**VisionThink: Smart and Efficient Vision Language Model via Reinforcement Learning**|Jiaya Jia Team|[2507.13348](http://arxiv.org/abs/2507.13348)|null|
|**2025-07-17**|**Leveraging Language Prior for Infrared Small Target Detection**|Pravendra Singh Team|[2507.13113](http://arxiv.org/abs/2507.13113)|null|
|**2025-07-17**|**GLAD: Generalizable Tuning for Vision-Language Models**|Shifeng Chen Team|[2507.13089](http://arxiv.org/abs/2507.13089)|null|
|**2025-07-17**|**Advancing Complex Wide-Area Scene Understanding with Hierarchical Coresets Selection**|Changwen Zheng Team|[2507.13061](http://arxiv.org/abs/2507.13061)|null|
|**2025-07-21**|**LaViPlan : Language-Guided Visual Path Planning with RLVR**|Hayeon Oh Team|[2507.12911](http://arxiv.org/abs/2507.12911)|null|
|**2025-07-17**|**City-VLM: Towards Multidomain Perception Scene Understanding via Multimodal Incomplete Learning**|Xiaowen Chu Team|[2507.12795](http://arxiv.org/abs/2507.12795)|null|
|**2025-07-16**|**VLMgineer: Vision Language Models as Robotic Toolsmiths**|Dinesh Jayaraman Team|[2507.12644](http://arxiv.org/abs/2507.12644)|null|
|**2025-07-16**|**NLI4VolVis: Natural Language Interaction for Volume Visualization via LLM Multi-Agents and Editable 3D Gaussian Splatting**|Chaoli Wang Team|[2507.12621](http://arxiv.org/abs/2507.12621)|null|
|**2025-07-16**|**MindJourney: Test-Time Scaling with World Models for Spatial Reasoning**|Chuang Gan Team|[2507.12508](http://arxiv.org/abs/2507.12508)|null|
|**2025-07-16**|**ReAL-AD: Towards Human-Like Reasoning in End-to-End Autonomous Driving**|Xinge Zhu Team|[2507.12499](http://arxiv.org/abs/2507.12499)|null|
|**2025-07-15**|**Spatially Grounded Explanations in Vision Language Models for Document Visual Question Answering**|Dimosthenis Karatzas Team|[2507.12490](http://arxiv.org/abs/2507.12490)|null|
|**2025-07-20**|**PhysX-3D: Physical-Grounded 3D Asset Generation**|Ziwei Liu Team|[2507.12465](http://arxiv.org/abs/2507.12465)|null|
|**2025-07-16**|**Describe Anything Model for Visual Question Answering on Text-rich Images**|Min Xu Team|[2507.12441](http://arxiv.org/abs/2507.12441)|null|
|**2025-07-16**|**AutoVDC: Automated Vision Data Cleaning Using Vision-Language Models**|Sihao Ding Team|[2507.12414](http://arxiv.org/abs/2507.12414)|null|
|**2025-07-16**|**Generate to Ground: Multimodal Text Conditioning Boosts Phrase Grounding in Medical Vision-Language Models**|Bernhard Kainz Team|[2507.12236](http://arxiv.org/abs/2507.12236)|null|
|**2025-07-16**|**InstructFLIP: Exploring Unified Vision-Language Model for Face Anti-spoofing**|Wen-Huang Cheng Team|[2507.12060](http://arxiv.org/abs/2507.12060)|null|
|**2025-07-16**|**GS-Bias: Global-Spatial Bias Learner for Single-Image Test-Time Adaptation of Vision-Language Models**|Rongrong Ji Team|[2507.11969](http://arxiv.org/abs/2507.11969)|null|
|**2025-07-16**|**POLYCHARTQA: Benchmarking Large Vision-Language Models with Multilingual Chart Question Answering**|Qin Jin Team|[2507.11939](http://arxiv.org/abs/2507.11939)|null|
|**2025-07-15**|**Seeing the Signs: A Survey of Edge-Deployable OCR Models for Billboard Visibility Analysis**|Lihang Ying Team|[2507.11730](http://arxiv.org/abs/2507.11730)|null|
|**2025-07-18**|**How Far Have Medical Vision-Language Models Come? A Comprehensive Benchmarking Study**|Rossella Arcucci Team|[2507.11200](http://arxiv.org/abs/2507.11200)|null|
|**2025-07-15**|**Bridging the Gap in Vision Language Models in Identifying Unsafe Concepts Across Modalities**|Yang Zhang Team|[2507.11155](http://arxiv.org/abs/2507.11155)|null|
|**2025-07-15**|**Assessing Color Vision Test in Large Vision-language Models**|Hongyang Chen Team|[2507.11153](http://arxiv.org/abs/2507.11153)|null|
|**2025-07-15**|**MSA at ImageCLEF 2025 Multimodal Reasoning: Multilingual Multimodal Reasoning With Ensemble Vision Language Models**|Hamza Moustafa Team|[2507.11114](http://arxiv.org/abs/2507.11114)|null|
|**2025-07-15**|**Tactical Decision for Multi-UGV Confrontation with a Vision-Language Model-Based Commander**|Lei Chen Team|[2507.11079](http://arxiv.org/abs/2507.11079)|null|
|**2025-07-15**|**Bridge Feature Matching and Cross-Modal Alignment with Mutual-filtering for Zero-shot Anomaly Detection**|Guanzhong Tian Team|[2507.11003](http://arxiv.org/abs/2507.11003)|null|
|**2025-07-14**|**EmbRACE-3K: Embodied Reasoning and Action in Complex Environments**|Xiaojuan Qi Team|[2507.10548](http://arxiv.org/abs/2507.10548)|null|
|**2025-07-14**|**CoralVQA: A Large-Scale Visual Question Answering Dataset for Coral Reef Image Understanding**|Yi Wang Team|[2507.10449](http://arxiv.org/abs/2507.10449)|null|
|**2025-07-14**|**Beyond Graph Model: Reliable VLM Fine-Tuning via Random Graph Adapter**|Bin Luo Team|[2507.10355](http://arxiv.org/abs/2507.10355)|null|
|**2025-07-14**|**Synthesizing Near-Boundary OOD Samples for Out-of-Distribution Detection**|Wenqiang Zhang Team|[2507.10225](http://arxiv.org/abs/2507.10225)|null|
|**2025-07-14**|**BlueGlass: A Framework for Composite AI Safety**|Kay-Ulrich Scholl Team|[2507.10106](http://arxiv.org/abs/2507.10106)|null|
|**2025-07-14**|**Foundation Model Driven Robotics: A Comprehensive Review**|Ammar Waheed Team|[2507.10087](http://arxiv.org/abs/2507.10087)|null|
|**2025-07-14**|**LayLens: Improving Deepfake Understanding through Simplified Explanations**|Abhinav Dhall Team|[2507.10066](http://arxiv.org/abs/2507.10066)|null|
|**2025-07-14**|**CoSMo: A Multimodal Transformer for Page Stream Segmentation in Comic Books**|Dimosthenis Karatzas Team|[2507.10053](http://arxiv.org/abs/2507.10053)|null|
|**2025-07-14**|**Text-Driven Causal Representation Learning for Source-Free Domain Generalization**|Zhen Lei Team|[2507.09961](http://arxiv.org/abs/2507.09961)|null|
|**2025-07-13**|**NegRefine: Refining Negative Label-Based Zero-Shot OOD Detection**|Pulei Xiong Team|[2507.09795](http://arxiv.org/abs/2507.09795)|null|
|**2025-07-13**|**Towards Fine-Grained Adaptation of CLIP via a Self-Trained Alignment Score**|Muhammad Haris Khan Team|[2507.09615](http://arxiv.org/abs/2507.09615)|null|
|**2025-07-13**|**Advancing Reliable Test-Time Adaptation of Vision-Language Models under Visual Variations**|Guiguang Ding Team|[2507.09500](http://arxiv.org/abs/2507.09500)|null|
|**2025-07-13**|**GLIMPSE: Do Large Vision-Language Models Truly Think With Videos or Just Glimpse at Them?**|Huaxiu Yao Team|[2507.09491](http://arxiv.org/abs/2507.09491)|null|
|**2025-07-12**|**Uncertainty-Driven Expert Control: Enhancing the Reliability of Medical Vision-Language Models**|Tat-Seng Chua Team|[2507.09209](http://arxiv.org/abs/2507.09209)|null|
|**2025-07-12**|**MCA-LLaVA: Manhattan Causal Attention for Reducing Hallucination in Large Vision-Language Models**|Dahan Wang Team|[2507.09184](http://arxiv.org/abs/2507.09184)|null|
|**2025-07-12**|**OPENXRD: A Comprehensive Benchmark and Enhancement Framework for LLM/MLLM XRD Question Answering**|Niaz Abdolrahim Team|[2507.09155](http://arxiv.org/abs/2507.09155)|null|
|**2025-07-12**|**RadEyeVideo: Enhancing general-domain Large Vision Language Model for chest X-ray analysis with video representations of eye gaze**|Honghan Wu Team|[2507.09097](http://arxiv.org/abs/2507.09097)|null|
|**2025-07-11**|**BlindSight: Harnessing Sparsity for Efficient VLMs**|Steven K. Reinhardt Team|[2507.09071](http://arxiv.org/abs/2507.09071)|null|
|**2025-07-11**|**Beyond vividness: Content analysis of induced hallucinations reveals the hidden structure of individual differences in visual imagery**|Seana Coulson Team|[2507.09011](http://arxiv.org/abs/2507.09011)|null|
|**2025-07-11**|**VIP: Visual Information Protection through Adversarial Attacks on Vision-Language Models**|Olivier Déforges Team|[2507.08982](http://arxiv.org/abs/2507.08982)|null|
|**2025-07-11**|**ByDeWay: Boost Your multimodal LLM with DEpth prompting in a Training-Free Way**|Subarna Tripathi Team|[2507.08679](http://arxiv.org/abs/2507.08679)|null|
|**2025-07-11**|**Adaptive Framework for Ambient Intelligence in Rehabilitation Assistance**|András Lőrincz Team|[2507.08624](http://arxiv.org/abs/2507.08624)|null|
|**2025-07-11**|**Emergent Natural Language with Communication Games for Improving Image Captioning Capabilities without Additional Data**|Ambedkar Dukkipati Team|[2507.08610](http://arxiv.org/abs/2507.08610)|null|
|**2025-07-11**|**BayesTTA: Continual-Temporal Test-Time Adaptation for Vision-Language Models via Gaussian Discriminant Analysis**|Hui Xiong Team|[2507.08607](http://arxiv.org/abs/2507.08607)|null|
|**2025-07-11**|**Efficient Deployment of Vision-Language Models on Mobile Devices: A Case Study on OnePlus 13R**|Sanidhya Kashyap Team|[2507.08505](http://arxiv.org/abs/2507.08505)|null|
|**2025-07-11**|**LLaPa: A Vision-Language Model Framework for Counterfactual-Aware Procedural Planning**|Lei Fan Team|[2507.08496](http://arxiv.org/abs/2507.08496)|null|
|**2025-07-11**|**Multi-modal Mutual-Guidance Conditional Prompt Learning for Vision-Language Models**|Jianping Fan Team|[2507.08410](http://arxiv.org/abs/2507.08410)|null|
|**2025-07-11**|**Making VLMs More Robot-Friendly: Self-Critical Distillation of Low-Level Procedural Reasoning**|Yejin Choi Team|[2507.08224](http://arxiv.org/abs/2507.08224)|null|
|**2025-07-10**|**CLIP Won't Learn Object-Attribute Binding from Natural Data and Here is Why**|Thomas Brox Team|[2507.07985](http://arxiv.org/abs/2507.07985)|null|
|**2025-07-10**|**Scaling RL to Long Videos**|Song Han Team|[2507.07966](http://arxiv.org/abs/2507.07966)|null|
|**2025-07-10**|**SAGE: A Visual Language Model for Anomaly Detection via Fact Enhancement and Entropy-aware Alignment**|Lei Fan Team|[2507.07939](http://arxiv.org/abs/2507.07939)|null|
|**2025-07-10**|**MoSE: Skill-by-Skill Mixture-of-Expert Learning for Autonomous Driving**|Chao Zhang Team|[2507.07818](http://arxiv.org/abs/2507.07818)|null|
|**2025-07-10**|**Energy-Guided Decoding for Object Hallucination Mitigation**|Christopher Zach Team|[2507.07731](http://arxiv.org/abs/2507.07731)|null|
|**2025-07-10**|**One Object, Multiple Lies: A Benchmark for Cross-task Adversarial Attack on Unified Vision-Language Models**|Cairong Zhao Team|[2507.07709](http://arxiv.org/abs/2507.07709)|null|
|**2025-07-10**|**Rationale-Enhanced Decoding for Multi-modal Chain-of-Thought**|Daiki Chijiwa Team|[2507.07685](http://arxiv.org/abs/2507.07685)|null|
|**2025-07-11**|**ViLU: Learning Vision-Language Uncertainties for Failure Prediction**|Nicolas Thome Team|[2507.07620](http://arxiv.org/abs/2507.07620)|null|
|**2025-07-10**|**LOSC: LiDAR Open-voc Segmentation Consolidator**|Renaud Marlet Team|[2507.07605](http://arxiv.org/abs/2507.07605)|null|
|**2025-07-10**|**The Synergy Dilemma of Long-CoT SFT and RL: Investigating Post-Training Techniques for Reasoning VLMs**|Qun Liu Team|[2507.07562](http://arxiv.org/abs/2507.07562)|null|
|**2025-07-10**|**ArchiveGPT: A human-centered evaluation of using a vision language model for image cataloguing**|Markus Huff Team|[2507.07551](http://arxiv.org/abs/2507.07551)|null|
|**2025-07-11**|**Entity Re-identification in Visual Storytelling via Contrastive Reinforcement Learning**|David Martins de Matos Team|[2507.07340](http://arxiv.org/abs/2507.07340)|null|
|**2025-07-09**|**ADIEE: Automatic Dataset Creation and Scorer for Instruction-Guided Image Editing Evaluation**|Suren Kumar Team|[2507.07317](http://arxiv.org/abs/2507.07317)|null|
|**2025-07-09**|**LangNavBench: Evaluation of Natural Language Understanding in Semantic Navigation**|Angel X. Chang Team|[2507.07299](http://arxiv.org/abs/2507.07299)|null|
|**2025-07-09**|**MagiC: Evaluating Multimodal Cognition Toward Grounded Visual Reasoning**|Dan Goldwasser Team|[2507.07297](http://arxiv.org/abs/2507.07297)|null|
|**2025-07-09**|**4KAgent: Agentic Any Image to 4K Super-Resolution**|Zhengzhong Tu Team|[2507.07105](http://arxiv.org/abs/2507.07105)|null|
|**2025-07-14**|**Vision-Language-Vision Auto-Encoder: Scalable Knowledge Distillation from Diffusion Models**|Junfei Xiao Team|[2507.07104](http://arxiv.org/abs/2507.07104)|**[link](https://lambert-x.github.io/Vision-Language-Vision/)**|
|**2025-07-09**|**Evaluating Attribute Confusion in Fashion Text-to-Image Generation**|Davide Talon Team|[2507.07079](http://arxiv.org/abs/2507.07079)|null|
|**2025-07-09**|**Free on the Fly: Enhancing Flexibility in Test-Time Adaptation with Online EM**|Sibei Yang Team|[2507.06973](http://arxiv.org/abs/2507.06973)|null|
|**2025-07-09**|**CheXPO: Preference Optimization for Chest X-ray VLMs with Counterfactual Rationale**|Quan Wang Team|[2507.06959](http://arxiv.org/abs/2507.06959)|null|
|**2025-07-09**|**VisualTrap: A Stealthy Backdoor Attack on GUI Agents via Visual Grounding Manipulation**|Tat-Seng Chua Team|[2507.06899](http://arxiv.org/abs/2507.06899)|null|
|**2025-07-09**|**HVI-CIDNet+: Beyond Extreme Darkness for Low-Light Image Enhancement**|Yanning Zhang Team|[2507.06814](http://arxiv.org/abs/2507.06814)|null|
|**2025-07-09**|**Finetuning Vision-Language Models as OCR Systems for Low-Resource Languages: A Case Study of Manchu**|Donghyeok Choi Team|[2507.06761](http://arxiv.org/abs/2507.06761)|null|
|**2025-07-09**|**Text-promptable Object Counting via Quantity Awareness Enhancement**|Li Li Team|[2507.06679](http://arxiv.org/abs/2507.06679)|null|
|**2025-07-09**|**Cross-Modal Dual-Causal Learning for Long-Term Action Recognition**|Fan Chao Team|[2507.06603](http://arxiv.org/abs/2507.06603)|null|
|**2025-07-09**|**Bilateral Collaboration with Large Vision-Language Models for Open Vocabulary Human-Object Interaction Detection**|Xiangmin Xu Team|[2507.06510](http://arxiv.org/abs/2507.06510)|null|
|**2025-07-09**|**3D-Generalist: Self-Improving Vision-Language-Action Models for Crafting 3D Worlds**|Nick Haber Team|[2507.06484](http://arxiv.org/abs/2507.06484)|null|
|**2025-07-08**|**VisioPath: Vision-Language Enhanced Model Predictive Control for Safe Autonomous Navigation in Mixed Traffic**|Andreas A. Malikopoulos Team|[2507.06441](http://arxiv.org/abs/2507.06441)|null|
|**2025-07-08**|**CultureCLIP: Empowering CLIP with Cultural Awareness through Synthetic Images and Contextualized Captions**|Yi R. Fung Team|[2507.06210](http://arxiv.org/abs/2507.06210)|null|
|**2025-07-08**|**Enhancing Scientific Visual Question Answering through Multimodal Reasoning and Ensemble Modeling**|Naga Harshita Marupaka Team|[2507.06183](http://arxiv.org/abs/2507.06183)|null|
|**2025-07-10**|**Skywork-R1V3 Technical Report**|Yahui Zhou Team|[2507.06167](http://arxiv.org/abs/2507.06167)|null|
|**2025-07-08**|**LangMamba: A Language-driven Mamba Framework for Low-dose CT Denoising with Vision-language Models**|Hongming Shan Team|[2507.06140](http://arxiv.org/abs/2507.06140)|null|
|**2025-07-08**|**GeoMag: A Vision-Language Model for Pixel-level Fine-Grained Remote Sensing Image Parsing**|Hao Liu Team|[2507.05887](http://arxiv.org/abs/2507.05887)|null|
|**2025-07-08**|**Bridging Perception and Language: A Systematic Benchmark for LVLMs' Understanding of Amodal Completion Reports**|Hitomi Yanaka Team|[2507.05799](http://arxiv.org/abs/2507.05799)|null|
|**2025-07-08**|**SPADE: Spatial-Aware Denoising Network for Open-vocabulary Panoptic Scene Graph Generation with Long- and Local-range Context Reasoning**|Tao He Team|[2507.05798](http://arxiv.org/abs/2507.05798)|null|
|**2025-07-08**|**A Satellite-Ground Synergistic Large Vision-Language Model System for Earth Observation**|Yue Gao Team|[2507.05731](http://arxiv.org/abs/2507.05731)|null|
|**2025-07-09**|**Integrated Structural Prompt Learning for Vision-Language Models**|Bin Luo Team|[2507.05677](http://arxiv.org/abs/2507.05677)|null|
|**2025-07-08**|**R-VLM: Region-Aware Vision Language Model for Precise GUI Grounding**|Shabnam Ghadar Team|[2507.05673](http://arxiv.org/abs/2507.05673)|null|
|**2025-07-08**|**Dynamic Rank Adaptation for Vision-Language Models**|Bin Luo Team|[2507.05668](http://arxiv.org/abs/2507.05668)|null|
|**2025-07-08**|**Structured Task Solving via Modular Embodied Intelligence: A Case Study on Rubik's Cube**|Shenghai Yuan Team|[2507.05607](http://arxiv.org/abs/2507.05607)|null|
|**2025-07-08**|**Rethinking Layered Graphic Design Generation with a Top-Down Approach**|Qifeng Chen Team|[2507.05601](http://arxiv.org/abs/2507.05601)|null|
|**2025-07-08**|**PaddleOCR 3.0 Technical Report**|Yanjun Ma Team|[2507.05595](http://arxiv.org/abs/2507.05595)|null|
|**2025-07-07**|**Fine-Grained Vision-Language Modeling for Multimodal Training Assistants in Augmented Reality**|Junxiao Wang Team|[2507.05515](http://arxiv.org/abs/2507.05515)|null|
|**2025-07-07**|**Llama Nemoretriever Colembed: Top-Performing Text-Image Retrieval Model**|Even Oldridge Team|[2507.05513](http://arxiv.org/abs/2507.05513)|null|
|**2025-07-07**|**OpenWorldSAM: Extending SAM2 for Universal Image Segmentation with Language Prompts**|Priyadarshini Panda Team|[2507.05427](http://arxiv.org/abs/2507.05427)|null|
|**2025-07-07**|**pFedMMA: Personalized Federated Fine-Tuning with Multi-Modal Adapter for Vision-Language Models**|Ramtin Pedarsani Team|[2507.05394](http://arxiv.org/abs/2507.05394)|null|
|**2025-07-07**|**NavigScene: Bridging Local Perception and Global Navigation for Beyond-Visual-Range Autonomous Driving**|Cheng Lu Team|[2507.05227](http://arxiv.org/abs/2507.05227)|null|
|**2025-07-07**|**All in One: Visual-Description-Guided Unified Point Cloud Segmentation**|Rao Muhammad Anwer Team|[2507.05211](http://arxiv.org/abs/2507.05211)|null|
|**2025-07-07**|**Differential Attention for Multimodal Crisis Event Analysis**|Abdullah-Al-Zubaer Imran Team|[2507.05165](http://arxiv.org/abs/2507.05165)|null|
|**2025-07-07**|**INTER: Mitigating Hallucination in Large Vision-Language Models by Interaction Guidance Sampling**|Bo Zheng Team|[2507.05056](http://arxiv.org/abs/2507.05056)|null|
|**2025-07-07**|**Adaptation of Multi-modal Representation Models for Multi-task Surgical Computer Vision**|Nicolas Padoy Team|[2507.05020](http://arxiv.org/abs/2507.05020)|null|
|**2025-07-07**|**Training-free Generation of Temporally Consistent Rewards from VLMs**|Jian Tang Team|[2507.04789](http://arxiv.org/abs/2507.04789)|null|
|**2025-07-07**|**Vision-Language Models Can't See the Obvious**|Sanath Narayan Team|[2507.04741](http://arxiv.org/abs/2507.04741)|null|
|**2025-07-07**|**An analysis of vision-language models for fabric retrieval**|Fabio Poiesi Team|[2507.04735](http://arxiv.org/abs/2507.04735)|null|
|**2025-07-07**|**A Visual Leap in CLIP Compositionality Reasoning through Generation of Counterfactual Sets**|Jie Zhou Team|[2507.04699](http://arxiv.org/abs/2507.04699)|null|
|**2025-07-07**|**MOSU: Autonomous Long-range Robot Navigation with Multi-modal Scene Understanding**|Dinesh Manocha Team|[2507.04686](http://arxiv.org/abs/2507.04686)|null|
|**2025-07-07**|**Identify, Isolate, and Purge: Mitigating Hallucinations in LVLMs via Self-Evolving Distillation**|Chang Xu Team|[2507.04680](http://arxiv.org/abs/2507.04680)|null|
|**2025-07-06**|**VLM-TDP: VLM-guided Trajectory-conditioned Diffusion Policy for Robust Long-Horizon Manipulation**|Lei Han Team|[2507.04524](http://arxiv.org/abs/2507.04524)|null|
|**2025-07-08**|**FA: Forced Prompt Learning of Vision-Language Models for Out-of-Distribution Detection**|Ruixuan Wang Team|[2507.04511](http://arxiv.org/abs/2507.04511)|null|
|**2025-07-06**|**MVL-Loc: Leveraging Vision-Language Model for Generalizable Multi-Scene Camera Relocalization**|Changhao Chen Team|[2507.04509](http://arxiv.org/abs/2507.04509)|null|
|**2025-07-06**|**Think Twice Before You Judge: Mixture of Dual Reasoning Experts for Multimodal Sarcasm Detection**|Sanasam Ranbir Singh Team|[2507.04458](http://arxiv.org/abs/2507.04458)|null|
|**2025-07-06**|**Multi-Modal Semantic Parsing for the Interpretation of Tombstone Inscriptions**|Johan Bos Team|[2507.04377](http://arxiv.org/abs/2507.04377)|null|
|**2025-07-05**|**LVLM-Composer's Explicit Planning for Image Generation**|Amina Grant Team|[2507.04152](http://arxiv.org/abs/2507.04152)|null|
|**2025-07-05**|**Unlocking Compositional Control: Self-Supervision for LVLM-Based Image Generation**|Hunter Young Team|[2507.04151](http://arxiv.org/abs/2507.04151)|null|
|**2025-07-05**|**PresentAgent: Multimodal Agent for Presentation Video Generation**|Yang Zhao Team|[2507.04036](http://arxiv.org/abs/2507.04036)|null|
|**2025-07-05**|**A Comparative Study of Specialized LLMs as Dense Retrievers**|Jiafeng Guo Team|[2507.03958](http://arxiv.org/abs/2507.03958)|null|
|**2025-07-03**|**ArtGS:3D Gaussian Splatting for Interactive Visual-Physical Modeling and Manipulation of Articulated Objects**|Cewu Lu Team|[2507.02600](http://arxiv.org/abs/2507.02600)|null|
|**2025-07-02**|**cVLA: Towards Efficient Camera-Space VLAs**|Thomas Brox Team|[2507.02190](http://arxiv.org/abs/2507.02190)|null|
|**2025-07-02**|**Large Language Models for Crash Detection in Video: A Survey of Methods, Datasets, and Challenges**|Anuj Sharma Team|[2507.02074](http://arxiv.org/abs/2507.02074)|null|
|**2025-07-01**|**Temporal Chain of Thought: Long-Video Understanding by Thinking in Frames**|Cordelia Schmid Team|[2507.02001](http://arxiv.org/abs/2507.02001)|null|
|**2025-07-02**|**How Do Vision-Language Models Process Conflicting Information Across Modalities?**|Ellie Pavlick Team|[2507.01790](http://arxiv.org/abs/2507.01790)|null|
|**2025-07-02**|**Facial Emotion Learning with Text-Guided Multiview Fusion via Vision-Language Model for 3D/4D Facial Expression Recognition**|Muzammil Behzad Team|[2507.01673](http://arxiv.org/abs/2507.01673)|null|
|**2025-07-02**|**MARVIS: Modality Adaptive Reasoning over VISualizations**|Chinmay Hegde Team|[2507.01544](http://arxiv.org/abs/2507.01544)|null|
|**2025-07-02**|**Following the Clues: Experiments on Person Re-ID using Cross-Modal Intelligence**|Martin Schramm Team|[2507.01504](http://arxiv.org/abs/2507.01504)|null|
|**2025-07-02**|**BioMARS: A Multi-Agent Robotic System for Autonomous Biological Experiments**|Mingzhai Sun Team|[2507.01485](http://arxiv.org/abs/2507.01485)|null|
|**2025-07-03**|**TriVLA: A Triple-System-Based Unified Vision-Language-Action Model for General Robot Control**|Yanwei Fu Team|[2507.01424](http://arxiv.org/abs/2507.01424)|null|
|**2025-07-02**|**CaptionSmiths: Flexibly Controlling Language Pattern in Image Captioning**|Yoshitaka Ushiku Team|[2507.01409](http://arxiv.org/abs/2507.01409)|null|
|**2025-07-02**|**Long-Tailed Distribution-Aware Router For Mixture-of-Experts in Large Vision-Language Model**|Xi Li Team|[2507.01351](http://arxiv.org/abs/2507.01351)|null|
|**2025-07-02**|**AIGVE-MACS: Unified Multi-Aspect Commenting and Scoring Model for AI-Generated Video Evaluation**|Jiawei Zhang Team|[2507.01255](http://arxiv.org/abs/2507.01255)|null|
|**2025-07-02**|**GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning**|Jie Tang Team|[2507.01006](http://arxiv.org/abs/2507.01006)|null|
|**2025-07-04**|**Robotic Manipulation by Imitating Generated Videos Without Physical Demonstrations**|Yunzhu Li Team|[2507.00990](http://arxiv.org/abs/2507.00990)|null|
|**2025-07-01**|**Thinking Beyond Tokens: From Brain-Inspired Intelligence to Cognitive Foundations for Artificial General Intelligence and its Societal Impact**|Seyedali Mirjalili Team|[2507.00951](http://arxiv.org/abs/2507.00951)|null|
|**2025-07-01**|**The Age of Sensorial Zero Trust: Why We Can No Longer Trust Our Senses**|Fabio Correa Xavier Team|[2507.00907](http://arxiv.org/abs/2507.00907)|null|
|**2025-07-01**|**ONLY: One-Layer Intervention Sufficiently Mitigates Hallucinations in Large Vision-Language Models**|Yaqi Xie Team|[2507.00898](http://arxiv.org/abs/2507.00898)|null|
|**2025-07-01**|**GaussianVLM: Scene-centric 3D Vision-Language Models using Language-aligned Gaussian Splats for Embodied Reasoning and Beyond**|Luc Van Gool Team|[2507.00886](http://arxiv.org/abs/2507.00886)|null|
|**2025-07-01**|**UPRE: Zero-Shot Domain Adaptation for Object Detection via Unified Prompt and Representation Enhancement**|Xiangxiang Chu Team|[2507.00721](http://arxiv.org/abs/2507.00721)|null|
|**2025-07-01**|**Contrasting Cognitive Styles in Vision-Language Models: Holistic Attention in Japanese Versus Analytical Focus in English**|Rajesh Sharma Team|[2507.00700](http://arxiv.org/abs/2507.00700)|null|
|**2025-07-01**|**Context-Aware Academic Emotion Dataset and Benchmark**|Wenwu Yang Team|[2507.00586](http://arxiv.org/abs/2507.00586)|null|
|**2025-07-01**|**Not All Attention Heads Are What You Need: Refining CLIP's Image Representation with Attention Ablation**|Rong Xiao Team|[2507.00537](http://arxiv.org/abs/2507.00537)|null|
|**2025-07-01**|**Box-QAymo: Box-Referring VQA Dataset for Autonomous Driving**|Yadan Luo Team|[2507.00525](http://arxiv.org/abs/2507.00525)|null|
|**2025-06-30**|**EXPERT: An Explainable Image Captioning Evaluation Metric with Structured Explanations**|Sungzoon Cho Team|[2506.24016](http://arxiv.org/abs/2506.24016)|null|
|**2025-06-30**|**The Illusion of Progress? A Critical Look at Test-Time Adaptation for Vision-Language Models**|Tieniu Tan Team|[2506.24000](http://arxiv.org/abs/2506.24000)|null|
|**2025-06-30**|**GroundingDINO-US-SAM: Text-Prompted Multi-Organ Segmentation in Ultrasound with LoRA-Tuned Vision-Language Models**|Hassan Rivaz Team|[2506.23903](http://arxiv.org/abs/2506.23903)|null|
|**2025-06-30**|**A Closer Look at Conditional Prompt Tuning for Vision-Language Models**|Heng Tao Shen Team|[2506.23856](http://arxiv.org/abs/2506.23856)|null|
|**2025-06-30**|**Interpretable Zero-Shot Learning with Locally-Aligned Vision-Language Model**|Fahad Shahbaz Khan Team|[2506.23822](http://arxiv.org/abs/2506.23822)|null|
|**2025-06-30**|**Visual Textualization for Image Prompted Object Detection**|Yan Xu Team|[2506.23785](http://arxiv.org/abs/2506.23785)|null|
|**2025-06-30**|**PAC Bench: Do Foundation Models Understand Prerequisites for Executing Manipulation Policies?**|Ransalu Senanayake Team|[2506.23725](http://arxiv.org/abs/2506.23725)|null|
|**2025-06-30**|**On the Domain Robustness of Contrastive Vision-Language Models**|Erik Rodner Team|[2506.23663](http://arxiv.org/abs/2506.23663)|null|
|**2025-06-30**|**CAI: Caption-Sensitive Attention Intervention for Mitigating Object Hallucination in Large Vision-Language Models**|Bing Qin Team|[2506.23590](http://arxiv.org/abs/2506.23590)|null|
|**2025-06-30**|**A Clinically-Grounded Two-Stage Framework for Renal CT Report Generation**|Jie Xu Team|[2506.23584](http://arxiv.org/abs/2506.23584)|null|
|**2025-07-01**|**ZonUI-3B: A Lightweight Vision-Language Model for Cross-Resolution GUI Grounding**|ShengJing Yang Team|[2506.23491](http://arxiv.org/abs/2506.23491)|null|
|**2025-06-30**|**Sanitizing Manufacturing Dataset Labels Using Vision-Language Models**|Vinh Nguyen Team|[2506.23465](http://arxiv.org/abs/2506.23465)|null|
|**2025-06-29**|**GeoProg3D: Compositional Visual Reasoning for City-Scale 3D Language Fields**|Yutaka Matsuo Team|[2506.23352](http://arxiv.org/abs/2506.23352)|null|
|**2025-06-29**|**IR3D-Bench: Evaluating Vision-Language Model Scene Understanding as Agentic Inverse Rendering**|Brandon Y. Feng Team|[2506.23329](http://arxiv.org/abs/2506.23329)|null|
|**2025-07-01**|**SurgTPGS: Semantic 3D Surgical Scene Understanding with Text Promptable Gaussian Splatting**|Hongliang Ren Team|[2506.23309](http://arxiv.org/abs/2506.23309)|null|
|**2025-06-29**|**Decoding Memes: Benchmarking Narrative Role Classification across Multilingual and Multimodal Models**|Tanmoy Chakraborty Team|[2506.23122](http://arxiv.org/abs/2506.23122)|null|
|**2025-06-29**|**MoCa: Modality-aware Continual Pre-training Makes Better Bidirectional Multimodal Embeddings**|Zhicheng Dou Team|[2506.23115](http://arxiv.org/abs/2506.23115)|null|
|**2025-06-29**|**Empowering Small VLMs to Think with Dynamic Memorization and Exploration**|Long Chen Team|[2506.23061](http://arxiv.org/abs/2506.23061)|null|
|**2025-06-29**|**SoMi-ToM: Evaluating Multi-Perspective Theory of Mind in Embodied Social Interactions**|Maarten Sap Team|[2506.23046](http://arxiv.org/abs/2506.23046)|null|
|**2025-06-28**|**Revisiting CroPA: A Reproducibility Study and Enhancements for Cross-Prompt Adversarial Transferability in Vision-Language Models**|Swadesh Swain Team|[2506.22982](http://arxiv.org/abs/2506.22982)|null|
|**2025-06-27**|**MiCo: Multi-image Contrast for Reinforcement Visual Reasoning**|Hengshuang Zhao Team|[2506.22434](http://arxiv.org/abs/2506.22434)|null|
|**2025-06-27**|**Test-Time Consistency in Vision Language Models**|Leonid Sigal Team|[2506.22395](http://arxiv.org/abs/2506.22395)|null|
|**2025-06-27**|**Exploiting Vision Language Model for Training-Free 3D Point Cloud OOD Detection via Graph Score Propagation**|Xun Xu Team|[2506.22375](http://arxiv.org/abs/2506.22375)|null|
|**2025-06-27**|**Rethinking Visual Token Reduction in LVLMs under Cross-modal Misalignment**|Bo Du Team|[2506.22283](http://arxiv.org/abs/2506.22283)|null|
|**2025-06-27**|**COOCO -- Common Objects Out-of-Context -- Semantic Violation in Scenes: Investigating Multimodal Context in Referential Communication**|Albert Gatt Team|[2506.22274](http://arxiv.org/abs/2506.22274)|null|
|**2025-06-27**|**Visual Structures Helps Visual Reasoning: Addressing the Binding Problem in VLMs**|Mahdieh Soleymani Baghshah Team|[2506.22146](http://arxiv.org/abs/2506.22146)|null|
|**2025-06-27**|**Universal Retrieval for Multimodal Trajectory Modeling**|Dehan Kong Team|[2506.22056](http://arxiv.org/abs/2506.22056)|null|
|**2025-06-27**|**Partial CLIP is Enough: Chimera-Seg for Zero-shot Semantic Segmentation**|Daisuke Deguchi Team|[2506.22032](http://arxiv.org/abs/2506.22032)|null|
|**2025-06-27**|**SODA: Out-of-Distribution Detection in Domain-Shifted Point Clouds via Neighborhood Propagation**|Xulei Yang Team|[2506.21892](http://arxiv.org/abs/2506.21892)|null|
|**2025-06-27**|**Integrating Multi-Modal Sensors: A Review of Fusion Techniques for Intelligent Vehicles**|Matthew J. Barth Team|[2506.21885](http://arxiv.org/abs/2506.21885)|null|
|**2025-06-27**|**Do Vision-Language Models Have Internal World Models? Towards an Atomic Evaluation**|Zhiting Hu Team|[2506.21876](http://arxiv.org/abs/2506.21876)|null|
|**2025-06-27**|**On the Feasibility of Poisoning Text-to-Image AI Models via Adversarial Mislabeling**|Ben Y. Zhao Team|[2506.21874](http://arxiv.org/abs/2506.21874)|null|
|**2025-06-27**|**Remote Sensing Large Vision-Language Model: Semantic-augmented Multi-level Alignment and Semantic-aware Expert Modeling**|Yong Man Ro Team|[2506.21863](http://arxiv.org/abs/2506.21863)|null|
|**2025-06-27**|**Embodied Domain Adaptation for Object Detection**|Feras Dayoub Team|[2506.21860](http://arxiv.org/abs/2506.21860)|null|
|**2025-06-27**|**The Cost of Avoiding Backpropagation**|Hui Guan Team|[2506.21833](http://arxiv.org/abs/2506.21833)|null|
|**2025-06-26**|**ViStruct: Simulating Expert-Like Reasoning Through Task Decomposition and Visual Attention Cues**|Carolina Nobre Team|[2506.21762](http://arxiv.org/abs/2506.21762)|null|
|**2025-06-26**|**Fine-Grained Preference Optimization Improves Spatial Reasoning in VLMs**|Ismini Lourentzou Team|[2506.21656](http://arxiv.org/abs/2506.21656)|null|
|**2025-06-26**|**Mitigating Hallucination of Large Vision-Language Models via Dynamic Logits Calibration**|Jian Wu Team|[2506.21509](http://arxiv.org/abs/2506.21509)|null|
|**2025-06-26**|**Global and Local Entailment Learning for Natural World Imagery**|Nathan Jacobs Team|[2506.21476](http://arxiv.org/abs/2506.21476)|null|
|**2025-06-26**|**Spatial Mental Modeling from Limited Views**|Li Fei-Fei Team|[2506.21458](http://arxiv.org/abs/2506.21458)|null|
|**2025-06-27**|**ShotBench: Expert-Level Cinematic Understanding in Vision-Language Models**|Ziwei Liu Team|[2506.21356](http://arxiv.org/abs/2506.21356)|null|
|**2025-06-26**|**LLaVA-Pose: Enhancing Human Pose and Action Understanding via Keypoint-Integrated Instruction Tuning**|Hayaru Shouno Team|[2506.21317](http://arxiv.org/abs/2506.21317)|null|
|**2025-06-26**|**DrishtiKon: Multi-Granular Visual Grounding for Text-Rich Document Images**|Ganesh Ramakrishnan Team|[2506.21316](http://arxiv.org/abs/2506.21316)|null|
|**2025-06-26**|**World-aware Planning Narratives Enhance Large Vision-Language Model Planner**|Xipeng QIu Team|[2506.21230](http://arxiv.org/abs/2506.21230)|null|
|**2025-06-26**|**Personalized Federated Learning via Dual-Prompt Optimization and Cross Fusion**|Jian Liang Team|[2506.21144](http://arxiv.org/abs/2506.21144)|null|
|**2025-06-26**|**V2X-REALM: Vision-Language Model-Based Robust End-to-End Cooperative Autonomous Driving with Adaptive Long-Tail Modeling**|Bin Ran Team|[2506.21041](http://arxiv.org/abs/2506.21041)|null|
|**2025-06-26**|**Multimodal Prompt Alignment for Facial Expression Recognition**|Shutao Li Team|[2506.21017](http://arxiv.org/abs/2506.21017)|null|
|**2025-06-26**|**Style-Aligned Image Composition for Robust Detection of Abnormal Cells in Cytopathology**|S Kevin Zhou Team|[2506.21001](http://arxiv.org/abs/2506.21001)|null|
|**2025-06-26**|**TSDASeg: A Two-Stage Model with Direct Alignment for Interactive Point Cloud Segmentation**|Yihong Wu Team|[2506.20991](http://arxiv.org/abs/2506.20991)|null|
|**2025-06-26**|**SharpZO: Hybrid Sharpness-Aware Vision Language Model Prompt Tuning via Forward-Only Passes**|Zheng Zhang Team|[2506.20990](http://arxiv.org/abs/2506.20990)|null|
|**2025-06-26**|**Parallels Between VLA Model Post-Training and Human Motor Learning: Progress, Challenges, and Trends**|Zeng-Guang Hou Team|[2506.20966](http://arxiv.org/abs/2506.20966)|null|
|**2025-06-26**|**E-FreeM2: Efficient Training-Free Multi-Scale and Cross-Modal News Verification via MLLMs**|Minh-Son Dao Team|[2506.20944](http://arxiv.org/abs/2506.20944)|null|
|**2025-06-25**|**Leveraging Vision-Language Models to Select Trustworthy Super-Resolution Samples Generated by Diffusion Models**|Zafer Dogan Team|[2506.20832](http://arxiv.org/abs/2506.20832)|null|
|**2025-06-25**|**How do Foundation Models Compare to Skeleton-Based Approaches for Gesture Recognition in Human-Robot Interaction?**|Bastian Leibe Team|[2506.20795](http://arxiv.org/abs/2506.20795)|null|
|**2025-06-27**|**Shape2Animal: Creative Animal Generation from Natural Silhouettes**|Trung-Nghia Le Team|[2506.20616](http://arxiv.org/abs/2506.20616)|null|
|**2025-06-25**|**HRIBench: Benchmarking Vision-Language Models for Real-Time Human Perception in Human-Robot Interaction**|Maja Matarić Team|[2506.20566](http://arxiv.org/abs/2506.20566)|null|
|**2025-06-25**|**Med-Art: Diffusion Transformer for 2D Medical Text-to-Image Generation**|Morten Rieger Hannemose Team|[2506.20449](http://arxiv.org/abs/2506.20449)|null|
|**2025-06-25**|**CARMA: Context-Aware Situational Grounding of Human-Robot Group Interactions by Combining Vision-Language Models with Object and Action Recognition**|Michael Gienger Team|[2506.20373](http://arxiv.org/abs/2506.20373)|null|
|**2025-06-25**|**Mobile-R1: Towards Interactive Reinforcement Learning for VLM-Based Mobile Agent via Task-Level Rewards**|Bo Zheng Team|[2506.20332](http://arxiv.org/abs/2506.20332)|null|
|**2025-06-25**|**MIRAGE: A Benchmark for Multimodal Information-Seeking and Reasoning in Agricultural Expert-Guided Conversations**|Vikram S. Adve Team|[2506.20100](http://arxiv.org/abs/2506.20100)|null|
|**2025-06-24**|**Unified Vision-Language-Action Model**|Zhaoxiang Zhang Team|[2506.19850](http://arxiv.org/abs/2506.19850)|null|
|**2025-06-24**|**Evaluating Compliance with Visualization Guidelines in Diagrams for Scientific Publications Using Large Vision Language Models**|Christoph M. Friedrich Team|[2506.19825](http://arxiv.org/abs/2506.19825)|null|
|**2025-06-24**|**CronusVLA: Transferring Latent Motion Across Time for Multi-Frame Prediction in Manipulation**|Jiangmiao Pang Team|[2506.19816](http://arxiv.org/abs/2506.19816)|null|
|**2025-06-24**|**UltraAD: Fine-Grained Ultrasound Anomaly Classification via Few-Shot CLIP Adaptation**|Zhongliang Jiang Team|[2506.19694](http://arxiv.org/abs/2506.19694)|null|
|**2025-06-24**|**PEVLM: Parallel Encoding for Vision-Language Models**|Yong Wu Team|[2506.19651](http://arxiv.org/abs/2506.19651)|null|
|**2025-06-24**|**V2T-CoT: From Vision to Text Chain-of-Thought for Medical Reasoning and Diagnosis**|Zuozhu Liu Team|[2506.19610](http://arxiv.org/abs/2506.19610)|null|
|**2025-06-24**|**ChordPrompt: Orchestrating Cross-Modal Prompt Synergy for Multi-Domain Incremental Learning in CLIP**|Bokui Chen Team|[2506.19608](http://arxiv.org/abs/2506.19608)|null|
|**2025-06-24**|**Fake or Real, Can Robots Tell? Evaluating Embodied Vision-Language Models on Real and 3D-Printed Objects**|Angelo Cangelosi Team|[2506.19579](http://arxiv.org/abs/2506.19579)|null|
|**2025-06-24**|**Visual hallucination detection in large vision-language models via evidential conflict**|Liping Jing Team|[2506.19513](http://arxiv.org/abs/2506.19513)|null|
|**2025-06-24**|**T-Rex: Task-Adaptive Spatial Representation Extraction for Robotic Manipulation with Vision-Language Models**|Qingyao Wu Team|[2506.19498](http://arxiv.org/abs/2506.19498)|null|
|**2025-06-24**|**Emergence of Text Readability in Vision Language Models**|Bohyung Han Team|[2506.19389](http://arxiv.org/abs/2506.19389)|null|
|**2025-06-24**|**Robotic Perception with a Large Tactile-Vision-Language Model for Physical Property Inference**|Nutan Chen Team|[2506.19303](http://arxiv.org/abs/2506.19303)|null|
|**2025-06-24**|**Open-Vocabulary Camouflaged Object Segmentation with Cascaded Vision Language Models**|Dan Zeng Team|[2506.19300](http://arxiv.org/abs/2506.19300)|null|
|**2025-06-24**|**Da Yu: Towards USV-Based Image Captioning for Waterway Surveillance and Scene Understanding**|Hui Xiong Team|[2506.19288](http://arxiv.org/abs/2506.19288)|null|
|**2025-06-24**|**MSR-Align: Policy-Grounded Multimodal Alignment for Safety-Aware Reasoning in Vision-Language Models**|Bo Zheng Team|[2506.19257](http://arxiv.org/abs/2506.19257)|null|
|**2025-06-24**|**Scaffolding Dexterous Manipulation with Vision-Language Models**|Dorsa Sadigh Team|[2506.19212](http://arxiv.org/abs/2506.19212)|null|
|**2025-06-23**|**Reading Smiles: Proxy Bias in Foundation Models for Facial Emotion Recognition**|Bjoern W. Schuller Team|[2506.19079](http://arxiv.org/abs/2506.19079)|null|
|**2025-06-23**|**HAWAII: Hierarchical Visual Knowledge Transfer for Efficient Vision-Language Models**|Krzysztof Czarnecki Team|[2506.19072](http://arxiv.org/abs/2506.19072)|null|
|**2025-06-23**|**GLIMPSE: Gradient-Layer Importance Mapping for Prompted Visual Saliency Explanation for Generative LVLMs**|Guanxi Shen Team|[2506.18985](http://arxiv.org/abs/2506.18985)|null|
|**2025-06-23**|**VQ-Insight: Teaching VLMs for AI-Generated Video Quality Understanding via Progressive Visual Reinforcement Learning**|Jian Zhang Team|[2506.18564](http://arxiv.org/abs/2506.18564)|null|
|**2025-06-23**|**Generalizing Vision-Language Models to Novel Domains: A Comprehensive Survey**|Heng Tao Shen Team|[2506.18504](http://arxiv.org/abs/2506.18504)|null|
|**2025-06-23**|**InternSpatial: A Comprehensive Dataset for Spatial Reasoning in Vision-Language Models**|Wenhai Wang Team|[2506.18385](http://arxiv.org/abs/2506.18385)|null|
|**2025-06-23**|**Taming Vision-Language Models for Medical Image Analysis: A Comprehensive Review**|Jing Qin Team|[2506.18378](http://arxiv.org/abs/2506.18378)|null|
|**2025-06-23**|**Escaping the SpuriVerse: Can Large Vision-Language Models Generalize Beyond Seen Spurious Correlations?**|Bill Howe Team|[2506.18322](http://arxiv.org/abs/2506.18322)|null|
|**2025-06-24**|**Referring Expression Instance Retrieval and A Strong End-to-End Baseline**|JinQiao Wang Team|[2506.18246](http://arxiv.org/abs/2506.18246)|null|
|**2025-06-23**|**Drive-R1: Bridging Reasoning and Planning in VLMs for Autonomous Driving with Reinforcement Learning**|Xinhai Zhao Team|[2506.18234](http://arxiv.org/abs/2506.18234)|null|
|**2025-06-22**|**See-in-Pairs: Reference Image-Guided Comparative Vision-Language Models for Medical Diagnosis**|Xiaoxiao Li Team|[2506.18140](http://arxiv.org/abs/2506.18140)|null|
|**2025-06-22**|**CLGRPO: Reasoning Ability Enhancement for Small VLMs**|Zhiwang Zhang Team|[2506.18048](http://arxiv.org/abs/2506.18048)|null|
|**2025-06-22**|**Adapting Vision-Language Models for Evaluating World Models**|Sarah Parisot Team|[2506.17967](http://arxiv.org/abs/2506.17967)|null|
|**2025-06-21**|**RoboMonkey: Scaling Test-Time Sampling and Verification for Vision-Language-Action Models**|Marco Pavone Team|[2506.17811](http://arxiv.org/abs/2506.17811)|null|
|**2025-06-21**|**MDSAM:Memory-Driven Sparse Attention Matrix for LVLMs Hallucination Mitigation**|Xiaochuan Shi Team|[2506.17664](http://arxiv.org/abs/2506.17664)|null|
|**2025-06-21**|**Histopathology Image Report Generation by Vision Language Model with Multimodal In-Context Learning**|Yu-Chiang Frank Wang Team|[2506.17645](http://arxiv.org/abs/2506.17645)|null|
|**2025-06-21**|**CLiViS: Unleashing Cognitive Map through Linguistic-Visual Synergy for Embodied Visual Reasoning**|Xiaoling Wang Team|[2506.17629](http://arxiv.org/abs/2506.17629)|null|
|**2025-06-21**|**DRAMA-X: A Fine-grained Intent Prediction and Risk Reasoning Benchmark For Driving**|Zhengzhong Tu Team|[2506.17590](http://arxiv.org/abs/2506.17590)|null|
|**2025-06-21**|**HalluRNN: Mitigating Hallucinations via Recurrent Cross-Layer Reasoning in Large Vision-Language Models**|Tao He Team|[2506.17587](http://arxiv.org/abs/2506.17587)|null|
|**2025-06-20**|**Trustworthy Few-Shot Transfer of Medical VLMs through Split Conformal Prediction**|Jose Dolz Team|[2506.17503](http://arxiv.org/abs/2506.17503)|null|
|**2025-06-20**|**Few-Shot, Now for Real: Medical VLMs Adaptation without Balanced Sets or Validation**|Ismail Ben Ayed Team|[2506.17500](http://arxiv.org/abs/2506.17500)|null|
|**2025-06-20**|**General-Purpose Robotic Navigation via LVLM-Orchestrated Perception, Reasoning, and Acting**|Georgios Georgakis Team|[2506.17462](http://arxiv.org/abs/2506.17462)|null|
|**2025-06-20**|**Aha Moment Revisited: Are VLMs Truly Capable of Self Verification in Inference-time Scaling?**|Klara Nahrstedt Team|[2506.17417](http://arxiv.org/abs/2506.17417)|null|
|**2025-06-20**|**VLN-R1: Vision-Language Navigation via Reinforcement Fine-Tuning**|Hengshuang Zhao Team|[2506.17221](http://arxiv.org/abs/2506.17221)|null|
|**2025-06-20**|**Machine Mental Imagery: Empower Multimodal Reasoning with Latent Visual Tokens**|Chuang Gan Team|[2506.17218](http://arxiv.org/abs/2506.17218)|null|
|**2025-06-20**|**Do We Need Large VLMs for Spotting Soccer Actions?**|Sandeep Chaurasia Team|[2506.17144](http://arxiv.org/abs/2506.17144)|null|
|**2025-06-20**|**Prmpt2Adpt: Prompt-Based Zero-Shot Domain Adaptation for Resource-Constrained Environments**|Nathaniel D. Bastian Team|[2506.16994](http://arxiv.org/abs/2506.16994)|null|
|**2025-06-20**|**FOCUS: Unified Vision-Language Modeling for Interactive Editing Driven by Referential Segmentation**|Jinqiao Wang Team|[2506.16806](http://arxiv.org/abs/2506.16806)|null|
|**2025-06-20**|**Co-VisiON: Co-Visibility ReasONing on Sparse Image Sets of Indoor Scenes**|Chen Feng Team|[2506.16805](http://arxiv.org/abs/2506.16805)|null|
|**2025-06-20**|**Cross-Modal Obfuscation for Jailbreak Attacks on Large Vision-Language Models**|Xiaohua Xu Team|[2506.16760](http://arxiv.org/abs/2506.16760)|null|
|**2025-06-20**|**TeSG: Textual Semantic Guidance for Infrared and Visible Image Fusion**|Xinbo Gao Team|[2506.16730](http://arxiv.org/abs/2506.16730)|null|
|**2025-06-20**|**V-CASS: Vision-context-aware Expressive Speech Synthesis for Enhancing User Understanding of Videos**|Xiaoyu Qin Team|[2506.16716](http://arxiv.org/abs/2506.16716)|null|
|**2025-06-20**|**VLM-Empowered Multi-Mode System for Efficient and Safe Planetary Navigation**|Liang Ding Team|[2506.16703](http://arxiv.org/abs/2506.16703)|null|
|**2025-06-20**|**LaVi: Efficient Large Vision-Language Models via Internal Feature Modulation**|Jing Liu Team|[2506.16691](http://arxiv.org/abs/2506.16691)|null|
|**2025-06-19**|**CodeDiffuser: Attention-Enhanced Diffusion Policy via VLM-Generated Code for Instruction Ambiguity**|Yunzhu Li Team|[2506.16652](http://arxiv.org/abs/2506.16652)|null|
|**2025-06-19**|**History-Augmented Vision-Language Models for Frontier-Based Zero-Shot Object Navigation**|Fatemeh Afghah Team|[2506.16623](http://arxiv.org/abs/2506.16623)|null|
|**2025-06-19**|**GoalLadder: Incremental Goal Discovery with Vision-Language Models**|Shimon Whiteson Team|[2506.16396](http://arxiv.org/abs/2506.16396)|null|
|**2025-06-19**|**CLIP-MG: Guiding Semantic Attention with Skeletal Pose Features and RGB Data for Micro-Gesture Recognition on the iMiGUE Dataset**|Amith Adiraju Team|[2506.16385](http://arxiv.org/abs/2506.16385)|null|
|**2025-06-19**|**FOCoOp: Enhancing Out-of-Distribution Robustness in Federated Prompt Learning for Vision-Language Models**|Tat-Seng Chua Team|[2506.16218](http://arxiv.org/abs/2506.16218)|null|
|**2025-06-19**|**AutoV: Learning to Retrieve Visual Prompt for Large Vision-Language Models**|Shanghang Zhang Team|[2506.16112](http://arxiv.org/abs/2506.16112)|null|
|**2025-06-19**|**Stepping Out of Similar Semantic Space for Open-Vocabulary Segmentation**|Yansong Tang Team|[2506.16058](http://arxiv.org/abs/2506.16058)|null|
|**2025-06-19**|**DualTHOR: A Dual-Arm Humanoid Simulation Platform for Contingency-Aware Planning**|Zongqing Lu Team|[2506.16012](http://arxiv.org/abs/2506.16012)|null|
|**2025-06-18**|**VectorEdits: A Dataset and Benchmark for Instruction-Based Editing of Vector Graphics**|Michal Štefánik Team|[2506.15903](http://arxiv.org/abs/2506.15903)|null|
|**2025-06-18**|**GenRecal: Generation after Recalibration from Large to Small Vision-Language Models**|Yueh-Hua Wu Team|[2506.15681](http://arxiv.org/abs/2506.15681)|null|
|**2025-06-18**|**Dual-Stage Value-Guided Inference with Margin-Based Reward Adjustment for Fast and Faithful VLM Captioning**|Imran Razzak Team|[2506.15649](http://arxiv.org/abs/2506.15649)|null|
|**2025-06-18**|**FindingDory: A Benchmark to Evaluate Memory in Embodied Agents**|Zsolt Kira Team|[2506.15635](http://arxiv.org/abs/2506.15635)|null|
|**2025-06-18**|**WikiMixQA: A Multimodal Benchmark for Question Answering over Tables and Charts**|Rémi Lebret Team|[2506.15594](http://arxiv.org/abs/2506.15594)|**[link](https://github.com/negar-foroutan/wikimixqa)**|
|**2025-06-18**|**DiscoSG: Towards Discourse-Level Text Scene Graph Parsing through Iterative Graph Refinement**|Zhuang Li Team|[2506.15583](http://arxiv.org/abs/2506.15583)|**[link](https://github.com/shaoqlin/discosg)**|
|**2025-06-18**|**Context-Informed Grounding Supervision**|Minjoon Seo Team|[2506.15480](http://arxiv.org/abs/2506.15480)|**[link](https://github.com/kaistai/cings)**|
|**2025-06-19**|**OpenPath: Open-Set Active Learning for Pathology Image Classification via Pre-trained Vision-Language Models**|Guotai Wang Team|[2506.15318](http://arxiv.org/abs/2506.15318)|null|
|**2025-06-18**|**MEGC2025: Micro-Expression Grand Challenge on Spot Then Recognize and Visual Question Answering**|Adrian K. Davision Team|[2506.15298](http://arxiv.org/abs/2506.15298)|null|
|**2025-06-18**|**ReSeDis: A Dataset for Referring-based Object Search across Large-Scale Image Collections**|Shin'ichi Satoh Team|[2506.15180](http://arxiv.org/abs/2506.15180)|null|
|**2025-06-18**|**DyNaVLM: Zero-Shot Vision-Language Navigation System with Dynamic Viewpoints and Self-Refining Graph Memory**|Yue Gao Team|[2506.15096](http://arxiv.org/abs/2506.15096)|null|
|**2025-06-18**|**An Empirical Study of Bugs in Data Visualization Libraries**|Chengnian Sun Team|[2506.15084](http://arxiv.org/abs/2506.15084)|**[link](https://github.com/williamlus/dataviz-lib-bugs)**|
|**2025-06-17**|**PeRL: Permutation-Enhanced Reinforcement Learning for Interleaved Vision-Language Reasoning**|Yeyun Gong Team|[2506.14907](http://arxiv.org/abs/2506.14907)|**[link](https://github.com/alchemistyzz/perl)**|
|**2025-06-17**|**RobotSmith: Generative Robotic Tool Design for Acquisition of Complex Manipulation Skills**|Chuang Gan Team|[2506.14763](http://arxiv.org/abs/2506.14763)|null|
|**2025-06-17**|**Casper: Inferring Diverse Intents for Assistive Teleoperation with Vision Language Models**|Yuke Zhu Team|[2506.14727](http://arxiv.org/abs/2506.14727)|null|
|**2025-06-17**|**AGENTSAFE: Benchmarking the Safety of Embodied Agents on Hazardous Instructions**|Dacheng Tao Team|[2506.14697](http://arxiv.org/abs/2506.14697)|null|
|**2025-06-17**|**Recognition through Reasoning: Reinforcing Image Geo-localization with Large Vision-Language Models**|Jiaheng Wei Team|[2506.14674](http://arxiv.org/abs/2506.14674)|null|
|**2025-06-17**|**StreetLens: Enabling Human-Centered AI Agents for Neighborhood Assessment from Street View Imagery**|Michelle Pasco Team|[2506.14670](http://arxiv.org/abs/2506.14670)|null|
|**2025-06-17**|**SIRI-Bench: Challenging VLMs' Spatial Intelligence through Complex Reasoning Tasks**|Liang Lin Team|[2506.14512](http://arxiv.org/abs/2506.14512)|null|
|**2025-06-17**|**Can Pretrained Vision-Language Embeddings Alone Guide Robot Navigation?**|Soumik Sarkar Team|[2506.14507](http://arxiv.org/abs/2506.14507)|**[link](https://github.com/oadamharoon/text2nav)**|
|**2025-06-17**|**Adapting Lightweight Vision Language Models for Radiological Visual Question Answering**|Chang Sun Team|[2506.14451](http://arxiv.org/abs/2506.14451)|null|
|**2025-06-17**|**Causally Steered Diffusion for Automated Video Counterfactual Generation**|Sotirios A. Tsaftaris Team|[2506.14404](http://arxiv.org/abs/2506.14404)|null|
|**2025-06-17**|**Narrate2Nav: Real-Time Visual Navigation with Implicit Language Reasoning in Human-Centric Environments**|Xuesu Xiao Team|[2506.14233](http://arxiv.org/abs/2506.14233)|null|
|**2025-06-17**|**Interpreting Biomedical VLMs on High-Imbalance Out-of-Distributions: An Insight into BiomedCLIP on Radiology**|Benjamin Kwan Team|[2506.14136](http://arxiv.org/abs/2506.14136)|null|
|**2025-06-17**|**A Hierarchical Test Platform for Vision Language Model (VLM)-Integrated Real-World Autonomous Driving**|Ziran Wang Team|[2506.14100](http://arxiv.org/abs/2506.14100)|null|
|**2025-06-16**|**Disentangling 3D from Large Vision-Language Models for Controlled Portrait Generation**|Hyeongwoo Kim Team|[2506.14015](http://arxiv.org/abs/2506.14015)|null|
|**2025-06-16**|**GRaD-Nav++: Vision-Language Model Enabled Visual Drone Navigation with Gaussian Radiance Fields and Differentiable Dynamics**|Mac Schwager Team|[2506.14009](http://arxiv.org/abs/2506.14009)|null|
|**2025-06-16**|**Comparison of ConvNeXt and Vision-Language Models for Breast Density Assessment in Screening Mammography**|Alejandro Santos-Díaz Team|[2506.13964](http://arxiv.org/abs/2506.13964)|null|
|**2025-06-16**|**HierVL: Semi-Supervised Segmentation leveraging Hierarchical Vision-Language Synergy with Dynamic Text-Spatial Query Alignment**|Abdul Bais Team|[2506.13925](http://arxiv.org/abs/2506.13925)|null|
|**2025-06-16**|**Touch begins where vision ends: Generalizable policies for contact-rich manipulation**|Raunaq Bhirangi Team|[2506.13762](http://arxiv.org/abs/2506.13762)|null|
|**2025-06-16**|**Prompting with the Future: Open-World Model Predictive Control with Interactive Digital Twins**|Wei-Chiu Ma Team|[2506.13761](http://arxiv.org/abs/2506.13761)|null|
|**2025-06-16**|**OTFusion: Bridging Vision-only and Vision-Language Models via Optimal Transport for Transductive Zero-Shot Learning**|Yonghang Tai Team|[2506.13723](http://arxiv.org/abs/2506.13723)|null|
|**2025-06-16**|**ROSA: Harnessing Robot States for Vision-Language and Action Alignment**|Xiaoyan Sun Team|[2506.13679](http://arxiv.org/abs/2506.13679)|null|
|**2025-06-16**|**DualEdit: Dual Editing for Knowledge Updating in Vision-Language Models**|Hanspeter Pfister Team|[2506.13638](http://arxiv.org/abs/2506.13638)|null|
|**2025-06-16**|**VLM-SFD: VLM-Assisted Siamese Flow Diffusion Framework for Dual-Arm Cooperative Manipulation**|Wei Pan Team|[2506.13428](http://arxiv.org/abs/2506.13428)|null|
|**2025-06-16**|**Uncertainty-Informed Active Perception for Open Vocabulary Object Goal Navigation**|Marija Popović Team|[2506.13367](http://arxiv.org/abs/2506.13367)|null|
|**2025-06-16**|**Anomaly Object Segmentation with Vision-Language Models for Steel Scrap Recycling**|Rei Kawakami Team|[2506.13282](http://arxiv.org/abs/2506.13282)|null|
|**2025-06-16**|**Screen Hijack: Visual Poisoning of VLM Agents in Mobile Environments**|Ee-Chien Chang Team|[2506.13205](http://arxiv.org/abs/2506.13205)|null|
|**2025-06-16**|**Dynamic Context-oriented Decomposition for Task-aware Low-rank Adaptation with Less Forgetting and Faster Convergence**|Bernard Ghanem Team|[2506.13187](http://arxiv.org/abs/2506.13187)|null|
|**2025-06-16**|**GreedyPrune: Retenting Critical Visual Token Set for Large Vision Language Models**|Jun Wang Team|[2506.13166](http://arxiv.org/abs/2506.13166)|null|
|**2025-06-16**|**Rethinking Test-Time Scaling for Medical AI: Model and Task-Aware Strategies for LLMs and VLMs**|Byung-Hoon Kim Team|[2506.13102](http://arxiv.org/abs/2506.13102)|null|
|**2025-06-16**|**PRISM2: Unlocking Multi-Modal General Pathology AI with Clinical Dialogue**|Siqi Liu Team|[2506.13063](http://arxiv.org/abs/2506.13063)|null|
|**2025-06-17**|**HKD4VLM: A Progressive Hybrid Knowledge Distillation Framework for Robust Multimodal Hallucination and Factuality Detection in VLMs**|Xuezhi Cao Team|[2506.13038](http://arxiv.org/abs/2506.13038)|null|
|**2025-06-15**|**CAPO: Reinforcing Consistent Reasoning in Medical Decision-Making**|Zuozhu Liu Team|[2506.12849](http://arxiv.org/abs/2506.12849)|null|
|**2025-06-15**|**Enhancing Rating-Based Reinforcement Learning to Effectively Leverage Feedback from Large Vision-Language Models**|Chang D. Yoo Team|[2506.12822](http://arxiv.org/abs/2506.12822)|null|
|**2025-06-15**|**Native Visual Understanding: Resolving Resolution Dilemmas in Vision-Language Models**|Wentao Zhang Team|[2506.12776](http://arxiv.org/abs/2506.12776)|null|
|**2025-06-15**|**NAP-Tuning: Neural Augmented Prompt Tuning for Adversarially Robust Vision-Language Models**|Jitao Sang Team|[2506.12706](http://arxiv.org/abs/2506.12706)|null|
|**2025-06-15**|**Evaluating Cell Type Inference in Vision Language Models Under Varying Visual Context**|Sandeep Singhal Team|[2506.12683](http://arxiv.org/abs/2506.12683)|null|
|**2025-06-14**|**Not All Tokens and Heads Are Equally Important: Dual-Level Attention Intervention for Hallucination Mitigation**|Yuexian Zou Team|[2506.12609](http://arxiv.org/abs/2506.12609)|null|
|**2025-06-13**|**Affogato: Learning Open-Vocabulary Affordance Grounding with Automated Data Generation at Scale**|Minsu Cho Team|[2506.12009](http://arxiv.org/abs/2506.12009)|null|
|**2025-06-13**|**How Visual Representations Map to Language Feature Space in Multimodal LLMs**|Neel Nanda Team|[2506.11976](http://arxiv.org/abs/2506.11976)|null|
|**2025-06-13**|**Rethinking Multilingual Vision-Language Translation: Dataset, Evaluation, and Adaptation**|Kaifu Zhang Team|[2506.11820](http://arxiv.org/abs/2506.11820)|null|
|**2025-06-13**|**MTabVQA: Evaluating Multi-Tabular Reasoning of Language Models in Visual Space**|Jan Strich Team|[2506.11684](http://arxiv.org/abs/2506.11684)|null|
|**2025-06-13**|**VLM@school -- Evaluation of AI image understanding on German middle school knowledge**|Vincent Tischler Team|[2506.11604](http://arxiv.org/abs/2506.11604)|null|
|**2025-06-16**|**EasyARC: Evaluating Vision Language Models on True Visual Reasoning**|Aylin Akkus Team|[2506.11595](http://arxiv.org/abs/2506.11595)|null|
|**2025-06-13**|**Foundation Models in Autonomous Driving: A Survey on Scenario Generation and Scenario Analysis**|Johannes Betz Team|[2506.11526](http://arxiv.org/abs/2506.11526)|null|
|**2025-06-13**|**Manager: Aggregating Insights from Unimodal Experts in Two-Tower VLMs and MLLMs**|Min-Yen Kan Team|[2506.11515](http://arxiv.org/abs/2506.11515)|null|
|**2025-06-13**|**Taming Stable Diffusion for Computed Tomography Blind Super-Resolution**|Lichao Mou Team|[2506.11496](http://arxiv.org/abs/2506.11496)|null|
|**2025-06-13**|**On the Natural Robustness of Vision-Language Models Against Visual Perception Attacks in Autonomous Driving**|Mert D. Pesé Team|[2506.11472](http://arxiv.org/abs/2506.11472)|null|
|**2025-06-12**|**Poutine: Vision-Language-Trajectory Pre-Training and Reinforcement Learning Post-Training Enable Robust End-to-End Autonomous Driving**|Liam Paull Team|[2506.11234](http://arxiv.org/abs/2506.11234)|null|
|**2025-06-12**|**AIR: Zero-shot Generative Model Adaptation with Iterative Refinement**|Ngai-Man Cheung Team|[2506.10895](http://arxiv.org/abs/2506.10895)|**[link](https://github.com/guimeng-leo-liu/air)**|
|**2025-06-13**|**RationalVLA: A Rational Vision-Language-Action Model with Dual System**|Haoang Li Team|[2506.10826](http://arxiv.org/abs/2506.10826)|null|
|**2025-06-12**|**Grounded Vision-Language Navigation for UAVs with Open-Vocabulary Goal Understanding**|Mir Feroskhan Team|[2506.10756](http://arxiv.org/abs/2506.10756)|null|
|**2025-06-13**|**IQE-CLIP: Instance-aware Query Embedding for Zero-/Few-shot Anomaly Detection in Medical Domain**|Yefeng Zheng Team|[2506.10730](http://arxiv.org/abs/2506.10730)|**[link](https://github.com/hongh0/iqe-clip)**|
|**2025-06-12**|**GigaVideo-1: Advancing Video Generation via Automatic Feedback with 4 GPU-Hours Fine-Tuning**|Guan Huang Team|[2506.10639](http://arxiv.org/abs/2506.10639)|null|
|**2025-06-12**|**Text to Image for Multi-Label Image Recognition with Joint Prompt-Adapter Learning**|Yong Liu Team|[2506.10575](http://arxiv.org/abs/2506.10575)|null|
|**2025-06-12**|**LLMs Are Not Yet Ready for Deepfake Image Detection**|Kristen Moore Team|[2506.10474](http://arxiv.org/abs/2506.10474)|null|
|**2025-06-12**|**UrbanSense:AFramework for Quantitative Analysis of Urban Streetscapes leveraging Vision Large Language Models**|Shuai Lu Team|[2506.10342](http://arxiv.org/abs/2506.10342)|null|
|**2025-06-12**|**Using Vision Language Models to Detect Students' Academic Emotion through Facial Expressions**|Gaowei Chen Team|[2506.10334](http://arxiv.org/abs/2506.10334)|null|
|**2025-06-12**|**HalLoc: Token-level Localization of Hallucinations for Vision Language Models**|Gunhee Kim Team|[2506.10286](http://arxiv.org/abs/2506.10286)|null|
|**2025-06-11**|**Q2E: Query-to-Event Decomposition for Zero-Shot Multilingual Text-to-Video Retrieval**|Francis Ferraro Team|[2506.10202](http://arxiv.org/abs/2506.10202)|null|
|**2025-06-11**|**Improving Personalized Search with Regularized Low-Rank Parameter Updates**|Bryan Russell Team|[2506.10182](http://arxiv.org/abs/2506.10182)|null|
|**2025-06-11**|**A Navigation Framework Utilizing Vision-Language Models**|Kaiyu tang Team|[2506.10172](http://arxiv.org/abs/2506.10172)|null|
|**2025-06-11**|**One Patient, Many Contexts: Scaling Medical AI Through Contextual Intelligence**|Marinka Zitnik Team|[2506.10157](http://arxiv.org/abs/2506.10157)|null|
|**2025-06-11**|**ViCrit: A Verifiable Reinforcement Learning Proxy Task for Visual Perception in VLMs**|Lijuan Wang Team|[2506.10128](http://arxiv.org/abs/2506.10128)|null|
|**2025-06-11**|**Test-Time Adaptation for Generalizable Task Progress Estimation**|Alessandra Russo Team|[2506.10085](http://arxiv.org/abs/2506.10085)|null|
|**2025-06-11**|**Reinforcing Spatial Reasoning in Vision-Language Models with Interwoven Thinking and Visual Drawing**|Tieniu Tan Team|[2506.09965](http://arxiv.org/abs/2506.09965)|**[link](https://github.com/antresearchnlp/vilasr)**|
|**2025-06-11**|**From Intention to Execution: Probing the Generalization Boundaries of Vision-Language-Action Models**|Chen Feng Team|[2506.09930](http://arxiv.org/abs/2506.09930)|null|
|**2025-06-11**|**3D-Aware Vision-Language Models Fine-Tuning with Geometric Distillation**|Hyunjung Shim Team|[2506.09883](http://arxiv.org/abs/2506.09883)|**[link](https://github.com/kaist-cvml/3d-vlm-gd)**|
|**2025-06-11**|**Adding simple structure at inference improves Vision-Language Compositionality**|Gorka Azkune Team|[2506.09691](http://arxiv.org/abs/2506.09691)|**[link](https://github.com/imirandam/structure-inference-compositionality)**|
|**2025-06-11**|**FedVLMBench: Benchmarking Federated Fine-Tuning of Vision-Language Models**|Liangqiong Qu Team|[2506.09638](http://arxiv.org/abs/2506.09638)|null|
|**2025-06-11**|**Revisit What You See: Disclose Language Prior in Vision Tokens for Efficient Guided Decoding of LVLMs**|Jaehyung Kim Team|[2506.09522](http://arxiv.org/abs/2506.09522)|**[link](https://github.com/bscho333/ReVisiT)**|
|**2025-06-11**|**Provoking Multi-modal Few-Shot LVLM via Exploration-Exploitation In-Context Learning**|Jia Li Team|[2506.09473](http://arxiv.org/abs/2506.09473)|null|
|**2025-06-11**|**TOGA: Temporally Grounded Open-Ended Video QA with Weak Supervision**|Susmit Jha Team|[2506.09445](http://arxiv.org/abs/2506.09445)|null|
|**2025-06-11**|**DAVSP: Safety Alignment for Large Vision-Language Models via Deep Aligned Visual Safety Prompt**|Ge Li Team|[2506.09353](http://arxiv.org/abs/2506.09353)|null|
|**2025-06-10**|**UAD: Unsupervised Affordance Distillation for Generalization in Robotic Manipulation**|Li Fei-Fei Team|[2506.09284](http://arxiv.org/abs/2506.09284)|null|
|**2025-06-10**|**MultiNet: An Open-Source Software Toolkit \& Benchmark Suite for the Evaluation and Adaptation of Multimodal Action Models**|Harshvardhan Sikka Team|[2506.09172](http://arxiv.org/abs/2506.09172)|null|
|**2025-06-10**|**VIKI-R: Coordinating Embodied Multi-Agent Cooperation via Reinforcement Learning**|Zhenfei Yin Team|[2506.09049](http://arxiv.org/abs/2506.09049)|null|
|**2025-06-11**|**Same Task, Different Circuits: Disentangling Modality-Specific Mechanisms in VLMs**|Yonatan Belinkov Team|[2506.09047](http://arxiv.org/abs/2506.09047)|null|
|**2025-06-10**|**Autoregressive Semantic Visual Reconstruction Helps VLMs Understand Better**|Jiaqi Wang Team|[2506.09040](http://arxiv.org/abs/2506.09040)|null|
|**2025-06-10**|**Efficient Medical Vision-Language Alignment Through Adapting Masked Vision Models**|Liansheng Wang Team|[2506.08990](http://arxiv.org/abs/2506.08990)|null|
|**2025-06-10**|**Socratic-MCTS: Test-Time Visual Reasoning by Asking the Right Questions**|Yejin Choi Team|[2506.08927](http://arxiv.org/abs/2506.08927)|null|
|**2025-06-12**|**Video-CoT: A Comprehensive Dataset for Spatiotemporal Understanding of Videos Based on Chain-of-Thought**|Shanghang Zhang Team|[2506.08817](http://arxiv.org/abs/2506.08817)|null|
|**2025-06-10**|**Multimodal Representation Alignment for Cross-modal Information Retrieval**|Luis A. Leiva Team|[2506.08774](http://arxiv.org/abs/2506.08774)|null|
|**2025-06-10**|**PhyBlock: A Progressive Benchmark for Physical Understanding and Planning via 3D Block Assembly**|Xiaodan Liang Team|[2506.08708](http://arxiv.org/abs/2506.08708)|null|
|**2025-06-10**|**VReST: Enhancing Reasoning in Large Vision-Language Models through Tree Search and Self-Reward Mechanism**|Weijiang Yu Team|[2506.08691](http://arxiv.org/abs/2506.08691)|null|
|**2025-06-10**|**ATAS: Any-to-Any Self-Distillation for Enhanced Open-Vocabulary Dense Prediction**|Taesup Kim Team|[2506.08678](http://arxiv.org/abs/2506.08678)|null|
|**2025-06-10**|**Convergence of Spectral Principal Paths: How Deep Networks Distill Linear Representations from Noisy Inputs**|Ang Li Team|[2506.08543](http://arxiv.org/abs/2506.08543)|null|
|**2025-06-10**|**Better Reasoning with Less Data: Enhancing VLMs Through Unified Modality Scoring**|Jiaheng Wei Team|[2506.08429](http://arxiv.org/abs/2506.08429)|null|
|**2025-06-11**|**SafeCoT: Improving VLM Safety with Minimal Reasoning**|Chaochao Lu Team|[2506.08399](http://arxiv.org/abs/2506.08399)|null|
|**2025-06-10**|**SECOND: Mitigating Perceptual Hallucination in Vision-Language Models via Selective and Contrastive Decoding**|Jaeyoung Do Team|[2506.08391](http://arxiv.org/abs/2506.08391)|null|
|**2025-06-09**|**A Good CREPE needs more than just Sugar: Investigating Biases in Compositional Vision-Language Benchmarks**|Matthias Bethge Team|[2506.08227](http://arxiv.org/abs/2506.08227)|null|
|**2025-06-11**|**GIQ: Benchmarking 3D Geometric Reasoning of Vision Foundation Models with Simulated and Real Polyhedra**|Guha Balakrishnan Team|[2506.08194](http://arxiv.org/abs/2506.08194)|null|
|**2025-06-09**|**Open World Scene Graph Generation using Vision Language Models**|Anuj Karpatne Team|[2506.08189](http://arxiv.org/abs/2506.08189)|null|
|**2025-06-09**|**CuRe: Cultural Gaps in the Long Tail of Text-to-Image Systems**|Ramya Korlakai Vinayak Team|[2506.08071](http://arxiv.org/abs/2506.08071)|null|
|**2025-06-10**|**Vision Transformers Don't Need Trained Registers**|Yossi Gandelsman Team|[2506.08010](http://arxiv.org/abs/2506.08010)|null|
|**2025-06-09**|**Hidden in plain sight: VLMs overlook their visual representations**|Trevor Darrell Team|[2506.08008](http://arxiv.org/abs/2506.08008)|null|
|**2025-06-09**|**BridgeVLA: Input-Output Alignment for Efficient 3D Manipulation Learning with Vision-Language Models**|Tieniu Tan Team|[2506.07961](http://arxiv.org/abs/2506.07961)|null|
|**2025-06-09**|**Decoupling the Image Perception and Multimodal Reasoning for Reasoning Segmentation with Digital Twin Representations**|Yiqing Shen Team|[2506.07943](http://arxiv.org/abs/2506.07943)|null|
|**2025-06-09**|**Mimicking or Reasoning: Rethinking Multi-Modal In-Context Learning in Vision-Language Models**|Zsolt Kira Team|[2506.07936](http://arxiv.org/abs/2506.07936)|null|
|**2025-06-09**|**SAM2Auto: Auto Annotation Using FLASH**|Q. M. Jonathan Wu Team|[2506.07850](http://arxiv.org/abs/2506.07850)|null|
|**2025-06-09**|**Image Reconstruction as a Tool for Feature Analysis**|Andrey Kuznetsov Team|[2506.07803](http://arxiv.org/abs/2506.07803)|null|
|**2025-06-09**|**Re-ranking Reasoning Context with Tree Search Makes Large Vision-Language Models Stronger**|Shiming Xiang Team|[2506.07785](http://arxiv.org/abs/2506.07785)|null|
|**2025-06-09**|**Language-Vision Planner and Executor for Text-to-Visual Reasoning**|Ling Liu Team|[2506.07778](http://arxiv.org/abs/2506.07778)|null|
|**2025-06-10**|**ArchiLense: A Framework for Quantitative Analysis of Architectural Styles Based on Vision Large Language Models**|Shuai Lu Team|[2506.07739](http://arxiv.org/abs/2506.07739)|null|
|**2025-06-09**|**OpenSplat3D: Open-Vocabulary 3D Instance Segmentation using Gaussian Splatting**|Bastian Leibe Team|[2506.07697](http://arxiv.org/abs/2506.07697)|null|
|**2025-06-09**|**Unblocking Fine-Grained Evaluation of Detailed Captions: An Explaining AutoRater and Critic-and-Revise Pipeline**|Idan Szpektor Team|[2506.07631](http://arxiv.org/abs/2506.07631)|null|
|**2025-06-09**|**Event-Priori-Based Vision-Language Model for Efficient Visual Understanding**|Michele Magno Team|[2506.07627](http://arxiv.org/abs/2506.07627)|null|
|**2025-06-10**|**SAFEFLOW: A Principled Protocol for Trustworthy and Transactional Autonomous Agent Systems**|Zhengzhong Tu Team|[2506.07564](http://arxiv.org/abs/2506.07564)|null|
|**2025-06-10**|**GTR-CoT: Graph Traversal as Visual Chain of Thought for Molecular Structure Recognition**|Conghui He Team|[2506.07553](http://arxiv.org/abs/2506.07553)|null|
|**2025-06-09**|**Taking Flight with Dialogue: Enabling Natural Language Control for PX4-based Drone Agent**|Ting Yang Ling Team|[2506.07509](http://arxiv.org/abs/2506.07509)|null|
|**2025-06-09**|**Genesis: Multimodal Driving Scene Generation with Spatio-Temporal and Cross-Modal Consistency**|Xinggang Wang Team|[2506.07497](http://arxiv.org/abs/2506.07497)|null|
|**2025-06-09**|**CoCoA-Mix: Confusion-and-Confidence-Aware Mixture Model for Context Optimization**|Hyun Myung Team|[2506.07484](http://arxiv.org/abs/2506.07484)|null|
|**2025-06-09**|**LiteVLM: A Low-Latency Vision-Language Model Inference Pipeline for Resource-Constrained Environments**|Josh Park Team|[2506.07416](http://arxiv.org/abs/2506.07416)|null|
|**2025-06-09**|**MrM: Black-Box Membership Inference Attacks against Multimodal RAG Systems**|Tao Qi Team|[2506.07399](http://arxiv.org/abs/2506.07399)|null|
|**2025-06-06**|**CoMemo: LVLMs Need Image Context with Image Memory**|Jifeng Dai Team|[2506.06279](http://arxiv.org/abs/2506.06279)|null|
|**2025-06-06**|**Movie Facts and Fibs (MF $^2$ ): A Benchmark for Long Movie Understanding**|André F. T. Martins Team|[2506.06275](http://arxiv.org/abs/2506.06275)|null|
|**2025-06-06**|**Challenging Vision-Language Models with Surgical Data: A New Dataset and Broad Benchmarking Study**|Lena Maier-Hein Team|[2506.06232](http://arxiv.org/abs/2506.06232)|null|
|**2025-06-06**|**GenIR: Generative Visual Feedback for Mental Image Retrieval**|James Davis Team|[2506.06220](http://arxiv.org/abs/2506.06220)|null|
|**2025-06-06**|**STSBench: A Spatio-temporal Scenario Benchmark for Multi-modal Large Language Models in Autonomous Driving**|Horst Possegger Team|[2506.06218](http://arxiv.org/abs/2506.06218)|null|
|**2025-06-06**|**WisWheat: A Three-Tiered Vision-Language Dataset for Wheat Management**|Zijian Wang Team|[2506.06084](http://arxiv.org/abs/2506.06084)|null|
|**2025-06-06**|**Full Conformal Adaptation of Medical Vision-Language Models**|Jose Dolz Team|[2506.06076](http://arxiv.org/abs/2506.06076)|null|
|**2025-06-06**|**BEAST: Efficient Tokenization of B-Splines Encoded Action Sequences for Imitation Learning**|Rudolf Lioutikov Team|[2506.06072](http://arxiv.org/abs/2506.06072)|null|
|**2025-06-06**|**MCA-Bench: A Multimodal Benchmark for Evaluating CAPTCHA Robustness Against VLM-based Attacks**|Yiren Song Team|[2506.05982](http://arxiv.org/abs/2506.05982)|null|
|**2025-06-06**|**HMVLM: Multistage Reasoning-Enhanced Vision-Language Model for Long-Tailed Driving Scenarios**|Weihao Gu Team|[2506.05883](http://arxiv.org/abs/2506.05883)|null|
|**2025-06-06**|**Do Large Vision-Language Models Distinguish between the Actual and Apparent Features of Illusions?**|Hitomi Yanaka Team|[2506.05765](http://arxiv.org/abs/2506.05765)|null|
|**2025-06-06**|**MoralCLIP: Contrastive Alignment of Vision-and-Language Representations with Moral Foundations Theory**|João Magalhães Team|[2506.05696](http://arxiv.org/abs/2506.05696)|null|
|**2025-06-06**|**DriveAction: A Benchmark for Exploring Human-like Driving Decisions in VLA Models**|Xianpeng Lang Team|[2506.05667](http://arxiv.org/abs/2506.05667)|null|
|**2025-06-05**|**MORSE-500: A Programmatically Controllable Video Benchmark to Stress-Test Multimodal Reasoning**|Furong Huang Team|[2506.05523](http://arxiv.org/abs/2506.05523)|null|
|**2025-06-05**|**Degradation-Aware Image Enhancement via Vision-Language Classification**|Zibo Meng Team|[2506.05450](http://arxiv.org/abs/2506.05450)|null|
|**2025-06-09**|**Coordinated Robustness Evaluation Framework for Vision-Language Models**|Soumyendu Sarkar Team|[2506.05429](http://arxiv.org/abs/2506.05429)|null|
|**2025-06-06**|**Does Your 3D Encoder Really Work? When Pretrain-SFT from 2D VLMs Meets 3D VLMs**|Xiaodan Liang Team|[2506.05318](http://arxiv.org/abs/2506.05318)|null|
|**2025-06-05**|**MonkeyOCR: Document Parsing with a Structure-Recognition-Relation Triplet Paradigm**|Xiang Bai Team|[2506.05218](http://arxiv.org/abs/2506.05218)|null|
|**2025-06-05**|**Quantifying Cross-Modality Memorization in Vision-Language Models**|Chiyuan Zhang Team|[2506.05198](http://arxiv.org/abs/2506.05198)|null|
|**2025-06-05**|**CIVET: Systematic Evaluation of Understanding in VLMs**|Giuseppe Riccardi Team|[2506.05146](http://arxiv.org/abs/2506.05146)|null|
|**2025-06-05**|**PixCell: A generative foundation model for digital histopathology images**|Dimitris Samaras Team|[2506.05127](http://arxiv.org/abs/2506.05127)|null|
|**2025-06-05**|**A Survey on Vietnamese Document Analysis and Recognition: Challenges and Future Directions**|Dung Nguyen Team|[2506.05061](http://arxiv.org/abs/2506.05061)|null|
|**2025-06-05**|**Hierarchical Language Models for Semantic Navigation and Manipulation in an Aerial-Ground Robotic System**|Moju Zhao Team|[2506.05020](http://arxiv.org/abs/2506.05020)|null|
|**2025-06-05**|**ConECT Dataset: Overcoming Data Scarcity in Context-Aware E-Commerce MT**|Mikołaj Koszowski Team|[2506.04929](http://arxiv.org/abs/2506.04929)|null|
|**2025-06-05**|**SRD: Reinforcement-Learned Semantic Perturbation for Backdoor Defense in VLMs**|Dacheng Tao Team|[2506.04743](http://arxiv.org/abs/2506.04743)|null|
|**2025-06-05**|**Robust Few-Shot Vision-Language Model Adaptation**|Shu Kong Team|[2506.04713](http://arxiv.org/abs/2506.04713)|null|
|**2025-06-05**|**HoliSafe: Holistic Safety Benchmarking and Modeling with Safety Meta Token for Vision-Language Model**|Sung Ju Hwang Team|[2506.04704](http://arxiv.org/abs/2506.04704)|null|
|**2025-06-05**|**SmartAvatar: Text- and Image-Guided Human Avatar Generation with VLM AI Agents**|Yu-Wing Tai Team|[2506.04606](http://arxiv.org/abs/2506.04606)|null|
|**2025-06-05**|**MuSciClaims: Multimodal Scientific Claim Verification**|Niranjan Balasubramanian Team|[2506.04585](http://arxiv.org/abs/2506.04585)|null|
|**2025-06-05**|**Handle-based Mesh Deformation Guided By Vision Language Model**|Aniket Bera Team|[2506.04562](http://arxiv.org/abs/2506.04562)|null|
|**2025-06-04**|**RoboRefer: Towards Spatial Referring with Reasoning in Vision-Language Models for Robotics**|Shanghang Zhang Team|[2506.04308](http://arxiv.org/abs/2506.04308)|null|
|**2025-06-04**|**Image Editing As Programs with Diffusion Models**|Xinchao Wang Team|[2506.04158](http://arxiv.org/abs/2506.04158)|null|
|**2025-06-04**|**Recent Advances in Medical Image Classification**|Ngoc Quoc Ly Team|[2506.04129](http://arxiv.org/abs/2506.04129)|null|
|**2025-06-04**|**LaF-GRPO: In-Situ Navigation Instruction Generation for the Visually Impaired via GRPO with LLM-as-Follower Reward**|Jing Li Team|[2506.04070](http://arxiv.org/abs/2506.04070)|null|
|**2025-06-04**|**Mitigating Hallucinations in Large Vision-Language Models via Entity-Centric Multimodal Preference Optimization**|Min Zhang Team|[2506.04039](http://arxiv.org/abs/2506.04039)|null|
|**2025-06-04**|**Vocabulary-free few-shot learning for Vision-Language Models**|Christophe De Vleeschouwer Team|[2506.04005](http://arxiv.org/abs/2506.04005)|null|
|**2025-06-04**|**DiffCAP: Diffusion-based Cumulative Adversarial Purification for Vision Language Models**|Anders Holst Team|[2506.03933](http://arxiv.org/abs/2506.03933)|null|
|**2025-06-04**|**Zero-Shot Temporal Interaction Localization for Egocentric Videos**|Hesheng Wang Team|[2506.03662](http://arxiv.org/abs/2506.03662)|null|
|**2025-06-04**|**Spatial Understanding from Videos: Structured Prompts Meet Simulation Data**|Liqiang Nie Team|[2506.03642](http://arxiv.org/abs/2506.03642)|null|
|**2025-06-04**|**VLMs Can Aggregate Scattered Training Patches**|Chaochao Lu Team|[2506.03614](http://arxiv.org/abs/2506.03614)|null|
|**2025-06-04**|**BiMa: Towards Biases Mitigation for Text-Video Retrieval via Scene Element Guidance**|Ngan Le Team|[2506.03589](http://arxiv.org/abs/2506.03589)|null|
|**2025-06-04**|**MiMo-VL Technical Report**|Bingquan Xia Team|[2506.03569](http://arxiv.org/abs/2506.03569)|null|
|**2025-06-04**|**Target Semantics Clustering via Text Representations for Robust Universal Domain Adaptation**|Yixin Zhang Team|[2506.03521](http://arxiv.org/abs/2506.03521)|null|
|**2025-06-04**|**DenseDPO: Fine-Grained Temporal Preference Optimization for Video Diffusion Models**|Aliaksandr Siarohin Team|[2506.03517](http://arxiv.org/abs/2506.03517)|null|
|**2025-06-04**|**POLARIS: A High-contrast Polarimetric Imaging Benchmark Dataset for Exoplanetary Disk Representation Learning**|Weixin Yao Team|[2506.03511](http://arxiv.org/abs/2506.03511)|**[link](https://github.com/astraeus999/POLARIS_img_analysis)**|
|**2025-06-03**|**Toward Reliable VLM: A Fine-Grained Benchmark and Framework for Exposure, Bias, and Inference in Korean Street Views**|Hansaem Kim Team|[2506.03371](http://arxiv.org/abs/2506.03371)|null|
|**2025-06-03**|**Robustness in Both Domains: CLIP Needs a Robust Text Encoder**|Volkan Cevher Team|[2506.03355](http://arxiv.org/abs/2506.03355)|null|
|**2025-06-03**|**Grounded Vision-Language Interpreter for Integrated Task and Motion Planning**|Atsushi Hashimoto Team|[2506.03270](http://arxiv.org/abs/2506.03270)|null|
|**2025-06-03**|**OmniSpatial: Towards Comprehensive Spatial Reasoning Benchmark for Vision Language Models**|Li Yi Team|[2506.03135](http://arxiv.org/abs/2506.03135)|null|
|**2025-06-03**|**EgoVLM: Policy Optimization for Egocentric Video Understanding**|Linshen Liu Team|[2506.03097](http://arxiv.org/abs/2506.03097)|null|
|**2025-06-03**|**DPO Learning with LLMs-Judge Signal for Computer Use Agents**|Phillip Howard Team|[2506.03095](http://arxiv.org/abs/2506.03095)|null|
|**2025-06-03**|**From Flat to Hierarchical: Extracting Sparse Representations with Matching Pursuit**|Demba Ba Team|[2506.03093](http://arxiv.org/abs/2506.03093)|null|
|**2025-06-03**|**Text-guided Generation of Efficient Personalized Inspection Plans**|Aniket Bera Team|[2506.02917](http://arxiv.org/abs/2506.02917)|null|
|**2025-06-04**|**FlySearch: Exploring how vision-language models explore**|Maciej Wołczyk Team|[2506.02896](http://arxiv.org/abs/2506.02896)|null|
|**2025-06-03**|**Surfer-H Meets Holo1: Cost-Efficient Web Agent Powered by Open Weights**|Tony Wu Team|[2506.02865](http://arxiv.org/abs/2506.02865)|null|
|**2025-06-03**|**SemVink: Advancing VLMs' Semantic Understanding of Optical Illusions via Visual Global Thinking**|Yiwei Wang Team|[2506.02803](http://arxiv.org/abs/2506.02803)|null|
|**2025-06-04**|**Open-PMC-18M: A High-Fidelity Large Scale Medical Dataset for Multimodal Representation Learning**|Arash Afkanpour Team|[2506.02738](http://arxiv.org/abs/2506.02738)|null|
|**2025-06-03**|**Iterative Self-Improvement of Vision Language Models for Image Scoring and Self-Explanation**|Toshihiko Yamasaki Team|[2506.02708](http://arxiv.org/abs/2506.02708)|null|
|**2025-06-03**|**Small Aid, Big Leap: Efficient Test-Time Adaptation for Vision-Language Models with AdaptNet**|Zhi Wang Team|[2506.02671](http://arxiv.org/abs/2506.02671)|null|
|**2025-06-03**|**Hierarchical Question-Answering for Driving Scene Understanding Using Vision-Language Models**|Dong Seog Han Team|[2506.02615](http://arxiv.org/abs/2506.02615)|null|
|**2025-06-03**|**Kernel-based Unsupervised Embedding Alignment for Enhanced Visual Representation in Vision-language Models**|Farzan Farnia Team|[2506.02557](http://arxiv.org/abs/2506.02557)|null|
|**2025-06-03**|**Sign Language: Towards Sign Understanding for Robot Autonomy**|David Hsu Team|[2506.02556](http://arxiv.org/abs/2506.02556)|null|
|**2025-06-03**|**SurgVLM: A Large Vision-Language Model and Systematic Evaluation Benchmark for Surgical Intelligence**|Yueming Jin Team|[2506.02555](http://arxiv.org/abs/2506.02555)|null|
|**2025-06-03**|**Rethinking Post-Unlearning Behavior of Large Vision-Language Models**|Kyomin Jung Team|[2506.02541](http://arxiv.org/abs/2506.02541)|null|
|**2025-06-04**|**MemoryOut: Learning Principal Features via Multimodal Sparse Filtering Network for Semi-supervised Video Anomaly Detection**|Qingyao Wu Team|[2506.02535](http://arxiv.org/abs/2506.02535)|null|
|**2025-06-03**|**VS-Bench: Evaluating VLMs for Strategic Reasoning and Decision-Making in Multi-Agent Environments**|Yu Wang Team|[2506.02387](http://arxiv.org/abs/2506.02387)|null|
|**2025-06-03**|**Auto-Labeling Data for Object Detection**|Jason J. Corso Team|[2506.02359](http://arxiv.org/abs/2506.02359)|null|
|**2025-06-03**|**RATE-Nav: Region-Aware Termination Enhancement for Zero-shot Object Navigation with Vision-Language Models**|Jianzong Wang Team|[2506.02354](http://arxiv.org/abs/2506.02354)|null|
|**2025-05-30**|**ReasonGen-R1: CoT for Autoregressive Image generation models through SFT and RL**|Lili Qiu Team|[2505.24875](http://arxiv.org/abs/2505.24875)|null|
|**2025-05-30**|**ProxyThinker: Test-Time Guidance through Small Visual Reasoners**|Vicente Ordonez Team|[2505.24872](http://arxiv.org/abs/2505.24872)|null|
|**2025-05-30**|**GenSpace: Benchmarking Spatially-Aware Image Generation**|Zhou Zhao Team|[2505.24870](http://arxiv.org/abs/2505.24870)|null|
|**2025-05-30**|**Time Blindness: Why Video-Language Models Can't See What Humans Can?**|Mohamed Elhoseiny Team|[2505.24867](http://arxiv.org/abs/2505.24867)|null|
|**2025-05-30**|**Conformal Prediction for Zero-Shot Models**|Jose Dolz Team|[2505.24693](http://arxiv.org/abs/2505.24693)|null|
|**2025-05-30**|**BIMA: Bijective Maximum Likelihood Learning Approach to Hallucination Prediction and Mitigation in Large Vision-Language Models**|Khoa Luu Team|[2505.24649](http://arxiv.org/abs/2505.24649)|null|
|**2025-05-30**|**SARD: A Large-Scale Synthetic Arabic OCR Dataset for Book-Style Text Recognition**|Wadii Boulila Team|[2505.24600](http://arxiv.org/abs/2505.24600)|null|
|**2025-05-30**|**AMIA: Automatic Masking and Joint Intention Analysis Makes LVLMs Robust Jailbreak Defenders**|Liang Ding Team|[2505.24519](http://arxiv.org/abs/2505.24519)|null|
|**2025-05-30**|**CaMMT: Benchmarking Culturally Aware Multimodal Machine Translation**|Thamar Solorio Team|[2505.24456](http://arxiv.org/abs/2505.24456)|null|
|**2025-05-30**|**Advancing Compositional Awareness in CLIP with Efficient Fine-Tuning**|Matthias Hein Team|[2505.24424](http://arxiv.org/abs/2505.24424)|null|
|**2025-05-30**|**MMAFFBen: A Multilingual and Multimodal Affective Analysis Benchmark for Evaluating LLMs and VLMs**|Sophia Ananiadou Team|[2505.24423](http://arxiv.org/abs/2505.24423)|null|
|**2025-05-30**|**Grid-LOGAT: Grid Based Local and Global Area Transcription for Video Question Answering**|Fadoua Ghourabi Team|[2505.24371](http://arxiv.org/abs/2505.24371)|null|
|**2025-05-30**|**KEVER^2: Knowledge-Enhanced Visual Emotion Reasoning and Retrieval**|Yong Li Team|[2505.24342](http://arxiv.org/abs/2505.24342)|null|
|**2025-05-30**|**ROAD: Responsibility-Oriented Reward Design for Reinforcement Learning in Autonomous Driving**|Songan Zhang Team|[2505.24317](http://arxiv.org/abs/2505.24317)|null|
|**2025-05-30**|**Benchmarking Foundation Models for Zero-Shot Biometric Tasks**|Arun Ross Team|[2505.24214](http://arxiv.org/abs/2505.24214)|null|
|**2025-05-30**|**Bootstrapping LLM Robustness for VLM Safety via Reducing the Pretraining Modality Gap**|Baharan Mirzasoleiman Team|[2505.24208](http://arxiv.org/abs/2505.24208)|null|
|**2025-05-30**|**DrVD-Bench: Do Vision-Language Models Reason Like Human Doctors in Medical Image Diagnosis?**|Xuegong Zhang Team|[2505.24173](http://arxiv.org/abs/2505.24173)|null|
|**2025-05-30**|**CSVQA: A Chinese Multimodal Benchmark for Evaluating STEM Reasoning Capabilities of VLMs**|Xuchen Song Team|[2505.24120](http://arxiv.org/abs/2505.24120)|null|
|**2025-05-29**|**mRAG: Elucidating the Design Space of Multi-modal Retrieval-Augmented Generation**|Zhengzhong Tu Team|[2505.24073](http://arxiv.org/abs/2505.24073)|null|
|**2025-05-29**|**Multi-RAG: A Multimodal Retrieval-Augmented Generation System for Adaptive Video Understanding**|Tinoosh Mohsenin Team|[2505.23990](http://arxiv.org/abs/2505.23990)|null|
|**2025-05-29**|**ZeroGUI: Automating Online GUI Learning at Zero Human Cost**|Jifeng Dai Team|[2505.23762](http://arxiv.org/abs/2505.23762)|**[link](https://github.com/opengvlab/zerogui)**|
|**2025-05-29**|**Puzzled by Puzzles: When Vision-Language Models Can't Take a Hint**|David M. Chan Team|[2505.23759](http://arxiv.org/abs/2505.23759)|**[link](https://github.com/kyunnilee/visual_puzzles)**|
|**2025-05-29**|**To Trust Or Not To Trust Your Vision-Language Model's Prediction**|Olga Fink Team|[2505.23745](http://arxiv.org/abs/2505.23745)|**[link](https://github.com/epfl-imos/trustvlm)**|
|**2025-05-29**|**LayerPeeler: Autoregressive Peeling for Layer-wise Image Vectorization**|Jing Liao Team|[2505.23740](http://arxiv.org/abs/2505.23740)|null|
|**2025-05-29**|**Knowledge Insulating Vision-Language-Action Models: Train Fast, Run Fast, Generalize Better**|Sergey Levine Team|[2505.23705](http://arxiv.org/abs/2505.23705)|null|
|**2025-05-29**|**Grounded Reinforcement Learning for Visual Reasoning**|Katerina Fragkiadaki Team|[2505.23678](http://arxiv.org/abs/2505.23678)|null|
|**2025-05-29**|**Uni-MuMER: Unified Multi-Task Fine-Tuning of Vision-Language Model for Handwritten Mathematical Expression Recognition**|Liangcai Gao Team|[2505.23566](http://arxiv.org/abs/2505.23566)|null|
|**2025-05-30**|**Qwen Look Again: Guiding Vision-Language Reasoning Models to Re-attention Visual Information**|Weiping Li Team|[2505.23558](http://arxiv.org/abs/2505.23558)|**[link](https://github.com/liar406/look_again)**|
|**2025-05-29**|**TRAP: Targeted Redirecting of Agentic Preferences**|Gagandeep Singh Team|[2505.23518](http://arxiv.org/abs/2505.23518)|null|
|**2025-05-29**|**VCapsBench: A Large-scale Fine-grained Benchmark for Video Caption Quality Evaluation**|Xu-Cheng Yin Team|[2505.23484](http://arxiv.org/abs/2505.23484)|**[link](https://github.com/gxym/vcapsbench)**|
|**2025-05-29**|**Beam-Guided Knowledge Replay for Knowledge-Rich Image Captioning using Vision-Language Model**|Muzammil Behzad Team|[2505.23358](http://arxiv.org/abs/2505.23358)|null|
|**2025-05-29**|**LADA: Scalable Label-Specific CLIP Adapter for Continual Learning**|Min-Ling Zhang Team|[2505.23271](http://arxiv.org/abs/2505.23271)|**[link](https://github.com/maolinluo/lada)**|
|**2025-05-29**|**VLM-RRT: Vision Language Model Guided RRT Search for Autonomous UAV Navigation**|Panayiotis Kolios Team|[2505.23267](http://arxiv.org/abs/2505.23267)|null|
|**2025-05-29**|**Disrupting Vision-Language Model-Driven Navigation Services via Adversarial Object Fusion**|Tao Xiang Team|[2505.23266](http://arxiv.org/abs/2505.23266)|null|
|**2025-05-29**|**ChartMind: A Comprehensive Benchmark for Complex Real-world Multimodal Chart Question Answering**|Lei Wang Team|[2505.23242](http://arxiv.org/abs/2505.23242)|null|
|**2025-05-29**|**PhotoArtAgent: Intelligent Photo Retouching with Language Model-Based Artist Agents**|Jinjin Gu Team|[2505.23130](http://arxiv.org/abs/2505.23130)|null|
|**2025-05-29**|**Are Unified Vision-Language Models Necessary: Generalization Across Understanding and Generation**|Yu Cheng Team|[2505.23043](http://arxiv.org/abs/2505.23043)|**[link](https://github.com/majordavidzhang/generalization_unified_vlm)**|
|**2025-05-29**|**An Empirical Study of Federated Prompt Learning for Vision Language Model**|Mang Ye Team|[2505.23024](http://arxiv.org/abs/2505.23024)|null|
|**2025-05-29**|**SeG-SR: Integrating Semantic Knowledge into Remote Sensing Image Super-Resolution via Vision-Language Model**|Zhenwei Shi Team|[2505.23010](http://arxiv.org/abs/2505.23010)|null|
|**2025-05-29**|**QLIP: A Dynamic Quadtree Vision Prior Enhances MLLM Performance Without Retraining**|Muhao Chen Team|[2505.23004](http://arxiv.org/abs/2505.23004)|**[link](https://github.com/kyrochi/qlip)**|
|**2025-05-28**|**Zero-Shot Vision Encoder Grafting via LLM Surrogates**|Tom Goldstein Team|[2505.22664](http://arxiv.org/abs/2505.22664)|**[link](https://github.com/facebookresearch/zero)**|
|**2025-05-28**|**Training Free Stylized Abstraction**|Vishal M. Patel Team|[2505.22663](http://arxiv.org/abs/2505.22663)|null|
|**2025-05-28**|**VScan: Rethinking Visual Token Reduction for Efficient Large Vision-Language Models**|Dong Yu Team|[2505.22654](http://arxiv.org/abs/2505.22654)|null|
|**2025-05-28**|**Sherlock: Self-Correcting Reasoning in Vision-Language Models**|Ruqi Zhang Team|[2505.22651](http://arxiv.org/abs/2505.22651)|null|
|**2025-05-28**|**Hypothesis Testing in Imaging Inverse Problems**|Marcelo Pereyra Team|[2505.22481](http://arxiv.org/abs/2505.22481)|null|
|**2025-05-28**|**Zero-Shot 3D Visual Grounding from Vision-Language Models**|Junwei Liang Team|[2505.22429](http://arxiv.org/abs/2505.22429)|null|
|**2025-05-28**|**IKIWISI: An Interactive Visual Pattern Generator for Evaluating the Reliability of Vision-Language Models Without Ground Truth**|Syed Masum Billah Team|[2505.22305](http://arxiv.org/abs/2505.22305)|null|
|**2025-05-28**|**Investigating Mechanisms for In-Context Vision Language Binding**|Vineet Gandhi Team|[2505.22200](http://arxiv.org/abs/2505.22200)|null|
|**2025-05-29**|**Improving Brain-to-Image Reconstruction via Fine-Grained Text Bridging**|Piji Li Team|[2505.22150](http://arxiv.org/abs/2505.22150)|null|
|**2025-05-28**|**3D Question Answering via only 2D Vision-Language Models**|Qianru Sun Team|[2505.22143](http://arxiv.org/abs/2505.22143)|null|
|**2025-05-28**|**Reinforced Reasoning for Embodied Planning**|Bo Jin Team|[2505.22050](http://arxiv.org/abs/2505.22050)|null|
|**2025-05-28**|**Balanced Token Pruning: Accelerating Vision Language Models Beyond Local Optimization**|Xinlei Chen Team|[2505.22038](http://arxiv.org/abs/2505.22038)|null|
|**2025-05-28**|**Pearl: A Multimodal Culturally-Aware Arabic Instruction Dataset**|Muhammad Abdul-Mageed Team|[2505.21979](http://arxiv.org/abs/2505.21979)|null|
|**2025-05-29**|**DORAEMON: Decentralized Ontology-aware Reliable Agent with Enhanced Memory Oriented Navigation**|Xin Tan Team|[2505.21969](http://arxiv.org/abs/2505.21969)|null|
|**2025-05-28**|**Seeing the Threat: Vulnerabilities in Vision-Language Models to Adversarial Attack**|Usman Naseem Team|[2505.21967](http://arxiv.org/abs/2505.21967)|null|
|**2025-05-28**|**Towards Comprehensive Scene Understanding: Integrating First and Third-Person Views for LVLMs**|Byonghyo Shim Team|[2505.21955](http://arxiv.org/abs/2505.21955)|null|
|**2025-05-28**|**Vision-Language-Action Model with Open-World Embodied Reasoning from Pretrained Knowledge**|Yi Xu Team|[2505.21906](http://arxiv.org/abs/2505.21906)|null|
|**2025-05-28**|**Test-Time Adaptation of Vision-Language Models for Open-Vocabulary Semantic Segmentation**|Christian Desrosiers Team|[2505.21844](http://arxiv.org/abs/2505.21844)|null|
|**2025-05-27**|**MMTBENCH: A Unified Benchmark for Complex Multimodal Table Reasoning**|Vivek Gupta Team|[2505.21771](http://arxiv.org/abs/2505.21771)|null|
|**2025-05-27**|**MedBridge: Bridging Foundation Vision-Language Models to Medical Image Diagnosis**|Christian Wachinger Team|[2505.21698](http://arxiv.org/abs/2505.21698)|null|
|**2025-05-27**|**ViewSpatial-Bench: Evaluating Multi-perspective Spatial Localization in Vision-Language Models**|Yueting Zhuang Team|[2505.21500](http://arxiv.org/abs/2505.21500)|null|
|**2025-05-27**|**AdInject: Real-World Black-Box Attacks on Web Agents via Advertising Delivery**|Qing Wang Team|[2505.21499](http://arxiv.org/abs/2505.21499)|null|
|**2025-05-27**|**Mitigating Hallucination in Large Vision-Language Models via Adaptive Attention Calibration**|Ziwei Zhu Team|[2505.21472](http://arxiv.org/abs/2505.21472)|null|
|**2025-05-27**|**ID-Align: RoPE-Conscious Position Remapping for Dynamic High-Resolution Adaptation in Vision-Language Models**|Wentao Zhang Team|[2505.21465](http://arxiv.org/abs/2505.21465)|null|
|**2025-05-27**|**LazyVLM: Neuro-Symbolic Approach to Video Analytics**|M. Tamer Özsu Team|[2505.21459](http://arxiv.org/abs/2505.21459)|null|
|**2025-05-27**|**DeCAF: Decentralized Consensus-And-Factorization for Low-Rank Adaptation of Foundation Models**|Soumik Sarkar Team|[2505.21382](http://arxiv.org/abs/2505.21382)|null|
|**2025-05-27**|**XBOUND: Exploring the Capability Boundaries of Device-Control Agents through Trajectory Tree Exploration**|Min Zhang Team|[2505.21279](http://arxiv.org/abs/2505.21279)|null|
|**2025-05-27**|**Interpreting Social Bias in LVLMs via Information Flow Analysis and Multi-Round Dialogue Evaluation**|Yutao Yue Team|[2505.21106](http://arxiv.org/abs/2505.21106)|null|
|**2025-05-27**|**DisasterM3: A Remote Sensing Vision-Language Dataset for Disaster Damage Assessment and Response**|Naoto Yokoya Team|[2505.21089](http://arxiv.org/abs/2505.21089)|null|
|**2025-05-27**|**LPOI: Listwise Preference Optimization for Vision Language Models**|Gunhee Kim Team|[2505.21061](http://arxiv.org/abs/2505.21061)|null|
|**2025-05-27**|**RefAV: Towards Planning-Centric Scenario Mining**|Neehar Peri Team|[2505.20981](http://arxiv.org/abs/2505.20981)|null|
|**2025-05-27**|**On VLMs for Diverse Tasks in Multimodal Meme Classification**|Jasabanta Patro Team|[2505.20937](http://arxiv.org/abs/2505.20937)|null|
|**2025-05-27**|**A Stereotype Content Analysis on Color-related Social Bias in Large Vision Language Models**|Bugeun Kim Team|[2505.20901](http://arxiv.org/abs/2505.20901)|null|
|**2025-05-27**|**AVCD: Mitigating Hallucinations in Audio-Visual Large Language Models through Contrastive Decoding**|Joon Son Chung Team|[2505.20862](http://arxiv.org/abs/2505.20862)|null|
|**2025-05-27**|**Rendering-Aware Reinforcement Learning for Vector Graphics Generation**|Marco Pedersoli Team|[2505.20793](http://arxiv.org/abs/2505.20793)|null|
|**2025-05-27**|**FM-Planner: Foundation Model Guided Path Planning for Autonomous Drone Navigation**|Mir Feroskhan Team|[2505.20783](http://arxiv.org/abs/2505.20783)|null|
|**2025-05-27**|**Jigsaw-Puzzles: From Seeing to Understanding to Reasoning in Vision-Language Models**|Yao Yang Team|[2505.20728](http://arxiv.org/abs/2505.20728)|null|
|**2025-05-27**|**ManiTaskGen: A Comprehensive Task Generator for Benchmarking and Improving Vision-Language Agents on Embodied Decision-Making**|Hao Su Team|[2505.20726](http://arxiv.org/abs/2505.20726)|null|
|**2025-05-27**|**Automating eHMI Action Design with LLMs for Automated Vehicle Communication**|Takeo Igarashi Team|[2505.20711](http://arxiv.org/abs/2505.20711)|null|
|**2025-05-27**|**GIFARC: Synthetic Dataset for Leveraging Human-Intuitive Analogies to Elevate AI Reasoning**|Sundong Kim Team|[2505.20672](http://arxiv.org/abs/2505.20672)|null|
|**2025-05-26**|**Seeing is Believing, but How Much? A Comprehensive Analysis of Verbalized Calibration in Vision-Language Models**|Naoto Yokoya Team|[2505.20236](http://arxiv.org/abs/2505.20236)|null|
|**2025-05-26**|**Agentic 3D Scene Generation with Spatially Contextualized VLMs**|Chi-Keung Tang Team|[2505.20129](http://arxiv.org/abs/2505.20129)|null|
|**2025-05-26**|**MEBench: A Novel Benchmark for Understanding Mutual Exclusivity Bias in Vision-Language Models**|James M. Rehg Team|[2505.20122](http://arxiv.org/abs/2505.20122)|null|
|**2025-05-27**|**EmoNet-Face: An Expert-Annotated Benchmark for Synthetic Emotion Recognition**|Sören Auer Team|[2505.20033](http://arxiv.org/abs/2505.20033)|null|
|**2025-05-26**|**ViTaPEs: Visuotactile Position Encodings for Cross-Modal Alignment in Multimodal Transformers**|Elmar Rückert Team|[2505.20032](http://arxiv.org/abs/2505.20032)|null|
|**2025-05-26**|**Decomposing Complex Visual Comprehension into Atomic Visual Skills for Vision Language Models**|Ernest K. Ryu Team|[2505.20021](http://arxiv.org/abs/2505.20021)|null|
|**2025-05-26**|**Can Visual Encoder Learn to See Arrows?**|Hiroaki Ozaki Team|[2505.19944](http://arxiv.org/abs/2505.19944)|null|
|**2025-05-26**|**Attention! You Vision Language Model Could Be Maliciously Manipulated**|Shudong Zhang Team|[2505.19911](http://arxiv.org/abs/2505.19911)|null|
|**2025-05-26**|**Underwater Diffusion Attention Network with Contrastive Language-Image Joint Learning for Underwater Image Enhancement**|Muzammil Behzad Team|[2505.19895](http://arxiv.org/abs/2505.19895)|null|
|**2025-05-26**|**One Surrogate to Fool Them All: Universal, Transferable, and Targeted Adversarial Attacks with CLIP**|Kehuan Zhang Team|[2505.19840](http://arxiv.org/abs/2505.19840)|null|
|**2025-05-26**|**TeViR: Text-to-Video Reward with Diffusion Models for Efficient Reinforcement Learning**|Dongbin Zhao Team|[2505.19769](http://arxiv.org/abs/2505.19769)|null|
|**2025-05-26**|**Modeling Beyond MOS: Quality Assessment Models Must Integrate Context, Reasoning, and Multimodality**|Alessandro Bruno Team|[2505.19696](http://arxiv.org/abs/2505.19696)|null|
|**2025-05-26**|**Grounding Language with Vision: A Conditional Mutual Information Calibrated Decoding Strategy for Reducing Hallucinations in LVLMs**|Shu-Tao Xia Team|[2505.19678](http://arxiv.org/abs/2505.19678)|null|
|**2025-05-26**|**JailBound: Jailbreaking Internal Safety Boundaries of Vision-Language Models**|Yingchun Wang Team|[2505.19610](http://arxiv.org/abs/2505.19610)|null|
|**2025-05-26**|**What You Perceive Is What You Conceive: A Cognition-Inspired Framework for Open Vocabulary Image Segmentation**|Rongrong Ji Team|[2505.19569](http://arxiv.org/abs/2505.19569)|null|
|**2025-05-26**|**FlowCut: Rethinking Redundancy via Information Flow for Efficient Vision-Language Models**|Ruixuan Li Team|[2505.19536](http://arxiv.org/abs/2505.19536)|null|
|**2025-05-26**|**Locality-Aware Zero-Shot Human-Object Interaction Detection**|Minsu Cho Team|[2505.19503](http://arxiv.org/abs/2505.19503)|null|
|**2025-05-26**|**Enhancing Visual Reliance in Text Generation: A Bayesian Perspective on Mitigating Hallucination in Large Vision-Language Models**|Guoliang Kang Team|[2505.19498](http://arxiv.org/abs/2505.19498)|null|
|**2025-05-26**|**Unveiling the Compositional Ability Gap in Vision-Language Reasoning Model**|Yu Cheng Team|[2505.19406](http://arxiv.org/abs/2505.19406)|null|
|**2025-05-27**|**DiffVLA: Vision-Language Guided Diffusion Planning for Autonomous Driving**|Hao Zhao Team|[2505.19381](http://arxiv.org/abs/2505.19381)|null|
|**2025-05-26**|**DiSa: Directional Saliency-Aware Prompt Learning for Generalizable Vision-Language Models**|Fatemeh Afghah Team|[2505.19373](http://arxiv.org/abs/2505.19373)|null|
|**2025-05-23**|**VideoGameBench: Can Vision-Language Models complete popular video games?**|Ofir Press Team|[2505.18134](http://arxiv.org/abs/2505.18134)|null|
|**2025-05-23**|**One RL to See Them All: Visual Triple Unified Reinforcement Learning**|Junjie Yan Team|[2505.18129](http://arxiv.org/abs/2505.18129)|null|
|**2025-05-23**|**CXReasonBench: A Benchmark for Evaluating Structured Diagnostic Reasoning in Chest X-rays**|Edward Choi Team|[2505.18087](http://arxiv.org/abs/2505.18087)|null|
|**2025-05-23**|**FDBPL: Faster Distillation-Based Prompt Learning for Region-Aware Vision-Language Models Adaptation**|Shibiao Xu Team|[2505.18053](http://arxiv.org/abs/2505.18053)|null|
|**2025-05-23**|**Clip4Retrofit: Enabling Real-Time Image Labeling on Edge Devices via Cross-Architecture CLIP Distillation**|Bogdan Sorin Coseriu Team|[2505.18039](http://arxiv.org/abs/2505.18039)|null|
|**2025-05-23**|**Few-Shot Learning from Gigapixel Images via Hierarchical Vision-Language Alignment and Modeling**|Mun Yong Yi Team|[2505.17982](http://arxiv.org/abs/2505.17982)|null|
|**2025-05-23**|**VLM Models and Automated Grading of Atopic Dermatitis**|Hamed Ghodrati Team|[2505.17835](http://arxiv.org/abs/2505.17835)|null|
|**2025-05-23**|**Seeing It or Not? Interpretable Vision-aware Latent Steering to Mitigate Object Hallucinations**|Chao Shen Team|[2505.17812](http://arxiv.org/abs/2505.17812)|null|
|**2025-05-23**|**U2-BENCH: Benchmarking Large Vision-Language Models on Ultrasound Understanding**|Hongcheng Guo Team|[2505.17779](http://arxiv.org/abs/2505.17779)|null|
|**2025-05-23**|**SafeMVDrive: Multi-view Safety-Critical Driving Video Synthesis in the Real World Domain**|Yu Li Team|[2505.17727](http://arxiv.org/abs/2505.17727)|null|
|**2025-05-23**|**Seek-CAD: A Self-refined Generative Modeling for 3D Parametric CAD Using Local Inference via DeepSeek**|Xiangdong Zhou Team|[2505.17702](http://arxiv.org/abs/2505.17702)|null|
|**2025-05-23**|**Towards General Continuous Memory for Vision-Language Models**|Biwei Huang Team|[2505.17670](http://arxiv.org/abs/2505.17670)|null|
|**2025-05-23**|**EVADE: Multimodal Benchmark for Evasive Content Detection in E-Commerce Applications**|Min Yang Team|[2505.17654](http://arxiv.org/abs/2505.17654)|null|
|**2025-05-23**|**HoloLLM: Multisensory Foundation Model for Language-Grounded Human Sensing and Reasoning**|Jianfei Yang Team|[2505.17645](http://arxiv.org/abs/2505.17645)|null|
|**2025-05-23**|**Enhancing Large Vision-Language Models with Layout Modality for Table Question Answering on Japanese Annual Securities Reports**|Takahiro Omi Team|[2505.17625](http://arxiv.org/abs/2505.17625)|null|
|**2025-05-23**|**CAS-IQA: Teaching Vision-Language Models for Synthetic Angiography Quality Assessment**|Zeng-Guang Hou Team|[2505.17619](http://arxiv.org/abs/2505.17619)|null|
|**2025-05-23**|**Decoupled Visual Interpretation and Linguistic Reasoning for Math Problem Solving**|Wangmeng Zuo Team|[2505.17609](http://arxiv.org/abs/2505.17609)|null|
|**2025-05-23**|**A Unified Multi-Scale Attention-Based Network for Automatic 3D Segmentation of Lung Parenchyma & Nodules In Thoracic CT Images**|Furqan Shaukat Team|[2505.17602](http://arxiv.org/abs/2505.17602)|null|
|**2025-05-23**|**Multimodal Conversation Structure Understanding**|David Bamman Team|[2505.17536](http://arxiv.org/abs/2505.17536)|null|
|**2025-05-23**|**Do You Keep an Eye on What I Ask? Mitigating Multimodal Hallucination via Attention-Guided Ensemble Decoding**|Sungzoon Cho Team|[2505.17529](http://arxiv.org/abs/2505.17529)|null|
|**2025-05-22**|**Think or Not? Selective Reasoning via Reinforcement Learning for Vision-Language Models**|Mike Zheng Shou Team|[2505.16854](http://arxiv.org/abs/2505.16854)|**[link](https://github.com/kokolerk/ton)**|
|**2025-05-23**|**LaViDa: A Large Diffusion Language Model for Multimodal Understanding**|Aditya Grover Team|[2505.16839](http://arxiv.org/abs/2505.16839)|**[link](https://github.com/jacklishufan/lavida)**|
|**2025-05-22**|**From EduVisBench to EduVisAgent: A Benchmark and Multi-Agent Framework for Pedagogical Visualization**|Huaxiu Yao Team|[2505.16832](http://arxiv.org/abs/2505.16832)|**[link](https://github.com/aiming-lab/eduvisbench)**|
|**2025-05-22**|**Perceptual Quality Assessment for Embodied AI**|Guangtao Zhai Team|[2505.16815](http://arxiv.org/abs/2505.16815)|**[link](https://github.com/lcysyzxdxc/embodiediqa)**|
|**2025-05-22**|**SOLVE: Synergy of Language-Vision and End-to-End Networks for Autonomous Driving**|Hongsheng Li Team|[2505.16805](http://arxiv.org/abs/2505.16805)|null|
|**2025-05-22**|**REOBench: Benchmarking Robustness of Earth Observation Foundation Models**|Tianjin Huang Team|[2505.16793](http://arxiv.org/abs/2505.16793)|**[link](https://github.com/lx709/reobench)**|
|**2025-05-22**|**Single Domain Generalization for Few-Shot Counting via Universal Representation Matching**|Xinghao Chen Team|[2505.16778](http://arxiv.org/abs/2505.16778)|**[link](https://github.com/jbr97/urm)**|
|**2025-05-22**|**IFEval-Audio: Benchmarking Instruction-Following Capability in Audio-based Large Language Models**|AiTi Aw Team|[2505.16774](http://arxiv.org/abs/2505.16774)|**[link](https://github.com/audiollms/audiobench)**|
|**2025-05-22**|**Self-Rewarding Large Vision-Language Models for Optimizing Prompts in Text-to-Image Generation**|Jianbing Shen Team|[2505.16763](http://arxiv.org/abs/2505.16763)|null|
|**2025-05-22**|**SD-MAD: Sign-Driven Few-shot Multi-Anomaly Detection in Medical Images**|Mahsa Baktashmotlagh Team|[2505.16659](http://arxiv.org/abs/2505.16659)|null|
|**2025-05-22**|**Point, Detect, Count: Multi-Task Medical Image Understanding with Instruction-Tuned Vision-Language Models**|Pål Halvorsen Team|[2505.16647](http://arxiv.org/abs/2505.16647)|null|
|**2025-05-22**|**MEgoHand: Multimodal Egocentric Hand-Object Interaction Motion Generation**|Zongqing Lu Team|[2505.16602](http://arxiv.org/abs/2505.16602)|null|
|**2025-05-22**|**ManipLVM-R1: Reinforcement Learning for Reasoning in Embodied Manipulation with Large Vision-Language Models**|Xiuying Chen Team|[2505.16517](http://arxiv.org/abs/2505.16517)|null|
|**2025-05-22**|**Implicit Jailbreak Attacks via Cross-Modal Information Concealment on Vision-Language Models**|Yaochu Jin Team|[2505.16446](http://arxiv.org/abs/2505.16446)|null|
|**2025-05-22**|**Circle-RoPE: Cone-like Decoupled Rotary Positional Embedding for Large Vision-Language Models**|Kai Han Team|[2505.16416](http://arxiv.org/abs/2505.16416)|**[link](https://github.com/lose4578/circlerope)**|
|**2025-05-22**|**Mitigating Hallucinations in Vision-Language Models through Image-Guided Head Suppression**|Souvik Kundu Team|[2505.16411](http://arxiv.org/abs/2505.16411)|**[link](https://github.com/yueche77/spin)**|
|**2025-05-22**|**VL-SAFE: Vision-Language Guided Safety-Aware Reinforcement Learning with World Models for Autonomous Driving**|Samuel Labi Team|[2505.16377](http://arxiv.org/abs/2505.16377)|null|
|**2025-05-22**|**MM-MovieDubber: Towards Multi-Modal Learning for Multi-Modal Movie Dubbing**|Xinhan Di Team|[2505.16279](http://arxiv.org/abs/2505.16279)|null|
|**2025-05-22**|**When VLMs Meet Image Classification: Test Sets Renovation via Missing Label Identification**|Jiaheng Wei Team|[2505.16149](http://arxiv.org/abs/2505.16149)|null|
|**2025-05-22**|**Steering LVLMs via Sparse Autoencoder for Hallucination Mitigation**|Junfeng Fang Team|[2505.16146](http://arxiv.org/abs/2505.16146)|null|
|**2025-05-21**|**InstructSAM: A Training-Free Framework for Instruction-Oriented Remote Sensing Object Recognition**|Xue Yang Team|[2505.15818](http://arxiv.org/abs/2505.15818)|null|
|**2025-05-21**|**From Grounding to Manipulation: Case Studies of Foundation Model Integration in Embodied Robotic Systems**|Soujanya Poria Team|[2505.15685](http://arxiv.org/abs/2505.15685)|null|
|**2025-05-21**|**FragFake: A Dataset for Fine-Grained Detection of Edited Images with Vision Language Models**|Qian Wang Team|[2505.15644](http://arxiv.org/abs/2505.15644)|null|
|**2025-05-21**|**Visual Perturbation and Adaptive Hard Negative Contrastive Learning for Compositional Reasoning in Vision-Language Models**|Ya Wang Team|[2505.15576](http://arxiv.org/abs/2505.15576)|**[link](https://github.com/nynu-bdai/ahnpl)**|
|**2025-05-21**|**TinyDrive: Multiscale Visual Question Answering with Selective Token Routing for Autonomous Driving**|Abdallah Shami Team|[2505.15564](http://arxiv.org/abs/2505.15564)|null|
|**2025-05-21**|**Clapper: Compact Learning and Video Representation in VLMs**|Fuzheng Zhang Team|[2505.15529](http://arxiv.org/abs/2505.15529)|null|
|**2025-05-21**|**Robo2VLM: Visual Question Answering from Large-Scale In-the-Wild Robot Manipulation Datasets**|Ken Goldberg Team|[2505.15517](http://arxiv.org/abs/2505.15517)|null|
|**2025-05-21**|**Visual Thoughts: A Unified Perspective of Understanding Multimodal Chain-of-Thought**|Libo Qin Team|[2505.15510](http://arxiv.org/abs/2505.15510)|null|
|**2025-05-21**|**Prompt Tuning Vision Language Models with Margin Regularizer for Few-Shot Learning under Distribution Shifts**|Soma Biswas Team|[2505.15506](http://arxiv.org/abs/2505.15506)|**[link](https://github.com/debarshigit/promptmargin)**|
|**2025-05-21**|**Beyond Linearity: Squeeze-and-Recalibrate Blocks for Few-Shot Whole Slide Image Classification**|Irwin King Team|[2505.15504](http://arxiv.org/abs/2505.15504)|null|
|**2025-05-21**|**Seeing Through Deception: Uncovering Misleading Creator Intent in Multimodal News with Vision-Language Models**|Bryan Hooi Team|[2505.15489](http://arxiv.org/abs/2505.15489)|null|
|**2025-05-21**|**Chain-of-Focus: Adaptive Visual Search and Zooming for Multimodal Reasoning via RL**|Qing Li Team|[2505.15436](http://arxiv.org/abs/2505.15436)|null|
|**2025-05-21**|**TimeCausality: Evaluating the Causal Ability in Time Dimension for Vision Language Models**|Keze Wang Team|[2505.15435](http://arxiv.org/abs/2505.15435)|null|
|**2025-05-21**|**On the Robustness of Medical Vision-Language Models: Are they Truly Generalizable?**|Mohammad Yaqub Team|[2505.15425](http://arxiv.org/abs/2505.15425)|null|
|**2025-05-21**|**Are Vision-Language Models Safe in the Wild? A Meme-Based Benchmark Study**|Hwanjo Yu Team|[2505.15389](http://arxiv.org/abs/2505.15389)|null|
|**2025-05-21**|**RAZER: Robust Accelerated Zero-Shot 3D Open-Vocabulary Panoptic Reconstruction with Spatio-Temporal Aggregation**|Farshad Khorrami Team|[2505.15373](http://arxiv.org/abs/2505.15373)|null|
|**2025-05-21**|**Better Safe Than Sorry? Overreaction Problem of Vision Language Models in Visual Emergency Recognition**|Youngsook Song Team|[2505.15367](http://arxiv.org/abs/2505.15367)|null|
|**2025-05-21**|**AgentThink: A Unified Framework for Tool-Augmented Chain-of-Thought Reasoning in Vision-Language Models for Autonomous Driving**|Diange Yang Team|[2505.15298](http://arxiv.org/abs/2505.15298)|null|
|**2025-05-21**|**Blind Spot Navigation: Evolutionary Discovery of Sensitive Semantic Concepts for LVLMs**|Zibin Zheng Team|[2505.15265](http://arxiv.org/abs/2505.15265)|null|
|**2025-05-21**|**Fooling the LVLM Judges: Visual Biases in LVLM-Based Evaluation**|Kyomin Jung Team|[2505.15249](http://arxiv.org/abs/2505.15249)|null|
|**2025-05-20**|**UniCTokens: Boosting Personalized Understanding and Generation via Unified Concept Tokens**|Wentao Zhang Team|[2505.14671](http://arxiv.org/abs/2505.14671)|null|
|**2025-05-20**|**CAD-Coder: An Open-Source Vision-Language Model for Computer-Aided Design Code Generation**|Faez Ahmed Team|[2505.14646](http://arxiv.org/abs/2505.14646)|null|
|**2025-05-20**|**Debating for Better Reasoning: An Unsupervised Multimodal Approach**|Mirella Lapata Team|[2505.14627](http://arxiv.org/abs/2505.14627)|null|
|**2025-05-21**|**PlanGPT-VL: Enhancing Urban Planning with Domain-Specific Vision-Language Models**|Wenjia Zhang Team|[2505.14481](http://arxiv.org/abs/2505.14481)|null|
|**2025-05-20**|**RAVENEA: A Benchmark for Multimodal Retrieval-Augmented Visual Culture Understanding**|Serge Belongie Team|[2505.14462](http://arxiv.org/abs/2505.14462)|**[link](https://github.com/yfyuan01/ravenea)**|
|**2025-05-20**|**SCAN: Semantic Document Layout Analysis for Textual and Visual Retrieval-Augmented Generation**|Masafumi Oyamada Team|[2505.14381](http://arxiv.org/abs/2505.14381)|null|
|**2025-05-20**|**Towards Embodied Cognition in Robots via Spatially Grounded Synthetic Worlds**|Agnieszka Wykowska Team|[2505.14366](http://arxiv.org/abs/2505.14366)|null|
|**2025-05-20**|**DeepEyes: Incentivizing "Thinking with Images" via Reinforcement Learning**|Xing Yu Team|[2505.14362](http://arxiv.org/abs/2505.14362)|**[link](https://github.com/visual-agent/deepeyes)**|
|**2025-05-20**|**Vision-Language Modeling Meets Remote Sensing: Models, Datasets and Perspectives**|Gui-Song Xia Team|[2505.14361](http://arxiv.org/abs/2505.14361)|null|
|**2025-05-20**|**Plane Geometry Problem Solving with Multi-modal Reasoning: A Survey**|Dongwoo Kim Team|[2505.14340](http://arxiv.org/abs/2505.14340)|null|
|**2025-05-20**|**Aligning Attention Distribution to Information Flow for Hallucination Mitigation in Large Vision-Language Models**|Chong Feng Team|[2505.14257](http://arxiv.org/abs/2505.14257)|null|
|**2025-05-20**|**Visual Agentic Reinforcement Fine-Tuning**|Jiaqi Wang Team|[2505.14246](http://arxiv.org/abs/2505.14246)|**[link](https://github.com/liuziyu77/visual-rft)**|
|**2025-05-20**|**VoQA: Visual-only Question Answering**|Lei Huang Team|[2505.14227](http://arxiv.org/abs/2505.14227)|null|
|**2025-05-20**|**Breaking Language Barriers or Reinforcing Bias? A Study of Gender and Racial Disparities in Multilingual Contrastive Vision Language Models**|Matthew Purver Team|[2505.14160](http://arxiv.org/abs/2505.14160)|null|
|**2025-05-20**|**Building a Stable Planner: An Extended Finite State Machine Based Planning Module for Mobile GUI Agent**|Xuming Hu Team|[2505.14141](http://arxiv.org/abs/2505.14141)|null|
|**2025-05-20**|**NOVA: A Benchmark for Anomaly Localization and Clinical Reasoning in Brain MRI**|Benedikt Wiestler Team|[2505.14064](http://arxiv.org/abs/2505.14064)|null|
|**2025-05-20**|**ShieldVLM: Safeguarding the Multimodal Implicit Toxicity via Deliberative Reasoning with LVLMs**|Minlie Huang Team|[2505.14035](http://arxiv.org/abs/2505.14035)|null|
|**2025-05-20**|**Toward Effective Reinforcement Learning Fine-Tuning for Medical VQA in Vision-Language Models**|Yalin Wang Team|[2505.13973](http://arxiv.org/abs/2505.13973)|null|
|**2025-05-20**|**APEX: Empowering LLMs with Physics-Based Task Planning for Real-time Insight**|Ambuj Singh Team|[2505.13921](http://arxiv.org/abs/2505.13921)|**[link](https://github.com/hwj20/apex_exp)**|
|**2025-05-20**|**InSpire: Vision-Language-Action Models with Intrinsic Spatial Reasoning**|Jingkuan Song Team|[2505.13888](http://arxiv.org/abs/2505.13888)|null|
|**2025-05-19**|**ChartMuseum: Testing Visual Reasoning Capabilities of Large Vision-Language Models**|Greg Durrett Team|[2505.13444](http://arxiv.org/abs/2505.13444)|null|
|**2025-05-19**|**G1: Bootstrapping Perception and Reasoning Abilities of Vision-Language Model via Reinforcement Learning**|Baobao Chang Team|[2505.13426](http://arxiv.org/abs/2505.13426)|**[link](https://github.com/chenllliang/g1)**|
|**2025-05-19**|**Seeing, Saying, Solving: An LLM-to-TL Framework for Cooperative Robots**|Shreyas Kousik Team|[2505.13376](http://arxiv.org/abs/2505.13376)|null|
|**2025-05-20**|**Unlabeled Data or Pre-trained Model: Rethinking Semi-Supervised Learning and Pretrain-Finetuning**|Lan-Zhe Guo Team|[2505.13317](http://arxiv.org/abs/2505.13317)|null|
|**2025-05-19**|**I'll believe it when I see it: Images increase misinformation sharing in Vision-Language Models**|R. Maria del Rio-Chanona Team|[2505.13302](http://arxiv.org/abs/2505.13302)|**[link](https://github.com/3lis/misinfo_vlm)**|
|**2025-05-19**|**Computer Vision Models Show Human-Like Sensitivity to Geometric and Topological Concepts**|Sashank Varma Team|[2505.13281](http://arxiv.org/abs/2505.13281)|null|
|**2025-05-19**|**From Local Details to Global Context: Advancing Vision-Language Models with Attention-Based Selection**|Jian Liang Team|[2505.13233](http://arxiv.org/abs/2505.13233)|**[link](https://github.com/bit-da/abs)**|
|**2025-05-19**|**ViPlan: A Benchmark for Visual Planning with Symbolic Predicates and Vision-Language Models**|Pekka Marttinen Team|[2505.13180](http://arxiv.org/abs/2505.13180)|**[link](https://github.com/merlerm/viplan)**|
|**2025-05-19**|**Hearing from Silence: Reasoning Audio Descriptions from Silent Videos via Vision-Language Model**|Dong Yu Team|[2505.13062](http://arxiv.org/abs/2505.13062)|null|
|**2025-05-20**|**3D Visual Illusion Depth Estimation**|Yunde Jia Team|[2505.13061](http://arxiv.org/abs/2505.13061)|**[link](https://github.com/yaochengtang/3d-visual-illusion-depth-estimation)**|
|**2025-05-19**|**MindOmni: Unleashing Reasoning Generation in Vision Language Models with RGPO**|Ying Shan Team|[2505.13031](http://arxiv.org/abs/2505.13031)|**[link](https://github.com/easonxiao-888/mindomni)**|
|**2025-05-19**|**Uniformity First: Uniformity-aware Test-time Adaptation of Vision-language Models against Image Corruption**|Tomoki Hamagami Team|[2505.12912](http://arxiv.org/abs/2505.12912)|**[link](https://github.com/kzkadc/uninfo)**|
|**2025-05-19**|**TinyAlign: Boosting Lightweight Vision-Language Models by Mitigating Modal Alignment Bottlenecks**|Jin Dong Team|[2505.12884](http://arxiv.org/abs/2505.12884)|null|
|**2025-05-19**|**FlightGPT: Towards Generalizable and Interpretable UAV Vision-and-Language Navigation with Vision-Language Models**|Renxin Zhong Team|[2505.12835](http://arxiv.org/abs/2505.12835)|null|
|**2025-05-19**|**VLC Fusion: Vision-Language Conditioned Sensor Fusion for Robust Object Detection**|Ransalu Senanayake Team|[2505.12715](http://arxiv.org/abs/2505.12715)|null|
|**2025-05-19**|**TS-VLM: Text-Guided SoftSort Pooling for Vision-Language Models in Multi-View Driving Reasoning**|Soodeh Nikan Team|[2505.12670](http://arxiv.org/abs/2505.12670)|null|
|**2025-05-19**|**Predicting Reaction Time to Comprehend Scenes with Foveated Scene Understanding Maps**|Miguel P. Eckstein Team|[2505.12660](http://arxiv.org/abs/2505.12660)|null|
|**2025-05-19**|**AutoMat: Enabling Automated Crystal Structure Reconstruction from Microscopy via Agentic Tool Use**|Fei Wei Team|[2505.12650](http://arxiv.org/abs/2505.12650)|**[link](https://github.com/yyt-2378/automat)**|
|**2025-05-19**|**Use as Many Surrogates as You Want: Selective Ensemble Attack to Unleash Transferability without Sacrificing Resource Efficiency**|Zhengyu Zhao Team|[2505.12644](http://arxiv.org/abs/2505.12644)|null|
|**2025-05-19**|**Scalable Video-to-Dataset Generation for Cross-Platform Mobile Agents**|Honglak Lee Team|[2505.12632](http://arxiv.org/abs/2505.12632)|null|
|**2025-05-16**|**Patho-R1: A Multimodal Reinforcement Learning-Based Pathology Expert Reasoner**|Hong Bu Team|[2505.11404](http://arxiv.org/abs/2505.11404)|null|
|**2025-05-16**|**Search-TTA: A Multimodal Test-Time Adaptation Framework for Visual Search in the Wild**|Guillaume Sartoretti Team|[2505.11350](http://arxiv.org/abs/2505.11350)|null|
|**2025-05-16**|**Temporally-Grounded Language Generation: A Benchmark for Real-Time Vision-Language Models**|Joyce Chai Team|[2505.11326](http://arxiv.org/abs/2505.11326)|null|
|**2025-05-16**|**Sample Efficient Reinforcement Learning via Large Vision Language Model Distillation**|Chang D. Yoo Team|[2505.11221](http://arxiv.org/abs/2505.11221)|null|
|**2025-05-16**|**Redundancy-Aware Pretraining of Vision-Language Foundation Models in Remote Sensing**|Begüm Demir Team|[2505.11121](http://arxiv.org/abs/2505.11121)|null|
|**2025-05-16**|**CUBIC: Concept Embeddings for Unsupervised Bias Identification using VLMs**|Natalia Díaz-Rodríguez Team|[2505.11060](http://arxiv.org/abs/2505.11060)|null|
|**2025-05-16**|**Exploiting the Asymmetric Uncertainty Structure of Pre-trained VLMs on the Unit Hypersphere**|Prashant Singh Team|[2505.11029](http://arxiv.org/abs/2505.11029)|null|
|**2025-05-16**|**On DeepSeekMoE: Statistical Benefits of Shared Experts and Normalized Sigmoid Gating**|Alessandro Rinaldo Team|[2505.10860](http://arxiv.org/abs/2505.10860)|null|
|**2025-05-16**|**Benchmarking performance, explainability, and evaluation strategies of vision-language models for surgery: Challenges and opportunities**|Shan Lin Team|[2505.10764](http://arxiv.org/abs/2505.10764)|null|
|**2025-05-15**|**GeoGrid-Bench: Can Foundation Models Understand Multimodal Gridded Geo-Spatial Data?**|Tanwi Mallick Team|[2505.10714](http://arxiv.org/abs/2505.10714)|null|
|**2025-05-15**|**MOSAIC: A Multi-View 2.5D Organ Slice Selector with Cross-Attentional Reasoning for Anatomically-Aware CT Localization in Medical Organ Segmentation**|Muzammil Behzad Team|[2505.10672](http://arxiv.org/abs/2505.10672)|null|
|**2025-05-15**|**CLIP Embeddings for AI-Generated Image Detection: A Few-Shot Study with Lightweight Classifier**|Ziyang Ou Team|[2505.10664](http://arxiv.org/abs/2505.10664)|null|
|**2025-05-15**|**Mitigate Language Priors in Large Vision-Language Models by Cross-Images Contrastive Decoding**|Chong Feng Team|[2505.10634](http://arxiv.org/abs/2505.10634)|null|
|**2025-05-15**|**MMLongBench: Benchmarking Long-Context Vision-Language Models Effectively and Thoroughly**|Mark Steedman Team|[2505.10610](http://arxiv.org/abs/2505.10610)|null|
|**2025-05-18**|**MASSV: Multimodal Adaptation and Self-Data Distillation for Speculative Decoding of Vision-Language Models**|Vithursan Thangarasa Team|[2505.10526](http://arxiv.org/abs/2505.10526)|null|
|**2025-05-16**|**AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenges**|Manoj Karkee Team|[2505.10468](http://arxiv.org/abs/2505.10468)|null|
|**2025-05-15**|**Vision language models have difficulty recognizing virtual objects**|J. G. Trafton Team|[2505.10453](http://arxiv.org/abs/2505.10453)|null|
|**2025-05-15**|**MMRL++: Parameter-Efficient and Interaction-Aware Representation Learning for Vision-Language Models**|Xiaodong Gu Team|[2505.10088](http://arxiv.org/abs/2505.10088)|**[link](https://github.com/yunncheng/MMRL)**|
|**2025-05-15**|**AdaptCLIP: Adapting CLIP for Universal Visual Anomaly Detection**|Chengjie Wang Team|[2505.09926](http://arxiv.org/abs/2505.09926)|**[link](https://github.com/gaobb/AdaptCLIP)**|
|**2025-05-14**|**Unfettered Forceful Skill Acquisition with Physical Reasoning and Coordinate Frame Labeling**|Nikolaus Correll Team|[2505.09731](http://arxiv.org/abs/2505.09731)|null|
|**2025-05-14**|**ManipBench: Benchmarking Vision-Language Models for Low-Level Robot Manipulation**|Daniel Seita Team|[2505.09698](http://arxiv.org/abs/2505.09698)|null|
|**2025-05-14**|**LAS: Loss-less ANN-SNN Conversion for Fully Spike-Driven Large Language Models**|Yanan Sun Team|[2505.09659](http://arxiv.org/abs/2505.09659)|**[link](https://github.com/lc783/las)**|
|**2025-05-14**|**Variational Visual Question Answering**|Marcus Rohrbach Team|[2505.09591](http://arxiv.org/abs/2505.09591)|null|
|**2025-05-14**|**VTLA: Vision-Tactile-Language-Action Model with Preference Learning for Insertion Manipulation**|Shuo Wang Team|[2505.09577](http://arxiv.org/abs/2505.09577)|null|
|**2025-05-14**|**Flash-VL 2B: Optimizing Vision-Language Model Performance for Ultra-Low Latency and High Throughput**|Lin Ma Team|[2505.09498](http://arxiv.org/abs/2505.09498)|null|
|**2025-05-14**|**Unsupervised Multiview Contrastive Language-Image Joint Learning with Pseudo-Labeled Prompts Via Vision-Language Model for 3D/4D Facial Expression Recognition**|Muzammil Behzad Team|[2505.09336](http://arxiv.org/abs/2505.09336)|null|
|**2025-05-14**|**MetaUAS: Universal Anomaly Segmentation with One-Prompt Meta-Learning**|Bin-Bin Gao Team|[2505.09265](http://arxiv.org/abs/2505.09265)|null|
|**2025-05-14**|**Beyond General Prompts: Automated Prompt Refinement using Contrastive Class Alignment Scores for Disambiguating Objects in Vision-Language Models**|Ross Greer Team|[2505.09139](http://arxiv.org/abs/2505.09139)|null|
|**2025-05-14**|**Seeing Beyond the Scene: Enhancing Vision-Language Models with Interactional Reasoning**|Qing Li Team|[2505.09118](http://arxiv.org/abs/2505.09118)|null|
|**2025-05-14**|**OpenLKA: An Open Dataset of Lane Keeping Assist from Recent Car Models under Real-world Driving Conditions**|Hao Zhou Team|[2505.09092](http://arxiv.org/abs/2505.09092)|**[link](https://github.com/openlka/openlka)**|
|**2025-05-13**|**Prioritizing Image-Related Tokens Enhances Vision-Language Pre-Training**|Heng Ji Team|[2505.08971](http://arxiv.org/abs/2505.08971)|**[link](https://github.com/yangyi-chen/prior)**|
|**2025-05-15**|**Behind Maya: Building a Multilingual Vision Language Model**|Alham Fikri Aji Team|[2505.08910](http://arxiv.org/abs/2505.08910)|**[link](https://github.com/nahidalam/maya)**|
|**2025-05-12**|**Position: Restructuring of Categories and Implementation of Guidelines Essential for VLM Adoption in Healthcare**|Imon Banerjee Team|[2505.08818](http://arxiv.org/abs/2505.08818)|null|
|**2025-05-13**|**Extending Large Vision-Language Model for Diverse Interactive Tasks in Autonomous Driving**|Xiang Bai Team|[2505.08725](http://arxiv.org/abs/2505.08725)|**[link](https://github.com/zc-zhao/drivemonkey)**|
|**2025-05-13**|**OpenThinkIMG: Learning to Think with Images via Visual Tool Reinforcement Learning**|Yu Cheng Team|[2505.08617](http://arxiv.org/abs/2505.08617)|**[link](https://github.com/zhaochen0110/openthinkimg)**|
|**2025-05-13**|**From Seeing to Doing: Bridging Reasoning and Decision for Robotic Manipulation**|Jianye Hao Team|[2505.08548](http://arxiv.org/abs/2505.08548)|null|
|**2025-05-13**|**Judging the Judges: Can Large Vision-Language Models Fairly Evaluate Chart Comprehension and Reasoning?**|Jimmy Huang Team|[2505.08468](http://arxiv.org/abs/2505.08468)|**[link](https://github.com/tahmedge/chart_lvlm_judge)**|
|**2025-05-13**|**MA-ROESL: Motion-aware Rapid Reward Optimization for Efficient Robot Skill Learning from Single Videos**|Wei Zhang Team|[2505.08367](http://arxiv.org/abs/2505.08367)|null|
|**2025-05-13**|**Removing Watermarks with Partial Regeneration using Semantic Information**|Michael W. Mahoney Team|[2505.08234](http://arxiv.org/abs/2505.08234)|**[link](https://github.com/krtit/semanticregen)**|
|**2025-05-13**|**CLTP: Contrastive Language-Tactile Pre-training for 3D Contact Geometry Understanding**|Shuo Wang Team|[2505.08194](http://arxiv.org/abs/2505.08194)|null|
|**2025-05-13**|**DSADF: Thinking Fast and Slow for Decision Making**|Shufei Zhang Team|[2505.08189](http://arxiv.org/abs/2505.08189)|null|
|**2025-05-12**|**Imagine, Verify, Execute: Memory-Guided Agentic Exploration with Vision-Language Models**|Jia-Bin Huang Team|[2505.07815](http://arxiv.org/abs/2505.07815)|null|
|**2025-05-12**|**Reproducibility, Replicability, and Insights into Visual Document Retrieval with Late Interaction**|Andrew Yates Team|[2505.07730](http://arxiv.org/abs/2505.07730)|null|
|**2025-05-12**|**Through the Looking Glass: Common Sense Consistency Evaluation of Weird Images**|Vasily Konovalov Team|[2505.07704](http://arxiv.org/abs/2505.07704)|null|
|**2025-05-12**|**Beyond CLIP Generalization: Against Forward&Backward Forgetting Adapter for Continual Learning of Vision-Language Models**|Yihong Gong Team|[2505.07690](http://arxiv.org/abs/2505.07690)|null|
|**2025-05-12**|**Simple Semi-supervised Knowledge Distillation from Vision-Language Models via $\mathbf{\texttt{D}}$ual-$\mathbf{\texttt{H}}$ead $\mathbf{\texttt{O}}$ ptimization**|Sung Ju Hwang Team|[2505.07675](http://arxiv.org/abs/2505.07675)|null|
|**2025-05-12**|**Discrete Visual Tokens of Autoregression, by Diffusion, and for Reasoning**|Hanwang Zhang Team|[2505.07538](http://arxiv.org/abs/2505.07538)|null|
|**2025-05-12**|**AI-Enabled Accurate Non-Invasive Assessment of Pulmonary Hypertension Progression via Multi-Modal Echocardiography**|Xiaomeng Li Team|[2505.07347](http://arxiv.org/abs/2505.07347)|null|
|**2025-05-12**|**Skywork-VL Reward: An Effective Reward Model for Multimodal Understanding and Reasoning**|Yahui Zhou Team|[2505.07263](http://arxiv.org/abs/2505.07263)|null|
|**2025-05-12**|**Incomplete In-context Learning**|Yangshijie Zhang Team|[2505.07251](http://arxiv.org/abs/2505.07251)|null|
|**2025-05-12**|**UAV-CodeAgents: Scalable UAV Mission Planning via Multi-Agent ReAct and Vision-Language Reasoning**|Dzmitry Tsetserukou Team|[2505.07236](http://arxiv.org/abs/2505.07236)|null|
|**2025-05-12**|**Language-Driven Dual Style Mixing for Single-Domain Generalized Object Detection**|Ningjiang Chen Team|[2505.07219](http://arxiv.org/abs/2505.07219)|**[link](https://github.com/qinhongda8/ldds)**|
|**2025-05-12**|**Internet of Agents: Fundamentals, Applications, and Challenges**|Dusit Niyato Team|[2505.07176](http://arxiv.org/abs/2505.07176)|null|
|**2025-05-12**|**Critique Before Thinking: Mitigating Hallucination through Rationale-Augmented Instruction Tuning**|Weiping Wang Team|[2505.07172](http://arxiv.org/abs/2505.07172)|null|
|**2025-05-12**|**EmoVLM-KD: Fusing Distilled Expertise with Vision-Language Models for Visual Emotion Analysis**|Eunil Park Team|[2505.07164](http://arxiv.org/abs/2505.07164)|null|
|**2025-05-11**|**A Vision-Language Foundation Model for Leaf Disease Identification**|Luyl-Da Quach Team|[2505.07019](http://arxiv.org/abs/2505.07019)|null|
|**2025-05-11**|**Hallucination-Aware Multimodal Benchmark for Gastrointestinal Image Analysis with Large Vision-Language Models**|Binod Bhattarai Team|[2505.07001](http://arxiv.org/abs/2505.07001)|null|
|**2025-05-11**|**UniDiffGrasp: A Unified Framework Integrating VLM Reasoning and VLM-Guided Part Diffusion for Open-Vocabulary Constrained Grasping with Dual Arms**|Zhenze Liu Team|[2505.06832](http://arxiv.org/abs/2505.06832)|null|
|**2025-05-10**|**STRIVE: Structured Representation Integrating VLM Reasoning for Efficient Object Navigation**|Jean Oh Team|[2505.06729](http://arxiv.org/abs/2505.06729)|null|
|**2025-05-10**|**METOR: A Unified Framework for Mutual Enhancement of Objects and Relationships in Open-vocabulary Video Visual Relationship Detection**|Shuo Yang Team|[2505.06663](http://arxiv.org/abs/2505.06663)|**[link](https://github.com/wangyongqi558/METOR)**|
|**2025-05-10**|**Integrating Video and Text: A Balanced Approach to Multimodal Summary Generation and Evaluation**|Nancy F. Chen Team|[2505.06594](http://arxiv.org/abs/2505.06594)|null|
|**2025-05-09**|**MM-Skin: Enhancing Dermatology Vision-Language Model with an Image-Text Dataset Derived from Textbooks**|Bo Yan Team|[2505.06152](http://arxiv.org/abs/2505.06152)|**[link](https://github.com/zwq803/mm-skin)**|
|**2025-05-09**|**Leveraging Vision-Language Models for Visual Grounding and Analysis of Automotive UI**|Dominik Bollmann Team|[2505.05895](http://arxiv.org/abs/2505.05895)|null|
|**2025-05-09**|**Describe Anything in Medical Images**|Min Xu Team|[2505.05804](http://arxiv.org/abs/2505.05804)|null|
|**2025-05-09**|**3D CAVLA: Leveraging Depth and 3D Context to Generalize Vision Language Action Models for Unseen Tasks**|Farshad Khorrami Team|[2505.05800](http://arxiv.org/abs/2505.05800)|null|
|**2025-05-08**|**Fine-Tuning Video-Text Contrastive Model for Primate Behavior Retrieval from Unlabeled Raw Videos**|Nina S. T. Hirata Team|[2505.05681](http://arxiv.org/abs/2505.05681)|null|
|**2025-05-08**|**X-Transfer Attacks: Towards Super Transferable Adversarial Attacks on CLIP**|James Bailey Team|[2505.05528](http://arxiv.org/abs/2505.05528)|**[link](https://github.com/HanxunH/XTransferBench)**|
|**2025-05-08**|**Bring Reason to Vision: Understanding Perception and Reasoning through Model Merging**|Junxian He Team|[2505.05464](http://arxiv.org/abs/2505.05464)|**[link](https://github.com/shiqichen17/vlm_merging)**|
|**2025-05-08**|**SITE: towards Spatial Intelligence Thorough Evaluation**|Boqing Gong Team|[2505.05456](http://arxiv.org/abs/2505.05456)|null|
|**2025-05-08**|**DSDrive: Distilling Large Language Model for Lightweight End-to-End Autonomous Driving with Unified Reasoning and Planning**|Jun Ma Team|[2505.05360](http://arxiv.org/abs/2505.05360)|null|
|**2025-05-08**|**Hearing and Seeing Through CLIP: A Framework for Self-Supervised Sound Source Localization**|Joon Son Chung Team|[2505.05343](http://arxiv.org/abs/2505.05343)|**[link](https://github.com/swimmiing/ACL-SSL)**|
|**2025-05-08**|**Mapping User Trust in Vision Language Models: Research Landscape, Challenges, and Prospects**|Matteo Matteucci Team|[2505.05318](http://arxiv.org/abs/2505.05318)|null|
|**2025-05-08**|**Biomed-DPT: Dual Modality Prompt Tuning for Biomedical Vision-Language Models**|Meng Zhang Team|[2505.05189](http://arxiv.org/abs/2505.05189)|null|
|**2025-05-08**|**OpenworldAUC: Towards Unified Evaluation and Optimization for Open-world Prompt Tuning**|Qingming Huang Team|[2505.05180](http://arxiv.org/abs/2505.05180)|**[link](https://github.com/huacong/openworldauc)**|
|**2025-05-08**|**Probabilistic Embeddings for Frozen Vision-Language Models: Uncertainty Quantification with Gaussian Process Latent Variable Models**|Joachim Denzler Team|[2505.05163](http://arxiv.org/abs/2505.05163)|null|
|**2025-05-08**|**CacheFL: Efficient Federated Cache Model Fine-Tuning for Vision-Language Models**|Furao Shen Team|[2505.05130](http://arxiv.org/abs/2505.05130)|null|
|**2025-05-08**|**X-Driver: Explainable Autonomous Driving with Vision-Language Models**|Zengfeng Zeng Team|[2505.05098](http://arxiv.org/abs/2505.05098)|null|
|**2025-05-08**|**Image-Text Relation Prediction for Multilingual Tweets**|Edison Marrese-Taylor Team|[2505.05040](http://arxiv.org/abs/2505.05040)|null|
|**2025-05-09**|**G-FOCUS: Towards a Robust Method for Assessing UI Design Persuasiveness**|Youngjae Yu Team|[2505.05026](http://arxiv.org/abs/2505.05026)|null|
|**2025-05-08**|**Split Matching for Inductive Zero-shot Semantic Segmentation**|Daisuke Deguchi Team|[2505.05023](http://arxiv.org/abs/2505.05023)|null|
|**2025-05-08**|**LVLM-MPC Collaboration for Autonomous Driving: A Safety-Aware and Task-Scalable Control Architecture**|Tatsuya Suzuki Team|[2505.04980](http://arxiv.org/abs/2505.04980)|null|
|**2025-05-07**|**Vision-Language-Action Models: Concepts, Progress, Applications and Challenges**|Manoj Karkee Team|[2505.04769](http://arxiv.org/abs/2505.04769)|null|
|**2025-05-07**|**"I Can See Forever!": Evaluating Real-time VideoLLMs for Assisting Individuals with Visual Impairments**|Xinlei He Team|[2505.04488](http://arxiv.org/abs/2505.04488)|null|
|**2025-05-07**|**DeCLIP: Decoupled Learning for Open-Vocabulary Dense Perception**|Zhuotao Tian Team|[2505.04410](http://arxiv.org/abs/2505.04410)|**[link](https://github.com/xiaomoguhz/declip)**|
|**2025-05-07**|**CM1 -- A Dataset for Evaluating Few-Shot Information Extraction with Large Vision Language Models**|Gernot A. Fink Team|[2505.04214](http://arxiv.org/abs/2505.04214)|null|
|**2025-05-07**|**R^3-VQA: "Read the Room" by Video Social Reasoning**|Lifeng Fan Team|[2505.04147](http://arxiv.org/abs/2505.04147)|null|
|**2025-05-06**|**X-Reasoner: Towards Generalizable Reasoning Across Modalities and Domains**|Hoifung Poon Team|[2505.03981](http://arxiv.org/abs/2505.03981)|null|
|**2025-05-06**|**Fill the Gap: Quantifying and Reducing the Modality Gap in Image-Text Representation Learning**|Victor Amblard Team|[2505.03703](http://arxiv.org/abs/2505.03703)|null|
|**2025-05-06**|**Distribution-Conditional Generation: From Class Distribution to Creative Generation**|Xin Geng Team|[2505.03667](http://arxiv.org/abs/2505.03667)|null|
|**2025-05-06**|**Learning Unknown Spoof Prompts for Generalized Face Anti-Spoofing Using Only Real Face Images**|Zhenan Sun Team|[2505.03611](http://arxiv.org/abs/2505.03611)|null|
|**2025-05-06**|**Learning Knowledge-based Prompts for Robust 3D Mask Presentation Attack Detection**|Ming-Hsuan Yang Team|[2505.03610](http://arxiv.org/abs/2505.03610)|null|
|**2025-05-06**|**Mitigating Image Captioning Hallucinations in Vision-Language Models**|Xi Li Team|[2505.03420](http://arxiv.org/abs/2505.03420)|null|
|**2025-05-07**|**Enhancing Target-unspecific Tasks through a Features Matrix**|Jun Yu Team|[2505.03414](http://arxiv.org/abs/2505.03414)|null|
|**2025-05-06**|**Reducing Annotation Burden in Physical Activity Research Using Vision-Language Models**|Aiden Doherty Team|[2505.03374](http://arxiv.org/abs/2505.03374)|null|
|**2025-05-06**|**A Vision-Language Model for Focal Liver Lesion Classification**|Chen Yen-Wei Team|[2505.03350](http://arxiv.org/abs/2505.03350)|null|
|**2025-05-06**|**From Word to Sentence: A Large-Scale Multi-Instance Dataset for Open-Set Aerial Detection**|Rong Xiao Team|[2505.03334](http://arxiv.org/abs/2505.03334)|null|
|**2025-05-06**|**Seeing the Abstract: Translating the Abstract Language for Vision Language Models**|Yiming Wang Team|[2505.03242](http://arxiv.org/abs/2505.03242)|**[link](https://github.com/davidetalon/fashionact)**|
|**2025-05-06**|**VLM Q-Learning: Aligning Vision-Language Models for Interactive Decision-Making**|Juan Carlos Niebles Team|[2505.03181](http://arxiv.org/abs/2505.03181)|null|
|**2025-05-06**|**Robust Fairness Vision-Language Learning for Medical Image Analysis**|Shu Hu Team|[2505.03153](http://arxiv.org/abs/2505.03153)|**[link](https://github.com/purdue-m2/robust_fairness_for_medical_image)**|
|**2025-05-05**|**Adversarial Robustness Analysis of Vision-Language Models in Medical Image Segmentation**|Manish Dhakal Team|[2505.02971](http://arxiv.org/abs/2505.02971)|null|
|**2025-05-05**|**LISAT: Language-Instructed Segmentation Assistant for Satellite Imagery**|David M. Chan Team|[2505.02829](http://arxiv.org/abs/2505.02829)|null|
|**2025-05-05**|**HapticVLM: VLM-Driven Texture Recognition Aimed at Intelligent Haptic Interaction**|Dzmitry Tsetserukou Team|[2505.02569](http://arxiv.org/abs/2505.02569)|null|
|**2025-05-05**|**Tevatron 2.0: Unified Document Retrieval Toolkit across Scale, Language, and Modality**|Jimmy Lin Team|[2505.02466](http://arxiv.org/abs/2505.02466)|null|
|**2025-05-05**|**Recent Advances in Out-of-Distribution Detection with CLIP-Like Models: A Survey**|Songcan Chen Team|[2505.02448](http://arxiv.org/abs/2505.02448)|null|
|**2025-05-05**|**SuperEdit: Rectifying and Facilitating Supervision for Instruction-Based Image Editing**|Sijie Zhu Team|[2505.02370](http://arxiv.org/abs/2505.02370)|**[link](https://github.com/bytedance/superedit)**|
|**2025-05-05**|**TeDA: Boosting Vision-Lanuage Models for Zero-Shot 3D Object Retrieval via Testing-time Distribution Alignment**|Xinwei He Team|[2505.02325](http://arxiv.org/abs/2505.02325)|null|
|**2025-05-04**|**Compositional Image-Text Matching and Retrieval by Grounding Entities**|Jana Košecká Team|[2505.02278](http://arxiv.org/abs/2505.02278)|null|
|**2025-05-04**|**Handling Imbalanced Pseudolabels for Vision-Language Models with Concept Alignment and Confusion-Aware Calibrated Margin**|Xinyang Chen Team|[2505.02056](http://arxiv.org/abs/2505.02056)|null|
|**2025-05-04**|**A Comprehensive Analysis for Visual Object Hallucination in Large Vision-Language Models**|Xinya Du Team|[2505.01958](http://arxiv.org/abs/2505.01958)|null|
|**2025-05-03**|**PhysNav-DG: A Novel Adaptive Framework for Robust VLM-Sensor Fusion in Navigation Applications**|Santosh Patapati Team|[2505.01881](http://arxiv.org/abs/2505.01881)|null|
|**2025-05-03**|**Enhancing the Learning Experience: Using Vision-Language Models to Generate Questions for Educational Videos**|Anett Hoppe Team|[2505.01790](http://arxiv.org/abs/2505.01790)|null|
|**2025-05-03**|**An LLM-Empowered Low-Resolution Vision System for On-Device Human Behavior Understanding**|Guoliang Xing Team|[2505.01743](http://arxiv.org/abs/2505.01743)|null|
|**2025-05-03**|**Vision and Intention Boost Large Language Model in Long-Term Action Anticipation**|Yanning Zhang Team|[2505.01713](http://arxiv.org/abs/2505.01713)|null|
|**2025-05-03**|**RoBridge: A Hierarchical Architecture Bridging Cognition and Execution for General Robotic Manipulation**|Xiaodan Liang Team|[2505.01709](http://arxiv.org/abs/2505.01709)|null|
|**2025-05-03**|**Topology-Aware CLIP Few-Shot Learning**|Dazhi Huang Team|[2505.01694](http://arxiv.org/abs/2505.01694)|null|
|**2025-05-02**|**TEMPURA: Temporal Event Masked Prediction and Understanding for Reasoning in Action**|Jenq-Neng Hwang Team|[2505.01583](http://arxiv.org/abs/2505.01583)|null|
|**2025-05-02**|**Grounding Task Assistance with Multimodal Cues from a Single Demonstration**|Andrew D. Wilson Team|[2505.01578](http://arxiv.org/abs/2505.01578)|null|
|**2025-05-02**|**Dynamic Robot Tool Use with Vision Language Models**|Ahmed H. Qureshi Team|[2505.01399](http://arxiv.org/abs/2505.01399)|null|
|**2025-05-02**|**Evaluating Vision Language Model Adaptations for Radiology Report Generation in Low-Resource Languages**|Valerio Guarrasi Team|[2505.01096](http://arxiv.org/abs/2505.01096)|null|
|**2025-05-02**|**Any-to-Any Vision-Language Model for Multimodal X-ray Imaging and Radiological Report Generation**|Valerio Guarrasi Team|[2505.01091](http://arxiv.org/abs/2505.01091)|null|
|**2025-05-02**|**Transferable Adversarial Attacks on Black-Box Vision-Language Models**|Matt Fredrikson Team|[2505.01050](http://arxiv.org/abs/2505.01050)|null|
|**2025-04-30**|**Entropy Heat-Mapping: Localizing GPT-Based OCR Errors with Sliding-Window Shannon Analysis**|Alexei Kaltchenko Team|[2505.00746](http://arxiv.org/abs/2505.00746)|null|
|**2025-05-01**|**Robotic Visual Instruction**|Xianzheng Ma Team|[2505.00693](http://arxiv.org/abs/2505.00693)|null|
|**2025-05-01**|**Visual Test-time Scaling for GUI Agent Grounding**|Honglak Lee Team|[2505.00684](http://arxiv.org/abs/2505.00684)|null|
|**2025-05-01**|**DeCo: Task Decomposition and Skill Composition for Zero-Shot Generalization in Long-Horizon 3D Manipulation**|Yang Gao Team|[2505.00527](http://arxiv.org/abs/2505.00527)|null|
|**2025-05-01**|**LightEMMA: Lightweight End-to-End Multimodal Model for Autonomous Driving**|Henry X. Liu Team|[2505.00284](http://arxiv.org/abs/2505.00284)|null|
|**2025-05-01**|**AdCare-VLM: Leveraging Large Vision Language Model (LVLM) to Monitor Long-Term Medication Adherence and Care**|Tianming Liu Team|[2505.00275](http://arxiv.org/abs/2505.00275)|null|
|**2025-04-30**|**V3LMA: Visual 3D-enhanced Language Model for Autonomous Driving**|Markus Lienkamp Team|[2505.00156](http://arxiv.org/abs/2505.00156)|null|
|**2025-04-30**|**Detecting and Mitigating Hateful Content in Multimodal Memes with Vision-Language Models**|Xintao Wu Team|[2505.00150](http://arxiv.org/abs/2505.00150)|null|
|**2025-04-30**|**Investigating Zero-Shot Diagnostic Pathology in Vision-Language Models with Efficient Prompt Design**|Mahdi S. Hosseini Team|[2505.00134](http://arxiv.org/abs/2505.00134)|null|
|**2025-04-30**|**Early Exit and Multi Stage Knowledge Distillation in VLMs for Video Summarization**|Ganesh Ramakrishnan Team|[2504.21831](http://arxiv.org/abs/2504.21831)|null|
|**2025-04-30**|**Black-Box Visual Prompt Engineering for Mitigating Object Hallucination in Large Vision Language Models**|Lin Lee Cheong Team|[2504.21559](http://arxiv.org/abs/2504.21559)|null|
|**2025-04-30**|**RoboGround: Robotic Manipulation with Grounded Vision-Language Priors**|Zhou Zhao Team|[2504.21530](http://arxiv.org/abs/2504.21530)|null|
|**2025-04-30**|**Vision-Language Model-Based Semantic-Guided Imaging Biomarker for Early Lung Cancer Detection**|William Hsu Team|[2504.21344](http://arxiv.org/abs/2504.21344)|null|
|**2025-04-29**|**MemeBLIP2: A novel lightweight multimodal system to detect harmful memes**|Lisha Xu Team|[2504.21226](http://arxiv.org/abs/2504.21226)|null|
|**2025-04-29**|**GLIP-OOD: Zero-Shot Graph OOD Detection with Foundation Model**|Yue Zhao Team|[2504.21186](http://arxiv.org/abs/2504.21186)|null|
|**2025-04-29**|**Token-Level Prompt Mixture with Parameter-Free Routing for Federated Domain Generalization**|Xiaojun Chang Team|[2504.21063](http://arxiv.org/abs/2504.21063)|null|
|**2025-04-29**|**Real-Time Wayfinding Assistant for Blind and Low-Vision Users**|Farhan Sadaf Team|[2504.20976](http://arxiv.org/abs/2504.20976)|null|
|**2025-04-29**|**FedMVP: Federated Multi-modal Visual Prompt Tuning for Vision-Language Models**|Elisa Ricci Team|[2504.20860](http://arxiv.org/abs/2504.20860)|null|
|**2025-04-29**|**In-Context Edit: Enabling Instructional Image Editing with In-Context Generation in Large Scale Diffusion Transformer**|Yi Yang Team|[2504.20690](http://arxiv.org/abs/2504.20690)|null|
|**2025-04-29**|**SpaRE: Enhancing Spatial Reasoning in Vision-Language Models with Synthetic Data**|Freda Shi Team|[2504.20648](http://arxiv.org/abs/2504.20648)|null|
|**2025-04-29**|**PRISM: Projection-based Reward Integration for Scene-Aware Real-to-Sim-to-Real Transfer with Few Demonstrations**|Xuguang Lan Team|[2504.20520](http://arxiv.org/abs/2504.20520)|null|
|**2025-04-29**|**Antidote: A Unified Framework for Mitigating LVLM Hallucinations in Counterfactual Presupposition and Object Perception**|Xiaoqiang Li Team|[2504.20468](http://arxiv.org/abs/2504.20468)|null|
|**2025-04-29**|**Plant Disease Detection through Multimodal Large Language Models and Convolutional Neural Networks**|Dimitrios K. Nasiopoulos Team|[2504.20419](http://arxiv.org/abs/2504.20419)|null|
|**2025-04-29**|**FiLA-Video: Spatio-Temporal Compression for Fine-Grained Long Video Understanding**|Bo Zheng Team|[2504.20384](http://arxiv.org/abs/2504.20384)|null|
|**2025-04-28**|**A Multimodal Pipeline for Clinical Data Extraction: Applying Vision-Language Models to Scans of Transfusion Reaction Reports**|Christoph M. Friedrich Team|[2504.20220](http://arxiv.org/abs/2504.20220)|null|
|**2025-04-28**|**Weaving Context Across Images: Improving Vision-Language Models through Focus-Centric Visual Chains**|Rui Yan Team|[2504.20199](http://arxiv.org/abs/2504.20199)|null|
|**2025-04-28**|**SpatialReasoner: Towards Explicit and Generalizable 3D Spatial Reasoning**|Alan Yuille Team|[2504.20024](http://arxiv.org/abs/2504.20024)|null|
|**2025-04-28**|**EcoWikiRS: Learning Ecological Representation of Satellite Images from Weak Supervision with Species Observations and Wikipedia**|Diego Marcos Team|[2504.19742](http://arxiv.org/abs/2504.19742)|null|
|**2025-04-28**|**Contrastive Language-Image Learning with Augmented Textual Prompts for 3D/4D FER Using Vision-Language Model**|Guoying Zhao Team|[2504.19739](http://arxiv.org/abs/2504.19739)|null|
|**2025-04-28**|**VCM: Vision Concept Modeling Based on Implicit Contrastive Learning with Vision-Language Instruction Fine-Tuning**|Xiaobo Xia Team|[2504.19627](http://arxiv.org/abs/2504.19627)|null|
|**2025-04-28**|**LR-IAD:Mask-Free Industrial Anomaly Detection with Logical Reasoning**|Aimin Yang Team|[2504.19524](http://arxiv.org/abs/2504.19524)|null|
|**2025-04-27**|**DeepSPG: Exploring Deep Semantic Prior Guidance for Low-light Image Enhancement with Multimodal Learning**|Shini Han Team|[2504.19127](http://arxiv.org/abs/2504.19127)|null|
|**2025-04-27**|**Boosting Single-domain Generalized Object Detection via Vision-Language Knowledge Interaction**|Jian Liu Team|[2504.19086](http://arxiv.org/abs/2504.19086)|null|
|**2025-04-26**|**Multi-Resolution Pathology-Language Pre-training Model with Text-Guided Visual Representation**|Arif Mahmood Team|[2504.18856](http://arxiv.org/abs/2504.18856)|null|
|**2025-04-26**|**Video CLIP Model for Multi-View Echocardiography Interpretation**|Norihiko Takeda Team|[2504.18800](http://arxiv.org/abs/2504.18800)|null|
|**2025-04-25**|**A Review of 3D Object Detection with Vision-Language Models**|Manoj Karkee Team|[2504.18738](http://arxiv.org/abs/2504.18738)|null|
|**2025-04-25**|**Proof-of-TBI -- Fine-Tuned Vision Language Model Consortium and OpenAI-o3 Reasoning LLM-Based Medical Diagnosis Support System for Mild Traumatic Brain Injury (TBI) Prediction**|Donna Broshek Team|[2504.18671](http://arxiv.org/abs/2504.18671)|null|
|**2025-04-25**|**Generalization Capability for Imitation Learning**|Yixiao Wang Team|[2504.18538](http://arxiv.org/abs/2504.18538)|null|
|**2025-04-25**|**Fast-Slow Thinking for Large Vision-Language Model Reasoning**|Fei Wu Team|[2504.18458](http://arxiv.org/abs/2504.18458)|null|
|**2025-04-25**|**Reason Like a Radiologist: Chain-of-Thought and Reinforcement Learning for Verifiable Report Generation**|Guang Yang Team|[2504.18453](http://arxiv.org/abs/2504.18453)|null|
|**2025-04-25**|**Revisiting Data Auditing in Large Vision-Language Models**|Zhuosheng Zhang Team|[2504.18349](http://arxiv.org/abs/2504.18349)|null|
|**2025-04-25**|**A Large Vision-Language Model based Environment Perception System for Visually Impaired People**|Shiguo Lian Team|[2504.18027](http://arxiv.org/abs/2504.18027)|null|
|**2025-04-24**|**CAMU: Context Augmentation for Meme Understanding**|Aditya Joshi Team|[2504.17902](http://arxiv.org/abs/2504.17902)|null|
|**2025-04-24**|**FashionM3: Multimodal, Multitask, and Multiround Fashion Assistant based on Unified Vision-Language Model**|Waikeung Wong Team|[2504.17826](http://arxiv.org/abs/2504.17826)|null|
|**2025-04-25**|**Data-Driven Calibration of Prediction Sets in Large Vision-Language Models Based on Inductive Conformal Prediction**|Weiyan Wen Team|[2504.17671](http://arxiv.org/abs/2504.17671)|null|
|**2025-04-24**|**SDVPT: Semantic-Driven Visual Prompt Tuning for Open-World Object Counting**|Qingming Huang Team|[2504.17395](http://arxiv.org/abs/2504.17395)|null|
|**2025-04-24**|**M-MRE: Extending the Mutual Reinforcement Effect to Multimodal Information Extraction**|Tatsunori Mori Team|[2504.17353](http://arxiv.org/abs/2504.17353)|null|
|**2025-04-24**|**DIMT25@ICDAR2025: HW-TSC's End-to-End Document Image Machine Translation System Leveraging Large Vision-Language Model**|Hao Yang Team|[2504.17315](http://arxiv.org/abs/2504.17315)|null|
|**2025-04-24**|**Cracking the Code of Action: a Generative Approach to Affordances for Reinforcement Learning**|Khimya Khetarpal Team|[2504.17282](http://arxiv.org/abs/2504.17282)|null|
|**2025-04-24**|**Perspective-Aware Reasoning in Vision-Language Models via Mental Imagery Simulation**|Minhyuk Sung Team|[2504.17207](http://arxiv.org/abs/2504.17207)|null|
|**2025-04-23**|**Distilling semantically aware orders for autoregressive image generation**|Marco Pedersoli Team|[2504.17069](http://arxiv.org/abs/2504.17069)|null|
|**2025-04-23**|**DyMU: Dynamic Merging and Virtual Unmerging for Efficient VLMs**|Ran Xu Team|[2504.17040](http://arxiv.org/abs/2504.17040)|null|
|**2025-04-24**|**V $^2$ R-Bench: Holistically Evaluating LVLM Robustness to Fundamental Visual Variations**|Yi R. Fung Team|[2504.16727](http://arxiv.org/abs/2504.16727)|null|
|**2025-04-23**|**Streetscape Analysis with Generative AI (SAGAI): Vision-Language Assessment and Mapping of Urban Scenes**|Giovanni Fusco Team|[2504.16538](http://arxiv.org/abs/2504.16538)|null|
|**2025-04-23**|**TraveLLaMA: Facilitating Multi-modal Large Language Models to Understand Urban Scenes and Provide Travel Assistance**|Jiaya Jia Team|[2504.16505](http://arxiv.org/abs/2504.16505)|null|
|**2025-04-23**|**FrogDogNet: Fourier frequency Retained visual prompt Output Guidance for Domain Generalization of CLIP in Remote Sensing**|Biplab Banerjee Team|[2504.16433](http://arxiv.org/abs/2504.16433)|null|
|**2025-04-22**|**CLIP-IT: CLIP-based Pairing for Histology Images Classification**|Eric Granger Team|[2504.16181](http://arxiv.org/abs/2504.16181)|null|
|**2025-04-22**|**MMInference: Accelerating Pre-filling for Long-Context VLMs via Modality-Aware Permutation Sparse Attention**|Lili Qiu Team|[2504.16083](http://arxiv.org/abs/2504.16083)|null|
|**2025-04-22**|**MR. Video: "MapReduce" is the Principle for Long Video Understanding**|Yu-Xiong Wang Team|[2504.16082](http://arxiv.org/abs/2504.16082)|null|
|**2025-04-22**|**Describe Anything: Detailed Localized Image and Video Captioning**|Yin Cui Team|[2504.16072](http://arxiv.org/abs/2504.16072)|null|
|**2025-04-22**|**Vision language models are unreliable at trivial spatial cognition**|J. Gregory Trafton Team|[2504.16061](http://arxiv.org/abs/2504.16061)|null|
|**2025-04-22**|**Vision-Language Models Are Not Pragmatically Competent in Referring Expression Generation**|Joyce Chai Team|[2504.16060](http://arxiv.org/abs/2504.16060)|null|
|**2025-04-22**|**Evaluating Vision Language Models (VLMs) for Radiology: A Comprehensive Analysis**|Judy Gichoya Team|[2504.16047](http://arxiv.org/abs/2504.16047)|null|
|**2025-04-22**|**LiveCC: Learning Video LLM with Streaming Speech Transcription at Scale**|Mike Zheng Shou Team|[2504.16030](http://arxiv.org/abs/2504.16030)|null|
|**2025-04-24**|**Meta-Entity Driven Triplet Mining for Aligning Medical Vision-Language Models**|Tolga Çukur Team|[2504.15929](http://arxiv.org/abs/2504.15929)|null|
|**2025-04-21**|**CAPTURe: Evaluating Spatial Reasoning in Vision Language Models via Occluded Object Counting**|Mohit Bansal Team|[2504.15485](http://arxiv.org/abs/2504.15485)|null|
|**2025-04-21**|**Eagle 2.5: Boosting Long-Context Post-Training for Frontier Vision-Language Models**|Guilin Liu Team|[2504.15271](http://arxiv.org/abs/2504.15271)|null|
|**2025-04-21**|**KGMEL: Knowledge Graph-Enhanced Multimodal Entity Linking**|Kijung Shin Team|[2504.15135](http://arxiv.org/abs/2504.15135)|**[link](https://github.com/juyeonnn/kgmel)**|
|**2025-04-21**|**Benchmarking Large Vision-Language Models on Fine-Grained Image Tasks: A Comprehensive Evaluation**|Serge Belongie Team|[2504.14988](http://arxiv.org/abs/2504.14988)|**[link](https://github.com/seu-vipgroup/fg-bmk)**|
|**2025-04-21**|**VLM as Policy: Common-Law Content Moderation Framework for Short Video Platform**|Kun Gai Team|[2504.14904](http://arxiv.org/abs/2504.14904)|null|
|**2025-04-21**|**Object-Level Verbalized Confidence Calibration in Vision-Language Models via Semantic Perturbation**|Yunji Chen Team|[2504.14848](http://arxiv.org/abs/2504.14848)|null|
|**2025-04-20**|**OmniV-Med: Scaling Medical Vision-Language Model for Universal Visual Understanding**|Zuozhu Liu Team|[2504.14692](http://arxiv.org/abs/2504.14692)|null|
|**2025-04-20**|**NVSMask3D: Hard Visual Prompting with Camera Pose Interpolation for 3D Open Vocabulary Instance Segmentation**|Juho Kannala Team|[2504.14638](http://arxiv.org/abs/2504.14638)|null|
|**2025-04-20**|**LGD: Leveraging Generative Descriptions for Zero-Shot Referring Image Segmentation**|Yongsheng Gao Team|[2504.14467](http://arxiv.org/abs/2504.14467)|null|
|**2025-04-20**|**Neglected Risks: The Disturbing Reality of Children's Images in Datasets and the Urgent Call for Accountability**|Sandra Avila Team|[2504.14446](http://arxiv.org/abs/2504.14446)|null|
|**2025-04-19**|**Hydra: An Agentic Reasoning Approach for Enhancing Adversarial Robustness and Mitigating Hallucinations in Vision-Language Models**|Nathaniel D. Bastian Team|[2504.14395](http://arxiv.org/abs/2504.14395)|null|
|**2025-04-19**|**How Well Can General Vision-Language Models Learn Medicine By Watching Public Educational Videos?**|James Zou Team|[2504.14391](http://arxiv.org/abs/2504.14391)|null|
|**2025-04-19**|**A Multimodal Recaptioning Framework to Account for Perceptual Diversity in Multilingual Vision-Language Modeling**|Adriana Kovashka Team|[2504.14359](http://arxiv.org/abs/2504.14359)|null|
|**2025-04-19**|**Diffusion-based Dynamic Contract for Federated AI Agent Construction in Mobile Metaverses**|Chau Yuen Team|[2504.14326](http://arxiv.org/abs/2504.14326)|null|
|**2025-04-19**|**Enhancing Multimodal In-Context Learning for Image Classification through Coreset Optimization**|Xu Yang Team|[2504.14200](http://arxiv.org/abs/2504.14200)|null|
|**2025-04-19**|**Bayesian Principles Improve Prompt Learning In Vision-Language Models**|Mijung Park Team|[2504.14123](http://arxiv.org/abs/2504.14123)|null|
|**2025-04-19**|**PEFT A2Z: Parameter-Efficient Fine-Tuning Survey for Large Language and Vision Models**|Ozlem Ozmen Garibay Team|[2504.14117](http://arxiv.org/abs/2504.14117)|null|
|**2025-04-21**|**Analysing the Robustness of Vision-Language-Models to Common Corruptions**|Umair Bin Mansoor Team|[2504.13690](http://arxiv.org/abs/2504.13690)|null|
|**2025-04-18**|**EyecareGPT: Boosting Comprehensive Ophthalmology Understanding with Tailored Dataset, Benchmark and Model**|Beng Chin Ooi Team|[2504.13650](http://arxiv.org/abs/2504.13650)|**[link](https://github.com/dcdmllm/eyecaregpt)**|
|**2025-04-18**|**PV-VLM: A Multimodal Vision-Language Approach Incorporating Sky Images for Intra-Hour Photovoltaic Power Forecasting**|Miao Yu Team|[2504.13624](http://arxiv.org/abs/2504.13624)|null|
|**2025-04-18**|**Chain-of-Thought Textual Reasoning for Few-shot Temporal Action Localization**|Huadong Ma Team|[2504.13460](http://arxiv.org/abs/2504.13460)|null|
|**2025-04-18**|**Towards a Multi-Agent Vision-Language System for Zero-Shot Novel Hazardous Object Detection for Autonomous Driving Safety**|Ross Greer Team|[2504.13399](http://arxiv.org/abs/2504.13399)|null|
|**2025-04-17**|**VLLFL: A Vision-Language Model Based Lightweight Federated Learning Framework for Smart Agriculture**|Yanbo Huang Team|[2504.13365](http://arxiv.org/abs/2504.13365)|null|
|**2025-04-17**|**Chain-of-Modality: Learning Manipulation Programs from Multimodal Human Videos with Vision-Language-Models**|Jacky Liang Team|[2504.13351](http://arxiv.org/abs/2504.13351)|null|
|**2025-04-17**|**WildFireCan-MMD: A Multimodal dataset for Classification of User-generated Content During Wildfires in Canada**|Marzieh Amini Team|[2504.13231](http://arxiv.org/abs/2504.13231)|null|
|**2025-04-17**|**PerceptionLM: Open-Access Data and Models for Detailed Visual Understanding**|Christoph Feichtenhofer Team|[2504.13180](http://arxiv.org/abs/2504.13180)|null|
|**2025-04-17**|**Generate, but Verify: Reducing Hallucination in Vision-Language Models with Retrospective Resampling**|David M. Chan Team|[2504.13169](http://arxiv.org/abs/2504.13169)|**[link](https://github.com/tsunghan-wu/reverse_vlm)**|
|**2025-04-17**|**Low-hallucination Synthetic Captions for Large-Scale Vision-Language Model Pre-training**|Zhanhui Kang Team|[2504.13123](http://arxiv.org/abs/2504.13123)|null|
|**2025-04-17**|**Probing and Inducing Combinational Creativity in Vision-Language Models**|Zilong Zheng Team|[2504.13120](http://arxiv.org/abs/2504.13120)|null|
|**2025-04-17**|**Object-Driven Narrative in AR: A Scenario-Metaphor Framework with VLM Integration**|Yong Hong Kuo Team|[2504.13119](http://arxiv.org/abs/2504.13119)|null|
|**2025-04-17**|**Early Accessibility: Automating Alt-Text Generation for UI Icons During App Development**|Christoph Csallner Team|[2504.13069](http://arxiv.org/abs/2504.13069)|null|
|**2025-04-17**|**NoisyRollout: Reinforcing Visual Reasoning with Data Augmentation**|Michael Qizhe Shieh Team|[2504.13055](http://arxiv.org/abs/2504.13055)|null|
|**2025-04-17**|**Embodied-R: Collaborative Framework for Activating Embodied Spatial Reasoning in Foundation Models via Reinforcement Learning**|Wenwu Zhu Team|[2504.12680](http://arxiv.org/abs/2504.12680)|**[link](https://github.com/embodiedcity/embodied-r.code)**|
|**2025-04-17**|**VLMGuard-R1: Proactive Safety Alignment for VLMs via Reasoning-Driven Prompt Optimization**|Siheng Chen Team|[2504.12661](http://arxiv.org/abs/2504.12661)|null|
|**2025-04-16**|**Sparsity Outperforms Low-Rank Projections in Few-Shot Adaptation**|Éric Granger Team|[2504.12436](http://arxiv.org/abs/2504.12436)|**[link](https://github.com/nairouz/SO)**|
|**2025-04-16**|**FLIP Reasoning Challenge**|Roger Wattenhofer Team|[2504.12256](http://arxiv.org/abs/2504.12256)|null|
|**2025-04-16**|**Efficient Contrastive Decoding with Probabilistic Hallucination Detection - Mitigating Hallucinations in Large Vision Language Models -**|Hanno Gottschalk Team|[2504.12137](http://arxiv.org/abs/2504.12137)|null|
|**2025-04-17**|**Securing the Skies: A Comprehensive Survey on Anti-UAV Methods, Benchmarking, and Future Directions**|Zhi-Qi Cheng Team|[2504.11967](http://arxiv.org/abs/2504.11967)|null|
|**2025-04-16**|**Beyond Words: Augmenting Discriminative Richness via Diffusions in Unsupervised Prompt Learning**|Yi Chang Team|[2504.11930](http://arxiv.org/abs/2504.11930)|null|
|**2025-04-16**|**A Visual RAG Pipeline for Few-Shot Fine-Grained Product Classification**|Janis Keuper Team|[2504.11838](http://arxiv.org/abs/2504.11838)|null|
|**2025-04-17**|**DVLTA-VQA: Decoupled Vision-Language Modeling with Text-Guided Adaptation for Blind Video Quality Assessment**|Moncef Gabbouj Team|[2504.11733](http://arxiv.org/abs/2504.11733)|null|
|**2025-04-16**|**Interpreting the Linear Structure of Vision-language Model Embedding Spaces**|Stephanie Gil Team|[2504.11695](http://arxiv.org/abs/2504.11695)|null|
|**2025-04-16**|**VLM-Fuzz: Vision Language Model Assisted Recursive Depth-first Search Exploration for Effective UI Testing of Android Apps**|Mariano Ceccato Team|[2504.11675](http://arxiv.org/abs/2504.11675)|null|
|**2025-04-15**|**Co-STAR: Collaborative Curriculum Self-Training with Adaptive Regularization for Source-Free Video Domain Adaptation**|Majid Mirmehdi Team|[2504.11669](http://arxiv.org/abs/2504.11669)|null|
|**2025-04-17**|**PATFinger: Prompt-Adapted Transferable Fingerprinting against Unauthorized Multimodal Dataset Usage**|Lina Wang Team|[2504.11509](http://arxiv.org/abs/2504.11509)|null|
|**2025-04-15**|**From Gaze to Insight: Bridging Human Visual Attention and Vision Language Model Explanation for Weakly-Supervised Medical Image Segmentation**|Jungong Han Team|[2504.11368](http://arxiv.org/abs/2504.11368)|null|
|**2025-04-17**|**UI-E2I-Synth: Advancing GUI Grounding with Large-Scale Instruction Synthesis**|Yan Lu Team|[2504.11257](http://arxiv.org/abs/2504.11257)|null|
|**2025-04-15**|**R-TPT: Improving Adversarial Robustness of Vision-Language Models through Test-Time Prompt Tuning**|Ran He Team|[2504.11195](http://arxiv.org/abs/2504.11195)|null|
|**2025-06-30**|**Benchmarking Vision Language Models on German Factual Data**|Vincent Tischler Team|[2504.11108](http://arxiv.org/abs/2504.11108)|null|
|**2025-04-16**|**Consensus Entropy: Harnessing Multi-VLM Agreement for Self-Verifying and Self-Improving OCR**|Gongshen Liu Team|[2504.11101](http://arxiv.org/abs/2504.11101)|null|
|**2025-04-15**|**QAVA: Query-Agnostic Visual Attack to Large Vision-Language Models**|Yu Wang Team|[2504.11038](http://arxiv.org/abs/2504.11038)|null|
|**2025-04-15**|**Can Vision-Language Models Understand and Interpret Dynamic Gestures from Pedestrians? Pilot Datasets and Exploration Towards Instructive Nonverbal Commands for Cooperative Autonomous Vehicles**|Ross Greer Team|[2504.10873](http://arxiv.org/abs/2504.10873)|null|
|**2025-04-15**|**LVLM_CSP: Accelerating Large Vision Language Models via Clustering, Scattering, and Pruning for Reasoning Segmentation**|Mohsen Imani Team|[2504.10854](http://arxiv.org/abs/2504.10854)|null|
|**2025-04-15**|**Enhancing Features in Long-tailed Data Using Large Vision Mode**|Xuesong Li Team|[2504.10852](http://arxiv.org/abs/2504.10852)|null|
|**2025-04-14**|**ReasonDrive: Efficient Visual Question Answering for Autonomous Vehicles with Reasoning-Enhanced Small Vision-Language Models**|Lifeng Zhou Team|[2504.10757](http://arxiv.org/abs/2504.10757)|null|
|**2025-04-14**|**AgMMU: A Comprehensive Agricultural Multimodal Understanding and Reasoning Benchmark**|Yu-Xiong Wang Team|[2504.10568](http://arxiv.org/abs/2504.10568)|null|
|**2025-04-14**|**Pixel-SAIL: Single Transformer For Pixel-Grounded Understanding**|Jiashi Feng Team|[2504.10465](http://arxiv.org/abs/2504.10465)|null|
|**2025-04-15**|**GUI-R1 : A Generalist R1-Style Vision-Language Action Model For GUI Agents**|Run Luo Team|[2504.10458](http://arxiv.org/abs/2504.10458)|null|
|**2025-04-14**|**SlowFastVAD: Video Anomaly Detection via Integrating Simple Detector and RAG-Enhanced Vision-Language Model**|Yanning Zhang Team|[2504.10320](http://arxiv.org/abs/2504.10320)|null|
|**2025-04-15**|**Breaking the Data Barrier -- Building GUI Agents Through Task Generalization**|Junxian He Team|[2504.10127](http://arxiv.org/abs/2504.10127)|null|
|**2025-04-14**|**AGO: Adaptive Grounding for Open World 3D Occupancy Prediction**|Andreas Zell Team|[2504.10117](http://arxiv.org/abs/2504.10117)|null|
|**2025-04-14**|**CameraBench: Benchmarking Visual Reasoning in MLLMs via Photography**|Jun-Cheng Chen Team|[2504.10090](http://arxiv.org/abs/2504.10090)|null|
|**2025-04-14**|**Summarization of Multimodal Presentations with Vision-Language Models: Study of the Effect of Modalities and Structure**|Frédéric Dufaux Team|[2504.10049](http://arxiv.org/abs/2504.10049)|null|
|**2025-04-14**|**Aligning Anime Video Generation with Human Feedback**|Zuxuan Wu Team|[2504.10044](http://arxiv.org/abs/2504.10044)|null|
|**2025-04-14**|**KeyMPs: One-Shot Vision-Language Guided Motion Generation by Sequencing DMPs for Occlusion-Rich Tasks**|Takamitsu Matsubara Team|[2504.10011](http://arxiv.org/abs/2504.10011)|null|
|**2025-04-14**|**GenTe: Generative Real-world Terrains for General Legged Robot Locomotion Control**|Xiaoqiang Ji Team|[2504.09997](http://arxiv.org/abs/2504.09997)|null|
|**2025-04-14**|**Resampling Benchmark for Efficient Comprehensive Evaluation of Large Vision-Language Models**|Keisuke Ozawa Team|[2504.09979](http://arxiv.org/abs/2504.09979)|null|
|**2025-04-14**|**Can VLMs Assess Similarity Between Graph Visualizations?**|Jinwook Seo Team|[2504.09859](http://arxiv.org/abs/2504.09859)|null|
|**2025-04-14**|**VDocRAG: Retrieval-Augmented Generation over Visually-Rich Documents**|Jun Suzuki Team|[2504.09795](http://arxiv.org/abs/2504.09795)|null|
|**2025-04-13**|**A Survey on Efficient Vision-Language Models**|Nirmalya Roy Team|[2504.09724](http://arxiv.org/abs/2504.09724)|null|
|**2025-04-13**|**Metropolis-Hastings Captioning Game: Knowledge Fusion of Vision Language Models via Decentralized Bayesian Inference**|Tadahiro Taniguchi Team|[2504.09620](http://arxiv.org/abs/2504.09620)|null|
|**2025-04-13**|**DualPrompt-MedCap: A Dual-Prompt Enhanced Approach for Medical Image Captioning**|Mukesh Prasad Team|[2504.09598](http://arxiv.org/abs/2504.09598)|null|
|**2025-04-15**|**Vision-Language Model for Object Detection and Segmentation: A Review and Evaluation**|Yunhong Wang Team|[2504.09480](http://arxiv.org/abs/2504.09480)|null|
|**2025-04-13**|**Identity-Aware Vision-Language Model for Explainable Face Forgery Detection**|Yu-Gang Jiang Team|[2504.09439](http://arxiv.org/abs/2504.09439)|null|
|**2025-04-13**|**BabyVLM: Data-Efficient Pretraining of VLMs Inspired by Infant Learning**|Boqing Gong Team|[2504.09426](http://arxiv.org/abs/2504.09426)|null|
|**2025-04-12**|**PathVLM-R1: A Reinforcement Learning-Driven Reasoning Model for Pathology Visual-Language Tasks**|Yang Liu Team|[2504.09258](http://arxiv.org/abs/2504.09258)|null|
|**2025-04-11**|**AstroLLaVA: towards the unification of astronomical data and natural language**|Dimitrios Tanoglidis Team|[2504.08583](http://arxiv.org/abs/2504.08583)|null|
|**2025-04-11**|**EO-VLM: VLM-Guided Energy Overload Attacks on Vision Models**|Jinwoo Kim Team|[2504.08205](http://arxiv.org/abs/2504.08205)|null|
|**2025-04-10**|**Investigating Vision-Language Model for Point Cloud-based Vehicle Classification**|Camille Kamga Team|[2504.08154](http://arxiv.org/abs/2504.08154)|null|
|**2025-04-10**|**The AI Scientist-v2: Workshop-Level Automated Scientific Discovery via Agentic Tree Search**|David Ha Team|[2504.08066](http://arxiv.org/abs/2504.08066)|null|
|**2025-04-10**|**VCR-Bench: A Comprehensive Evaluation Framework for Video Chain-of-Thought Reasoning**|Feng Zhao Team|[2504.07956](http://arxiv.org/abs/2504.07956)|null|
|**2025-04-10**|**SAMJAM: Zero-Shot Video Scene Graph Generation for Egocentric Kitchen Videos**|Yuhao Chen Team|[2504.07867](http://arxiv.org/abs/2504.07867)|null|
|**2025-04-10**|**CollEX -- A Multimodal Agentic RAG System Enabling Interactive Exploration of Scientific Collections**|Chris Biemann Team|[2504.07643](http://arxiv.org/abs/2504.07643)|null|
|**2025-04-10**|**VLM-R1: A Stable and Generalizable R1-style Large Vision-Language Model**|Tiancheng Zhao Team|[2504.07615](http://arxiv.org/abs/2504.07615)|**[link](https://github.com/om-ai-lab/vlm-r1)**|
|**2025-04-10**|**TokenFocus-VQA: Enhancing Text-to-Image Alignment with Position-Aware Focus and Multi-Perspective Aggregations on LVLMs**|Xuezhi Cao Team|[2504.07556](http://arxiv.org/abs/2504.07556)|null|
|**2025-04-10**|**Why We Feel: Breaking Boundaries in Emotional Reasoning with Multimodal Large Language Models**|Xian-Sheng Hua Team|[2504.07521](http://arxiv.org/abs/2504.07521)|**[link](https://github.com/lum1104/eibench)**|
|**2025-04-10**|**Kimi-VL Technical Report**|Ziwei Chen Team|[2504.07491](http://arxiv.org/abs/2504.07491)|**[link](https://github.com/moonshotai/kimi-vl)**|
|**2025-04-09**|**Perception in Reflection**|Vishal M. Patel Team|[2504.07165](http://arxiv.org/abs/2504.07165)|null|
|**2025-04-09**|**Kaleidoscope: In-language Exams for Massively Multilingual Vision Evaluation**|Marzieh Fadaee Team|[2504.07072](http://arxiv.org/abs/2504.07072)|null|
|**2025-04-09**|**Are Vision-Language Models Ready for Dietary Assessment? Exploring the Next Frontier in AI-Powered Food Image Recognition**|Aythami Morales Team|[2504.06925](http://arxiv.org/abs/2504.06925)|null|
|**2025-04-09**|**MovSAM: A Single-image Moving Object Segmentation Framework Based on Deep Thinking**|Hesheng Wang Team|[2504.06863](http://arxiv.org/abs/2504.06863)|null|
|**2025-04-09**|**ZIP: An Efficient Zeroth-order Prompt Tuning for Black-box Vision-Language Models**|Namhoon Lee Team|[2504.06838](http://arxiv.org/abs/2504.06838)|null|
|**2025-04-09**|**LVC: A Lightweight Compression Framework for Enhancing VLMs in Long Video Understanding**|Bo XU Team|[2504.06835](http://arxiv.org/abs/2504.06835)|null|
|**2025-04-08**|**PromptHMR: Promptable Human Mesh Recovery**|Muhammed Kocabas Team|[2504.06397](http://arxiv.org/abs/2504.06397)|null|
|**2025-04-08**|**SemiDAViL: Semi-supervised Domain Adaptation with Vision-Language Guidance for Semantic Segmentation**|Zhaozheng Yin Team|[2504.06389](http://arxiv.org/abs/2504.06389)|null|
|**2025-04-08**|**OmniSVG: A Unified Scalable Vector Graphics Generation Model**|Yu-Gang Jiang Team|[2504.06263](http://arxiv.org/abs/2504.06263)|null|
|**2025-04-08**|**Latent Multimodal Reconstruction for Misinformation Detection**|Panagiotis C. Petrantonakis Team|[2504.06010](http://arxiv.org/abs/2504.06010)|**[link](https://github.com/stevejpapad/miscaptioned-image-reconstruction)**|
|**2025-04-08**|**Measuring Déjà vu Memorization Efficiently**|Kamalika Chaudhuri Team|[2504.05651](http://arxiv.org/abs/2504.05651)|null|
|**2025-04-08**|**A Lightweight Large Vision-language Model for Multimodal Medical Images**|Navid Toosy Saidy Team|[2504.05575](http://arxiv.org/abs/2504.05575)|null|
|**2025-04-10**|**ChartQAPro: A More Diverse and Challenging Benchmark for Chart Question Answering**|Shafiq Joty Team|[2504.05506](http://arxiv.org/abs/2504.05506)|null|
|**2025-04-07**|**Trust Through Transparency: Explainable Social Navigation for Autonomous Mobile Robots via Vision-Language Models**|Aliasghar Arab Team|[2504.05477](http://arxiv.org/abs/2504.05477)|null|
|**2025-04-07**|**Taxonomy-Aware Evaluation of Vision-Language Models**|Stella Frank Team|[2504.05457](http://arxiv.org/abs/2504.05457)|null|
|**2025-04-07**|**Probing the Visualization Literacy of Vision Language Models: the Good, the Bad, and the Ugly**|Anamaria Crisan Team|[2504.05445](http://arxiv.org/abs/2504.05445)|null|
|**2025-04-07**|**InteractVLM: 3D Interaction Reasoning from 2D Foundational Models**|Dimitrios Tzionas Team|[2504.05303](http://arxiv.org/abs/2504.05303)|null|
|**2025-04-07**|**SmolVLM: Redefining small and efficient multimodal models**|Thomas Wolf Team|[2504.05299](http://arxiv.org/abs/2504.05299)|null|
|**2025-04-07**|**A Reality Check of Vision-Language Pre-training in Radiology: Have We Progressed Using Text?**|Ismail Ben Ayed Team|[2504.05227](http://arxiv.org/abs/2504.05227)|null|
|**2025-04-07**|**Vision-Language Model Predictive Control for Manipulation Planning and Trajectory Generation**|Wei Zhang Team|[2504.05225](http://arxiv.org/abs/2504.05225)|null|
|**2025-04-08**|**A Taxonomy of Self-Handover**|Katsushi Ikeuchi Team|[2504.04939](http://arxiv.org/abs/2504.04939)|null|
|**2025-04-07**|**SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models**|Lorenz Hufe Team|[2504.04893](http://arxiv.org/abs/2504.04893)|null|
|**2025-04-07**|**Don't Lag, RAG: Training-Free Adversarial Detection Using RAG**|Ofer Hadar Team|[2504.04858](http://arxiv.org/abs/2504.04858)|null|
|**2025-04-07**|**OCC-MLLM-CoT-Alpha: Towards Multi-stage Occlusion Recognition Based on Large Language Models via 3D-Aware Supervision and Chain-of-Thoughts Guidance**|Xinhan Di Team|[2504.04781](http://arxiv.org/abs/2504.04781)|null|
|**2025-04-07**|**Feedback-Enhanced Hallucination-Resistant Vision-Language Model for Real-Time Scene Understanding**|Zahir Alsulaimawi Team|[2504.04772](http://arxiv.org/abs/2504.04772)|null|
|**2025-04-07**|**Grounding 3D Object Affordance with Language Instructions, Visual Observations and Interactions**|Yue Wang Team|[2504.04744](http://arxiv.org/abs/2504.04744)|null|
|**2025-04-07**|**Enhancing Compositional Reasoning in Vision-Language Models with Synthetic Preference Data**|Venkatesh Saligrama Team|[2504.04740](http://arxiv.org/abs/2504.04740)|null|
|**2025-04-06**|**M2IV: Towards Efficient and Fine-grained Multimodal In-Context Learning in Large Vision-Language Models**|Ruixiang Tang Team|[2504.04633](http://arxiv.org/abs/2504.04633)|null|
|**2025-04-06**|**Foundation Models for Software Engineering of Cyber-Physical Systems: the Road Ahead**|Shaukat Ali Team|[2504.04630](http://arxiv.org/abs/2504.04630)|null|
|**2025-04-06**|**Enhance Then Search: An Augmentation-Search Strategy with Foundation Models for Cross-Domain Few-Shot Object Detection**|Xiaomeng Huang Team|[2504.04517](http://arxiv.org/abs/2504.04517)|**[link](https://github.com/jaychempan/ETS)**|
|**2025-04-06**|**OmniDrive: A Holistic Vision-Language Dataset for Autonomous Driving with Counterfactual Reasoning**|Jose M. Alvarez Team|[2504.04348](http://arxiv.org/abs/2504.04348)|null|
|**2025-04-06**|**MedM-VL: What Makes a Good Medical LVLM?**|Ji Wu Team|[2504.04323](http://arxiv.org/abs/2504.04323)|null|
|**2025-04-05**|**GROVE: A Generalized Reward for Learning Open-Vocabulary Physical Skill**|Siyuan Huang Team|[2504.04191](http://arxiv.org/abs/2504.04191)|null|
|**2025-04-05**|**LATTE: Lightweight Attention-based Traffic Accident Anticipation Engine**|Zhenning Li Team|[2504.04103](http://arxiv.org/abs/2504.04103)|null|
|**2025-04-05**|**TARAC: Mitigating Hallucination in LVLMs via Temporal Attention Real-time Accumulative Connection**|Xiaohua Xu Team|[2504.04099](http://arxiv.org/abs/2504.04099)|null|
|**2025-04-04**|**VideoComp: Advancing Fine-Grained Compositional and Temporal Alignment in Video-Text Models**|Anelia Angelova Team|[2504.03970](http://arxiv.org/abs/2504.03970)|null|
|**2025-04-04**|**Know What You do Not Know: Verbalized Uncertainty Estimation Robustness on Corrupted Images in Vision-Language Models**|Matias Valdenegro-Toro Team|[2504.03440](http://arxiv.org/abs/2504.03440)|null|
|**2025-04-04**|**SARLANG-1M: A Benchmark for Vision-Language Modeling in SAR Image Understanding**|Naoto Yokoya Team|[2504.03254](http://arxiv.org/abs/2504.03254)|null|
|**2025-04-04**|**Seeing is Believing: Belief-Space Planning with Foundation Models as Uncertainty Estimators**|Lawson L. S. Wong Team|[2504.03245](http://arxiv.org/abs/2504.03245)|null|
|**2025-04-04**|**Mamba as a Bridge: Where Vision Foundation Models Meet Vision Language Models for Domain-Generalized Semantic Segmentation**|Robby T. Tan Team|[2504.03193](http://arxiv.org/abs/2504.03193)|null|
|**2025-04-04**|**NuScenes-SpatialQA: A Spatial Understanding and Reasoning Benchmark for Vision-Language Models in Autonomous Driving**|Zhengzhong Tu Team|[2504.03164](http://arxiv.org/abs/2504.03164)|null|
|**2025-04-04**|**TokenFLEX: Unified VLM Training for Flexible Visual Tokens Inference**|Xianpeng Lang Team|[2504.03154](http://arxiv.org/abs/2504.03154)|null|
|**2025-04-04**|**MORAL: A Multimodal Reinforcement Learning Framework for Decision Making in Autonomous Laboratories**|Arvind Ramanathan Team|[2504.03153](http://arxiv.org/abs/2504.03153)|null|
|**2025-04-03**|**QID: Efficient Query-Informed ViTs in Data-Scarce Regimes for OCR-free Visual Document Understanding**|Bryan Wang Team|[2504.02971](http://arxiv.org/abs/2504.02971)|null|
|**2025-04-03**|**STING-BEE: Towards Vision-Language Model for Real-World X-ray Baggage Security Inspection**|Naoufel Werghi Team|[2504.02823](http://arxiv.org/abs/2504.02823)|null|
|**2025-04-03**|**Sparse Autoencoders Learn Monosemantic Features in Vision-Language Models**|Zeynep Akata Team|[2504.02821](http://arxiv.org/abs/2504.02821)|null|
|**2025-04-03**|**Systematic Evaluation of Large Vision-Language Models for Surgical Artificial Intelligence**|Serena Yeung-Levy Team|[2504.02799](http://arxiv.org/abs/2504.02799)|null|
|**2025-04-03**|**Robot-Led Vision Language Model Wellbeing Assessment of Children**|Hatice Gunes Team|[2504.02765](http://arxiv.org/abs/2504.02765)|null|
|**2025-04-04**|**Rethinking RL Scaling for Vision Language Models: A Transparent, From-Scratch Framework and Comprehensive Evaluation Scheme**|Pengfei Liu Team|[2504.02587](http://arxiv.org/abs/2504.02587)|null|
|**2025-04-03**|**Multimodal Fusion and Vision-Language Models: A Survey for Robot Vision**|Shibiao Xu Team|[2504.02477](http://arxiv.org/abs/2504.02477)|null|
|**2025-04-03**|**Scaling Video-Language Models to 10K Frames via Hierarchical Differential Distillation**|Rui Yan Team|[2504.02438](http://arxiv.org/abs/2504.02438)|null|
|**2025-04-03**|**ReuseDroid: A VLM-empowered Android UI Test Migrator Boosted by Active Feedback**|Hailong Wang Team|[2504.02357](http://arxiv.org/abs/2504.02357)|null|
|**2025-04-03**|**Large (Vision) Language Models are Unsupervised In-Context Learners**|Maria Brbic Team|[2504.02349](http://arxiv.org/abs/2504.02349)|**[link](https://github.com/mlbio-epfl/joint-inference)**|
|**2025-04-03**|**Re-thinking Temporal Search for Long-Form Video Understanding**|Manling Li Team|[2504.02259](http://arxiv.org/abs/2504.02259)|null|
|**2025-04-03**|**SocialGesture: Delving into Multi-person Gesture Understanding**|James M. Rehg Team|[2504.02244](http://arxiv.org/abs/2504.02244)|null|
|**2025-04-02**|**FineLIP: Extending CLIP's Reach via Fine-Grained Alignment with Longer Text Inputs**|Fatima Albreiki Team|[2504.01916](http://arxiv.org/abs/2504.01916)|**[link](https://github.com/tiiuae/FineLIP)**|
|**2025-04-02**|**Is Temporal Prompting All We Need For Limited Labeled Action Recognition?**|Xiaobo Jin Team|[2504.01890](http://arxiv.org/abs/2504.01890)|null|
|**2025-04-02**|**Prompting Medical Vision-Language Models to Mitigate Diagnosis Bias by Generating Realistic Dermoscopic Images**|Abdullah-Al-Zubaer Imran Team|[2504.01838](http://arxiv.org/abs/2504.01838)|**[link](https://github.com/munia03/dermdit)**|
|**2025-04-02**|**BlenderGym: Benchmarking Foundational Model Systems for Graphics Editing**|Leonidas Guibas Team|[2504.01786](http://arxiv.org/abs/2504.01786)|null|
|**2025-04-02**|**AdPO: Enhancing the Adversarial Robustness of Large Vision-Language Models with Preference Optimization**|Linli Xu Team|[2504.01735](http://arxiv.org/abs/2504.01735)|null|
|**2025-04-02**|**Reasoning LLMs for User-Aware Multimodal Conversational Agents**|Mohamed Chetouani Team|[2504.01700](http://arxiv.org/abs/2504.01700)|null|
|**2025-04-02**|**CLIP-SLA: Parameter-Efficient CLIP Adaptation for Continuous Sign Language Recognition**|Hamzah Luqman Team|[2504.01666](http://arxiv.org/abs/2504.01666)|**[link](https://github.com/snalyami/CLIP-SLA)**|
|**2025-04-02**|**BioAtt: Anatomical Prior Driven Low-Dose CT Denoising**|UiHyun Cho Team|[2504.01662](http://arxiv.org/abs/2504.01662)|null|
|**2025-04-02**|**Text Speaks Louder than Vision: ASCII Art Reveals Textual Biases in Vision-Language Models**|Ming-Hsuan Yang Team|[2504.01589](http://arxiv.org/abs/2504.01589)|null|
|**2025-03-25**|**Vision-R1: Evolving Human-Free Alignment in Large Vision-Language Models via Vision-Guided Reinforcement Learning**|Jinqiao Wang Team|[2503.18013](http://arxiv.org/abs/2503.18013)|**[link](https://github.com/jefferyZhan/Griffon/tree/master/Vision-R1)**|
|**2024-12-02**|**VARCO-VISION: Expanding Frontiers in Korean Vision-Language Models**|Youngjune Kim Team|[2411.19103](http://arxiv.org/abs/2411.19103)|**[link](https://huggingface.co/NCSOFT/VARCO-VISION-14B.)**|
|**2025-05-19**|**Evaluating Vision-Language Models as Evaluators in Path Planning**|Ziyu Yao Team|[2411.18711](http://arxiv.org/abs/2411.18711)|null|
|**2025-03-11**|**ScVLM: Enhancing Vision-Language Model for Safety-Critical Event Understanding**|Feng Guo Team|[2410.00982](http://arxiv.org/abs/2410.00982)|null|
|**2024-09-24**|**Behavioral Bias of Vision-Language Models: A Behavioral Finance View**|Ming-Chang Chiu Team|[2409.15256](http://arxiv.org/abs/2409.15256)|null|
|**2024-08-01**|**Vision-Language Model Based Handwriting Verification**|Sargur Srihari Team|[2407.21788](http://arxiv.org/abs/2407.21788)|null|
|**2025-10-15**|**Exploring the Frontier of Vision-Language Models: A Survey of Current Methodologies and Future Directions**|Aman Chadha Team|[2404.07214](http://arxiv.org/abs/2404.07214)|null|
|**2024-05-10**|**Multi-Frame, Lightweight & Efficient Vision-Language Models for Question Answering in Autonomous Driving**|Mohan Trivedi Team|[2403.19838](http://arxiv.org/abs/2403.19838)|null|
|**2024-01-17**|**Evaluation and Enhancement of Semantic Grounding in Large Vision-Language Models**|Jie Yang Team|[2309.04041](http://arxiv.org/abs/2309.04041)|null|
|**2023-10-13**|**Distilling Large Vision-Language Model with Out-of-Distribution Generalizability**|Hao Su Team|[2307.03135](http://arxiv.org/abs/2307.03135)|**[link](https://xuanlinli17.github.io/pdfs/iccv23_large_vlm_distillation_poster.pdf)**|
|**2023-06-16**|**LVLM-eHub: A Comprehensive Evaluation Benchmark for Large Vision-Language Models**|Ping Luo Team|[2306.09265](http://arxiv.org/abs/2306.09265)|null|
|**2023-11-08**|**Investigating the Role of Attribute Context in Vision-Language Models for Object Recognition and Detection**|Adriana Kovashka Team|[2303.10093](http://arxiv.org/abs/2303.10093)|null|
|**2024-04-19**|**VLP: A Survey on Vision-Language Pre-training**|Bo Xu Team|[2202.09061](http://arxiv.org/abs/2202.09061)|null|
|**2022-10-07**|**Learning to Prompt for Vision-Language Models**|Ziwei Liu Team|[2109.01134](http://arxiv.org/abs/2109.01134)|null|

<p align=right>(<a href=#updated-on-20251217>back to top</a>)</p>

## VLA

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-12-12**|**BLURR: A Boosted Low-Resource Inference for Vision-Language-Action Models**|Yanfang Ye Team|[2512.11769](http://arxiv.org/abs/2512.11769)|**[link](https://github.com/JijiKing-Sam/BLURR-A-Boosted-Low-Resource-Inference-for-Vision-Language-Action-Model)**|
|**2025-12-12**|**Embodied Image Compression**|Guangtao Zhai Team|[2512.11612](http://arxiv.org/abs/2512.11612)|null|
|**2025-12-12**|**Atomic Action Slicing: Planner-Aligned Options for Generalist VLA Agents**|Boris Kraychev Team|[2512.11584](http://arxiv.org/abs/2512.11584)|null|
|**2025-12-12**|**An Anatomy of Vision-Language-Action Models: From Modules to Milestones and Challenges**|Jiankang Deng Team|[2512.11362](http://arxiv.org/abs/2512.11362)|null|
|**2025-12-12**|**Benchmarking the Generality of Vision-Language-Action Models**|Yangyue Wang Team|[2512.11315](http://arxiv.org/abs/2512.11315)|null|
|**2025-12-12**|**RoomPilot: Controllable Synthesis of Interactive Indoor Environments via Multimodal Semantic Parsing**|Ruihui Li Team|[2512.11234](http://arxiv.org/abs/2512.11234)|null|
|**2025-12-12**|**Seeing to Act, Prompting to Specify: A Bayesian Factorization of Vision Language Action Policy**|Yue Wang Team|[2512.11218](http://arxiv.org/abs/2512.11218)|null|
|**2025-12-11**|**WholeBodyVLA: Towards Unified Latent VLA for Whole-Body Loco-Manipulation Control**|Hongyang Li Team|[2512.11047](http://arxiv.org/abs/2512.11047)|null|
|**2025-12-11**|**WorldLens: Full-Spectrum Evaluations of Driving World Models in Real World**|Ziwei Liu Team|[2512.10958](http://arxiv.org/abs/2512.10958)|**[link](https://worldbench.github.io/worldlens)**|
|**2025-12-11**|**XDen-1K: A Density Field Dataset of Real-World Objects**|Jingyi Yu Team|[2512.10668](http://arxiv.org/abs/2512.10668)|null|
|**2025-12-11**|**RoboNeuron: A Modular Framework Linking Foundation Models and ROS for Embodied AI**|Jian Cheng Team|[2512.10394](http://arxiv.org/abs/2512.10394)|null|
|**2025-12-11**|**Latent Chain-of-Thought World Modeling for End-to-End Driving**|Boris Ivanovic Team|[2512.10226](http://arxiv.org/abs/2512.10226)|null|
|**2025-12-10**|**Openpi Comet: Competition Solution For 2025 BEHAVIOR Challenge**|Xiaohui Zeng Team|[2512.10071](http://arxiv.org/abs/2512.10071)|null|
|**2025-12-10**|**SimWorld-Robotics: Synthesizing Photorealistic and Dynamic Urban Environments for Multimodal Robot Navigation and Collaboration**|Tianmin Shu Team|[2512.10046](http://arxiv.org/abs/2512.10046)|null|
|**2025-12-10**|**HiF-VLA: Hindsight, Insight and Foresight through Motion Representation for Vision-Language-Action Models**|Donglin Wang Team|[2512.09928](http://arxiv.org/abs/2512.09928)|**[link](https://hifvla.github.io)**|
|**2025-12-10**|**Token Expand-Merge: Training-Free Token Compression for Vision-Language-Action Models**|Zhihe Lu Team|[2512.09927](http://arxiv.org/abs/2512.09927)|null|
|**2025-12-10**|**UniUGP: Unifying Understanding, Generation, and Planing For End-to-end Autonomous Driving**|Ying-Cong Chen Team|[2512.09864](http://arxiv.org/abs/2512.09864)|**[link](https://seed-uniugp.github.io/)**|
|**2025-12-10**|**GLaD: Geometric Latent Distillation for Vision-Language-Action Models**|Xiaojun Chang Team|[2512.09619](http://arxiv.org/abs/2512.09619)|null|
|**2025-12-10**|**UrbanNav: Learning Language-Guided Urban Navigation from Web-Scale Human Trajectories**|Jing Liu Team|[2512.09607](http://arxiv.org/abs/2512.09607)|null|
|**2025-12-10**|**Scene-agnostic Hierarchical Bimanual Task Planning via Visual Affordance Reasoning**|Sung-Hee Lee Team|[2512.09310](http://arxiv.org/abs/2512.09310)|null|
|**2025-12-09**|**See-Control: A Multimodal Agent Framework for Smartphone Interaction with a Robotic Arm**|Jun Wang Team|[2512.08629](http://arxiv.org/abs/2512.08629)|null|
|**2025-12-09**|**Mind to Hand: Purposeful Robotic Control via Embodied Reasoning**|Jianan Wang Team|[2512.08580](http://arxiv.org/abs/2512.08580)|null|
|**2025-12-09**|**Robust Finetuning of Vision-Language-Action Robot Policies via Parameter Merging**|Sergey Levine Team|[2512.08333](http://arxiv.org/abs/2512.08333)|null|
|**2025-12-08**|**An Introduction to Deep Reinforcement and Imitation Learning**|Pedro Santana Team|[2512.08052](http://arxiv.org/abs/2512.08052)|null|
|**2025-12-08**|**Online Segment Any 3D Thing as Instance Tracking**|Zhipeng Zhang Team|[2512.07599](http://arxiv.org/abs/2512.07599)|**[link](https://github.com/AutoLab-SAI-SJTU/AutoSeg3D)**|
|**2025-12-08**|**See Once, Then Act: Vision-Language-Action Model with Task Learning from One-Shot Video Demonstrations**|Yufeng Yue Team|[2512.07582](http://arxiv.org/abs/2512.07582)|null|
|**2025-12-08**|**Affordance Field Intervention: Enabling VLAs to Escape Memory Traps in Robotic Manipulation**|Chang Xu Team|[2512.07472](http://arxiv.org/abs/2512.07472)|null|
|**2025-12-08**|**Unified Camera Positional Encoding for Controlled Video Generation**|Jianfei Cai Team|[2512.07237](http://arxiv.org/abs/2512.07237)|**[link](https://github.com/chengzhag/UCPE)**|
|**2025-12-07**|**VideoVLA: Video Generators Can Be Generalizable Robot Manipulators**|Baining Guo Team|[2512.06963](http://arxiv.org/abs/2512.06963)|**[link](https://videovla-nips2025.github.io)**|
|**2025-12-07**|**Task adaptation of Vision-Language-Action model: 1st Place Solution for the 2025 BEHAVIOR Challenge**|Akash Karnatak Team|[2512.06951](http://arxiv.org/abs/2512.06951)|null|
|**2025-12-06**|**Beyond Model Jailbreak: Systematic Dissection of the "Ten DeadlySins" in Embodied Intelligence**|Xiuzhen Cheng Team|[2512.06387](http://arxiv.org/abs/2512.06387)|null|
|**2025-12-05**|**WAM-Flow: Parallel Coarse-to-Fine Motion Planning via Discrete Flow Matching for Autonomous Driving**|Siyu Zhu Team|[2512.06112](http://arxiv.org/abs/2512.06112)|**[link](https://github.com/fudan-generative-vision/WAM-Flow)**|
|**2025-12-05**|**Training-Time Action Conditioning for Efficient Real-Time Chunking**|Sergey Levine Team|[2512.05964](http://arxiv.org/abs/2512.05964)|null|
|**2025-12-05**|**SIMPACT: Simulation-Enabled Action Planning using Vision-Language Models**|Yilun Du Team|[2512.05955](http://arxiv.org/abs/2512.05955)|null|
|**2025-12-05**|**TRACE: A Framework for Analyzing and Enhancing Stepwise Reasoning in Vision-Language Models**|Babak Damavandi Team|[2512.05943](http://arxiv.org/abs/2512.05943)|null|
|**2025-12-05**|**Probing the effectiveness of World Models for Spatial Reasoning through Test-time Scaling**|Sarath Chandar Team|[2512.05809](http://arxiv.org/abs/2512.05809)|null|
|**2025-12-05**|**HiMoE-VLA: Hierarchical Mixture-of-Experts for Generalist Vision-Language-Action Policies**|Yu-Gang Jiang Team|[2512.05693](http://arxiv.org/abs/2512.05693)|null|
|**2025-12-05**|**Conscious Gaze: Adaptive Attention Mechanisms for Hallucination Mitigation in Vision-Language Models**|Guixian Zhang Team|[2512.05546](http://arxiv.org/abs/2512.05546)|null|
|**2025-12-05**|**VOST-SGG: VLM-Aided One-Stage Spatio-Temporal Scene Graph Generation**|Basura Fernando Team|[2512.05524](http://arxiv.org/abs/2512.05524)|null|
|**2025-12-04**|**From Segments to Scenes: Temporal Understanding in Autonomous Driving via Vision-Language Model**|Mohammad Akbari Team|[2512.05277](http://arxiv.org/abs/2512.05277)|null|
|**2025-12-04**|**STARE-VLA: Progressive Stage-Aware Reinforcement for Fine-Tuning Vision-Language-Action Models**|Benjamin Busam Team|[2512.05107](http://arxiv.org/abs/2512.05107)|null|
|**2025-12-04**|**TV2TV: A Unified Framework for Interleaved Language and Video Generation**|Emily Dinan Team|[2512.05103](http://arxiv.org/abs/2512.05103)|null|
|**2025-12-04**|**4DLangVGGT: 4D Language-Visual Geometry Grounded Transformer**|Xinggang Wang Team|[2512.05060](http://arxiv.org/abs/2512.05060)|**[link](https://github.com/hustvl/4DLangVGGT)**|
|**2025-12-04**|**FASTer: Toward Efficient Autoregressive Vision Language Action Modeling via Neural Action Tokenization**|Hang Zhao Team|[2512.04952](http://arxiv.org/abs/2512.04952)|null|
|**2025-12-04**|**SIMA 2: A Generalist Embodied Agent for Virtual Worlds**|Zoubin Ghahramani Team|[2512.04797](http://arxiv.org/abs/2512.04797)|null|
|**2025-12-04**|**Embodied Co-Design for Rapidly Evolving Agents: Taxonomy, Frontiers, and Challenges**|Xueqian Wang Team|[2512.04770](http://arxiv.org/abs/2512.04770)|null|
|**2025-12-04**|**E3AD: An Emotion-Aware Vision-Language-Action Model for Human-Centric End-to-End Autonomous Driving**|Chengzhong Xu Team|[2512.04733](http://arxiv.org/abs/2512.04733)|null|
|**2025-12-04**|**Towards Cross-View Point Correspondence in Vision-Language Models**|Xiaolong Zheng Team|[2512.04686](http://arxiv.org/abs/2512.04686)|null|
|**2025-12-04**|**When Robots Should Say "I Don't Know": Benchmarking Abstention in Embodied Question Answering**|Jianfei Yang Team|[2512.04597](http://arxiv.org/abs/2512.04597)|null|
|**2025-12-04**|**SAM3-I: Segment Anything with Instructions**|Li Cheng Team|[2512.04585](http://arxiv.org/abs/2512.04585)|null|
|**2025-12-04**|**X-Humanoid: Robotize Human Videos to Generate Humanoid Videos at Scale**|Mike Zheng Shou Team|[2512.04537](http://arxiv.org/abs/2512.04537)|null|
|**2025-12-04**|**EgoLCD: Egocentric Video Generation with Long Context Diffusion**|Hao Tang Team|[2512.04515](http://arxiv.org/abs/2512.04515)|null|
|**2025-12-04**|**BiTAgent: A Task-Aware Modular Framework for Bidirectional Coupling between Multimodal Large Language Models and World Models**|Wenwu Zhu Team|[2512.04513](http://arxiv.org/abs/2512.04513)|null|
|**2025-12-04**|**dVLM-AD: Enhance Diffusion Vision-Language-Model for Driving via Controllable Reasoning**|Chaowei Xiao Team|[2512.04459](http://arxiv.org/abs/2512.04459)|null|
|**2025-12-04**|**StreamEQA: Towards Streaming Video Understanding for Embodied Scenarios**|Xiaoling Wang Team|[2512.04451](http://arxiv.org/abs/2512.04451)|null|
|**2025-12-04**|**Vision-Language-Action Models for Selective Robotic Disassembly: A Case Study on Critical Component Extraction from Desktops**|Minghui Zheng Team|[2512.04446](http://arxiv.org/abs/2512.04446)|null|
|**2025-12-04**|**MindDrive: An All-in-One Framework Bridging World Models and Vision-Language Model for End-to-End Autonomous Driving**|Ziying Song Team|[2512.04441](http://arxiv.org/abs/2512.04441)|null|
|**2025-12-04**|**FALCON: Actively Decoupled Visuomotor Policies for Loco-Manipulation with Foundation-Model-Based Coordination**|Guillaume Sartoretti Team|[2512.04381](http://arxiv.org/abs/2512.04381)|null|
|**2025-12-04**|**Mitigating Object and Action Hallucinations in Multimodal LLMs via Self-Augmented Contrastive Alignment**|Yu-Chiang Frank Wang Team|[2512.04356](http://arxiv.org/abs/2512.04356)|**[link](https://kpc0810.github.io/santa/)**|
|**2025-12-03**|**ResponsibleRobotBench: Benchmarking Responsible Robot Manipulation using Multi-modal Large Language Models**|Jianwei Zhang Team|[2512.04308](http://arxiv.org/abs/2512.04308)|**[link](https://sites.google.com/view/responsible-robotbench)**|
|**2025-12-03**|**SpaceTools: Tool-Augmented Spatial Reasoning via Double Interactive RL**|Jonathan Tremblay Team|[2512.04069](http://arxiv.org/abs/2512.04069)|null|
|**2025-12-04**|**TempR1: Improving Temporal Understanding of MLLMs via Temporal-Aware Multi-Task Reinforcement Learning**|Limin Wang Team|[2512.03963](http://arxiv.org/abs/2512.03963)|null|
|**2025-12-03**|**Hierarchical Vision Language Action Model Using Success and Failure Demonstrations**|Sungjoon Choi Team|[2512.03913](http://arxiv.org/abs/2512.03913)|**[link](https://vine-vla.github.io/)**|
|**2025-12-03**|**PosA-VLA: Enhancing Action Generation via Pose-Conditioned Anchor Attention**|Mingming Gong Team|[2512.03724](http://arxiv.org/abs/2512.03724)|null|
|**2025-12-03**|**ToG-Bench: Task-Oriented Spatio-Temporal Grounding in Egocentric Videos**|Liang He Team|[2512.03666](http://arxiv.org/abs/2512.03666)|null|
|**2025-12-03**|**Towards Object-centric Understanding for Instructional Videos**|Yu Kong Team|[2512.03479](http://arxiv.org/abs/2512.03479)|null|
|**2025-12-03**|**Multimodal Reinforcement Learning with Agentic Verifier for AI Agents**|Jianfeng Gao Team|[2512.03438](http://arxiv.org/abs/2512.03438)|null|
|**2025-12-03**|**YOLOA: Real-Time Affordance Detection via LLM Adapter**|Xinbo Gao Team|[2512.03418](http://arxiv.org/abs/2512.03418)|null|
|**2025-12-02**|**DynamicVerse: A Physically-Aware Multimodal Framework for 4D World Modeling**|Zhiwen Fan Team|[2512.03000](http://arxiv.org/abs/2512.03000)|null|
|**2025-12-02**|**U4D: Uncertainty-Aware 4D World Modeling from LiDAR Sequences**|Qingshan Liu Team|[2512.02982](http://arxiv.org/abs/2512.02982)|null|
|**2025-12-02**|**VLA Models Are More Generalizable Than You Think: Revisiting Physical and Spatial Modeling**|Guangrun Wang Team|[2512.02902](http://arxiv.org/abs/2512.02902)|null|
|**2025-12-02**|**Action Anticipation at a Glimpse: To What Extent Can Multimodal Cues Replace Video?**|Jose Garcia-Rodriguez Team|[2512.02846](http://arxiv.org/abs/2512.02846)|null|
|**2025-12-02**|**Steering Vision-Language-Action Models as Anti-Exploration: A Test-Time Scaling Approach**|Xuelong Li Team|[2512.02834](http://arxiv.org/abs/2512.02834)|null|
|**2025-12-02**|**Radiologist Copilot: An Agentic Assistant with Orchestrated Tools for Radiology Reporting with Quality Control**|Xiaofan Zhang Team|[2512.02814](http://arxiv.org/abs/2512.02814)|null|
|**2025-12-02**|**Diagnose, Correct, and Learn from Manipulation Failures via Visual Symbols**|Yong-Lu Li Team|[2512.02787](http://arxiv.org/abs/2512.02787)|null|
|**2025-12-02**|**RoboWheel: A Data Engine from Real-World Human Demonstrations for Cross-Embodiment Robotic Learning**|Haoqian Wang Team|[2512.02729](http://arxiv.org/abs/2512.02729)|null|
|**2025-12-02**|**Vision to Geometry: 3D Spatial Memory for Sequential Embodied MLLM Reasoning and Exploration**|Yu Kong Team|[2512.02458](http://arxiv.org/abs/2512.02458)|null|
|**2025-12-01**|**EfficientFlow: Efficient Equivariant Flow Policy Learning for Embodied AI**|Xiangyu Xu Team|[2512.02020](http://arxiv.org/abs/2512.02020)|**[link](https://efficientflow.github.io/)**|
|**2025-12-01**|**ManualVLA: A Unified VLA Model for Chain-of-Thought Manual Generation and Robotic Manipulation**|Shanghang Zhang Team|[2512.02013](http://arxiv.org/abs/2512.02013)|null|
|**2025-12-01**|**KM-ViPE: Online Tightly Coupled Vision-Language-Geometry Fusion for Open-Vocabulary Semantic SLAM**|Sergey Kolyubin Team|[2512.01889](http://arxiv.org/abs/2512.01889)|null|
|**2025-12-02**|**Generative Action Tell-Tales: Assessing Human Motion in Synthesized Videos**|Deepti Ghadiyaram Team|[2512.01803](http://arxiv.org/abs/2512.01803)|null|
|**2025-12-01**|**GR-RL: Going Dexterous and Precise for Long-Horizon Robotic Manipulation**|Yonghui Wu Team|[2512.01801](http://arxiv.org/abs/2512.01801)|null|
|**2025-12-01**|**IGen: Scalable Data Generation for Robot Learning from Open-World Images**|Zhi Wang Team|[2512.01773](http://arxiv.org/abs/2512.01773)|null|
|**2025-12-01**|**DiG-Flow: Discrepancy-Guided Flow Matching for Robust VLA Models**|Zongqing Lu Team|[2512.01715](http://arxiv.org/abs/2512.01715)|null|
|**2025-12-01**|**SPARK: Sim-ready Part-level Articulated Reconstruction with VLM Knowledge**|Chenfanfu Jiang Team|[2512.01629](http://arxiv.org/abs/2512.01629)|**[link](https://heyumeng.com/SPARK/index.html.)**|
|**2025-12-01**|**NavForesee: A Unified Vision-Language World Model for Hierarchical Planning and Dual-Horizon Navigation Prediction**|Mu Xu Team|[2512.01550](http://arxiv.org/abs/2512.01550)|null|
|**2025-12-01**|**S $^2$ -MLLM: Boosting Spatial Reasoning Capability of MLLMs for 3D Visual Grounding with Structural Guidance**|Hesheng Wang Team|[2512.01223](http://arxiv.org/abs/2512.01223)|null|
|**2025-12-01**|**TabletopGen: Instance-Level Interactive 3D Tabletop Scene Generation from Text or Single Image**|Hu Su Team|[2512.01204](http://arxiv.org/abs/2512.01204)|**[link](https://d-robotics-ai-lab.github.io/TabletopGen.project/)**|
|**2025-11-30**|**VLASH: Real-Time VLAs via Future-State-Aware Asynchronous Inference**|Song Han Team|[2512.01031](http://arxiv.org/abs/2512.01031)|null|
|**2025-11-30**|**CycleManip: Enabling Cyclic Task Manipulation via Effective Historical Perception and Understanding**|Wei-Shi Zheng Team|[2512.01022](http://arxiv.org/abs/2512.01022)|**[link](https://isee-laboratory.github.io/OmniDexGrasp/)**|
|**2025-11-30**|**MM-ACT: Learn from Multimodal Parallel Generation to Act**|Ping Luo Team|[2512.00975](http://arxiv.org/abs/2512.00975)|null|
|**2025-11-30**|**SwiftVLA: Unlocking Spatiotemporal Dynamics for Lightweight VLA Models at Minimal Overhead**|Wenjun Mei Team|[2512.00903](http://arxiv.org/abs/2512.00903)|null|
|**2025-11-30**|**AFRAgent : An Adaptive Feature Renormalization Based High Resolution Aware GUI agent**|Mausoom Sarkar Team|[2512.00846](http://arxiv.org/abs/2512.00846)|null|
|**2025-11-30**|**Transforming Monolithic Foundation Models into Embodied Multi-Agent Architectures for Human-Robot Collaboration**|Huaping Liu Team|[2512.00797](http://arxiv.org/abs/2512.00797)|null|
|**2025-11-30**|**Sigma: The Key for Vision-Language-Action Models toward Telepathic Alignment**|Libo Wang Team|[2512.00783](http://arxiv.org/abs/2512.00783)|**[link](https://huggingface.co/Veltraxor/Sigma)**|
|**2025-11-29**|**Asset-Driven Sematic Reconstruction of Dynamic Scene with Multi-Human-Object Interactions**|Hamid Rezatofighi Team|[2512.00547](http://arxiv.org/abs/2512.00547)|null|
|**2025-11-29**|**Image Generation as a Visual Planner for Robotic Manipulation**|Ye Pang Team|[2512.00532](http://arxiv.org/abs/2512.00532)|null|
|**2025-11-29**|**CC-FMO: Camera-Conditioned Zero-Shot Single Image to 3D Scene Generation with Foundation Model Orchestration**|Gao Huang Team|[2512.00493](http://arxiv.org/abs/2512.00493)|null|
|**2025-11-28**|**DenseScan: Advancing 3D Scene Understanding with 2D Dense Annotation**|Tao Zhang Team|[2512.00226](http://arxiv.org/abs/2512.00226)|null|
|**2025-11-28**|**AutocleanEEG ICVision: Automated ICA Artifact Classification Using Vision-Language AI**|Ernest Pedapati Team|[2512.00194](http://arxiv.org/abs/2512.00194)|null|
|**2025-11-25**|**Arcadia: Toward a Full-Lifecycle Framework for Embodied Lifelong Learning**|Yueting Zhuang Team|[2512.00076](http://arxiv.org/abs/2512.00076)|null|
|**2025-10-31**|**Foundation Models for Trajectory Planning in Autonomous Driving: A Review of Progress and Open Challenges**|Puneet K. Dokania Team|[2512.00021](http://arxiv.org/abs/2512.00021)|null|
|**2025-11-28**|**Hunyuan-GameCraft-2: Instruction-following Interactive Game World Model**|Qinglin Lu Team|[2511.23429](http://arxiv.org/abs/2511.23429)|**[link](https://hunyuan-gamecraft-2.github.io/)**|
|**2025-11-28**|**Adapting Like Humans: A Metacognitive Agent with Test-time Reasoning**|Jun Wang Team|[2511.23262](http://arxiv.org/abs/2511.23262)|null|
|**2025-11-28**|**Obstruction reasoning for robotic grasping**|Fabio Poiesi Team|[2511.23186](http://arxiv.org/abs/2511.23186)|null|
|**2025-11-28**|**MindPower: Enabling Theory-of-Mind Reasoning in VLM-based Embodied Agents**|Wen-Huang Cheng Team|[2511.23055](http://arxiv.org/abs/2511.23055)|null|
|**2025-11-28**|**LatBot: Distilling Universal Latent Actions for Vision-Language-Action Models**|Jianlong Fu Team|[2511.23034](http://arxiv.org/abs/2511.23034)|**[link](https://mm-robot.github.io/distill_latent_action/)**|
|**2025-11-28**|**From Illusion to Intention: Visual Rationale Learning for Vision-Language Reasoning**|Yunfeng Yan Team|[2511.23031](http://arxiv.org/abs/2511.23031)|null|
|**2025-11-27**|**Distracted Robot: How Visual Clutter Undermine Robotic Manipulation**|Xuan Zhao Team|[2511.22780](http://arxiv.org/abs/2511.22780)|null|
|**2025-11-27**|**Improving Robotic Manipulation Robustness via NICE Scene Surgery**|Amir Rasouli Team|[2511.22777](http://arxiv.org/abs/2511.22777)|null|
|**2025-11-27**|**Mechanistic Finetuning of Vision-Language-Action Models via Few-Shot Demonstrations**|Roei Herzig Team|[2511.22697](http://arxiv.org/abs/2511.22697)|null|
|**2025-11-27**|**Beyond Success: Refining Elegant Robot Manipulation from Mixed-Quality Data via Just-in-Time Intervention**|Meibao Yao Team|[2511.22555](http://arxiv.org/abs/2511.22555)|null|
|**2025-11-27**|**CoT4AD: A Vision-Language-Action Model with Explicit Chain-of-Thought Reasoning for Autonomous Driving**|Hao Tang Team|[2511.22532](http://arxiv.org/abs/2511.22532)|null|
|**2025-11-27**|**SkeletonAgent: An Agentic Interaction Framework for Skeleton-based Action Recognition**|Zhenan Sun Team|[2511.22433](http://arxiv.org/abs/2511.22433)|null|
|**2025-11-27**|**DualVLA: Building a Generalizable Embodied Agent via Partial Decoupling of Reasoning and Action**|Feng Zhao Team|[2511.22134](http://arxiv.org/abs/2511.22134)|null|
|**2025-11-27**|**WorldWander: Bridging Egocentric and Exocentric Worlds in Video Generation**|Mike Zheng Shou Team|[2511.22098](http://arxiv.org/abs/2511.22098)|null|
|**2025-11-26**|**AmodalGen3D: Generative Amodal 3D Object Reconstruction from Sparse Unposed Views**|Yu-Wing Tai Team|[2511.21945](http://arxiv.org/abs/2511.21945)|null|
|**2025-11-26**|**Physics-Informed Spiking Neural Networks via Conservative Flux Quantization**|Lin Wang Team|[2511.21784](http://arxiv.org/abs/2511.21784)|null|
|**2025-11-26**|**Attention-Guided Patch-Wise Sparse Adversarial Attacks on Vision-Language-Action Models**|Nan Zhang Team|[2511.21663](http://arxiv.org/abs/2511.21663)|null|
|**2025-11-26**|**VacuumVLA: Boosting VLA Capabilities via a Unified Suction and Gripping Tool for Complex Robotic Manipulation**|Shaoshuai Shi Team|[2511.21557](http://arxiv.org/abs/2511.21557)|null|
|**2025-11-26**|**$\mathcal{E}_0$ : Enhancing Generalization and Fine-Grained Control in VLA Models via Continuized Discrete Diffusion**|Guangrun Wang Team|[2511.21542](http://arxiv.org/abs/2511.21542)|null|
|**2025-11-26**|**MADRA: Multi-Agent Debate for Risk-Aware Embodied Planning**|Xi Sheryl Zhang Team|[2511.21460](http://arxiv.org/abs/2511.21460)|null|
|**2025-11-26**|**From Observation to Action: Latent Action-based Primitive Segmentation for VLA Pre-training in Industrial Settings**|Alexander Kleiner Team|[2511.21428](http://arxiv.org/abs/2511.21428)|null|
|**2025-11-26**|**Towards an Effective Action-Region Tracking Framework for Fine-grained Video Action Recognition**|Zhiyong Wang Team|[2511.21202](http://arxiv.org/abs/2511.21202)|null|
|**2025-11-26**|**When Robots Obey the Patch: Universal Transferable Patch Attacks on Vision-Language-Action Models**|Xudong Jiang Team|[2511.21192](http://arxiv.org/abs/2511.21192)|null|
|**2025-11-26**|**MarketGen: A Scalable Simulation Platform with Auto-Generated Embodied Supermarket Environments**|Zhaoxiang Zhang Team|[2511.21161](http://arxiv.org/abs/2511.21161)|**[link](https://xuhu0529.github.io/MarketGen)**|
|**2025-11-26**|**OVOD-Agent: A Markov-Bandit Framework for Proactive Visual Reasoning and Self-Evolving Detection**|Chu He Team|[2511.21064](http://arxiv.org/abs/2511.21064)|null|
|**2025-11-26**|**CaptionQA: Is Your Caption as Useful as the Image Itself?**|Chenfeng Xu Team|[2511.21025](http://arxiv.org/abs/2511.21025)|null|
|**2025-11-26**|**ENACT: Evaluating Embodied Cognition with World Modeling of Egocentric Interaction**|Manling Li Team|[2511.20937](http://arxiv.org/abs/2511.20937)|null|
|**2025-11-25**|**Evo-Memory: Benchmarking LLM Agent Test-time Learning with Self-Evolving Memory**|Derek Zhiyuan Cheng Team|[2511.20857](http://arxiv.org/abs/2511.20857)|null|
|**2025-11-25**|**OVAL-Grasp: Open-Vocabulary Affordance Localization for Task Oriented Grasping**|Odest Chadwicke Jenkins Team|[2511.20841](http://arxiv.org/abs/2511.20841)|null|
|**2025-11-25**|**DeeAD: Dynamic Early Exit of Vision-Language Action for Efficient Autonomous Driving**|Chun Jason Xue Team|[2511.20720](http://arxiv.org/abs/2511.20720)|null|
|**2025-11-25**|**Inferix: A Block-Diffusion based Next-Generation Inference Engine for World Simulation**|Bohan Zhuang Team|[2511.20714](http://arxiv.org/abs/2511.20714)|null|
|**2025-11-25**|**Reinforcing Action Policies by Prophesying**|Li Zhang Team|[2511.20633](http://arxiv.org/abs/2511.20633)|**[link](https://LogosRoboticsGroup.github.io/ProphRL)**|
|**2025-11-25**|**Wanderland: Geometrically Grounded Simulation for Open-World Embodied AI**|Chen Feng Team|[2511.20620](http://arxiv.org/abs/2511.20620)|null|
|**2025-11-25**|**ArtiBench and ArtiBrain: Benchmarking Generalizable Vision-Language Articulated Object Manipulation**|Yan Xia Team|[2511.20330](http://arxiv.org/abs/2511.20330)|null|
|**2025-11-25**|**ScenarioCLIP: Pretrained Transferable Visual Language Models and Action-Genome Dataset for Natural Scene Analysis**|Abhijit Das Team|[2511.20274](http://arxiv.org/abs/2511.20274)|null|
|**2025-11-25**|**CostNav: A Navigation Benchmark for Cost-Aware Evaluation of Embodied Agents**|Yunsung Lee Team|[2511.20216](http://arxiv.org/abs/2511.20216)|null|
|**2025-11-25**|**Reasoning-VLA: A Fast and General Vision-Language-Action Reasoning Model for Autonomous Driving**|Tat-Seng Chua Team|[2511.19912](http://arxiv.org/abs/2511.19912)|null|
|**2025-11-25**|**MAPS: Preserving Vision-Language Representations via Module-Wise Proximity Scheduling for Better Vision-Language-Action Generalization**|Zsolt Kira Team|[2511.19878](http://arxiv.org/abs/2511.19878)|null|
|**2025-11-25**|**GigaWorld-0: World Models as Data Engine to Empower Embodied AI**|Zheng Zhu Team|[2511.19861](http://arxiv.org/abs/2511.19861)|**[link](https://giga-world-0.github.io/)**|
|**2025-11-25**|**Unifying Perception and Action: A Hybrid-Modality Pipeline with Implicit Visual Chain-of-Thought for Robotic Action Generation**|Sanglu Lu Team|[2511.19859](http://arxiv.org/abs/2511.19859)|null|
|**2025-11-24**|**Prune-Then-Plan: Step-Level Calibration for Stable Frontier Exploration in Embodied Question Answering**|Roni Sengupta Team|[2511.19768](http://arxiv.org/abs/2511.19768)|**[link](https://noahfrahm.github.io/Prune-Then-Plan-project-page/)**|
|**2025-11-24**|**Robot-Powered Data Flywheels: Deploying Robots in the Wild for Continual Data Collection and Foundation Model Adaptation**|Dorsa Sadigh Team|[2511.19647](http://arxiv.org/abs/2511.19647)|null|
|**2025-11-24**|**Learning Massively Multitask World Models for Continuous Control**|Xiaolong Wang Team|[2511.19584](http://arxiv.org/abs/2511.19584)|**[link](https://www.nicklashansen.com/NewtWM)**|
|**2025-11-24**|**Discover, Learn, and Reinforce: Scaling Vision-Language-Action Pretraining with Diverse RL-Generated Trajectories**|Jiang Bian Team|[2511.19528](http://arxiv.org/abs/2511.19528)|null|
|**2025-11-24**|**Mixture of Horizons in Action Chunking**|Mingyu Ding Team|[2511.19433](http://arxiv.org/abs/2511.19433)|null|
|**2025-11-24**|**Cook and Clean Together: Teaching Embodied Agents for Parallel Task Execution**|Xiang Bai Team|[2511.19430](http://arxiv.org/abs/2511.19430)|**[link](https://github.com/H-EmbodVis/GRANT})**|
|**2025-11-24**|**Rethinking Intermediate Representation for VLM-based Robot Manipulation**|Chi-Wing Fu Team|[2511.19315](http://arxiv.org/abs/2511.19315)|null|
|**2025-11-24**|**Percept-WAM: Perception-Enhanced World-Awareness-Action Model for Robust End-to-End Autonomous Driving**|Hang Xu Team|[2511.19221](http://arxiv.org/abs/2511.19221)|null|
|**2025-11-24**|**MonoSR: Open-Vocabulary Spatial Reasoning from Monocular Images**|Shijie Li Team|[2511.19119](http://arxiv.org/abs/2511.19119)|null|
|**2025-11-24**|**Agent Discovery in Internet of Agents: Challenges and Solutions**|Tom H. Luan Team|[2511.19113](http://arxiv.org/abs/2511.19113)|null|
|**2025-11-24**|**ReEXplore: Improving MLLMs for Embodied Exploration with Contextualized Retrospective Experience Replay**|Volker Tresp Team|[2511.19033](http://arxiv.org/abs/2511.19033)|null|
|**2025-11-24**|**AVA-VLA: Improving Vision-Language-Action models with Active Visual Attention**|Xiaoyuan Yu Team|[2511.18960](http://arxiv.org/abs/2511.18960)|null|
|**2025-11-24**|**Compressor-VLA: Instruction-Guided Visual Token Compression for Efficient Robotic Manipulation**|Wenjing Qian Team|[2511.18950](http://arxiv.org/abs/2511.18950)|null|
|**2025-11-24**|**Human-Centric Open-Future Task Discovery: Formulation, Benchmark, and Scalable Tree-Based Search**|Liang Lin Team|[2511.18929](http://arxiv.org/abs/2511.18929)|null|
|**2025-11-24**|**UNeMo: Collaborative Visual-Language Reasoning and Navigation via a Multimodal World Model**|Jianqiang Li Team|[2511.18845](http://arxiv.org/abs/2511.18845)|null|
|**2025-11-24**|**VideoPerceiver: Enhancing Fine-Grained Temporal Perception in Video Multimodal Large Language Models**|Danfeng Yan Team|[2511.18823](http://arxiv.org/abs/2511.18823)|null|
|**2025-11-24**|**MergeVLA: Cross-Skill Model Merging Toward a Generalist Vision-Language-Action Agent**|Yadan Luo Team|[2511.18810](http://arxiv.org/abs/2511.18810)|null|
|**2025-11-24**|**Understanding Task Transfer in Vision-Language Models**|Vineeth N. Balasubramanian Team|[2511.18787](http://arxiv.org/abs/2511.18787)|null|
|**2025-11-24**|**Any4D: Open-Prompt 4D Generation from Natural Language and Images**|Qiao Sun Team|[2511.18746](http://arxiv.org/abs/2511.18746)|null|
|**2025-11-24**|**Beyond Description: Cognitively Benchmarking Fine-Grained Action for Embodied Agents**|Yang Liu Team|[2511.18685](http://arxiv.org/abs/2511.18685)|null|
|**2025-11-23**|**TRANSPORTER: Transferring Visual Semantics from VLM Manifolds**|Alexandros Stergiou Team|[2511.18359](http://arxiv.org/abs/2511.18359)|**[link](https://alexandrosstergiou.github.io/TRANSPORTER)**|
|**2025-11-22**|**EgoControl: Controllable Egocentric Video Generation via 3D Full-Body Poses**|Juergen Gall Team|[2511.18173](http://arxiv.org/abs/2511.18173)|null|
|**2025-11-22**|**EchoVLA: Robotic Vision-Language-Action Model with Synergistic Declarative Memory for Mobile Manipulation**|Xiaodan Liang Team|[2511.18112](http://arxiv.org/abs/2511.18112)|null|
|**2025-11-22**|**Continually Evolving Skill Knowledge in Vision Language Action Model**|Hesheng Wang Team|[2511.18085](http://arxiv.org/abs/2511.18085)|null|
|**2025-11-22**|**ActDistill: General Action-Guided Self-Derived Distillation for Efficient Vision-Language-Action Models**|Guoli Yang Team|[2511.18082](http://arxiv.org/abs/2511.18082)|null|
|**2025-11-22**|**Switch-JustDance: Benchmarking Whole Body Motion Tracking Policies Using a Commercial Console Game**|Tianyu Li Team|[2511.17925](http://arxiv.org/abs/2511.17925)|null|
|**2025-11-22**|**MobileVLA-R1: Reinforcing Vision-Language-Action for Mobile Robots**|Hao Tang Team|[2511.17889](http://arxiv.org/abs/2511.17889)|null|
|**2025-11-22**|**The Horcrux: Mechanistically Interpretable Task Decomposition for Detecting and Mitigating Reward Hacking in Embodied AI Systems**|Jared Junkin Team|[2511.17869](http://arxiv.org/abs/2511.17869)|null|
|**2025-11-21**|**RynnVLA-002: A Unified Vision-Language-Action and World Model**|Hao Chen Team|[2511.17502](http://arxiv.org/abs/2511.17502)|null|
|**2025-11-21**|**IndustryNav: Exploring Spatial Reasoning of Embodied Agents in Dynamic Industrial Navigation**|Yu Kong Team|[2511.17384](http://arxiv.org/abs/2511.17384)|null|
|**2025-11-21**|**METIS: Multi-Source Egocentric Training for Integrated Dexterous Vision-Language-Action Model**|Shanghang Zhang Team|[2511.17366](http://arxiv.org/abs/2511.17366)|null|
|**2025-11-21**|**Robot Confirmation Generation and Action Planning Using Long-context Q-Former Integrated with Multimodal LLM**|Jonathan Le Roux Team|[2511.17335](http://arxiv.org/abs/2511.17335)|null|
|**2025-11-21**|**TP-MDDN: Task-Preferenced Multi-Demand-Driven Navigation with Autonomous Decision-Making**|Xiangyang Xue Team|[2511.17225](http://arxiv.org/abs/2511.17225)|null|
|**2025-11-21**|**VLA-4D: Embedding 4D Awareness into Vision-Language-Action Models for SpatioTemporally Coherent Robotic Manipulation**|Gim Hee Lee Team|[2511.17199](http://arxiv.org/abs/2511.17199)|null|
|**2025-11-21**|**Progress-Think: Semantic Progress Reasoning for Vision-Language Navigation**|Zhaoxin Fan Team|[2511.17097](http://arxiv.org/abs/2511.17097)|null|
|**2025-11-20**|**InternData-A1: Pioneering High-Fidelity Synthetic Data for Pre-training Generalist Policy**|Jiangmiao Pang Team|[2511.16651](http://arxiv.org/abs/2511.16651)|null|
|**2025-11-20**|**Bridging VLMs and Embodied Intelligence with Deliberate Practice Policy Optimization**|Xiaozhu Ju Team|[2511.16602](http://arxiv.org/abs/2511.16602)|null|
|**2025-11-20**|**MiMo-Embodied: X-Embodied Foundation Model Technical Report**|Long Chen Team|[2511.16518](http://arxiv.org/abs/2511.16518)|**[link](https://github.com/XiaomiMiMo/MiMo-Embodied)**|
|**2025-11-20**|**VLA-Pruner: Temporal-Aware Dual-Level Visual Token Pruning for Efficient Vision-Language-Action Inference**|Bo Zhao Team|[2511.16449](http://arxiv.org/abs/2511.16449)|null|
|**2025-11-20**|**The Shawshank Redemption of Embodied AI: Understanding and Benchmarking Indirect Environmental Jailbreaks**|Jianfeng Ma Team|[2511.16347](http://arxiv.org/abs/2511.16347)|null|
|**2025-11-20**|**FT-NCFM: An Influence-Aware Data Distillation Framework for Efficient VLA Models**|Mingsheng Shang Team|[2511.16233](http://arxiv.org/abs/2511.16233)|null|
|**2025-11-20**|**When Alignment Fails: Multimodal Adversarial Attacks on Vision-Language-Action Models**|Yaochu Jin Team|[2511.16203](http://arxiv.org/abs/2511.16203)|null|
|**2025-11-20**|**Mantis: A Versatile Vision-Language-Action Model with Disentangled Visual Foresight**|Zhijie Deng Team|[2511.16175](http://arxiv.org/abs/2511.16175)|null|
|**2025-11-20**|**EvoVLA: Self-Evolving Vision-Language-Action Model**|Hao Tang Team|[2511.16166](http://arxiv.org/abs/2511.16166)|null|
|**2025-10-31**|**DeepThinkVLA: Enhancing Reasoning Capability of Vision-Language-Action Models**|Zhouping Yin Team|[2511.15669](http://arxiv.org/abs/2511.15669)|null|
|**2025-11-19**|**SRPO: Self-Referential Policy Optimization for Vision-Language-Action Models**|Xipeng Qiu Team|[2511.15605](http://arxiv.org/abs/2511.15605)|null|
|**2025-11-19**|**Zero-Shot Open-Vocabulary Human Motion Grounding with Test-Time Training**|Jianfei Yang Team|[2511.15379](http://arxiv.org/abs/2511.15379)|null|
|**2025-11-19**|**Look, Zoom, Understand: The Robotic Eyeball for Embodied Perception**|Wenzhao Lian Team|[2511.15279](http://arxiv.org/abs/2511.15279)|null|
|**2025-11-19**|**Generating Natural-Language Surgical Feedback: From Structured Representation to Domain-Grounded Evaluation**|Andrew J. Hung Team|[2511.15159](http://arxiv.org/abs/2511.15159)|null|
|**2025-11-18**|**GeoSceneGraph: Geometric Scene Graph Diffusion Model for Text-guided 3D Indoor Scene Synthesis**|Helge Ritter Team|[2511.14884](http://arxiv.org/abs/2511.14884)|null|
|**2025-11-18**|**$π^{*}_{0.6}$ : a VLA That Learns From Experience**|Zhiyuan Zhou Team|[2511.14759](http://arxiv.org/abs/2511.14759)|null|
|**2025-11-18**|**NORA-1.5: A Vision-Language-Action Model Trained using World Model- and Action-based Preference Rewards**|Soujanya Poria Team|[2511.14659](http://arxiv.org/abs/2511.14659)|**[link](https://declare-lab.github.io/nora-1.5)**|
|**2025-11-18**|**Enhancing End-to-End Autonomous Driving with Risk Semantic Distillaion from VLM**|Siyuan Cheng Team|[2511.14499](http://arxiv.org/abs/2511.14499)|null|
|**2025-11-18**|**Continuous Vision-Language-Action Co-Learning with Semantic-Physical Alignment for Behavioral Cloning**|Hongpeng Wang Team|[2511.14396](http://arxiv.org/abs/2511.14396)|**[link](https://qhemu.github.io/CCoL/)**|
|**2025-11-18**|**GEN3D: Generating Domain-Free 3D Scenes from a Single Image**|Houde Liu Team|[2511.14291](http://arxiv.org/abs/2511.14291)|null|
|**2025-11-18**|**Towards Deploying VLA without Fine-Tuning: Plug-and-Play Inference-Time VLA Policy Steering via Embodied Evolutionary Diffusion**|Fei Chen Team|[2511.14178](http://arxiv.org/abs/2511.14178)|null|
|**2025-11-18**|**RoboTidy : A 3D Gaussian Splatting Household Tidying Benchmark for Embodied Navigation and Action**|Jiayu Chen Team|[2511.14161](http://arxiv.org/abs/2511.14161)|null|
|**2025-11-18**|**MVI-Bench: A Comprehensive Benchmark for Evaluating Robustness to Misleading Visual Inputs in LVLMs**|Lu Cheng Team|[2511.14159](http://arxiv.org/abs/2511.14159)|null|
|**2025-11-18**|**AsyncVLA: Asynchronous Flow Matching for Vision-Language-Action Models**|Biqing Qi Team|[2511.14148](http://arxiv.org/abs/2511.14148)|null|
|**2025-11-18**|**Multi-view Phase-aware Pedestrian-Vehicle Incident Reasoning Framework with Vision-Language Models**|Jidong J. Yang Team|[2511.14120](http://arxiv.org/abs/2511.14120)|null|
|**2025-11-19**|**Searching in Space and Time: Unified Memory-Action Loops for Open-World Object Retrieval**|Roberto Martín-Martín Team|[2511.14004](http://arxiv.org/abs/2511.14004)|null|
|**2025-11-17**|**TiViBench: Benchmarking Think-in-Video Reasoning for Video Generative Models**|Ying-Cong Chen Team|[2511.13704](http://arxiv.org/abs/2511.13704)|**[link](https://haroldchen19.github.io/TiViBench-Page/)**|
|**2025-11-17**|**PhysX-Anything: Simulation-Ready Physical 3D Assets from Single Image**|Ziwei Liu Team|[2511.13648](http://arxiv.org/abs/2511.13648)|**[link](https://physx-anything.github.io/)**|
|**2025-11-17**|**FreeAskWorld: An Interactive and Closed-Loop Simulator for Human-Centric Embodied AI**|Jiangtao Gong Team|[2511.13524](http://arxiv.org/abs/2511.13524)|null|
|**2025-11-17**|**Yanyun-3: Enabling Cross-Platform Strategy Game Operation with Vision-Language Models**|Yuxiang Sun Team|[2511.12937](http://arxiv.org/abs/2511.12937)|null|
|**2025-11-18**|**Uni-Hand: Universal Hand Motion Forecasting in Egocentric Views**|Hesheng Wang Team|[2511.12878](http://arxiv.org/abs/2511.12878)|null|
|**2025-11-16**|**BridgeEQA: Virtual Embodied Agents for Real Bridge Inspections**|Vedhus Hoskere Team|[2511.12676](http://arxiv.org/abs/2511.12676)|null|
|**2025-11-16**|**RoboAfford++: A Generative AI-Enhanced Dataset for Multimodal Affordance Learning in Robotic Manipulation and Navigation**|Long Chen Team|[2511.12436](http://arxiv.org/abs/2511.12436)|null|
|**2025-11-16**|**VLA-R: Vision-Language Action Retrieval toward Open-World End-to-End Autonomous Driving**|David Hyunchul Shim Team|[2511.12405](http://arxiv.org/abs/2511.12405)|null|
|**2025-11-15**|**Fast Reasoning Segmentation for Images and Videos**|Mathias Unberath Team|[2511.12368](http://arxiv.org/abs/2511.12368)|null|
|**2025-11-15**|**AttackVLA: Benchmarking Adversarial and Backdoor Attacks on Vision-Language-Action Models**|Yu-Gang Jiang Team|[2511.12149](http://arxiv.org/abs/2511.12149)|null|
|**2025-11-15**|**Decoupled Action Head: Confining Task Knowledge to Conditioning Layers**|Qi WU Team|[2511.12101](http://arxiv.org/abs/2511.12101)|null|
|**2025-11-15**|**SRSplat: Feed-Forward Super-Resolution Gaussian Splatting from Sparse Multi-View Images**|Min Tan Team|[2511.12040](http://arxiv.org/abs/2511.12040)|**[link](https://xinyuanhu66.github.io/SRSplat/)**|
|**2025-11-14**|**Large Language Models and 3D Vision for Intelligent Robotic Perception and Autonomy**|Karthick Thiyagarajan Team|[2511.11777](http://arxiv.org/abs/2511.11777)|null|
|**2025-11-12**|**Task-Aware 3D Affordance Segmentation via 2D Guidance and Geometric Refinement**|Gangyi Ding Team|[2511.11702](http://arxiv.org/abs/2511.11702)|null|
|**2025-11-14**|**Rethinking Progression of Memory State in Robotic Manipulation: An Object-Centric Perspective**|Ngan Le Team|[2511.11478](http://arxiv.org/abs/2511.11478)|null|
|**2025-11-14**|**EcoAlign: An Economically Rational Framework for Efficient LVLM Alignment**|Hongyi Zhang Team|[2511.11301](http://arxiv.org/abs/2511.11301)|null|
|**2025-11-14**|**Experiences from Benchmarking Vision-Language-Action Models for Robotic Manipulation**|Xi Zheng Team|[2511.11298](http://arxiv.org/abs/2511.11298)|null|
|**2025-11-14**|**AdaptPNP: Integrating Prehensile and Non-Prehensile Skills for Adaptive Robotic Manipulation**|Lin Shao Team|[2511.11052](http://arxiv.org/abs/2511.11052)|null|
|**2025-11-14**|**DEFT-LLM: Disentangled Expert Feature Tuning for Micro-Expression Recognition**|Jianqin Yin Team|[2511.10948](http://arxiv.org/abs/2511.10948)|null|
|**2025-11-14**|**Abstract 3D Perception for Spatial Intelligence in Vision-Language Models**|Hanspeter Pfister Team|[2511.10946](http://arxiv.org/abs/2511.10946)|null|
|**2025-11-13**|**Towards Blind and Low-Vision Accessibility of Lightweight VLMs and Custom LLM-Evals**|Pawan Goyal Team|[2511.10615](http://arxiv.org/abs/2511.10615)|null|
|**2025-11-13**|**OmniVGGT: Omni-Modality Driven Visual Geometry Grounded Transformer**|Ziwei Liu Team|[2511.10560](http://arxiv.org/abs/2511.10560)|**[link](https://livioni.github.io/OmniVGGT-official/)**|
|**2025-11-13**|**SemanticVLA: Semantic-Aligned Sparsification and Enhancement for Efficient Robotic Manipulation**|Liqiang Nie Team|[2511.10518](http://arxiv.org/abs/2511.10518)|**[link](https://github.com/JiuTian-VL/SemanticVLA)**|
|**2025-11-13**|**Facial-R1: Aligning Reasoning and Recognition for Facial Emotion Analysis**|Min Cao Team|[2511.10254](http://arxiv.org/abs/2511.10254)|null|
|**2025-11-13**|**SUGAR: Learning Skeleton Representation with Visual-Motion Knowledge for Action Recognition**|Zitong Yu Team|[2511.10091](http://arxiv.org/abs/2511.10091)|null|
|**2025-11-13**|**Phantom Menace: Exploring and Enhancing the Robustness of VLA Models against Physical Sensor Attacks**|Wenyuan Xu Team|[2511.10008](http://arxiv.org/abs/2511.10008)|null|
|**2025-11-13**|**EnvTrace: Simulation-Based Semantic Evaluation of LLM Code via Execution Trace Alignment -- Demonstrated at Synchrotron Beamlines**|Esther H. R. Tsai Team|[2511.09964](http://arxiv.org/abs/2511.09964)|null|
|**2025-11-13**|**Audio-VLA: Adding Contact Audio Perception to Vision-Language-Action Model for Robotic Manipulation**|Changbo Wang Team|[2511.09958](http://arxiv.org/abs/2511.09958)|null|
|**2025-11-12**|**MAP-VLA: Memory-Augmented Prompting for Vision-Language-Action Model in Robotic Manipulation**|Ziwei Wang Team|[2511.09516](http://arxiv.org/abs/2511.09516)|null|
|**2025-11-12**|**WMPO: World Model-based Policy Optimization for Vision-Language-Action Models**|Song Guo Team|[2511.09515](http://arxiv.org/abs/2511.09515)|**[link](https://wm-po.github.io)**|
|**2025-11-12**|**Think, Remember, Navigate: Zero-Shot Object-Goal Navigation with VLM-Powered Reasoning**|Fatemeh Afghah Team|[2511.08942](http://arxiv.org/abs/2511.08942)|null|
|**2025-11-12**|**Lumine: An Open Recipe for Building Generalist Agents in 3D Open Worlds**|Guang Shi Team|[2511.08892](http://arxiv.org/abs/2511.08892)|null|
|**2025-11-12**|**MirrorLimb: Implementing hand pose acquisition and robot teleoperation based on RealMirror**|Tao Shen Team|[2511.08865](http://arxiv.org/abs/2511.08865)|null|
|**2025-11-11**|**EAGLE: Episodic Appearance- and Geometry-aware Memory for Unified 2D-3D Visual Query Localization in Egocentric Vision**|Xun Tu Team|[2511.08007](http://arxiv.org/abs/2511.08007)|null|
|**2025-11-11**|**SONIC: Supersizing Motion Tracking for Natural Humanoid Whole-Body Control**|Yuke Zhu Team|[2511.07820](http://arxiv.org/abs/2511.07820)|**[link](https://nvlabs.github.io/SONIC/)**|
|**2025-11-11**|**ViPRA: Video Prediction for Robot Actions**|Deepak Pathak Team|[2511.07732](http://arxiv.org/abs/2511.07732)|**[link](https://vipra-project.github.io)**|
|**2025-11-11**|**LLM-GROP: Visually Grounded Robot Task and Motion Planning with Large Language Models**|Shiqi Zhang Team|[2511.07727](http://arxiv.org/abs/2511.07727)|null|
|**2025-11-10**|**TwinOR: Photorealistic Digital Twins of Dynamic Operating Rooms for Embodied AI Research**|Mathias Unberath Team|[2511.07412](http://arxiv.org/abs/2511.07412)|null|
|**2025-11-10**|**SpatialThinker: Reinforcing 3D Reasoning in Multimodal LLMs via Spatial Rewards**|Ronald Clark Team|[2511.07403](http://arxiv.org/abs/2511.07403)|null|
|**2025-11-10**|**How Do VLAs Effectively Inherit from VLMs?**|Jiang Bian Team|[2511.06619](http://arxiv.org/abs/2511.06619)|null|
|**2025-11-09**|**ExpReS-VLA: Specializing Vision-Language-Action Models Through Experience Replay and Retrieval**|Jeff Ichnowski Team|[2511.06202](http://arxiv.org/abs/2511.06202)|null|
|**2025-11-09**|**OpenVLN: Open-world aerial Vision-Language Navigation**|Yang Cong Team|[2511.06182](http://arxiv.org/abs/2511.06182)|null|
|**2025-11-08**|**10 Open Challenges Steering the Future of Vision-Language-Action Models**|David Hsu Team|[2511.05936](http://arxiv.org/abs/2511.05936)|null|
|**2025-11-11**|**Causal Tracing of Object Representations in Large Vision Language Models: Mechanistic Interpretability and Hallucination Mitigation**|Xiachong Feng Team|[2511.05923](http://arxiv.org/abs/2511.05923)|null|
|**2025-11-07**|**Lite VLA: Efficient Vision-Language-Action Control on CPU-Bound Edge Robots**|Mrinmoy Sarkar Team|[2511.05642](http://arxiv.org/abs/2511.05642)|null|
|**2025-11-06**|**Grounding Foundational Vision Models with 3D Human Poses for Robust Action Recognition**|Kevin Zhu Team|[2511.05622](http://arxiv.org/abs/2511.05622)|**[link](https://github.com/nbabey20/groundactrec)**|
|**2025-11-07**|**Visual Spatial Tuning**|Hengshuang Zhao Team|[2511.05491](http://arxiv.org/abs/2511.05491)|null|
|**2025-11-07**|**EveryDayVLA: A Vision-Language-Action Model for Affordable Robotic Manipulation**|Samuel Dickerson Team|[2511.05397](http://arxiv.org/abs/2511.05397)|null|
|**2025-11-07**|**psiUnity: A Platform for Multimodal Data-Driven XR**|Mohsen Moghaddam Team|[2511.05304](http://arxiv.org/abs/2511.05304)|null|
|**2025-11-07**|**TwinVLA: Data-Efficient Bimanual Manipulation with Twin Single-Arm Vision-Language-Action Models**|Youngwoon Lee Team|[2511.05275](http://arxiv.org/abs/2511.05275)|**[link](https://jellyho.github.io/TwinVLA/)**|
|**2025-11-07**|**Beyond Master and Apprentice: Grounding Foundation Models for Symbiotic Interactive Learning in a Shared Latent Space**|Elmar Rueckert Team|[2511.05203](http://arxiv.org/abs/2511.05203)|null|
|**2025-11-07**|**iFlyBot-VLM Technical Report**|Jia Pan Team|[2511.04976](http://arxiv.org/abs/2511.04976)|null|
|**2025-11-06**|**Evo-1: Lightweight Vision-Language-Action Model with Preserved Semantic Alignment**|Bo Zhao Team|[2511.04555](http://arxiv.org/abs/2511.04555)|**[link](https://github.com/MINT-SJTU/Evo-1)**|
|**2025-11-06**|**GraSP-VLA: Graph-based Symbolic Action Representation for Long-Horizon Planning with VLA Policies**|Cédric Buche Team|[2511.04357](http://arxiv.org/abs/2511.04357)|null|
|**2025-11-06**|**PhysCorr: Dual-Reward DPO for Physics-Constrained Text-to-Video Generation with Automated Preference Selection**|Qi Li Team|[2511.03997](http://arxiv.org/abs/2511.03997)|null|
|**2025-11-06**|**CaRF: Enhancing Multi-View Consistency in Referring 3D Gaussian Splatting Segmentation**|Yuan Xie Team|[2511.03992](http://arxiv.org/abs/2511.03992)|null|
|**2025-11-05**|**ROSBag MCP Server: Analyzing Robot Data with LLMs for Agentic Embodied AI Applications**|Giovanni Toffetti Team|[2511.03497](http://arxiv.org/abs/2511.03497)|null|
|**2025-11-05**|**EQ-Negotiator: Dynamic Emotional Personas Empower Small Language Models for Edge-Deployable Credit Negotiation**|Alexandra Brintrup Team|[2511.03370](http://arxiv.org/abs/2511.03370)|null|
|**2025-11-04**|**LEGO-Eval: Towards Fine-Grained Evaluation on Synthesizing 3D Embodied Environments with Tool Augmentation**|Jinyoung Yeo Team|[2511.03001](http://arxiv.org/abs/2511.03001)|null|
|**2025-11-04**|**TWIST2: Scalable, Portable, and Holistic Humanoid Data Collection System**|C. Karen Liu Team|[2511.02832](http://arxiv.org/abs/2511.02832)|**[link](https://yanjieze.com/TWIST2)**|
|**2025-11-04**|**XR-1: Towards Versatile Vision-Language-Action Models via Learning Unified Vision-Motion Representations**|Jian Tang Team|[2511.02776](http://arxiv.org/abs/2511.02776)|null|
|**2025-11-04**|**Learning Interactive World Model for Object-Centric Reinforcement Learning**|Sara Magliacane Team|[2511.02225](http://arxiv.org/abs/2511.02225)|null|
|**2025-11-01**|**iFlyBot-VLA Technical Report**|Jia Pan Team|[2511.01914](http://arxiv.org/abs/2511.01914)|null|
|**2025-11-03**|**3EED: Ground Everything Everywhere in 3D**|Ziwei Liu Team|[2511.01755](http://arxiv.org/abs/2511.01755)|**[link](https://project-3eed.github.io/)**|
|**2025-11-03**|**Unified Diffusion VLA: Vision-Language-Action Model via Joint Discrete Denoising Diffusion Process**|Haoang Li Team|[2511.01718](http://arxiv.org/abs/2511.01718)|null|
|**2025-11-03**|**PixelVLA: Advancing Pixel-level Understanding in Vision-Language-Action Model**|Yang Cong Team|[2511.01571](http://arxiv.org/abs/2511.01571)|null|
|**2025-11-03**|**RobustVLA: Robustness-Aware Reinforcement Post-Training for Vision-Language-Action Models**|Donglin Wang Team|[2511.01331](http://arxiv.org/abs/2511.01331)|null|
|**2025-11-03**|**Embodiment Transfer Learning for Vision-Language-Action Models**|Yaxin Peng Team|[2511.01224](http://arxiv.org/abs/2511.01224)|null|
|**2025-11-03**|**OmniVLA: Physically-Grounded Multimodal VLA with Unified Multi-Sensor Perception for Robotic Manipulation**|Lili Qiu Team|[2511.01210](http://arxiv.org/abs/2511.01210)|null|
|**2025-11-02**|**URDF-Anything: Constructing Articulated Objects with 3D Multimodal Language Model**|Shanghang Zhang Team|[2511.00940](http://arxiv.org/abs/2511.00940)|null|
|**2025-10-31**|**End-to-End Dexterous Arm-Hand VLA Policies via Shared Autonomy: VR Teleoperation Augmented by Autonomous Hand VLA Policy for Efficient Data Collection**|Zhibin Li Team|[2511.00139](http://arxiv.org/abs/2511.00139)|null|
|**2025-10-30**|**Self-Improving Vision-Language-Action Models with Data Generation via Residual RL**|Yuke Zhu Team|[2511.00091](http://arxiv.org/abs/2511.00091)|null|
|**2025-10-30**|**Alpamayo-R1: Bridging Reasoning and Action Prediction for Generalizable Autonomous Driving in the Long Tail**|Marco Pavone Team|[2511.00088](http://arxiv.org/abs/2511.00088)|null|
|**2025-10-31**|**Visual Backdoor Attacks on MLLM Embodied Decision Making via Contrastive Trigger Learning**|Daniel Kang Team|[2510.27623](http://arxiv.org/abs/2510.27623)|null|
|**2025-10-31**|**Dual-Stream Diffusion for World-Model Augmented Vision-Language-Action Model**|Jinwoo Shin Team|[2510.27607](http://arxiv.org/abs/2510.27607)|null|
|**2025-10-31**|**EBT-Policy: Energy Unlocks Emergent Physical Reasoning Capabilities**|Luhui Hu Team|[2510.27545](http://arxiv.org/abs/2510.27545)|null|
|**2025-10-30**|**A Multi-Modal Neuro-Symbolic Approach for Spatial Reasoning-Based Visual Grounding in Robotics**|Hamid Rezatofighi Team|[2510.27033](http://arxiv.org/abs/2510.27033)|null|
|**2025-10-30**|**Clone Deterministic 3D Worlds**|Yubei Chen Team|[2510.26782](http://arxiv.org/abs/2510.26782)|null|
|**2025-10-30**|**RoboOS-NeXT: A Unified Memory-based Framework for Lifelong, Scalable, and Robust Multi-Robot Collaboration**|Shanghang Zhang Team|[2510.26536](http://arxiv.org/abs/2510.26536)|null|
|**2025-10-30**|**Human-in-the-loop Online Rejection Sampling for Robotic Manipulation**|Yansong Tang Team|[2510.26406](http://arxiv.org/abs/2510.26406)|null|
|**2025-10-29**|**$π_\texttt{RL}$ : Online RL Fine-tuning for Flow-based Vision-Language-Action Models**|Chao Yu Team|[2510.25889](http://arxiv.org/abs/2510.25889)|null|
|**2025-10-29**|**Multimodal Spatial Reasoning in the Large Model Era: A Survey and Benchmarks**|Xuming Hu Team|[2510.25760](http://arxiv.org/abs/2510.25760)|null|
|**2025-10-29**|**Robotic Assistant: Completing Collaborative Tasks with Dexterous Vision-Language-Action Models**|Robert Katzschmann Team|[2510.25713](http://arxiv.org/abs/2510.25713)|null|
|**2025-10-29**|**Don't Blind Your VLA: Aligning Visual Representations for OOD Generalization**|Aleksandr I. Panov Team|[2510.25616](http://arxiv.org/abs/2510.25616)|null|
|**2025-10-29**|**SynHLMA:Synthesizing Hand Language Manipulation for Articulated Object with Discrete Human Object Interaction Representation**|Dan Guo Team|[2510.25268](http://arxiv.org/abs/2510.25268)|null|
|**2025-10-29**|**NanoVLA: Routing Decoupled Vision-Language Understanding for Nano-sized Generalist Robotic Policies**|Jinghui Lu Team|[2510.25122](http://arxiv.org/abs/2510.25122)|null|
|**2025-10-27**|**A Survey on Efficient Vision-Language-Action Models**|Heng Tao Shen Team|[2510.24795](http://arxiv.org/abs/2510.24795)|null|
|**2025-10-28**|**BLM $_1$ : A Boundless Large Model for Cross-Space, Cross-Task, and Cross-Embodiment Learning**|Heng Tao Shen Team|[2510.24161](http://arxiv.org/abs/2510.24161)|null|
|**2025-10-28**|**PFEA: An LLM-based High-Level Natural Language Planning and Feedback Embodied Agent for Human-Centered AI**|Philip Dames Team|[2510.24109](http://arxiv.org/abs/2510.24109)|null|
|**2025-10-27**|**RoboOmni: Proactive Robot Manipulation in Omni-modal Context**|Xipeng Qiu Team|[2510.23763](http://arxiv.org/abs/2510.23763)|null|
|**2025-10-27**|**UrbanVLA: A Vision-Language-Action Model for Urban Micromobility**|He Wang Team|[2510.23576](http://arxiv.org/abs/2510.23576)|null|
|**2025-10-27**|**Dexbotic: Open-Source Vision-Language-Action Toolbox**|Ziyu Zhang Team|[2510.23511](http://arxiv.org/abs/2510.23511)|**[link](https://dexbotic.com/.)**|
|**2025-10-27**|**Evaluation of Vision-LLMs in Surveillance Video**|Jelte P. Mense Team|[2510.23190](http://arxiv.org/abs/2510.23190)|null|
|**2025-10-26**|**Look and Tell: A Dataset for Multimodal Grounding Across Egocentric and Exocentric Views**|Jonas Beskow Team|[2510.22672](http://arxiv.org/abs/2510.22672)|**[link](https://huggingface.co/datasets/annadeichler/KTH-ARIA-referential)**|
|**2025-10-25**|**ACG: Action Coherence Guidance for Flow-based VLA models**|Jaegul Choo Team|[2510.22201](http://arxiv.org/abs/2510.22201)|null|
|**2025-10-24**|**Two-Steps Diffusion Policy for Robotic Manipulation via Genetic Denoising**|Yinchuan Li Team|[2510.21991](http://arxiv.org/abs/2510.21991)|null|
|**2025-10-23**|**Butter-Bench: Evaluating LLM Controlled Robots for Practical Intelligence**|Elias Aronsson Team|[2510.21860](http://arxiv.org/abs/2510.21860)|null|
|**2025-10-21**|**VITA-E: Natural Embodied Interaction with Concurrent Seeing, Hearing, Speaking, and Acting**|Ran He Team|[2510.21817](http://arxiv.org/abs/2510.21817)|**[link](https://lxysl.github.io/VITA-E/)**|
|**2025-10-24**|**Scalable Vision-Language-Action Model Pretraining for Robotic Manipulation with Real-Life Human Activity Videos**|Baining Guo Team|[2510.21571](http://arxiv.org/abs/2510.21571)|**[link](https://microsoft.github.io/VITRA/)**|
|**2025-10-24**|**Towards Reliable Code-as-Policies: A Neuro-Symbolic Framework for Embodied Task Planning**|Honguk Woo Team|[2510.21302](http://arxiv.org/abs/2510.21302)|null|
|**2025-10-23**|**SutureBot: A Precision Framework & Benchmark For Autonomous End-to-End Suturing**|Axel Krieger Team|[2510.20965](http://arxiv.org/abs/2510.20965)|null|
|**2025-10-15**|**Rethinking the Simulation vs. Rendering Dichotomy: No Free Lunch in Spatial World Modelling**|Hokin Deng Team|[2510.20835](http://arxiv.org/abs/2510.20835)|null|
|**2025-10-23**|**VAMOS: A Hierarchical Vision-Language-Action Model for Capability-Modulated and Steerable Navigation**|Abhishek Gupta Team|[2510.20818](http://arxiv.org/abs/2510.20818)|null|
|**2025-10-23**|**C-NAV: Towards Self-Evolving Continual Object Navigation in Open World**|Jing Liu Team|[2510.20685](http://arxiv.org/abs/2510.20685)|null|
|**2025-10-23**|**EmbodiedBrain: Expanding Performance Boundaries of Task Planning for Embodied Intelligence**|Yurui Zhu Team|[2510.20578](http://arxiv.org/abs/2510.20578)|null|
|**2025-10-23**|**GhostEI-Bench: Do Mobile Agents Resilience to Environmental Injection in Dynamic On-Device Environments?**|Yingchun Wang Team|[2510.20333](http://arxiv.org/abs/2510.20333)|null|
|**2025-10-23**|**MemER: Scaling Up Memory for Robot Control via Experience Retrieval**|Chelsea Finn Team|[2510.20328](http://arxiv.org/abs/2510.20328)|**[link](https://jen-pan.github.io/memer/)**|
|**2025-10-22**|**Seed3D 1.0: From Images to High-Fidelity Simulation-Ready 3D Assets**|Xuanmeng Zhang Team|[2510.19944](http://arxiv.org/abs/2510.19944)|**[link](https://seed.bytedance.com/seed3d)**|
|**2025-10-22**|**Learning Affordances at Inference-Time for Vision-Language-Action Models**|Sergey Levine Team|[2510.19752](http://arxiv.org/abs/2510.19752)|null|
|**2025-10-22**|**Memo: Training Memory-Efficient Embodied Agents with Reinforcement Learning**|Rahaf Aljundi Team|[2510.19732](http://arxiv.org/abs/2510.19732)|null|
|**2025-10-22**|**GigaBrain-0: A World Model-Powered Vision-Language-Action Model**|Zheng Zhu Team|[2510.19430](http://arxiv.org/abs/2510.19430)|**[link](https://gigabrain0.github.io/)**|
|**2025-10-22**|**Seeing Across Views: Benchmarking Spatial Reasoning of Vision-Language Models in Robotic Scenes**|Baining Guo Team|[2510.19400](http://arxiv.org/abs/2510.19400)|**[link](https://github.com/microsoft/MV-RoboBench)**|
|**2025-10-21**|**EfficientNav: Towards On-Device Object-Goal Navigation with Navigation Map Caching and Retrieval**|Meng Li Team|[2510.18546](http://arxiv.org/abs/2510.18546)|null|
|**2025-10-21**|**MoTVLA: A Vision-Language-Action Model with Unified Fast-Slow Reasoning**|Heng Yang Team|[2510.18337](http://arxiv.org/abs/2510.18337)|null|
|**2025-10-20**|**World-in-World: World Models in a Closed-Loop World**|Jieneng Chen Team|[2510.18135](http://arxiv.org/abs/2510.18135)|**[link](https://github.com/World-In-World/world-in-world)**|
|**2025-10-20**|**RESample: A Robust Data Augmentation Framework via Exploratory Sampling for Robotic Manipulation**|Ziwei Wang Team|[2510.17640](http://arxiv.org/abs/2510.17640)|null|
|**2025-10-20**|**From Spatial to Actions: Grounding Vision-Language-Action Model in Spatial Foundation Priors**|Pan Zhou Team|[2510.17439](http://arxiv.org/abs/2510.17439)|**[link](https://falcon-vla.github.io/)**|
|**2025-10-20**|**Bridging Embodiment Gaps: Deploying Vision-Language-Action Models on Soft Robots**|Josie Hughes Team|[2510.17369](http://arxiv.org/abs/2510.17369)|null|
|**2025-10-20**|**DiffVLA++: Bridging Cognitive Reasoning and End-to-End Driving through Metric-Guided Alignment**|Sun Hao Team|[2510.17148](http://arxiv.org/abs/2510.17148)|null|
|**2025-10-20**|**Semantic Intelligence: A Bio-Inspired Cognitive Framework for Embodied Agents**|Yang Liu Team|[2510.17129](http://arxiv.org/abs/2510.17129)|null|
|**2025-10-20**|**Efficient Vision-Language-Action Models for Embodied Manipulation: A Systematic Survey**|Jian Cheng Team|[2510.17111](http://arxiv.org/abs/2510.17111)|null|
|**2025-10-20**|**Consistent Zero-Shot Imitation with Contrastive Goal Inference**|Benjamin Eysenbach Team|[2510.17059](http://arxiv.org/abs/2510.17059)|null|
|**2025-10-19**|**A Comprehensive Survey on World Models for Embodied AI**|Yun Liu Team|[2510.16732](http://arxiv.org/abs/2510.16732)|**[link](https://github.com/Li-Zn-H/AwesomeWorldModels)**|
|**2025-10-18**|**MoS-VLA: A Vision-Language-Action Model with One-Shot Skill Adaptation**|Ufuk Topcu Team|[2510.16617](http://arxiv.org/abs/2510.16617)|null|
|**2025-10-18**|**Do What You Say: Steering Vision-Language-Action Models via Runtime Reasoning-Action Alignment Verification**|Claudia P'erez-D'Arpino Team|[2510.16281](http://arxiv.org/abs/2510.16281)|null|
|**2025-10-17**|**NEBULA: Do We Evaluate Vision-Language-Action Agents Correctly?**|Yu Yin Team|[2510.16263](http://arxiv.org/abs/2510.16263)|**[link](https://vulab-ai.github.io/NEBULA-Alpha/)**|
|**2025-10-17**|**Cosmos-Surg-dVRK: World Foundation Model-based Automated Online Evaluation of Surgical Robot Policy Learning**|Sean Huver Team|[2510.16240](http://arxiv.org/abs/2510.16240)|null|
|**2025-10-11**|**ESCA: Contextualizing Embodied Agents via Scene-Graph Generation**|Mayur Naik Team|[2510.15963](http://arxiv.org/abs/2510.15963)|null|
|**2025-10-17**|**VDRive: Leveraging Reinforced VLA and Diffusion Policy for End-to-end Autonomous Driving**|Zufeng Zhang Team|[2510.15446](http://arxiv.org/abs/2510.15446)|null|
|**2025-10-16**|**Generalized Dynamics Generation towards Scannable Physical World Model**|Antonio Torralba Team|[2510.15041](http://arxiv.org/abs/2510.15041)|null|
|**2025-10-16**|**UrbanVerse: Scaling Urban Simulation by Watching City-Tour Videos**|Bolei Zhou Team|[2510.15018](http://arxiv.org/abs/2510.15018)|**[link](https://urbanverseproject.github.io/)**|
|**2025-10-16**|**RDD: Retrieval-Based Demonstration Decomposer for Planner Alignment in Long-Horizon Tasks**|Jiachen Li Team|[2510.14968](http://arxiv.org/abs/2510.14968)|null|
|**2025-10-16**|**From Language to Locomotion: Retargeting-free Humanoid Control via Motion Latent Guidance**|Chang Xu Team|[2510.14952](http://arxiv.org/abs/2510.14952)|null|
|**2025-10-16**|**VLA^2: Empowering Vision-Language-Action Models with an Agentic Framework for Unseen Concept Manipulation**|Donglin Wang Team|[2510.14902](http://arxiv.org/abs/2510.14902)|null|
|**2025-10-16**|**QDepth-VLA: Quantized Depth Prediction as Auxiliary Supervision for Vision-Language-Action Models**|Haoran Li Team|[2510.14836](http://arxiv.org/abs/2510.14836)|null|
|**2025-10-16**|**RoboGPT-R1: Enhancing Robot Planning with Reinforcement Learning**|Haoran Li Team|[2510.14828](http://arxiv.org/abs/2510.14828)|null|
|**2025-10-16**|**Expertise need not monopolize: Action-Specialized Mixture of Experts for Vision-Language-Action Learning**|Yao Mu Team|[2510.14300](http://arxiv.org/abs/2510.14300)|null|
|**2025-10-15**|**InternVLA-M1: A Spatially Guided Vision-Language-Action Framework for Generalist Robot Policy**|Yangkun Zhu Team|[2510.13778](http://arxiv.org/abs/2510.13778)|null|
|**2025-10-15**|**LIBERO-Plus: In-depth Robustness Analysis of Vision-Language-Action Models**|Xipeng Qiu Team|[2510.13626](http://arxiv.org/abs/2510.13626)|null|
|**2025-10-15**|**DepthVLA: Enhancing Vision-Language-Action Models with Depth-Aware Spatial Reasoning**|Hang Zhao Team|[2510.13375](http://arxiv.org/abs/2510.13375)|null|
|**2025-10-15**|**Model-agnostic Adversarial Attack and Defense for Vision-Language-Action Models**|Jingfeng Zhang Team|[2510.13237](http://arxiv.org/abs/2510.13237)|null|
|**2025-10-15**|**VLA-0: Building State-of-the-Art VLAs with Zero Modification**|Fabio Ramos Team|[2510.13054](http://arxiv.org/abs/2510.13054)|null|
|**2025-10-14**|**SVAG-Bench: A Large-Scale Benchmark for Multi-Instance Spatio-temporal Video Action Grounding**|Thomas Seidl Team|[2510.13016](http://arxiv.org/abs/2510.13016)|null|
|**2025-10-14**|**SENTINEL: A Multi-Level Formal Framework for Safety Evaluation of LLM-based Embodied Agents**|Qi Zhu Team|[2510.12985](http://arxiv.org/abs/2510.12985)|null|
|**2025-10-14**|**DriveVLA-W0: World Models Amplify Data Scaling Law in Autonomous Driving**|Zhaoxiang Zhang Team|[2510.12796](http://arxiv.org/abs/2510.12796)|null|
|**2025-10-14**|**SPORTS: Simultaneous Panoptic Odometry, Rendering, Tracking and Segmentation for Urban Scenes Understanding**|Zhu Yang Team|[2510.12749](http://arxiv.org/abs/2510.12749)|null|
|**2025-10-14**|**Reflection-Based Task Adaptation for Self-Improving VLA**|Hongbin Zha Team|[2510.12710](http://arxiv.org/abs/2510.12710)|null|
|**2025-10-14**|**ERA: Transforming VLMs into Embodied Agents via Embodied Prior Learning and Online Reinforcement Learning**|Tong Zhang Team|[2510.12693](http://arxiv.org/abs/2510.12693)|null|
|**2025-10-14**|**Spatial Forcing: Implicit Spatial Representation Alignment for Vision-language-action Model**|Haoang Li Team|[2510.12276](http://arxiv.org/abs/2510.12276)|null|
|**2025-10-14**|**IL3D: A Large-Scale Indoor Layout Dataset for LLM-Driven 3D Scene Generation**|Pengbo Hu Team|[2510.12095](http://arxiv.org/abs/2510.12095)|null|
|**2025-10-14**|**EmboMatrix: A Scalable Training-Ground for Embodied Decision-Making**|Siheng Chen Team|[2510.12072](http://arxiv.org/abs/2510.12072)|null|
|**2025-10-13**|**Beyond 'Templates': Category-Agnostic Object Pose, Size, and Shape Estimation from a Single View**|Yanwei Fu Team|[2510.11687](http://arxiv.org/abs/2510.11687)|null|
|**2025-10-13**|**ManiAgent: An Agentic Framework for General Robotic Manipulation**|Xudong Liu Team|[2510.11660](http://arxiv.org/abs/2510.11660)|null|
|**2025-10-13**|**FOSSIL: Harnessing Feedback on Suboptimal Samples for Data-Efficient Generalisation with Imitation Learning for Embodied Vision-and-Language Tasks**|Alessandro Suglia Team|[2510.11307](http://arxiv.org/abs/2510.11307)|null|
|**2025-10-13**|**Vlaser: Vision-Language-Action Model with Synergistic Embodied Reasoning**|Zhi Hou Team|[2510.11027](http://arxiv.org/abs/2510.11027)|null|
|**2025-10-13**|**RoVer: Robot Reward Model as Test-Time Verifier for Vision-Language-Action Model**|Xinyu Wu Team|[2510.10975](http://arxiv.org/abs/2510.10975)|null|
|**2025-10-13**|**TabVLA: Targeted Backdoor Attacks on Vision-Language-Action Models**|Yu-Gang Jiang Team|[2510.10932](http://arxiv.org/abs/2510.10932)|null|
|**2025-10-12**|**The Irrational Machine: Neurosis and the Limits of Algorithmic Safety**|Daniel Howard Team|[2510.10823](http://arxiv.org/abs/2510.10823)|null|
|**2025-10-11**|**X-VLA: Soft-Prompted Transformer as Scalable Cross-Embodiment Vision-Language-Action Model**|Xianyuan Zhan Team|[2510.10274](http://arxiv.org/abs/2510.10274)|null|
|**2025-10-11**|**Dejavu: Towards Experience Feedback Learning for Embodied Intelligence**|Hongtao Lu Team|[2510.10181](http://arxiv.org/abs/2510.10181)|null|
|**2025-10-11**|**Reinforcement Fine-Tuning of Flow-Matching Policies for Vision-Language-Action Models**|Yi Zeng Team|[2510.09976](http://arxiv.org/abs/2510.09976)|null|
|**2025-10-08**|**OmniSAT: Compact Action Token, Faster Auto Regression**|Changsheng Xu Team|[2510.09667](http://arxiv.org/abs/2510.09667)|null|
|**2025-10-10**|**VITA-VLA: Efficiently Teaching Vision-Language Models to Act via Action Expert Distillation**|Caifeng Shan Team|[2510.09607](http://arxiv.org/abs/2510.09607)|**[link](https://ltbai.github.io/VITA-VLA/)**|
|**2025-10-10**|**TC-LoRA: Temporally Modulated Conditional LoRA for Adaptive Diffusion Control**|Ethem Can Team|[2510.09561](http://arxiv.org/abs/2510.09561)|null|
|**2025-10-10**|**PhysToolBench: Benchmarking Physical Tool Understanding for MLLMs**|Ying-Cong Chen Team|[2510.09507](http://arxiv.org/abs/2510.09507)|null|
|**2025-10-10**|**FOGMACHINE -- Leveraging Discrete-Event Simulation and Scene Graphs for Modeling Hierarchical, Interconnected Environments under Partial Observations from Mobile Agents**|Kai Furmans Team|[2510.09483](http://arxiv.org/abs/2510.09483)|null|
|**2025-10-10**|**Goal-oriented Backdoor Attack against Vision-Language-Action Models via Physical Objects**|Jingfeng Zhang Team|[2510.09269](http://arxiv.org/abs/2510.09269)|null|
|**2025-10-09**|**BEAR: Benchmarking and Enhancing Multimodal Language Models for Atomic Embodied Capabilities**|Lawson L. S. Wong Team|[2510.08759](http://arxiv.org/abs/2510.08759)|null|
|**2025-10-09**|**Unified World Models: Memory-Augmented Planning and Foresight for Visual Navigation**|Alexander G Hauptmann Team|[2510.08713](http://arxiv.org/abs/2510.08713)|**[link](https://github.com/F1y1113/UniWM)**|
|**2025-10-09**|**Don't Run with Scissors: Pruning Breaks VLA Models but They Can Be Recovered**|Shayegan Omidshafiei Team|[2510.08464](http://arxiv.org/abs/2510.08464)|null|
|**2025-10-09**|**Unlocking 3D Affordance Segmentation with 2D Semantic Knowledge**|Wei Shen Team|[2510.08316](http://arxiv.org/abs/2510.08316)|null|
|**2025-10-09**|**Practicing a Second Language Without Fear: Mixed Reality Agents for Interactive Group Conversation**|Diego Gomez-Zara Team|[2510.08227](http://arxiv.org/abs/2510.08227)|null|
|**2025-10-09**|**Executable Analytic Concepts as the Missing Link Between VLM Insight and Precise Manipulation**|Jianhua Sun Team|[2510.07975](http://arxiv.org/abs/2510.07975)|null|
|**2025-10-09**|**USIM and U0: A Vision-Language-Action Dataset and Model for General Underwater Robots**|Zhengxing Wu Team|[2510.07869](http://arxiv.org/abs/2510.07869)|**[link](https://vincentgu2000.github.io/u0project/)**|
|**2025-10-09**|**GTR-Bench: Evaluating Geo-Temporal Reasoning in Vision-Language Models**|Long Zeng Team|[2510.07791](http://arxiv.org/abs/2510.07791)|null|
|**2025-10-09**|**IntentionVLA: Generalizable and Efficient Embodied Intention Reasoning for Human-Robot Interaction**|Liqiang Nie Team|[2510.07778](http://arxiv.org/abs/2510.07778)|null|
|**2025-10-09**|**DEAS: DEtached value learning with Action Sequence for Scalable Offline RL**|Yuke Zhu Team|[2510.07730](http://arxiv.org/abs/2510.07730)|**[link](https://changyeon.site/deas)**|
|**2025-10-08**|**TrackVLA++: Unleashing Reasoning and Memory Capabilities in VLA Models for Embodied Visual Tracking**|He Wang Team|[2510.07134](http://arxiv.org/abs/2510.07134)|**[link](https://pku-epic.github.io/TrackVLA-plus-plus-Web/)**|
|**2025-10-08**|**The Contingencies of Physical Embodiment Allow for Open-Endedness and Care**|Antonio Damasio Team|[2510.07117](http://arxiv.org/abs/2510.07117)|null|
|**2025-10-08**|**Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications**|Yuke Zhu Team|[2510.07077](http://arxiv.org/abs/2510.07077)|**[link](https://vla-survey.github.io)**|
|**2025-10-08**|**Bring the Apple, Not the Sofa: Impact of Irrelevant Context in Embodied AI Commands on VLA Models**|Elena Tutubalina Team|[2510.07067](http://arxiv.org/abs/2510.07067)|null|
|**2025-10-08**|**RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training**|Yu Wang Team|[2510.06710](http://arxiv.org/abs/2510.06710)|**[link](https://github.com/RLinf/RLinf)**|
|**2025-10-07**|**EmbodiedCoder: Parameterized Embodied Mobile Manipulation via Modern Coding Model**|Zhaoxiang Zhang Team|[2510.06207](http://arxiv.org/abs/2510.06207)|**[link](https://anonymous.4open.science/w/Embodied-Coder/)**|
|**2025-10-07**|**Verifier-free Test-Time Sampling for Vision Language Action Models**|Jinwoo Shin Team|[2510.05681](http://arxiv.org/abs/2510.05681)|null|
|**2025-10-07**|**MetaVLA: Unified Meta Co-training For Efficient Embodied Adaption**|Marios Savvides Team|[2510.05580](http://arxiv.org/abs/2510.05580)|null|
|**2025-10-06**|**HyperVLA: Efficient Inference in Vision-Language-Action Models via Hypernetworks**|Shimon Whiteson Team|[2510.04898](http://arxiv.org/abs/2510.04898)|null|
|**2025-10-05**|**ContextVLA: Vision-Language-Action Model with Amortized Multi-Frame Context**|Jinwoo Shin Team|[2510.04246](http://arxiv.org/abs/2510.04246)|**[link](https://huiwon-jang.github.io/contextvla)**|
|**2025-10-05**|**SITCOM: Scaling Inference-Time COMpute for VLAs**|Esha Pahwa Team|[2510.04041](http://arxiv.org/abs/2510.04041)|null|
|**2025-10-04**|**Bridge Thinking and Acting: Unleashing Physical Potential of VLM with Generalizable Action Expert**|Chunhua Shen Team|[2510.03896](http://arxiv.org/abs/2510.03896)|null|
|**2025-10-04**|**NoTVLA: Narrowing of Dense Action Trajectories for Generalizable Robot Manipulation**|Chunhua Shen Team|[2510.03895](http://arxiv.org/abs/2510.03895)|null|
|**2025-10-04**|**LIBERO-PRO: Towards Robust and Fair Evaluation of Vision-Language-Action Models Beyond Memorization**|Lichao Sun Team|[2510.03827](http://arxiv.org/abs/2510.03827)|null|
|**2025-10-02**|**Gemini Robotics 1.5: Pushing the Frontier of Generalist Robots with Advanced Embodied Reasoning, Thinking, and Motion Transfer**|Yuxiang Zhou Team|[2510.03342](http://arxiv.org/abs/2510.03342)|null|
|**2025-10-03**|**MM-Nav: Multi-View VLA Model for Robust Visual Navigation via Multi-Expert Learning**|He Wang Team|[2510.03142](http://arxiv.org/abs/2510.03142)|**[link](https://pku-epic.github.io/MM-Nav-Web/)**|
|**2025-10-02**|**Contrastive Representation Regularization for Vision-Language-Action Models**|Jinwoo Shin Team|[2510.01711](http://arxiv.org/abs/2510.01711)|null|
|**2025-10-02**|**FailSafe: Reasoning and Recovery from Failures in Vision-Language-Action Models**|Bihan Wen Team|[2510.01642](http://arxiv.org/abs/2510.01642)|**[link](https://jimntu.github.io/FailSafe/)**|
|**2025-10-02**|**VLA-R1: Enhancing Reasoning in Vision-Language-Action Models**|Zheng Zhu Team|[2510.01623](http://arxiv.org/abs/2510.01623)|null|
|**2025-10-01**|**INSIGHT: INference-time Sequence Introspection for Generating Help Triggers in Vision-Language-Action Models**|Tesca FItzgerald Team|[2510.01389](http://arxiv.org/abs/2510.01389)|null|
|**2025-10-01**|**Compose Your Policies! Improving Diffusion-based or Flow-based Robot Policies via Test-time Distribution-level Composition**|Andrew F. Luo Team|[2510.01068](http://arxiv.org/abs/2510.01068)|**[link](https://sagecao1125.github.io/GPC-Site/)**|
|**2025-10-02**|**HAMLET: Switch your Vision-Language-Action Model into a History-Aware Policy**|Jinwoo Shin Team|[2510.00695](http://arxiv.org/abs/2510.00695)|**[link](https://myungkyukoo.github.io/hamlet/)**|
|**2025-10-01**|**Hybrid Training for Vision-Language-Action Models**|Daniel Dijkman Team|[2510.00600](http://arxiv.org/abs/2510.00600)|null|
|**2025-10-01**|**VLA-RFT: Vision-Language-Action Reinforcement Fine-tuning with Verified Rewards in World Simulators**|Weihua Su Team|[2510.00406](http://arxiv.org/abs/2510.00406)|null|
|**2025-09-30**|**MLA: A Multisensory Language-Action Model for Multimodal Understanding and Forecasting in Robotic Manipulation**|Shanghang Zhang Team|[2509.26642](http://arxiv.org/abs/2509.26642)|null|
|**2025-09-30**|**Seeing Space and Motion: Enhancing Latent Actions with Spatial and Dynamic Awareness for VLA**|Ruqi Huang Team|[2509.26251](http://arxiv.org/abs/2509.26251)|null|
|**2025-09-30**|**MUVLA: Learning to Explore Object Navigation via Map Understanding**|Jianye Hao Team|[2509.25966](http://arxiv.org/abs/2509.25966)|null|
|**2025-09-30**|**TacRefineNet: Tactile-Only Grasp Refinement Between Arbitrary In-Hand Object Poses**|Yangwei You Team|[2509.25746](http://arxiv.org/abs/2509.25746)|null|
|**2025-09-30**|**VLA Model Post-Training via Action-Chunked PPO and Self Behavior Cloning**|Zeng-Guang Hou Team|[2509.25718](http://arxiv.org/abs/2509.25718)|null|
|**2025-09-30**|**dVLA: Diffusion Vision-Language-Action Model with Multimodal Chain-of-Thought**|Yi Xu Team|[2509.25681](http://arxiv.org/abs/2509.25681)|null|
|**2025-09-29**|**AIRoA MoMa Dataset: A Large-Scale Hierarchical Dataset for Mobile Manipulation**|Tetsuya Ogata Team|[2509.25032](http://arxiv.org/abs/2509.25032)|null|
|**2025-09-29**|**World-Env: Leveraging World Model as a Virtual Environment for VLA Post-Training**|Qing Zhang Team|[2509.24948](http://arxiv.org/abs/2509.24948)|null|
|**2025-09-29**|**IA-VLA: Input Augmentation for Vision-Language-Action models in settings with semantically complex tasks**|Ville Kyrki Team|[2509.24768](http://arxiv.org/abs/2509.24768)|null|
|**2025-09-29**|**Emergent World Representations in OpenVLA**|Omar G. Younis Team|[2509.24559](http://arxiv.org/abs/2509.24559)|null|
|**2025-09-29**|**PhysiAgent: An Embodied Agent Framework in Physical World**|Xianyuan Zhan Team|[2509.24524](http://arxiv.org/abs/2509.24524)|null|
|**2025-09-28**|**AutoPrune: Each Complexity Deserves a Pruning Policy**|Zhipeng Zhang Team|[2509.23931](http://arxiv.org/abs/2509.23931)|null|
|**2025-09-28**|**Control Your Robot: A Unified System for Robot Control and Policy Deployment**|Bingshan Hu Team|[2509.23823](http://arxiv.org/abs/2509.23823)|**[link](https://github.com/Tian-Nian/control_your_robot)**|
|**2025-09-28**|**Focusing on What Matters: Object-Agent-centric Tokenization for Vision Language Action models**|Pietro Mazzaglia Team|[2509.23655](http://arxiv.org/abs/2509.23655)|null|
|**2025-09-27**|**Leave No Observation Behind: Real-time Correction for VLA Action Chunks**|Yusuke Iwasawa Team|[2509.23224](http://arxiv.org/abs/2509.23224)|null|
|**2025-09-27**|**Transferring Vision-Language-Action Models to Industry Applications: Architectures, Performance, and Challenges**|Zhibo Pang Team|[2509.23121](http://arxiv.org/abs/2509.23121)|null|
|**2025-09-26**|**VLA-Reasoner: Empowering Vision-Language-Action Models with Reasoning via Online Monte Carlo Tree Search**|Ziwei Wang Team|[2509.22643](http://arxiv.org/abs/2509.22643)|null|
|**2025-09-26**|**UnderwaterVLA: Dual-brain Vision-Language-Action architecture for Autonomous Underwater Navigation**|Dixia Fan Team|[2509.22441](http://arxiv.org/abs/2509.22441)|null|
|**2025-09-26**|**EMMA: Generalizing Real-World Robot Manipulation via Generative Visual Transfer**|Guan Huang Team|[2509.22407](http://arxiv.org/abs/2509.22407)|null|
|**2025-09-29**|**MimicDreamer: Aligning Human and Robot Demonstrations for Scalable VLA Training**|Xingang Wang Team|[2509.22199](http://arxiv.org/abs/2509.22199)|null|
|**2025-09-26**|**Actions as Language: Fine-Tuning VLMs into VLAs Without Catastrophic Forgetting**|Anirudha Majumdar Team|[2509.22195](http://arxiv.org/abs/2509.22195)|null|
|**2025-09-26**|**Action-aware Dynamic Pruning for Efficient Vision-Language-Action Manipulation**|Chang Xu Team|[2509.22093](http://arxiv.org/abs/2509.22093)|null|
|**2025-09-26**|**Developing Vision-Language-Action Model from Egocentric Videos**|Shinsuke Mori Team|[2509.21986](http://arxiv.org/abs/2509.21986)|null|
|**2025-09-20**|**KV-Efficient VLA: A Method of Speed up Vision Language Model with RNN-Gated Chunked KV Cache**|Long Zhuang Team|[2509.21354](http://arxiv.org/abs/2509.21354)|null|
|**2025-09-25**|**RetoVLA: Reusing Register Tokens for Spatial Reasoning in Vision-Language-Action Models**|Andrew Jaeyong Choi Team|[2509.21243](http://arxiv.org/abs/2509.21243)|null|
|**2025-09-24**|**Discrete Diffusion for Reflective Vision-Language-Action Models in Autonomous Driving**|Xianpeng Lang Team|[2509.20109](http://arxiv.org/abs/2509.20109)|null|
|**2025-09-24**|**FreezeVLA: Action-Freezing Attacks against Vision-Language-Action Models**|Yu-Gang Jiang Team|[2509.19870](http://arxiv.org/abs/2509.19870)|null|
|**2025-09-24**|**Beyond Human Demonstrations: Diffusion-Based Reinforcement Learning to Generate Data for VLA Training**|Yi Chen Team|[2509.19752](http://arxiv.org/abs/2509.19752)|null|
|**2025-09-23**|**Agentic Scene Policies: Unifying Space, Semantics, and Affordances for Robot Action**|Liam Paull Team|[2509.19571](http://arxiv.org/abs/2509.19571)|**[link](https://montrealrobotics.ca/agentic-scene-policies.github.io/)**|
|**2025-09-23**|**OmniVLA: An Omni-Modal Vision-Language-Action Model for Robot Navigation**|Sergey Levine Team|[2509.19480](http://arxiv.org/abs/2509.19480)|null|
|**2025-09-25**|**Pure Vision Language Action (VLA) Models: A Comprehensive Survey**|Qingguo Zhou Team|[2509.19012](http://arxiv.org/abs/2509.19012)|null|
|**2025-09-23**|**Eva-VLA: Evaluating Vision-Language-Action Models' Robustness Under Real-World Physical Variations**|Wen Yao Team|[2509.18953](http://arxiv.org/abs/2509.18953)|null|
|**2025-09-22**|**Latent Action Pretraining Through World Modeling**|Ian Reid Team|[2509.18428](http://arxiv.org/abs/2509.18428)|null|
|**2025-09-18**|**VLA-LPAF: Lightweight Perspective-Adaptive Fusion for Vision-Language-Action to Enable More Unconstrained Robotic Manipulation**|Anzhou Hou Team|[2509.18183](http://arxiv.org/abs/2509.18183)|null|
|**2025-09-19**|**CoReVLA: A Dual-Stage End-to-End Autonomous Driving Framework for Long-Tail Scenarios via Collect-and-Refine**|Jian Sun Team|[2509.15968](http://arxiv.org/abs/2509.15968)|null|
|**2025-09-19**|**A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning**|Jiangmiao Pang Team|[2509.15937](http://arxiv.org/abs/2509.15937)|null|
|**2025-09-18**|**RynnVLA-001: Using Human Demonstrations to Improve Robot Manipulation**|Xin Li Team|[2509.15212](http://arxiv.org/abs/2509.15212)|**[link](https://github.com/alibaba-damo-academy/RynnVLA-001)**|
|**2025-09-18**|**Robot Control Stack: A Lean Ecosystem for Robot Learning at Scale**|Florian Walter Team|[2509.14932](http://arxiv.org/abs/2509.14932)|null|
|**2025-09-18**|**CollabVLA: Self-Reflective Vision-Language-Action Model Dreaming Together with Human**|Huaping Liu Team|[2509.14889](http://arxiv.org/abs/2509.14889)|null|
|**2025-09-18**|**RealMirror: A Comprehensive, Open-Source Vision-Language-Action Platform for Embodied AI**|Tao Shen Team|[2509.14687](http://arxiv.org/abs/2509.14687)|null|
|**2025-09-18**|**Toward Embodiment Equivariant Vision-Language-Action Policy**|Yue Wang Team|[2509.14630](http://arxiv.org/abs/2509.14630)|null|
|**2025-09-17**|**CLAW: A Vision-Language-Action Framework for Weight-Aware Robotic Grasping**|Lifeng Zhou Team|[2509.14143](http://arxiv.org/abs/2509.14143)|null|
|**2025-09-17**|**SeqVLA: Sequential Task Execution for Long-Horizon Manipulation with Completion-Aware Vision-Language-Action Model**|Yiming Feng Team|[2509.14138](http://arxiv.org/abs/2509.14138)|null|
|**2025-09-22**|**GeoAware-VLA: Implicit Geometry Aware Vision-Language-Action Model**|Dezhen Song Team|[2509.14117](http://arxiv.org/abs/2509.14117)|null|
|**2025-09-17**|**Dual-Actor Fine-Tuning of VLA Models: A Talk-and-Tweak Human-in-the-Loop Approach**|Yangwei You Team|[2509.13774](http://arxiv.org/abs/2509.13774)|null|
|**2025-09-17**|**AdaThinkDrive: Adaptive Thinking via Reinforcement Learning for Autonomous Driving**|Zhi-xin Yang Team|[2509.13769](http://arxiv.org/abs/2509.13769)|null|
|**2025-09-13**|**OpenHA: A Series of Open-Source Hierarchical Agentic Models in Minecraft**|Yitao Liang Team|[2509.13347](http://arxiv.org/abs/2509.13347)|null|
|**2025-09-21**|**The Better You Learn, The Smarter You Prune: Towards Efficient Vision-language-action Models via Differentiable Token Pruning**|Xianpeng Lang Team|[2509.12594](http://arxiv.org/abs/2509.12594)|**[link](https://liauto-research.github.io/LightVLA)**|
|**2025-09-17**|**TrajBooster: Boosting Humanoid Whole-Body Manipulation via Trajectory-Centric Learning**|Donglin Wang Team|[2509.11839](http://arxiv.org/abs/2509.11839)|null|
|**2025-09-15**|**Cross-Platform Scaling of Vision-Language-Action Models from Edge to Cloud GPUs**|Yanzhi Wang Team|[2509.11480](http://arxiv.org/abs/2509.11480)|null|
|**2025-09-17**|**Enhancing Generalization in Vision-Language-Action Models by Preserving Pretrained Representations**|Xuanlin Li Team|[2509.11417](http://arxiv.org/abs/2509.11417)|**[link](https://gen-vla.github.io/)**|
|**2025-09-11**|**SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning**|Ning Ding Team|[2509.09674](http://arxiv.org/abs/2509.09674)|null|
|**2025-09-22**|**VLA-Adapter: An Effective Paradigm for Tiny-Scale Vision-Language-Action Model**|Donglin Wang Team|[2509.09372](http://arxiv.org/abs/2509.09372)|**[link](https://vla-adapter.github.io/)**|
|**2025-09-11**|**SQAP-VLA: A Synergistic Quantization-Aware Pruning Framework for High-Performance Vision-Language-Action Models**|Huanrui Yang Team|[2509.09090](http://arxiv.org/abs/2509.09090)|null|
|**2025-09-10**|**RoboChemist: Long-Horizon and Safety-Compliant Robotic Chemical Experimentation**|Hao Zhao Team|[2509.08820](http://arxiv.org/abs/2509.08820)|**[link](https://zzongzheng0918.github.io/RoboChemist.github.io/)**|
|**2025-09-09**|**TA-VLA: Elucidating the Design Space of Torque-aware Vision-Language-Action Models**|Hao Zhao Team|[2509.07962](http://arxiv.org/abs/2509.07962)|**[link](https://zzongzheng0918.github.io/Torque-Aware-VLA.github.io/})**|
|**2025-09-09**|**Graph-Fused Vision-Language-Action for Policy Reasoning in Multi-Arm Robotic Manipulation**|Yingbai Hu Team|[2509.07957](http://arxiv.org/abs/2509.07957)|null|
|**2025-09-09**|**F1: A Vision-Language-Action Model Bridging Understanding and Generation to Actions**|Jiangmiao Pang Team|[2509.06951](http://arxiv.org/abs/2509.06951)|**[link](https://aopolin-lv.github.io/F1-VLA/)**|
|**2025-09-11**|**LLaDA-VLA: Vision Language Diffusion Action Models**|Xiaoyan Sun Team|[2509.06932](http://arxiv.org/abs/2509.06932)|null|
|**2025-09-08**|**CRISP -- Compliant ROS2 Controllers for Learning-Based Manipulation Policies and Teleoperation**|Angela P. Schöllig Team|[2509.06819](http://arxiv.org/abs/2509.06819)|null|
|**2025-09-09**|**Leveraging Vision-Language Large Models for Interpretable Video Action Recognition with Semantic Tokenization**|Surasakdi Siripong Team|[2509.05695](http://arxiv.org/abs/2509.05695)|null|
|**2025-09-06**|**SpecPrune-VLA: Accelerating Vision-Language-Action Models via Action-Aware Self-Speculative Pruning**|Guohao Dai Team|[2509.05614](http://arxiv.org/abs/2509.05614)|null|
|**2025-09-06**|**OccVLA: Vision-Language-Action Model with Implicit 3D Occupancy Supervision**|Hang Zhao Team|[2509.05578](http://arxiv.org/abs/2509.05578)|null|
|**2025-09-05**|**OpenEgo: A Large-Scale Multimodal Egocentric Dataset for Dexterous Manipulation**|Yu Xiang Team|[2509.05513](http://arxiv.org/abs/2509.05513)|null|
|**2025-09-05**|**FLOWER: Democratizing Generalist Robot Policies with Efficient Vision-Language-Action Flow Policies**|Rudolf Lioutikov Team|[2509.04996](http://arxiv.org/abs/2509.04996)|null|
|**2025-09-04**|**Balancing Signal and Variance: Adaptive Offline RL Post-Training for VLA Flow Models**|Donglin Wang Team|[2509.04063](http://arxiv.org/abs/2509.04063)|null|
|**2025-09-04**|**FPC-VLA: A Vision-Language-Action Framework with a Supervisor for Failure Prediction and Correction**|Jingtai Liu Team|[2509.04018](http://arxiv.org/abs/2509.04018)|null|
|**2025-09-03**|**ANNIE: Be Careful of Your Robots**|Yiming Gan Team|[2509.03383](http://arxiv.org/abs/2509.03383)|null|
|**2025-09-05**|**Align-Then-stEer: Adapting the Vision-Language Action Models through Unified Latent Guidance**|Xuelong Li Team|[2509.02055](http://arxiv.org/abs/2509.02055)|null|
|**2025-09-02**|**AutoDrive-R $^2$ : Incentivizing Reasoning and Self-Reflection Capacity for VLA Model in Autonomous Driving**|Shuo Li Team|[2509.01944](http://arxiv.org/abs/2509.01944)|null|
|**2025-08-31**|**OmniReason: A Temporal-Guided Vision-Language-Action Framework for Autonomous Driving**|Jun Ma Team|[2509.00789](http://arxiv.org/abs/2509.00789)|null|
|**2025-08-30**|**Galaxea Open-World Dataset and G0 Dual-System VLA Model**|Hang Zhao Team|[2509.00576](http://arxiv.org/abs/2509.00576)|**[link](https://opengalaxea.github.io/G0/)**|
|**2025-08-30**|**Mechanistic interpretability for steering vision-language-action models**|Claire Tomlin Team|[2509.00328](http://arxiv.org/abs/2509.00328)|**[link](https://vla-mech-interp.github.io/)**|
|**2025-09-09**|**EmbodiedOneVision: Interleaved Vision-Text-Action Pretraining for General Robot Control**|Dong Wang Team|[2508.21112](http://arxiv.org/abs/2508.21112)|null|
|**2025-10-02**|**CogVLA: Cognition-Aligned Vision-Language-Action Model via Instruction-Driven Routing & Sparsification**|Liqiang Nie Team|[2508.21046](http://arxiv.org/abs/2508.21046)|**[link](https://jiutian-vl.github.io/CogVLA-page)**|
|**2025-08-27**|**Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding in Vision-Language-Action Policies**|Ping Luo Team|[2508.20072](http://arxiv.org/abs/2508.20072)|null|
|**2025-08-28**|**Long-VLA: Unleashing Long-Horizon Capability of Vision Language Action Model for Robot Manipulation**|Donglin Wang Team|[2508.19958](http://arxiv.org/abs/2508.19958)|**[link](https://long-vla.github.io)**|
|**2025-08-28**|**Ego-centric Predictive Model Conditioned on Hand Trajectories**|Mike Zheng Shou Team|[2508.19852](http://arxiv.org/abs/2508.19852)|null|
|**2025-08-15**|**TTF-VLA: Temporal Token Fusion via Pixel-Attention Integration for Vision-Language-Action Models**|Huiling Duan Team|[2508.19257](http://arxiv.org/abs/2508.19257)|null|
|**2025-08-26**|**MemoryVLA: Perceptual-Cognitive Memory in Vision-Language-Action Models for Robotic Manipulation**|Gao Huang Team|[2508.19236](http://arxiv.org/abs/2508.19236)|**[link](https://shihao1895.github.io/MemoryVLA)**|
|**2025-08-26**|**FlowVLA: Thinking in Motion with a Visual Chain of Thought**|Haoang Li Team|[2508.18269](http://arxiv.org/abs/2508.18269)|null|
|**2025-09-06**|**4D Visual Pre-training for Robot Learning**|Huazhe Xu Team|[2508.17230](http://arxiv.org/abs/2508.17230)|null|
|**2025-08-23**|**NinA: Normalizing Flows in Action. Training VLA Models with Normalizing Flows**|Vladislav Kurenkov Team|[2508.16845](http://arxiv.org/abs/2508.16845)|null|
|**2025-08-22**|**Do What? Teaching Vision-Language-Action Models to Reject the Impossible**|David M. Chan Team|[2508.16292](http://arxiv.org/abs/2508.16292)|null|
|**2025-11-13**|**Survey of Vision-Language-Action Models for Embodied Manipulation**|Dongbin Zhao Team|[2508.15201](http://arxiv.org/abs/2508.15201)|null|
|**2025-08-19**|**CAST: Counterfactual Labels Improve Instruction Following in Vision-Language-Action Models**|Sergey Levine Team|[2508.13446](http://arxiv.org/abs/2508.13446)|null|
|**2025-08-18**|**Grounding Actions in Camera Space: Observation-Centric Vision-Language-Action Policy**|Zhi Hou Team|[2508.13103](http://arxiv.org/abs/2508.13103)|null|
|**2025-09-01**|**Large VLM-based Vision-Language-Action Models for Robotic Manipulation: A Survey**|Liqiang Nie Team|[2508.13073](http://arxiv.org/abs/2508.13073)|**[link](https://github.com/JiuTian-VL/Large-VLM-based-VLA-for-Robotic-Manipulation)**|
|**2025-08-17**|**Improving Pre-Trained Vision-Language-Action Policies with Model-Based Search**|Glen Berseth Team|[2508.12211](http://arxiv.org/abs/2508.12211)|null|
|**2025-08-16**|**Toward General Physical Intelligence for Resilient Agile Manufacturing Automation**|Sunny Katyara Team|[2508.11960](http://arxiv.org/abs/2508.11960)|null|
|**2025-08-14**|**CorrectNav: Self-Correction Flywheel Empowers Vision-Language-Action Navigation Model**|Hao Dong Team|[2508.10416](http://arxiv.org/abs/2508.10416)|null|
|**2025-08-14**|**Large Model Empowered Embodied AI: A Survey on Decision-Making and Embodied Learning**|Ping Kuang Team|[2508.10399](http://arxiv.org/abs/2508.10399)|null|
|**2025-08-14**|**ReconVLA: Reconstructive Vision-Language-Action Model as Effective Robot Perceiver**|Haoang Li Team|[2508.10333](http://arxiv.org/abs/2508.10333)|null|
|**2025-08-13**|**GeoVLA: Empowering 3D Representations in Vision-Language-Action Models**|Jiale Cao Team|[2508.09071](http://arxiv.org/abs/2508.09071)|**[link](https://linsun449.github.io/GeoVLA/)**|
|**2025-08-12**|**Spatial Traces: Enhancing VLA Models with Spatial-Temporal Understanding**|Aleksandr I. Panov Team|[2508.09032](http://arxiv.org/abs/2508.09032)|null|
|**2025-08-22**|**OmniVTLA: Vision-Tactile-Language-Action Model with Semantic-Aligned Tactile Sensing**|Hengdi Zhang Team|[2508.08706](http://arxiv.org/abs/2508.08706)|**[link](https://readerek.github.io/Objtac.github.io)**|
|**2025-08-14**|**Reinforcement Learning in Vision: A Survey**|Mike Zheng Shou Team|[2508.08189](http://arxiv.org/abs/2508.08189)|null|
|**2025-08-12**|**MolmoAct: Action Reasoning Models that can Reason in Space**|Ranjay Krishna Team|[2508.07917](http://arxiv.org/abs/2508.07917)|**[link](https://allenai.org/blog/molmoact)**|
|**2025-08-13**|**AgentWorld: An Interactive Simulation Platform for Scene Construction and Mobile Robotic Manipulation**|Lei Han Team|[2508.07770](http://arxiv.org/abs/2508.07770)|null|
|**2025-08-23**|**GraphCoT-VLA: A 3D Spatial-Aware Reasoning Vision-Language-Action Model for Robotic Manipulation with Ambiguous Instructions**|Hong Zhang Team|[2508.07650](http://arxiv.org/abs/2508.07650)|null|
|**2025-08-15**|**IRL-VLA: Training an Vision-Language-Action Policy via Reward World Model**|Li Sun Team|[2508.06571](http://arxiv.org/abs/2508.06571)|null|
|**2025-08-06**|**Static and Plugged: Make Embodied Evaluation Simple**|Guangtao Zhai Team|[2508.06553](http://arxiv.org/abs/2508.06553)|null|
|**2025-08-06**|**A tutorial note on collecting simulated data for vision-language-action models**|Jingfeng Zhang Team|[2508.06547](http://arxiv.org/abs/2508.06547)|null|
|**2025-08-07**|**Information-Theoretic Graph Fusion with Vision-Language-Action Model for Policy Reasoning and Dual Robotic Control**|Hamid Reza Karimi Team|[2508.05342](http://arxiv.org/abs/2508.05342)|null|
|**2025-08-14**|**Towards Embodied Agentic AI: Review and Classification of LLM- and VLM-Driven Robot Autonomy and Interaction**|Jorge Peña Queralta Team|[2508.05294](http://arxiv.org/abs/2508.05294)|null|
|**2025-08-07**|**Learning to See and Act: Task-Aware View Planning for Robotic Manipulation**|Liang Lin Team|[2508.05186](http://arxiv.org/abs/2508.05186)|**[link](https://hcplab-sysu.github.io/TAVP)**|
|**2025-08-06**|**Perceiving and Acting in First-Person: A Dataset and Benchmark for Egocentric Human-Object-Human Interactions**|Xiaokang Yang Team|[2508.04681](http://arxiv.org/abs/2508.04681)|**[link](https://liangxuy.github.io/InterVLA/)**|
|**2025-08-06**|**Following Route Instructions using Large Vision-Language Models: A Comparison between Low-level and Panoramic Action Spaces**|Pierre Lison Team|[2508.02917](http://arxiv.org/abs/2508.02917)|null|
|**2025-08-04**|**MonoDream: Monocular Vision-Language Navigation with Panoramic Dreaming**|Zhaoxin Fan Team|[2508.02549](http://arxiv.org/abs/2508.02549)|null|
|**2025-08-04**|**CO-RFT: Efficient Fine-Tuning of Vision-Language-Action Models through Chunked Offline Reinforcement Learning**|Chunhe Xia Team|[2508.02219](http://arxiv.org/abs/2508.02219)|null|
|**2025-08-04**|**FedVLA: Federated Vision-Language-Action Learning with Dual Gating Mixture-of-Experts for Robotic Manipulation**|Xiaodong Wang Team|[2508.02190](http://arxiv.org/abs/2508.02190)|null|
|**2025-08-04**|**RICL: Adding In-Context Adaptability to Pre-Trained Vision-Language-Action Models**|Insup Lee Team|[2508.02062](http://arxiv.org/abs/2508.02062)|null|
|**2025-07-31**|**XRoboToolkit: A Cross-Platform Framework for Robot Teleoperation**|Ning Yang Team|[2508.00097](http://arxiv.org/abs/2508.00097)|**[link](https://github.com/XR-Robotics)**|
|**2025-07-31**|**villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models**|Jiang Bian Team|[2507.23682](http://arxiv.org/abs/2507.23682)|**[link](https://aka.ms/villa-x)**|
|**2025-07-31**|**A Unified Perception-Language-Action Framework for Adaptive Autonomous Driving**|Alois Knoll Team|[2507.23540](http://arxiv.org/abs/2507.23540)|null|
|**2025-08-02**|**FastDriveVLA: Efficient End-to-End Driving via Plug-and-Play Reconstruction-based Token Pruning**|Shanghang Zhang Team|[2507.23318](http://arxiv.org/abs/2507.23318)|null|
|**2025-07-30**|**Spec-VLA: Speculative Decoding for Vision-Language-Action Models with Relaxed Acceptance**|Derek F. Wong Team|[2507.22424](http://arxiv.org/abs/2507.22424)|null|
|**2025-07-23**|**InstructVLA: Vision-Language-Action Instruction Tuning from Understanding to Manipulation**|Jiangmiao Pang Team|[2507.17520](http://arxiv.org/abs/2507.17520)|null|
|**2025-07-23**|**ERMV: Editing 4D Robotic Multi-view images to enhance embodied agents**|Hesheng Wang Team|[2507.17462](http://arxiv.org/abs/2507.17462)|null|
|**2025-07-23**|**Confidence Calibration in Vision-Language-Action Models**|Richard Zemel Team|[2507.17383](http://arxiv.org/abs/2507.17383)|null|
|**2025-07-29**|**VLA-Touch: Enhancing Vision-Language-Action Models with Dual-Level Tactile Feedback**|Harold Soh Team|[2507.17294](http://arxiv.org/abs/2507.17294)|null|
|**2025-07-22**|**ThinkAct: Vision-Language-Action Reasoning via Reinforced Visual Latent Planning**|Fu-En Yang Team|[2507.16815](http://arxiv.org/abs/2507.16815)|**[link](https://jasper0314-huang.github.io/thinkact-vla/)**|
|**2025-07-21**|**Being-H0: Vision-Language-Action Pretraining from Large-Scale Human Videos**|Zongqing Lu Team|[2507.15597](http://arxiv.org/abs/2507.15597)|null|
|**2025-07-22**|**GR-3 Technical Report**|Yichu Yang Team|[2507.15493](http://arxiv.org/abs/2507.15493)|**[link](https://seed.bytedance.com/GR3/)**|
|**2025-07-18**|**EdgeVLA: Efficient Vision-Language-Action Models**|Benjamin Bolte Team|[2507.14049](http://arxiv.org/abs/2507.14049)|null|
|**2025-07-23**|**LaViPlan : Language-Guided Visual Path Planning with RLVR**|Hayeon Oh Team|[2507.12911](http://arxiv.org/abs/2507.12911)|null|
|**2025-07-17**|**AnyPos: Automated Task-Agnostic Actions for Bimanual Manipulation**|Jun Zhu Team|[2507.12768](http://arxiv.org/abs/2507.12768)|null|
|**2025-07-18**|**EgoVLA: Learning Vision-Language-Action Models from Egocentric Human Videos**|Xiaolong Wang Team|[2507.12440](http://arxiv.org/abs/2507.12440)|**[link](https://rchalyang.github.io/EgoVLA)**|
|**2025-07-14**|**Vision Language Action Models in Robotic Manipulation: A Systematic Review**|Irfan Hussain Team|[2507.10672](http://arxiv.org/abs/2507.10672)|null|
|**2025-07-12**|**Tactile-VLA: Unlocking Vision-Language-Action Model's Physical Knowledge for Tactile Generalization**|Yang Gao Team|[2507.09160](http://arxiv.org/abs/2507.09160)|null|
|**2025-07-09**|**3D-Generalist: Self-Improving Vision-Language-Action Models for Crafting 3D Worlds**|Nick Haber Team|[2507.06484](http://arxiv.org/abs/2507.06484)|**[link](https://ai.stanford.edu/~sunfanyun/3d-generalist/)**|
|**2025-07-07**|**NavigScene: Bridging Local Perception and Global Navigation for Beyond-Visual-Range Autonomous Driving**|Cheng Lu Team|[2507.05227](http://arxiv.org/abs/2507.05227)|null|
|**2025-10-06**|**VOTE: Vision-Language-Action Optimization with Trajectory Ensemble Voting**|Yanzhi Wang Team|[2507.05116](http://arxiv.org/abs/2507.05116)|null|
|**2025-07-17**|**DreamVLA: A Vision-Language-Action Model Dreamed with Comprehensive World Knowledge**|Xin Jin Team|[2507.04447](http://arxiv.org/abs/2507.04447)|null|
|**2025-07-06**|**Hijacking JARVIS: Benchmarking Mobile GUI Agents against Unprivileged Third Parties**|Yunxin Liu Team|[2507.04227](http://arxiv.org/abs/2507.04227)|null|
|**2025-07-03**|**DexVLG: Dexterous Vision-Language-Grasp Model at Scale**|He Wang Team|[2507.02747](http://arxiv.org/abs/2507.02747)|null|
|**2025-07-02**|**cVLA: Towards Efficient Camera-Space VLAs**|Thomas Brox Team|[2507.02190](http://arxiv.org/abs/2507.02190)|null|
|**2025-07-03**|**A Survey on Vision-Language-Action Models: An Action Tokenization Perspective**|Yaodong Yang Team|[2507.01925](http://arxiv.org/abs/2507.01925)|null|
|**2025-07-02**|**MoIRA: Modular Instruction Routing Architecture for Multi-Task Robotics**|Nadiya Shvai Team|[2507.01843](http://arxiv.org/abs/2507.01843)|null|
|**2025-07-03**|**TriVLA: A Triple-System-Based Unified Vision-Language-Action Model for General Robot Control**|Yanwei Fu Team|[2507.01424](http://arxiv.org/abs/2507.01424)|null|
|**2025-07-01**|**VQ-VLA: Improving Vision-Language-Action Models via Scaling Vector-Quantized Action Tokenizers**|Tong He Team|[2507.01016](http://arxiv.org/abs/2507.01016)|null|
|**2025-07-01**|**Evo-0: Vision-Language-Action Model with Implicit Spatial Understanding**|Bo Zhao Team|[2507.00416](http://arxiv.org/abs/2507.00416)|null|
|**2025-06-30**|**A Survey on Vision-Language-Action Models for Autonomous Driving**|Lijun Sun Team|[2506.24044](http://arxiv.org/abs/2506.24044)|null|
|**2025-06-27**|**4D-VLA: Spatiotemporal Vision-Language-Action Pretraining with Cross-Scene Calibration**|Li Zhang Team|[2506.22242](http://arxiv.org/abs/2506.22242)|null|
|**2025-08-08**|**Can Vision Language Models Understand Mimed Actions?**|Jonathan May Team|[2506.21586](http://arxiv.org/abs/2506.21586)|null|
|**2025-06-26**|**WorldVLA: Towards Autoregressive Action World Model**|Hao Chen Team|[2506.21539](http://arxiv.org/abs/2506.21539)|null|
|**2025-06-26**|**Parallels Between VLA Model Post-Training and Human Motor Learning: Progress, Challenges, and Trends**|Zeng-Guang Hou Team|[2506.20966](http://arxiv.org/abs/2506.20966)|null|
|**2025-06-25**|**Unified Vision-Language-Action Model**|Zhaoxiang Zhang Team|[2506.19850](http://arxiv.org/abs/2506.19850)|null|
|**2025-06-24**|**CronusVLA: Transferring Latent Motion Across Time for Multi-Frame Prediction in Manipulation**|Jiangmiao Pang Team|[2506.19816](http://arxiv.org/abs/2506.19816)|null|
|**2025-07-07**|**RoboMonkey: Scaling Test-Time Sampling and Verification for Vision-Language-Action Models**|Marco Pavone Team|[2506.17811](http://arxiv.org/abs/2506.17811)|null|
|**2025-06-21**|**RLRC: Reinforcement Learning-based Recovery for Compressed Vision-Language-Action Models**|Xiao Li Team|[2506.17639](http://arxiv.org/abs/2506.17639)|null|
|**2025-06-21**|**VLA-OS: Structuring and Dissecting Planning Representations and Paradigms in Vision-Language-Action Models**|Lin Shao Team|[2506.17561](http://arxiv.org/abs/2506.17561)|null|
|**2025-06-19**|**CapsDT: Diffusion-Transformer for Capsule Robot Manipulation**|Hongliang Ren Team|[2506.16263](http://arxiv.org/abs/2506.16263)|null|
|**2025-06-19**|**ControlVLA: Few-shot Object-centric Adaptation for Pre-trained Vision-Language-Action Models**|Siyuan Huang Team|[2506.16211](http://arxiv.org/abs/2506.16211)|null|
|**2025-06-19**|**ClutterDexGrasp: A Sim-to-Real System for General Dexterous Grasping in Cluttered Scenes**|Hao Dong Team|[2506.14317](http://arxiv.org/abs/2506.14317)|null|
|**2025-06-16**|**GRaD-Nav++: Vision-Language Model Enabled Visual Drone Navigation with Gaussian Radiance Fields and Differentiable Dynamics**|Mac Schwager Team|[2506.14009](http://arxiv.org/abs/2506.14009)|null|
|**2025-06-16**|**AutoVLA: A Vision-Language-Action Model for End-to-End Autonomous Driving with Adaptive Reasoning and Reinforcement Fine-Tuning**|Jiaqi Ma Team|[2506.13757](http://arxiv.org/abs/2506.13757)|**[link](https://github.com/ucla-mobility/AutoVLA)**|
|**2025-06-19**|**LeVERB: Humanoid Whole-Body Control with Latent Vision-Language Instruction**|Shankar Sastry Team|[2506.13751](http://arxiv.org/abs/2506.13751)|null|
|**2025-06-16**|**CEED-VLA: Consistency Vision-Language-Action Model with Early-Exit Decoding**|Haoang Li Team|[2506.13725](http://arxiv.org/abs/2506.13725)|null|
|**2025-06-16**|**ROSA: Harnessing Robot States for Vision-Language and Action Alignment**|Xiaoyan Sun Team|[2506.13679](http://arxiv.org/abs/2506.13679)|null|
|**2025-06-16**|**Block-wise Adaptive Caching for Accelerating Diffusion Policy**|Zhi Wang Team|[2506.13456](http://arxiv.org/abs/2506.13456)|null|
|**2025-06-19**|**A Comprehensive Survey on Continual Learning in Generative Models**|Cheng-Lin Liu Team|[2506.13045](http://arxiv.org/abs/2506.13045)|**[link](https://github.com/ghy0501/awesome-continual-learning-in-generative-models)**|
|**2025-06-19**|**SP-VLA: A Joint Model Scheduling and Token Pruning Approach for VLA Model Acceleration**|Wenwu Zhu Team|[2506.12723](http://arxiv.org/abs/2506.12723)|null|
|**2025-06-13**|**RationalVLA: A Rational Vision-Language-Action Model with Dual System**|Haoang Li Team|[2506.10826](http://arxiv.org/abs/2506.10826)|null|
|**2025-06-11**|**EfficientVLA: Training-Free Acceleration and Compression for Vision-Language-Action Models**|Linfeng Zhang Team|[2506.10100](http://arxiv.org/abs/2506.10100)|null|
|**2025-06-11**|**SAFE: Multitask Failure Detection for Vision-Language-Action Models**|Florian Shkurti Team|[2506.09937](http://arxiv.org/abs/2506.09937)|null|
|**2025-06-11**|**From Intention to Execution: Probing the Generalization Boundaries of Vision-Language-Action Models**|Chen Feng Team|[2506.09930](http://arxiv.org/abs/2506.09930)|null|
|**2025-06-17**|**An Open-Source Software Toolkit & Benchmark Suite for the Evaluation and Adaptation of Multimodal Action Models**|Harshvardhan Sikka Team|[2506.09172](http://arxiv.org/abs/2506.09172)|null|
|**2025-06-10**|**FreqPolicy: Efficient Flow-based Visuomotor Policy via Frequency Consistency**|Jian Tang Team|[2506.08822](http://arxiv.org/abs/2506.08822)|null|
|**2025-06-10**|**Hybrid Reasoning for Perception, Explanation, and Autonomous Action in Manufacturing**|Sebastian W. Pattinson Team|[2506.08462](http://arxiv.org/abs/2506.08462)|null|
|**2025-06-11**|**TGRPO :Fine-tuning Vision-Language-Action Model via Trajectory-wise Group Relative Policy Optimization**|Qi Wang Team|[2506.08440](http://arxiv.org/abs/2506.08440)|null|
|**2025-06-11**|**HiBerNAC: Hierarchical Brain-emulated Robotic Neural Agent Collective for Disentangling Complex Manipulation**|Cong Wang Team|[2506.08296](http://arxiv.org/abs/2506.08296)|null|
|**2025-06-14**|**Agentic Surgical AI: Surgeon Style Fingerprinting and Privacy Risk Quantification via Discrete Diffusion in a Vision-Language-Action Framework**|Jason H. Moore Team|[2506.08185](http://arxiv.org/abs/2506.08185)|**[link](https://github.com/huixin-zhan-ai/surgeon_style_fingerprinting)**|
|**2025-06-09**|**BridgeVLA: Input-Output Alignment for Efficient 3D Manipulation Learning with Vision-Language Models**|Tieniu Tan Team|[2506.07961](http://arxiv.org/abs/2506.07961)|null|
|**2025-06-09**|**Fast ECoT: Efficient Embodied Chain-of-Thought via Thoughts Reuse**|Chris Xiaoxuan Lu Team|[2506.07639](http://arxiv.org/abs/2506.07639)|null|
|**2025-06-09**|**BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation**|Xilin Chen Team|[2506.07530](http://arxiv.org/abs/2506.07530)|**[link](https://github.com/ustcwhy/bitvla)**|
|**2025-06-09**|**Real-Time Execution of Action Chunking Flow Policies**|Sergey Levine Team|[2506.07339](http://arxiv.org/abs/2506.07339)|null|
|**2025-06-12**|**Robotic Policy Learning via Human-assisted Action Preference Optimization**|Di Hu Team|[2506.07127](http://arxiv.org/abs/2506.07127)|null|
|**2025-06-07**|**RoboCerebra: A Large-scale Benchmark for Long-horizon Robotic Manipulation Evaluation**|Si Liu Team|[2506.06677](http://arxiv.org/abs/2506.06677)|null|
|**2025-06-06**|**MapleGrasp: Mask-guided Feature Pooling for Language-driven Efficient Robotic Grasping**|Farshad Khorrami Team|[2506.06535](http://arxiv.org/abs/2506.06535)|null|
|**2025-06-06**|**DriveAction: A Benchmark for Exploring Human-like Driving Decisions in VLA Models**|Xianpeng Lang Team|[2506.05667](http://arxiv.org/abs/2506.05667)|null|
|**2025-06-04**|**SwitchVLA: Execution-Aware Task Switching for Vision-Language-Action Models**|Jian Tang Team|[2506.03574](http://arxiv.org/abs/2506.03574)|null|
|**2025-06-03**|**Adversarial Attacks on Robotic Vision Language Action Models**|J. Zico Kolter Team|[2506.03350](http://arxiv.org/abs/2506.03350)|**[link](https://github.com/eliotjones1/robogcg)**|
|**2025-06-02**|**Fast-in-Slow: A Dual-System Foundation Model Unifying Fast Manipulation within Slow Reasoning**|Pheng-Ann Heng Team|[2506.01953](http://arxiv.org/abs/2506.01953)|null|
|**2025-06-02**|**SmolVLA: A Vision-Language-Action Model for Affordable and Efficient Robotics**|Remi Cadene Team|[2506.01844](http://arxiv.org/abs/2506.01844)|**[link](https://github.com/huggingface/lerobot)**|
|**2025-06-02**|**MLA-Trust: Benchmarking Trustworthiness of Multimodal LLM Agents in GUI Environments**|Jun Zhu Team|[2506.01616](http://arxiv.org/abs/2506.01616)|null|
|**2025-06-02**|**ReAgent-V: A Reward-Driven Multi-Agent Framework for Video Understanding**|Huaxiu Yao Team|[2506.01300](http://arxiv.org/abs/2506.01300)|null|
|**2025-06-01**|**OG-VLA: 3D-Aware Vision Language Action Model via Orthographic Image Generation**|Valts Blukis Team|[2506.01196](http://arxiv.org/abs/2506.01196)|null|
|**2025-05-31**|**LoHoVLA: A Unified Vision-Language-Action Model for Long-Horizon Embodied Tasks**|Zhijie Deng Team|[2506.00411](http://arxiv.org/abs/2506.00411)|null|
|**2025-05-30**|**Towards a Generalizable Bimanual Foundation Policy via Flow-based Video Prediction**|Xuelong Li Team|[2505.24156](http://arxiv.org/abs/2505.24156)|null|
|**2025-05-29**|**Impromptu VLA: Open Weights and Open Data for Driving Vision-Language-Action Models**|Hao Zhao Team|[2505.23757](http://arxiv.org/abs/2505.23757)|**[link](https://github.com/ahydchh/impromptu-vla)**|
|**2025-05-29**|**Knowledge Insulating Vision-Language-Action Models: Train Fast, Run Fast, Generalize Better**|Sergey Levine Team|[2505.23705](http://arxiv.org/abs/2505.23705)|null|
|**2025-05-29**|**Agentic Robot: A Brain-Inspired Framework for Vision-Language-Action Models in Embodied Agents**|Lichao Sun Team|[2505.23450](http://arxiv.org/abs/2505.23450)|null|
|**2025-05-29**|**TrackVLA: Embodied Visual Tracking in the Wild**|He Wang Team|[2505.23189](http://arxiv.org/abs/2505.23189)|null|
|**2025-05-28**|**ForceVLA: Enhancing VLA Models with a Force-aware MoE for Contact-rich Manipulation**|Wenqiang Zhang Team|[2505.22159](http://arxiv.org/abs/2505.22159)|null|
|**2025-05-29**|**ChatVLA-2: Vision-Language-Action Model with Open-World Embodied Reasoning from Pretrained Knowledge**|Yi Xu Team|[2505.21906](http://arxiv.org/abs/2505.21906)|null|
|**2025-05-27**|**EaqVLA: Encoding-aligned Quantization for Vision-Language-Action Models**|Xiang Chen Team|[2505.21567](http://arxiv.org/abs/2505.21567)|null|
|**2025-06-02**|**Hume: Introducing System-2 Thinking in Visual-Language-Action Model**|Xuelong Li Team|[2505.21432](http://arxiv.org/abs/2505.21432)|null|
|**2025-05-27**|**Think Twice, Act Once: Token-Aware Compression and Action Reuse for Efficient Inference in Vision-Language-Action Models**|Tao Chen Team|[2505.21200](http://arxiv.org/abs/2505.21200)|null|
|**2025-05-26**|**Embodied AI with Foundation Models for Mobile Service Robots: A Systematic Review**|Goldie Nejat Team|[2505.20503](http://arxiv.org/abs/2505.20503)|null|
|**2025-05-26**|**What Can RL Bring to VLA Generalization? An Empirical Study**|Yu Wang Team|[2505.19789](http://arxiv.org/abs/2505.19789)|null|
|**2025-05-26**|**RFTF: Reinforcement Fine-tuning for Embodied Agents with Temporal Feedback**|Yongtao Wang Team|[2505.19767](http://arxiv.org/abs/2505.19767)|null|
|**2025-05-25**|**ReFineVLA: Reasoning-Aware Teacher-Guided Transfer Fine-Tuning**|Minh Nhat Vu Team|[2505.19080](http://arxiv.org/abs/2505.19080)|null|
|**2025-05-24**|**Genie Centurion: Accelerating Scalable Real-World Robot Training with Human Rewind-and-Refine Guidance**|Maoqing Yao Team|[2505.18793](http://arxiv.org/abs/2505.18793)|null|
|**2025-05-24**|**VLA-RL: Towards Masterful and General Robotic Manipulation with Scalable Reinforcement Learning**|Ziwei Wang Team|[2505.18719](http://arxiv.org/abs/2505.18719)|**[link](https://github.com/guanxinglu/vlarl)**|
|**2025-05-22**|**ScanBot: Towards Intelligent Surface Scanning in Embodied Robotic Systems**|Farhad Imani Team|[2505.17295](http://arxiv.org/abs/2505.17295)|null|
|**2025-05-22**|**Interactive Post-Training for Vision-Language-Action Models**|Philipp Krähenbühl Team|[2505.17016](http://arxiv.org/abs/2505.17016)|null|
|**2025-05-22**|**Perceptual Quality Assessment for Embodied AI**|Guangtao Zhai Team|[2505.16815](http://arxiv.org/abs/2505.16815)|**[link](https://github.com/lcysyzxdxc/embodiediqa)**|
|**2025-05-22**|**BadVLA: Towards Backdoor Attacks on Vision-Language-Action Models via Objective-Decoupled Optimization**|Lichao Sun Team|[2505.16640](http://arxiv.org/abs/2505.16640)|null|
|**2025-05-22**|**DriveMoE: Mixture-of-Experts for Vision-Language-Action Model in End-to-End Autonomous Driving**|Junchi Yan Team|[2505.16278](http://arxiv.org/abs/2505.16278)|null|
|**2025-05-21**|**From Grounding to Manipulation: Case Studies of Foundation Model Integration in Embodied Robotic Systems**|Soujanya Poria Team|[2505.15685](http://arxiv.org/abs/2505.15685)|**[link](https://github.com/hritdy/claw_machine)**|
|**2025-05-24**|**Exploring the Limits of Vision-Language-Action Manipulations in Cross-task Generalization**|Junwei Liang Team|[2505.15660](http://arxiv.org/abs/2505.15660)|**[link](https://github.com/jiaming-zhou/X-ICM)**|
|**2025-05-21**|**FLARE: Robot Learning with Implicit World Modeling**|Linxi Fan Team|[2505.15659](http://arxiv.org/abs/2505.15659)|null|
|**2025-05-21**|**Saliency-Aware Quantized Imitation Learning for Efficient Robotic Control**|Jungwook Choi Team|[2505.15304](http://arxiv.org/abs/2505.15304)|null|
|**2025-05-21**|**EndoVLA: Dual-Phase Vision-Language-Action Model for Autonomous Tracking in Endoscopy**|Hongliang Ren Team|[2505.15206](http://arxiv.org/abs/2505.15206)|null|
|**2025-05-21**|**Object-Focus Actor for Data-efficient Robot Generalization Dexterous Manipulation**|Xiaodong He Team|[2505.15098](http://arxiv.org/abs/2505.15098)|null|
|**2025-05-20**|**AutoBio: A Simulation and Benchmark for Robotic Automation in Digital Biology Laboratory**|Ping Luo Team|[2505.14030](http://arxiv.org/abs/2505.14030)|null|
|**2025-05-22**|**InSpire: Vision-Language-Action Models with Intrinsic Spatial Reasoning**|Jingkuan Song Team|[2505.13888](http://arxiv.org/abs/2505.13888)|**[link](https://github.com/inspirevla/inspire)**|
|**2025-05-25**|**RoboFAC: A Comprehensive Framework for Robotic Failure Analysis and Correction**|Bo Zhao Team|[2505.12224](http://arxiv.org/abs/2505.12224)|null|
|**2025-05-17**|**OneTwoVLA: A Unified Vision-Language-Action Model with Adaptive Reasoning**|Yang Gao Team|[2505.11917](http://arxiv.org/abs/2505.11917)|null|
|**2025-05-16**|**Unveiling the Potential of Vision-Language-Action Models with Open-Ended Multimodal Instructions**|Donglin Wang Team|[2505.11214](http://arxiv.org/abs/2505.11214)|null|
|**2025-05-16**|**Conditioning Matters: Training Diffusion Policies is Faster Than You Think**|Jianye Hao Team|[2505.11123](http://arxiv.org/abs/2505.11123)|null|
|**2025-05-14**|**Real2Render2Real: Scaling Robot Data Without Dynamics Simulation or Robot Hardware**|Ken Goldberg Team|[2505.09601](http://arxiv.org/abs/2505.09601)|null|
|**2025-05-14**|**RT-cache: Efficient Robot Trajectory Retrieval System**|Amir Barati Farimani Team|[2505.09040](http://arxiv.org/abs/2505.09040)|null|
|**2025-05-13**|**From Seeing to Doing: Bridging Reasoning and Decision for Robotic Manipulation**|Jianye Hao Team|[2505.08548](http://arxiv.org/abs/2505.08548)|null|
|**2025-05-17**|**Training Strategies for Efficient Embodied Reasoning**|Sergey Levine Team|[2505.08243](http://arxiv.org/abs/2505.08243)|null|
|**2025-05-12**|**Pixel Motion as Universal Representation for Robot Control**|Michael S Ryoo Team|[2505.07817](http://arxiv.org/abs/2505.07817)|null|
|**2025-05-12**|**ReinboT: Amplifying Robot Visual-Language Manipulation with Reinforcement Learning**|Donglin Wang Team|[2505.07395](http://arxiv.org/abs/2505.07395)|null|
|**2025-05-15**|**UniVLA: Learning to Act Anywhere with Task-centric Latent Actions**|Hongyang Li Team|[2505.06111](http://arxiv.org/abs/2505.06111)|**[link](https://github.com/opendrivelab/univla)**|
|**2025-05-09**|**3D CAVLA: Leveraging Depth and 3D Context to Generalize Vision Language Action Models for Unseen Tasks**|Farshad Khorrami Team|[2505.05800](http://arxiv.org/abs/2505.05800)|null|
|**2025-05-08**|**Benchmarking Vision, Language, & Action Models in Procedurally Generated, Open Ended Action Environments**|Harshvardhan Sikka Team|[2505.05540](http://arxiv.org/abs/2505.05540)|**[link](https://github.com/ManifoldRG/MultiNet)**|
|**2025-05-09**|**Vision-Language-Action Models: Concepts, Progress, Applications and Challenges**|Manoj Karkee Team|[2505.04769](http://arxiv.org/abs/2505.04769)|null|
|**2025-05-06**|**OpenHelix: A Short Survey, Empirical Analysis, and Open-Source Dual-System VLA Model for Robotic Manipulation**|Donglin Wang Team|[2505.03912](http://arxiv.org/abs/2505.03912)|**[link](https://github.com/OpenHelix-robot/OpenHelix)**|
|**2025-05-16**|**Task Reconstruction and Extrapolation for $π_0$ using Text Latent**|Quanyi Li Team|[2505.03500](http://arxiv.org/abs/2505.03500)|null|
|**2025-05-06**|**GraspVLA: a Grasping Foundation Model Pre-trained on Billion-scale Synthetic Action Data**|He Wang Team|[2505.03233](http://arxiv.org/abs/2505.03233)|null|
|**2025-05-06**|**Automated Data Curation Using GPS & NLP to Generate Instruction-Action Pairs for Autonomous Vehicle Vision-Language Navigation Datasets**|Ross Greer Team|[2505.03174](http://arxiv.org/abs/2505.03174)|null|
|**2025-05-04**|**CrayonRobo: Object-Centric Prompt-Driven Vision-Language-Action Model for Robotic Manipulation**|Hao Dong Team|[2505.02166](http://arxiv.org/abs/2505.02166)|null|
|**2025-05-04**|**Interleave-VLA: Enhancing Robot Manipulation with Interleaved Image-Text Instructions**|Mingyu Ding Team|[2505.02152](http://arxiv.org/abs/2505.02152)|null|
|**2025-04-28**|**NORA: A Small Open-Sourced Generalist Vision Language Action Model for Embodied Tasks**|Soujanya Poria Team|[2504.19854](http://arxiv.org/abs/2504.19854)|null|
|**2025-04-22**|**$π_{0.5}$ : a Vision-Language-Action Model with Open-World Generalization**|Ury Zhilinsky Team|[2504.16054](http://arxiv.org/abs/2504.16054)|null|
|**2025-04-22**|**Few-Shot Vision-Language Action-Incremental Policy Learning**|Weili Guan Team|[2504.15517](http://arxiv.org/abs/2504.15517)|null|
|**2025-04-18**|**GUI-R1 : A Generalist R1-Style Vision-Language Action Model For GUI Agents**|Xiaobo Xia Team|[2504.10458](http://arxiv.org/abs/2504.10458)|null|
|**2025-04-09**|**OPAL: Encoding Causal Understanding of Physical Systems for Robot Learning**|Tyler Fenstermaker Team|[2504.06538](http://arxiv.org/abs/2504.06538)|null|
|**2025-04-02**|**Grounding Multimodal LLMs to Embodied Agents that Ask for Help with Reinforcement Learning**|Roozbeh Mottaghi Team|[2504.00907](http://arxiv.org/abs/2504.00907)|null|
|**2025-03-30**|**OpenDriveVLA: Towards End-to-end Autonomous Driving with Large Vision Language Action Model**|Alois C. Knoll Team|[2503.23463](http://arxiv.org/abs/2503.23463)|**[link](https://github.com/DriveVLA/OpenDriveVLA)**|
|**2025-03-27**|**CoT-VLA: Visual Chain-of-Thought Reasoning for Vision-Language-Action Models**|Tsung-Yi Lin Team|[2503.22020](http://arxiv.org/abs/2503.22020)|null|
|**2025-04-14**|**MoLe-VLA: Dynamic Layer-skipping Vision Language Action Model via Mixture-of-Layers for Efficient Robot Manipulation**|Shanghang Zhang Team|[2503.20384](http://arxiv.org/abs/2503.20384)|null|
|**2025-03-25**|**Gemini Robotics: Bringing AI into the Physical World**|Yuxiang Zhou Team|[2503.20020](http://arxiv.org/abs/2503.20020)|null|
|**2025-03-25**|**Dita: Scaling Diffusion Transformer for Generalist Vision-Language-Action Policy**|Yuntao Chen Team|[2503.19757](http://arxiv.org/abs/2503.19757)|null|
|**2025-03-25**|**DataPlatter: Boosting Robotic Manipulation Generalization with Minimal Costly Data**|Lin Ma Team|[2503.19516](http://arxiv.org/abs/2503.19516)|null|
|**2025-03-27**|**GR00T N1: An Open Foundation Model for Generalist Humanoid Robots**|Yuke Zhu Team|[2503.14734](http://arxiv.org/abs/2503.14734)|null|
|**2025-03-15**|**ReBot: Scaling Robot Learning with Real-to-Sim-to-Real Robotic Video Synthesis**|Mingyu Ding Team|[2503.14526](http://arxiv.org/abs/2503.14526)|null|
|**2025-03-17**|**MoManipVLA: Transferring Vision-language-action Models for General Mobile Manipulation**|Haibin Yan Team|[2503.13446](http://arxiv.org/abs/2503.13446)|null|
|**2025-03-17**|**HybridVLA: Collaborative Diffusion and Autoregression in a Unified Vision-Language-Action Model**|Shanghang Zhang Team|[2503.10631](http://arxiv.org/abs/2503.10631)|null|
|**2025-03-13**|**SimLingo: Vision-Only Closed-Loop Autonomous Driving with Language-Action Alignment**|Oleg Sinavski Team|[2503.09594](http://arxiv.org/abs/2503.09594)|null|
|**2025-03-12**|**CombatVLA: An Efficient Vision-Language-Action Model for Combat Tasks in 3D Action Role-Playing Games**|Bo Zheng Team|[2503.09527](http://arxiv.org/abs/2503.09527)|null|
|**2025-03-11**|**MoRE: Unlocking Scalability in Reinforcement Learning for Quadruped Vision-Language-Action Models**|Zongyuan Ge Team|[2503.08007](http://arxiv.org/abs/2503.08007)|null|
|**2025-03-10**|**PointVLA: Injecting the 3D World into Vision-Language-Action Models**|Yichen Zhu Team|[2503.07511](http://arxiv.org/abs/2503.07511)|null|
|**2025-03-11**|**CLAD: Constrained Latent Action Diffusion for Vision-Language Procedure Planning**|Andreas Bulling Team|[2503.06637](http://arxiv.org/abs/2503.06637)|null|
|**2025-03-06**|**Refined Policy Distillation: From VLA Generalists to RL Experts**|Florian Walter Team|[2503.05833](http://arxiv.org/abs/2503.05833)|null|
|**2025-03-06**|**VLA Model-Expert Collaboration for Bi-directional Manipulation Learning**|Zeng-Guang Hou Team|[2503.04163](http://arxiv.org/abs/2503.04163)|null|
|**2025-03-26**|**OTTER: A Vision-Language-Action Model with Text-Aware Visual Feature Extraction**|Pieter Abbeel Team|[2503.03734](http://arxiv.org/abs/2503.03734)|null|
|**2025-03-05**|**SafeVLA: Towards Safety Alignment of Vision-Language-Action Model via Safe Reinforcement Learning**|Yaodong Yang Team|[2503.03480](http://arxiv.org/abs/2503.03480)|null|
|**2025-03-04**|**Accelerating Vision-Language-Action Model Integrated with Action Chunking via Parallel Decoding**|Haoang Li Team|[2503.02310](http://arxiv.org/abs/2503.02310)|null|
|**2025-03-03**|**CognitiveDrone: A VLA Model and Evaluation Benchmark for Real-Time Cognitive Task Solving and Reasoning in UAVs**|Dzmitry Tsetserukou Team|[2503.01378](http://arxiv.org/abs/2503.01378)|null|
|**2025-10-15**|**CoVLA: Comprehensive Vision-Language-Action Dataset for Autonomous Driving**|Issei Yamamoto Team|[2408.10845](http://arxiv.org/abs/2408.10845)|**[link](https://turingmotors.github.io/covla-ad/)**|
|**2024-07-23**|**Can VLMs be used on videos for action recognition? LLMs are Visual Reasoning Coordinators**|Harsh Lunia Team|[2407.14834](http://arxiv.org/abs/2407.14834)|null|
|**2024-03-15**|**3D-VLA: A 3D Vision-Language-Action Generative World Model**|Chuang Gan Team|[2403.09631](http://arxiv.org/abs/2403.09631)|**[link](https://vis-www.cs.umass.edu/3dvla/)**|
|**2022-07-19**|**Zero-Shot Temporal Action Detection via Vision-Language Prompting**|Tao Xiang Team|[2207.08184](http://arxiv.org/abs/2207.08184)|**[link](https://github.com/sauradip/STALE)**|
|**2022-06-01**|**ADAPT: Vision-Language Navigation with Modality-Aligned Action Prompts**|Xiaodan Liang Team|[2205.15509](http://arxiv.org/abs/2205.15509)|null|
|**2022-08-16**|**A Dataset for Interactive Vision-Language Navigation with Unknown Command Feasibility**|Bryan A. Plummer Team|[2202.02312](http://arxiv.org/abs/2202.02312)|null|
|**2017-04-25**|**An Analysis of Action Recognition Datasets for Language and Vision Tasks**|Frank Keller Team|[1704.07129](http://arxiv.org/abs/1704.07129)|null|

<p align=right>(<a href=#updated-on-20251217>back to top</a>)</p>

## Humanoid

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-12-11**|**WholeBodyVLA: Towards Unified Latent VLA for Whole-Body Loco-Manipulation Control**|Hongyang Li Team|[2512.11047](http://arxiv.org/abs/2512.11047)|null|
|**2025-12-11**|**Symphony: A Heuristic Normalized Calibrated Advantage Actor and Critic Algorithm in application for Humanoid Robots**|József Dombi Team|[2512.10477](http://arxiv.org/abs/2512.10477)|null|
|**2025-12-10**|**A Hierarchical, Model-Based System for High-Performance Humanoid Soccer**|Dennis W. Hong Team|[2512.09431](http://arxiv.org/abs/2512.09431)|null|
|**2025-11-28**|**Learning When to Ask: Simulation-Trained Humanoids for Mental-Health Diagnosis**|Longbing Cao Team|[2512.08952](http://arxiv.org/abs/2512.08952)|null|
|**2025-12-09**|**SensHRPS: Sensing Comfortable Human-Robot Proxemics and Personal Space With Eye-Tracking**|Karsten Berns Team|[2512.08518](http://arxiv.org/abs/2512.08518)|null|
|**2025-12-08**|**Efficient and Compliant Control Framework for Versatile Human-Humanoid Collaborative Transportation**|Panagiotis Artemiadis Team|[2512.07819](http://arxiv.org/abs/2512.07819)|null|
|**2025-12-08**|**Gait-Adaptive Perceptive Humanoid Locomotion with Real-Time Under-Base Terrain Reconstruction**|Houqiang Li Team|[2512.07464](http://arxiv.org/abs/2512.07464)|null|
|**2025-12-07**|**CERNet: Class-Embedding Predictive-Coding RNN for Unified Robot Motion, Recognition, and Confidence Estimation**|Mathias Quoy Team|[2512.07041](http://arxiv.org/abs/2512.07041)|null|
|**2025-12-06**|**Learning Agile Striker Skills for Humanoid Soccer Robots from Noisy Sensory Input**|Peter Stone Team|[2512.06571](http://arxiv.org/abs/2512.06571)|null|
|**2025-12-04**|**From Generated Human Videos to Physically Plausible Robot Trajectories**|Roei Herzig Team|[2512.05094](http://arxiv.org/abs/2512.05094)|**[link](https://genmimic.github.io)**|
|**2025-12-04**|**Preliminary Analysis and Simulation of a Compact Variable Stiffness Wrist**|Giorgio Grioli Team|[2512.04973](http://arxiv.org/abs/2512.04973)|**[link](https://doi.org/10.1007/978-3-031-64057-5_9)**|
|**2025-12-04**|**X-Humanoid: Robotize Human Videos to Generate Humanoid Videos at Scale**|Mike Zheng Shou Team|[2512.04537](http://arxiv.org/abs/2512.04537)|null|
|**2025-12-03**|**SMP: Reusable Score-Matching Motion Priors for Physics-Based Character Control**|Xue Bin Peng Team|[2512.03028](http://arxiv.org/abs/2512.03028)|null|
|**2025-12-02**|**RoboWheel: A Data Engine from Real-World Human Demonstrations for Cross-Embodiment Robotic Learning**|Haoqian Wang Team|[2512.02729](http://arxiv.org/abs/2512.02729)|null|
|**2025-12-01**|**Learning Sim-to-Real Humanoid Locomotion in 15 Minutes**|Pieter Abbeel Team|[2512.01996](http://arxiv.org/abs/2512.01996)|**[link](https://younggyo.me/fastsac-humanoid)**|
|**2025-12-01**|**Modality-Augmented Fine-Tuning of Foundation Robot Policies for Cross-Embodiment Manipulation on GR1 and G1**|Songhwai Oh Team|[2512.01358](http://arxiv.org/abs/2512.01358)|null|
|**2025-12-01**|**Discovering Self-Protective Falling Policy for Humanoid Robot via Deep Reinforcement Learning**|Donglin Wang Team|[2512.01336](http://arxiv.org/abs/2512.01336)|null|
|**2025-11-30**|**Opening the Sim-to-Real Door for Humanoid Pixel-to-Action Policy Transfer**|Yuke Zhu Team|[2512.01061](http://arxiv.org/abs/2512.01061)|**[link](https://doorman-humanoid.github.io/)**|
|**2025-11-30**|**CycleManip: Enabling Cyclic Task Manipulation via Effective Historical Perception and Understanding**|Wei-Shi Zheng Team|[2512.01022](http://arxiv.org/abs/2512.01022)|**[link](https://isee-laboratory.github.io/OmniDexGrasp/)**|
|**2025-11-30**|**H-Zero: Cross-Humanoid Locomotion Pretraining Enables Few-shot Novel Embodiment Transfer**|Weinan Zhang Team|[2512.00971](http://arxiv.org/abs/2512.00971)|null|
|**2025-11-30**|**Sigma: The Key for Vision-Language-Action Models toward Telepathic Alignment**|Libo Wang Team|[2512.00783](http://arxiv.org/abs/2512.00783)|**[link](https://huggingface.co/Veltraxor/Sigma)**|
|**2025-11-30**|**MS-PPO: Morphological-Symmetry-Equivariant Policy for Legged Robot Locomotion**|Lu Gan Team|[2512.00727](http://arxiv.org/abs/2512.00727)|null|
|**2025-11-25**|**A Hierarchical Framework for Humanoid Locomotion with Supernumerary Limbs**|Bowen Zhi Team|[2512.00077](http://arxiv.org/abs/2512.00077)|null|
|**2025-11-28**|**SafeHumanoid: VLM-RAG-driven Control of Upper Body Impedance for Humanoid Robot**|Dzmitry Tsetserukou Team|[2511.23300](http://arxiv.org/abs/2511.23300)|null|
|**2025-11-28**|**Commanding Humanoid by Free-form Language: A Large Language Action Model with Unified Motion Vocabulary**|Jingya Wang Team|[2511.22963](http://arxiv.org/abs/2511.22963)|**[link](https://humanoidlla.github.io/)**|
|**2025-11-26**|**Kinematics-Aware Multi-Policy Reinforcement Learning for Force-Capable Humanoid Loco-Manipulation**|Qijun Chen Team|[2511.21169](http://arxiv.org/abs/2511.21169)|null|
|**2025-11-25**|**HAFO: A Force-Adaptive Control Framework for Humanoid Robots in Intense Interaction Environments**|Bin He Team|[2511.20275](http://arxiv.org/abs/2511.20275)|null|
|**2025-11-24**|**SENTINEL: A Fully End-to-End Language-Action Model for Humanoid Whole Body Control**|Zongqing Lu Team|[2511.19236](http://arxiv.org/abs/2511.19236)|null|
|**2025-11-24**|**Reference-Free Sampling-Based Model Predictive Control**|Justin Carpentier Team|[2511.19204](http://arxiv.org/abs/2511.19204)|null|
|**2025-11-24**|**AutoOdom: Learning Auto-regressive Proprioceptive Odometry for Legged Locomotion**|Mingguo Zhao Team|[2511.18857](http://arxiv.org/abs/2511.18857)|null|
|**2025-11-24**|**Head Stabilization for Wheeled Bipedal Robots via Force-Estimation-Based Admittance Control**|Ximin Lyu Team|[2511.18712](http://arxiv.org/abs/2511.18712)|null|
|**2025-11-23**|**SafeFall: Learning Protective Control for Humanoid Robots**|Siyuan Huang Team|[2511.18509](http://arxiv.org/abs/2511.18509)|null|
|**2025-11-22**|**Switch-JustDance: Benchmarking Whole Body Motion Tracking Policies Using a Commercial Console Game**|Tianyu Li Team|[2511.17925](http://arxiv.org/abs/2511.17925)|null|
|**2025-11-18**|**Translating Cultural Choreography from Humanoid Forms to Robotic Arm**|Aven-Le Zhou Team|[2511.17603](http://arxiv.org/abs/2511.17603)|null|
|**2025-11-21**|**Human Imitated Bipedal Locomotion with Frequency Based Gait Generator Network**|Omer Morgul Team|[2511.17387](http://arxiv.org/abs/2511.17387)|null|
|**2025-11-21**|**Agility Meets Stability: Versatile Humanoid Control with Heterogeneous Data**|Hongyang Li Team|[2511.17373](http://arxiv.org/abs/2511.17373)|null|
|**2025-11-20**|**InEKFormer: A Hybrid State Estimator for Humanoid Robots**|Frank Kirchner Team|[2511.16306](http://arxiv.org/abs/2511.16306)|null|
|**2025-11-19**|**VIRAL: Visual Sim-to-Real at Scale for Humanoid Loco-Manipulation**|Yuke Zhu Team|[2511.15200](http://arxiv.org/abs/2511.15200)|**[link](https://viral-humanoid.github.io/)**|
|**2025-11-18**|**HMC: Learning Heterogeneous Meta-Control for Contact-Rich Loco-Manipulation**|Xiaolong Wang Team|[2511.14756](http://arxiv.org/abs/2511.14756)|null|
|**2025-11-18**|**Gallant: Voxel Grid-based Humanoid Locomotion and Local-navigation across 3D Constrained Terrains**|Jiangmiao Pang Team|[2511.14625](http://arxiv.org/abs/2511.14625)|null|
|**2025-11-15**|**Learning Adaptive Neural Teleoperation for Humanoid Robots: From Inverse Kinematics to End-to-End Control**|Sanjar Atamuradov Team|[2511.12390](http://arxiv.org/abs/2511.12390)|null|
|**2025-11-14**|**Humanoid Whole-Body Badminton via Multi-Stage Reinforcement Learning**|Xiaoyu Ren Team|[2511.11218](http://arxiv.org/abs/2511.11218)|**[link](https://humanoid-badminton.github.io/Humanoid-Whole-Body-Badminton-via-Multi-Stage-Reinforcement-Learning)**|
|**2025-11-13**|**Robot Crash Course: Learning Soft and Stylized Falling**|Moritz Bächer Team|[2511.10635](http://arxiv.org/abs/2511.10635)|null|
|**2025-11-13**|**DecARt Leg: Design and Evaluation of a Novel Humanoid Robot Leg with Decoupled Actuation for Agile Locomotion**|Roman Gorbachev Team|[2511.10021](http://arxiv.org/abs/2511.10021)|null|
|**2025-11-12**|**SPIDER: Scalable Physics-Informed Dexterous Retargeting**|Francois Hogan Team|[2511.09484](http://arxiv.org/abs/2511.09484)|**[link](https://jc-bao.github.io/spider-project/)**|
|**2025-11-12**|**Unveiling the Impact of Data and Model Scaling on High-Level Control for Humanoid Robots**|Siheng Chen Team|[2511.09241](http://arxiv.org/abs/2511.09241)|null|
|**2025-11-12**|**RGMP: Recurrent Geometric-prior Multimodal Policy for Generalizable Humanoid Robot Manipulation**|Miao Li Team|[2511.09141](http://arxiv.org/abs/2511.09141)|null|
|**2025-11-10**|**Unified Humanoid Fall-Safety Policy from a Few Demonstrations**|Stella X. Yu Team|[2511.07407](http://arxiv.org/abs/2511.07407)|null|
|**2025-11-10**|**Human-Level Actuation for Humanoids**|MD-Nazmus Sunbeam Team|[2511.06796](http://arxiv.org/abs/2511.06796)|null|
|**2025-11-09**|**Sim-to-Real Transfer in Deep Reinforcement Learning for Bipedal Locomotion**|Chengxu Zhou Team|[2511.06465](http://arxiv.org/abs/2511.06465)|null|
|**2025-11-09**|**Whole-Body Control With Terrain Estimation of A 6-DoF Wheeled Bipedal Robot**|Ximin Lyu Team|[2511.06397](http://arxiv.org/abs/2511.06397)|null|
|**2025-11-09**|**Towards Adaptive Humanoid Control via Multi-Behavior Distillation and Reinforced Fine-Tuning**|Chenjia Bai Team|[2511.06371](http://arxiv.org/abs/2511.06371)|null|
|**2025-11-08**|**Towards Human-AI-Robot Collaboration and AI-Agent based Digital Twins for Parkinson's Disease Management: Review and Outlook**|Tareq Y. Al-Naffouri Team|[2511.06036](http://arxiv.org/abs/2511.06036)|null|
|**2025-11-06**|**ScheduleStream: Temporal Planning with Samplers for GPU-Accelerated Multi-Arm Task and Motion Planning & Scheduling**|Fabio Ramos Team|[2511.04758](http://arxiv.org/abs/2511.04758)|**[link](https://schedulestream.github.io)**|
|**2025-11-06**|**GentleHumanoid: Learning Upper-body Compliance for Contact-rich Human and Object Interaction**|C. Karen Liu Team|[2511.04679](http://arxiv.org/abs/2511.04679)|**[link](https://gentle-humanoid.axell.top)**|
|**2025-11-06**|**BFM-Zero: A Promptable Behavioral Foundation Model for Humanoid Control Using Unsupervised Reinforcement Learning**|Guanya Shi Team|[2511.04131](http://arxiv.org/abs/2511.04131)|null|
|**2025-11-06**|**Learning Vision-Driven Reactive Soccer Skills for Humanoid Robots**|Mingguo Zhao Team|[2511.03996](http://arxiv.org/abs/2511.03996)|**[link](https://humanoid-kick.github.io)**|
|**2025-11-05**|**OneOcc: Semantic Occupancy Prediction for Legged Robots with a Single Panoramic Camera**|Kaiwei Wang Team|[2511.03571](http://arxiv.org/abs/2511.03571)|**[link](https://github.com/MasterHow/OneOcc)**|
|**2025-11-04**|**TWIST2: Scalable, Portable, and Holistic Humanoid Data Collection System**|C. Karen Liu Team|[2511.02832](http://arxiv.org/abs/2511.02832)|**[link](https://yanjieze.com/TWIST2)**|
|**2025-11-03**|**MOBIUS: A Multi-Modal Bipedal Robot that can Walk, Crawl, Climb, and Roll**|Dennis Hong Team|[2511.01774](http://arxiv.org/abs/2511.01774)|null|
|**2025-11-02**|**Heuristic Step Planning for Learning Dynamic Bipedal Locomotion: A Comparative Study of Model-Based and Model-Free Approaches**|Roman Gorbachev Team|[2511.00840](http://arxiv.org/abs/2511.00840)|null|
|**2025-11-01**|**Descriptive Model-based Learning and Control for Bipedal Locomotion**|Andy Ruina Team|[2511.00512](http://arxiv.org/abs/2511.00512)|null|
|**2025-10-31**|**EgoMI: Learning Active Vision and Whole-Body Manipulation from Egocentric Human Demonstrations**|Philipp Wu Team|[2511.00153](http://arxiv.org/abs/2511.00153)|null|
|**2025-10-31**|**Towards a Multi-Embodied Grasping Agent**|Gerhard Neumann Team|[2510.27420](http://arxiv.org/abs/2510.27420)|null|
|**2025-10-30**|**Cooperative Task Spaces for Multi-Arm Manipulation Control based on Similarity Transformations**|Sylvain Calinon Team|[2510.26362](http://arxiv.org/abs/2510.26362)|null|
|**2025-11-05**|**Thor: Towards Human-Level Whole-Body Reactions for Intense Contact-Rich Environments**|Shaqi Luo Team|[2510.26280](http://arxiv.org/abs/2510.26280)|null|
|**2025-10-30**|**Beyond the Uncanny Valley: A Mixed-Method Investigation of Anthropomorphism in Protective Responses to Robot Abuse**|Renkai Ma Team|[2510.26082](http://arxiv.org/abs/2510.26082)|null|
|**2025-10-28**|**A Humanoid Visual-Tactile-Action Dataset for Contact-Rich Manipulation**|Kyung-Joong Kim Team|[2510.25725](http://arxiv.org/abs/2510.25725)|null|
|**2025-10-27**|**Awakening Facial Emotional Expressions in Human-Robot**|Jianwei Zhang Team|[2510.23059](http://arxiv.org/abs/2510.23059)|null|
|**2025-10-25**|**Toward Humanoid Brain-Body Co-design: Joint Optimization of Control and Morphology for Fall Recovery**|Guiliang Liu Team|[2510.22336](http://arxiv.org/abs/2510.22336)|null|
|**2025-10-21**|**SLICE: SLO-Driven Scheduling for LLM Inference on Edge Computing Devices**|Will Chow Team|[2510.18544](http://arxiv.org/abs/2510.18544)|null|
|**2025-10-20**|**Humanoid Goalkeeper: Learning from Position Conditioned Task-Motion Constraints**|Jiangmiao Pang Team|[2510.18002](http://arxiv.org/abs/2510.18002)|null|
|**2025-10-20**|**SoftMimic: Learning Compliant Whole-body Control from Examples**|Pulkit Agrawal Team|[2510.17792](http://arxiv.org/abs/2510.17792)|**[link](https://gmargo11.github.io/softmimic/)**|
|**2025-10-16**|**CBF-RL: Safety Filtering Reinforcement Learning in Training with Control Barrier Functions**|Aaron D. Ames Team|[2510.14959](http://arxiv.org/abs/2510.14959)|null|
|**2025-10-16**|**From Language to Locomotion: Retargeting-free Humanoid Control via Motion Latent Guidance**|Chang Xu Team|[2510.14952](http://arxiv.org/abs/2510.14952)|null|
|**2025-10-16**|**Towards Adaptable Humanoid Control via Adaptive Motion Tracking**|Jiangmiao Pang Team|[2510.14454](http://arxiv.org/abs/2510.14454)|null|
|**2025-10-15**|**A Modular Object Detection System for Humanoid Robots Using YOLO**|Meng Cheng Lau Team|[2510.13625](http://arxiv.org/abs/2510.13625)|null|
|**2025-10-15**|**Development of an Intuitive GUI for Non-Expert Teleoperation of Humanoid Robots**|Meng Cheng Lau Team|[2510.13594](http://arxiv.org/abs/2510.13594)|null|
|**2025-10-14**|**PolygMap: A Perceptive Locomotion Framework for Humanoid Robot Stair Climbing**|Yucong Wu Team|[2510.12346](http://arxiv.org/abs/2510.12346)|null|
|**2025-10-13**|**Ego-Vision World Model for Humanoid Contact Planning**|Koushil Sreenath Team|[2510.11682](http://arxiv.org/abs/2510.11682)|null|
|**2025-10-13**|**NaviGait: Navigating Dynamically Feasible Gait Libraries using Deep Reinforcement Learning**|Maegan Tucker Team|[2510.11542](http://arxiv.org/abs/2510.11542)|null|
|**2025-10-13**|**Simultaneous Calibration of Noise Covariance and Kinematics for State Estimation of Legged Robots via Bi-level Optimization**|Xiaobin Xiong Team|[2510.11539](http://arxiv.org/abs/2510.11539)|null|
|**2025-10-13**|**Path and Motion Optimization for Efficient Multi-Location Inspection with Humanoid Robots**|Yao Su Team|[2510.11401](http://arxiv.org/abs/2510.11401)|null|
|**2025-10-13**|**DemoHLM: From One Demonstration to Generalizable Humanoid Loco-Manipulation**|Zongqing Lu Team|[2510.11258](http://arxiv.org/abs/2510.11258)|null|
|**2025-10-13**|**PhysHSI: Towards a Real-World Generalizable and Natural Humanoid-Scene Interaction System**|Jiangmiao Pang Team|[2510.11072](http://arxiv.org/abs/2510.11072)|**[link](https://why618188.github.io/physhsi/)**|
|**2025-10-12**|**Preference-Conditioned Multi-Objective RL for Integrated Command Tracking and Force Compliance in Humanoid Locomotion**|Mingguo Zhao Team|[2510.10851](http://arxiv.org/abs/2510.10851)|null|
|**2025-10-11**|**It Takes Two: Learning Interactive Whole-Body Control Between Humanoid Robots**|Siheng Chen Team|[2510.10206](http://arxiv.org/abs/2510.10206)|null|
|**2025-10-10**|**Enhancing Diffusion Policy with Classifier-Free Guidance for Temporal Robotic Tasks**|Zhicheng He Team|[2510.09786](http://arxiv.org/abs/2510.09786)|null|
|**2025-10-09**|**Humanoid Everyday: A Comprehensive Robotic Dataset for Open-World Humanoid Manipulation**|Yue Wang Team|[2510.08807](http://arxiv.org/abs/2510.08807)|null|
|**2025-10-09**|**DexMan: Learning Bimanual Dexterous Manipulation from Human and Generated Videos**|Tsung-Wei Ke Team|[2510.08475](http://arxiv.org/abs/2510.08475)|**[link](https://embodiedai-ntu.github.io/dexman/index.html)**|
|**2025-10-09**|**Reliability of Single-Level Equality-Constrained Inverse Optimal Control**|Vincent Bonnet Team|[2510.08406](http://arxiv.org/abs/2510.08406)|null|
|**2025-10-09**|**Towards Proprioception-Aware Embodied Planning for Dual-Arm Humanoid Robots**|Zongqing Lu Team|[2510.07882](http://arxiv.org/abs/2510.07882)|null|
|**2025-10-09**|**Probabilistically-Safe Bipedal Navigation over Uncertain Terrain via Conformal Prediction and Contraction Analysis**|Glen Chou Team|[2510.07725](http://arxiv.org/abs/2510.07725)|null|
|**2025-10-08**|**DPL: Depth-only Perceptive Humanoid Locomotion via Realistic Depth Synthesis and Cross-Attention Terrain Reconstruction**|Qiang Zhang Team|[2510.07152](http://arxiv.org/abs/2510.07152)|null|
|**2025-10-07**|**A Co-Design Framework for Energy-Aware Monoped Jumping with Detailed Actuator Modeling**|Shishir Kolathaya Team|[2510.05923](http://arxiv.org/abs/2510.05923)|null|
|**2025-10-06**|**Walking, Rolling, and Beyond: First-Principles and RL Locomotion on a TARS-Inspired Robot**|Abhishek Warrier Team|[2510.05001](http://arxiv.org/abs/2510.05001)|null|
|**2025-10-05**|**Stability-Aware Retargeting for Humanoid Multi-Contact Teleoperation**|Robert Griffin Team|[2510.04353](http://arxiv.org/abs/2510.04353)|null|
|**2025-10-03**|**LapSurgie: Humanoid Robots Performing Surgery via Teleoperated Handheld Laparoscopy**|Michael C. Yip Team|[2510.03529](http://arxiv.org/abs/2510.03529)|null|
|**2025-10-03**|**Embracing Evolution: A Call for Body-Control Co-Design in Embodied Humanoid Robot**|Kui Jia Team|[2510.03081](http://arxiv.org/abs/2510.03081)|null|
|**2025-10-03**|**HumanoidExo: Scalable Whole-Body Humanoid Manipulation via Wearable Exoskeleton**|Yi Xu Team|[2510.03022](http://arxiv.org/abs/2510.03022)|null|
|**2025-10-02**|**Retargeting Matters: General Motion Retargeting for Humanoid Motion Tracking**|C. Karen Liu Team|[2510.02252](http://arxiv.org/abs/2510.02252)|null|
|**2025-10-02**|**Stand Up, NAO! Increasing the Reliability of Stand-Up Motions Through Error Compensation in Position Control**|Tim Laue Team|[2510.02129](http://arxiv.org/abs/2510.02129)|null|
|**2025-10-02**|**Like Playing a Video Game: Spatial-Temporal Optimization of Foot Trajectories for Controlled Football Kicking in Bipedal Robots**|Peng Lu Team|[2510.01843](http://arxiv.org/abs/2510.01843)|null|
|**2025-09-30**|**Learning Human Reaching Optimality Principles from Minimal Observation Inverse Reinforcement Learning**|Ludovic Righetti Team|[2510.00329](http://arxiv.org/abs/2510.00329)|null|
|**2025-09-30**|**OmniRetarget: Interaction-Preserving Data Generation for Humanoid Whole-Body Loco-Manipulation and Scene Interaction**|Guanya Shi Team|[2509.26633](http://arxiv.org/abs/2509.26633)|**[link](https://omniretarget.github.io)**|
|**2025-09-30**|**ISyHand: A Dexterous Multi-finger Robot Hand with an Articulated Palm**|Katherine J. Kuchenbecker Team|[2509.26236](http://arxiv.org/abs/2509.26236)|null|
|**2025-09-30**|**Evolutionary Continuous Adaptive RL-Powered Co-Design for Humanoid Chin-Up Performance**|Frank Kirchner Team|[2509.26082](http://arxiv.org/abs/2509.26082)|null|
|**2025-09-29**|**CoTaP: Compliant Task Pipeline and Reinforcement Learning of Its Controller with Compliance Modulation**|Yoshihiko Nakamura Team|[2509.25443](http://arxiv.org/abs/2509.25443)|null|
|**2025-09-29**|**Stabilizing Humanoid Robot Trajectory Generation via Physics-Informed Learning and Control-Informed Steering**|Daniele Pucci Team|[2509.24697](http://arxiv.org/abs/2509.24697)|null|
|**2025-09-29**|**Game Theory to Study Cooperation in Human-Robot Mixed Groups: Exploring the Potential of the Public Good Game**|Alessandra Sciutti Team|[2509.24530](http://arxiv.org/abs/2509.24530)|null|
|**2025-09-29**|**Preference-Based Long-Horizon Robotic Stacking with Multimodal Large Language Models**|Sethu Vijayakumar Team|[2509.24163](http://arxiv.org/abs/2509.24163)|null|
|**2025-09-28**|**SIG-Chat: Spatial Intent-Guided Conversational Gesture Generation Involving How, When and Where**|Chuanchen Luo Team|[2509.23852](http://arxiv.org/abs/2509.23852)|null|
|**2025-09-25**|**SEEC: Stable End-Effector Control with Model-Enhanced Residual Learning for Humanoid Loco-Manipulation**|Ye Zhao Team|[2509.21231](http://arxiv.org/abs/2509.21231)|null|
|**2025-09-25**|**RuN: Residual Policy for Natural Humanoid Locomotion**|Yong Liu Team|[2509.20696](http://arxiv.org/abs/2509.20696)|null|
|**2025-09-24**|**Large Pre-Trained Models for Bimanual Manipulation in 3D**|David Meger Team|[2509.20579](http://arxiv.org/abs/2509.20579)|null|
|**2025-09-24**|**VisualMimic: Visual Humanoid Loco-Manipulation via Motion Tracking and Generation**|Jiajun Wu Team|[2509.20322](http://arxiv.org/abs/2509.20322)|**[link](https://visualmimic.github.io)**|
|**2025-09-24**|**HL-IK: A Lightweight Implementation of Human-Like Inverse Kinematics in Humanoid Arms**|Houde Liu Team|[2509.20263](http://arxiv.org/abs/2509.20263)|null|
|**2025-09-23**|**Chasing Stability: Humanoid Running via Control Lyapunov Function Guided Reinforcement Learning**|Aaron D. Ames Team|[2509.19573](http://arxiv.org/abs/2509.19573)|null|
|**2025-09-23**|**RoMoCo: Robotic Motion Control Toolbox for Reduced-Order Model-Based Locomotion on Bipedal and Humanoid Robots**|Aaron D. Ames Team|[2509.19545](http://arxiv.org/abs/2509.19545)|null|
|**2025-09-23**|**Residual Off-Policy RL for Finetuning Behavior Cloning Policies**|Anusha Nagabandi Team|[2509.19301](http://arxiv.org/abs/2509.19301)|**[link](https://residual-offpolicy-rl.github.io)**|
|**2025-09-22**|**RL-augmented Adaptive Model Predictive Control for Bipedal Locomotion over Challenging Terrain**|Ye Zhao Team|[2509.18466](http://arxiv.org/abs/2509.18466)|null|
|**2025-09-20**|**HDMI: Learning Interactive Humanoid Whole-Body Control from Human Videos**|Guanya Shi Team|[2509.16757](http://arxiv.org/abs/2509.16757)|null|
|**2025-09-20**|**KungfuBot2: Learning Versatile Motion Skills for Humanoid Whole-Body Control**|Chenjia Bai Team|[2509.16638](http://arxiv.org/abs/2509.16638)|null|
|**2025-09-19**|**A Framework for Optimal Ankle Design of Humanoid Robots**|Daniele Pucci Team|[2509.16469](http://arxiv.org/abs/2509.16469)|null|
|**2025-09-19**|**A Matter of Height: The Impact of a Robotic Object on Human Compliance**|Hadas Erel Team|[2509.16032](http://arxiv.org/abs/2509.16032)|null|
|**2025-09-18**|**Implicit Kinodynamic Motion Retargeting for Human-to-humanoid Imitation Learning**|Haodong Zhang Team|[2509.15443](http://arxiv.org/abs/2509.15443)|null|
|**2025-09-18**|**CAD-Driven Co-Design for Flight-Ready Jet-Powered Humanoids**|Daniele Pucci Team|[2509.14935](http://arxiv.org/abs/2509.14935)|null|
|**2025-09-18**|**RealMirror: A Comprehensive, Open-Source Vision-Language-Action Platform for Embodied AI**|Tao Shen Team|[2509.14687](http://arxiv.org/abs/2509.14687)|null|
|**2025-09-17**|**Cybersecurity AI: Humanoid Robots as Attack Vectors**|Kevin Finisterre Team|[2509.14139](http://arxiv.org/abs/2509.14139)|null|
|**2025-09-17**|**The Cybersecurity of a Humanoid Robot**|Víctor Mayoral-Vilches Team|[2509.14096](http://arxiv.org/abs/2509.14096)|null|
|**2025-09-17**|**Behavior Foundation Model for Humanoid Robots**|Jiangmiao Pang Team|[2509.13780](http://arxiv.org/abs/2509.13780)|null|
|**2025-09-17**|**FSR-VLN: Fast and Slow Reasoning for Vision-Language Navigation with Hierarchical Multi-modal Scene Graph**|Zhizhong Su Team|[2509.13733](http://arxiv.org/abs/2509.13733)|**[link](https://horizonrobotics.github.io/robot_lab/fsr-vln/)**|
|**2025-09-16**|**Embracing Bulky Objects with Humanoid Robots: Whole-Body Manipulation with Reinforcement Learning**|Jun Ma Team|[2509.13534](http://arxiv.org/abs/2509.13534)|null|
|**2025-09-16**|**StageACT: Stage-Conditioned Imitation for Robust Humanoid Door Opening**|Shayegan Omidshafiei Team|[2509.13200](http://arxiv.org/abs/2509.13200)|null|
|**2025-09-14**|**Quantum deep reinforcement learning for humanoid robot navigation task**|Ahmed Biyabani Team|[2509.11388](http://arxiv.org/abs/2509.11388)|null|
|**2025-09-14**|**FEWT: Improving Humanoid Robot Perception with Frequency-Enhanced Wavelet-based Transformers**|Zhigong Song Team|[2509.11109](http://arxiv.org/abs/2509.11109)|null|
|**2025-09-12**|**Data-fused Model Predictive Control with Guarantees: Application to Flying Humanoid Robots**|Daniele Pucci Team|[2509.10353](http://arxiv.org/abs/2509.10353)|null|
|**2025-09-11**|**MimicDroid: In-Context Learning for Humanoid Robot Manipulation from Human Play Videos**|Yuke Zhu Team|[2509.09769](http://arxiv.org/abs/2509.09769)|null|
|**2025-09-11**|**AGILOped: Agile Open-Source Humanoid Robot for Research**|Sven Behnke Team|[2509.09364](http://arxiv.org/abs/2509.09364)|null|
|**2025-09-11**|**LIPM-Guided Reinforcement Learning for Stable and Perceptive Locomotion in Bipedal Robots**|Hua Chen Team|[2509.09106](http://arxiv.org/abs/2509.09106)|null|
|**2025-09-09**|**Attribute-based Object Grounding and Robot Grasp Detection with Spatial Reasoning**|Changhyun Choi Team|[2509.08126](http://arxiv.org/abs/2509.08126)|null|
|**2025-09-09**|**Interactive Shaping of Granular Media Using Reinforcement Learning**|Maren Bennewitz Team|[2509.06469](http://arxiv.org/abs/2509.06469)|null|
|**2025-09-06**|**Learning to Walk in Costume: Adversarial Motion Priors for Aesthetically Constrained Humanoids**|Dennis W. Hong Team|[2509.05581](http://arxiv.org/abs/2509.05581)|null|
|**2025-09-05**|**Hierarchical Reduced-Order Model Predictive Control for Robust Locomotion on Humanoid Robots**|Aaron D. Ames Team|[2509.04722](http://arxiv.org/abs/2509.04722)|null|
|**2025-09-03**|**The Role of Embodiment in Intuitive Whole-Body Teleoperation for Mobile Manipulation**|Georgia Chalvatzaki Team|[2509.03222](http://arxiv.org/abs/2509.03222)|null|
|**2025-09-03**|**CTBC: Contact-Triggered Blind Climbing for Wheeled Bipedal Robots with Instruction Learning and Reinforcement Learning**|Wenlong Liao Team|[2509.02986](http://arxiv.org/abs/2509.02986)|null|
|**2025-09-01**|**ManiFlow: A General Robot Manipulation Policy via Consistency Flow Training**|Dieter Fox Team|[2509.01819](http://arxiv.org/abs/2509.01819)|null|
|**2025-08-29**|**First Order Model-Based RL through Decoupled Backpropagation**|Ludovic Righetti Team|[2509.00215](http://arxiv.org/abs/2509.00215)|**[link](https://machines-in-motion.github.io/DMO/)**|
|**2025-08-28**|**HITTER: A HumanoId Table TEnnis Robot via Hierarchical Planning and Learning**|S. Shankar Sastry Team|[2508.21043](http://arxiv.org/abs/2508.21043)|null|
|**2025-08-28**|**Traversing Narrow Paths: A Two-Stage Reinforcement Learning Framework for Robust and Safe Humanoid Walking**|Shiwu Zhang Team|[2508.20661](http://arxiv.org/abs/2508.20661)|**[link](https://huangtc233.github.io/Traversing-the-Narrow-Path/)**|
|**2025-08-26**|**HuBE: Cross-Embodiment Human-like Behavior Execution for Humanoid Robots**|Guodong Guo Team|[2508.19002](http://arxiv.org/abs/2508.19002)|null|
|**2025-08-21**|**PriorFormer: A Transformer for Real-time Monocular 3D Human Pose Estimation with Versatile Geometric Priors**|Vincent Bonnet Team|[2508.18238](http://arxiv.org/abs/2508.18238)|null|
|**2025-08-25**|**Analysis of Harpy's Constrained Trotting and Jumping Maneuver**|Prathima Ananda Kumar Team|[2508.18139](http://arxiv.org/abs/2508.18139)|null|
|**2025-08-25**|**MEVITA: Open-Source Bipedal Robot Assembled from E-Commerce Components via Sheet Metal Welding**|Kei Okada Team|[2508.17684](http://arxiv.org/abs/2508.17684)|**[link](https://haraduka.github.io/mevita-hardware)**|
|**2025-08-24**|**SoK: Cybersecurity Assessment of Humanoid Ecosystem**|Yuval Elovici Team|[2508.17481](http://arxiv.org/abs/2508.17481)|null|
|**2025-08-20**|**LookOut: Real-World Humanoid Egocentric Navigation**|Leonidas J. Guibas Team|[2508.14466](http://arxiv.org/abs/2508.14466)|null|
|**2025-08-18**|**Accelerating Signal-Temporal-Logic-Based Task and Motion Planning of Bipedal Navigation using Benders Decomposition**|Ye Zhao Team|[2508.13407](http://arxiv.org/abs/2508.13407)|null|
|**2025-08-18**|**Scaling Whole-body Multi-contact Manipulation with Contact Optimization**|Sethu Vijayakumar Team|[2508.12980](http://arxiv.org/abs/2508.12980)|null|
|**2025-08-18**|**Foundation Model for Skeleton-Based Human Action Understanding**|Liang Wang Team|[2508.12586](http://arxiv.org/abs/2508.12586)|**[link](https://github.com/wengwanjiang/FoundSkelModel)**|
|**2025-08-17**|**Robot Trains Robot: Automatic Real-World Policy Adaptation and Learning for Humanoids**|Shuran Song Team|[2508.12252](http://arxiv.org/abs/2508.12252)|null|
|**2025-08-17**|**Humanoid Motion Scripting with Postural Synergies**|Oussama Khatib Team|[2508.12184](http://arxiv.org/abs/2508.12184)|null|
|**2025-08-16**|**No More Blind Spots: Learning Vision-Based Omnidirectional Bipedal Locomotion for Challenging Terrain**|Alan Fern Team|[2508.11929](http://arxiv.org/abs/2508.11929)|null|
|**2025-08-16**|**Contact-Rich and Deformable Foot Modeling for Locomotion Control of the Human Musculoskeletal System**|Yanan Sui Team|[2508.11885](http://arxiv.org/abs/2508.11885)|null|
|**2025-08-16**|**From Screen to Stage: Kid Cosmo, A Life-Like, Torque-Controlled Humanoid for Entertainment Robotics**|Dennis W. Hong Team|[2508.11884](http://arxiv.org/abs/2508.11884)|null|
|**2025-08-15**|**Anticipatory and Adaptive Footstep Streaming for Teleoperated Bipedal Robots**|Robert Griffin Team|[2508.11802](http://arxiv.org/abs/2508.11802)|null|
|**2025-08-15**|**A Comparative Study of Floating-Base Space Parameterizations for Agile Whole-Body Motion Planning**|Konstantinos Chatzilygeroudis Team|[2508.11520](http://arxiv.org/abs/2508.11520)|null|
|**2025-08-15**|**Pedestrian Dead Reckoning using Invariant Extended Kalman Filter**|Jiahao Chen Team|[2508.11396](http://arxiv.org/abs/2508.11396)|null|
|**2025-08-15**|**Learning Differentiable Reachability Maps for Optimization-based Humanoid Motion Generation**|Fumio Kanehiro Team|[2508.11275](http://arxiv.org/abs/2508.11275)|null|
|**2025-08-15**|**Geometry-Aware Predictive Safety Filters on Humanoids: From Poisson Safety Functions to CBF Constrained MPC**|Aaron D. Ames Team|[2508.11129](http://arxiv.org/abs/2508.11129)|null|
|**2025-08-14**|**MASH: Cooperative-Heterogeneous Multi-Agent Reinforcement Learning for Single Humanoid Robot Locomotion**|Yanjie Li Team|[2508.10423](http://arxiv.org/abs/2508.10423)|null|
|**2025-08-14**|**Hybrid Data-Driven Predictive Control for Robust and Reactive Exoskeleton Locomotion Synthesis**|Aaron D. Ames Team|[2508.10269](http://arxiv.org/abs/2508.10269)|null|
|**2025-08-13**|**GBC: Generalized Behavior-Cloning Framework for Whole-Body Humanoid Imitation**|Jun-Guo Lu Team|[2508.09960](http://arxiv.org/abs/2508.09960)|null|
|**2025-08-12**|**CLF-RL: Control Lyapunov Function Guided Reinforcement Learning**|Aaron D. Ames Team|[2508.09354](http://arxiv.org/abs/2508.09354)|null|
|**2025-07-17**|**Humanoid Robot Acrobatics Utilizing Complete Articulated Rigid Body Dynamics**|Gerald Brantner Team|[2508.08258](http://arxiv.org/abs/2508.08258)|null|
|**2025-08-11**|**BeyondMimic: From Motion Tracking to Versatile Humanoid Control via Guided Diffusion**|C. Karen Liu Team|[2508.08241](http://arxiv.org/abs/2508.08241)|**[link](https://beyondmimic.github.io/)**|
|**2025-08-11**|**PCHands: PCA-based Hand Pose Synergy Representation on Manipulators with N-DoF**|Lorenzo Natale Team|[2508.07945](http://arxiv.org/abs/2508.07945)|null|
|**2025-08-11**|**End-to-End Humanoid Robot Safe and Comfortable Locomotion Policy**|Junwei Liang Team|[2508.07611](http://arxiv.org/abs/2508.07611)|null|
|**2025-08-09**|**Learning a Vision-Based Footstep Planner for Hierarchical Walking Control**|Michael Posa Team|[2508.06779](http://arxiv.org/abs/2508.06779)|null|
|**2025-08-07**|**Examining the legibility of humanoid robot arm movements in a pointing task**|Igor Farkaš Team|[2508.05104](http://arxiv.org/abs/2508.05104)|null|
|**2025-08-06**|**INTENTION: Inferring Tendencies of Humanoid Robot Motion Through Interactive Intuition and Grounded VLM**|Nikos Tsagarakis Team|[2508.04931](http://arxiv.org/abs/2508.04931)|**[link](https://robo-intention.github.io)**|
|**2025-08-06**|**On the causality between affective impact and coordinated human-robot reactions**|Kasper Støy Team|[2508.04834](http://arxiv.org/abs/2508.04834)|null|
|**2025-08-06**|**Achieving Precise and Reliable Locomotion with Differentiable Simulation-Based System Identification**|Roman Gorbachev Team|[2508.04696](http://arxiv.org/abs/2508.04696)|null|
|**2025-08-06**|**Binaural Sound Event Localization and Detection Neural Network based on HRTF Localization Cues for Humanoid Robots**|Gyeong-Tae Lee Team|[2508.04333](http://arxiv.org/abs/2508.04333)|null|
|**2025-08-05**|**Optimizing Bipedal Locomotion for The 100m Dash With Comparison to Human Running**|Alan Fern Team|[2508.03070](http://arxiv.org/abs/2508.03070)|**[link](https://ieeexplore.ieee.org/document/10160436)**|
|**2025-08-04**|**Would you let a humanoid play storytelling with your child? A usability study on LLM-powered narrative Human-Robot Interaction**|Agnieszka Wykowska Team|[2508.02505](http://arxiv.org/abs/2508.02505)|null|
|**2025-08-04**|**Constrained Reinforcement Learning for Unstable Point-Feet Bipedal Locomotion Applied to the Bolt Robot**|Philippe Souères Team|[2508.02194](http://arxiv.org/abs/2508.02194)|null|
|**2025-08-04**|**Towards Immersive Human-X Interaction: A Real-Time Framework for Physically Plausible Motion Synthesis**|Jingya Wang Team|[2508.02106](http://arxiv.org/abs/2508.02106)|null|
|**2025-08-02**|**Coordinated Humanoid Robot Locomotion with Symmetry Equivariant Reinforcement Learning Policy**|Yue Gao Team|[2508.01247](http://arxiv.org/abs/2508.01247)|null|
|**2025-07-31**|**BarlowWalk: Self-supervised Representation Learning for Legged Robot Terrain-adaptive Locomotion**|Wenfu Xu Team|[2508.00939](http://arxiv.org/abs/2508.00939)|null|
|**2025-08-01**|**A Whole-Body Motion Imitation Framework from Human Data for Full-Size Humanoid Robot**|Rong Xiong Team|[2508.00362](http://arxiv.org/abs/2508.00362)|null|
|**2025-08-01**|**TOP: Time Optimization Policy for Stable and Accurate Standing Manipulation with Humanoid Robots**|Rong Xiong Team|[2508.00355](http://arxiv.org/abs/2508.00355)|null|
|**2025-07-31**|**CHILD (Controller for Humanoid Imitation and Live Demonstration): a Whole-Body Humanoid Teleoperation System**|Joohyung Kim Team|[2508.00162](http://arxiv.org/abs/2508.00162)|null|
|**2025-07-31**|**The Monado SLAM Dataset for Egocentric Visual-Inertial Tracking**|Taihú Pire Team|[2508.00088](http://arxiv.org/abs/2508.00088)|null|
|**2025-07-28**|**Binaural Sound Event Localization and Detection based on HRTF Cues for Humanoid Robots**|Yong-Hwa Park Team|[2507.20530](http://arxiv.org/abs/2507.20530)|null|
|**2025-07-28**|**LLMs-guided adaptive compensator: Bringing Adaptivity to Automatic Control Systems with Large Language Models**|Yusuke Iwasawa Team|[2507.20509](http://arxiv.org/abs/2507.20509)|null|
|**2025-07-27**|**Humanoid Occupancy: Enabling A Generalized Multimodal Occupancy Perception System on Humanoid Robots**|Qiang Zhang Team|[2507.20217](http://arxiv.org/abs/2507.20217)|null|
|**2025-07-27**|**LRR-Bench: Left, Right or Rotate? Vision-Language models Still Struggle With Spatial Understanding Tasks**|Xiaoshuang Shi Team|[2507.20174](http://arxiv.org/abs/2507.20174)|null|
|**2025-07-25**|**How Age Influences the Interpretation of Emotional Body Language in Humanoid Robots -- long paper version**|Giuseppe Palestra Team|[2507.19335](http://arxiv.org/abs/2507.19335)|null|
|**2025-07-24**|**Experimental Comparison of Whole-Body Control Formulations for Humanoid Robots in Task Acceleration and Task Force Spaces**|Christian Ott Team|[2507.18502](http://arxiv.org/abs/2507.18502)|**[link](https://youtu.be/Nfm50ycz-FU)**|
|**2025-07-22**|**Humanoid Robot Whole-body Geometric Calibration with Embedded Sensors and a Single Plane**|Florent Lamiraux Team|[2507.16369](http://arxiv.org/abs/2507.16369)|null|
|**2025-07-20**|**Integrating Reason-Based Moral Decision-Making in the Reinforcement Learning Architecture**|Lisa Dargasz Team|[2507.15895](http://arxiv.org/abs/2507.15895)|null|
|**2025-07-21**|**EMP: Executable Motion Prior for Humanoid Robot Standing Upper-body Motion Imitation**|Rong Xiong Team|[2507.15649](http://arxiv.org/abs/2507.15649)|null|
|**2025-07-18**|**Iteratively Learning Muscle Memory for Legged Robots to Master Adaptive and High Precision Locomotion**|Amit K. Sanyal Team|[2507.13662](http://arxiv.org/abs/2507.13662)|null|
|**2025-07-15**|**Robot Drummer: Learning Rhythmic Skills for Humanoid Drumming**|Loris Roveda Team|[2507.11498](http://arxiv.org/abs/2507.11498)|null|
|**2025-07-15**|**From Production Logistics to Smart Manufacturing: The Vision for a New RoboCup Industrial League**|Shohei Yasuda Team|[2507.11402](http://arxiv.org/abs/2507.11402)|null|
|**2025-07-14**|**Robust RL Control for Bipedal Locomotion with Closed Kinematic Chains**|Evgeny Ponomarev Team|[2507.10164](http://arxiv.org/abs/2507.10164)|null|
|**2025-07-14**|**Physics-Informed Neural Networks with Unscented Kalman Filter for Sensorless Joint Torque Estimation in Humanoid Robots**|Daniele Pucci Team|[2507.10105](http://arxiv.org/abs/2507.10105)|null|
|**2025-07-11**|**Keep on Going: Learning Robust Humanoid Motion Skills via Selective Adversarial Training**|Yue Gao Team|[2507.08303](http://arxiv.org/abs/2507.08303)|null|
|**2025-07-10**|**UniTracker: Learning Universal Whole-Body Motion Tracker for Humanoid Robots**|Weinan Zhang Team|[2507.07356](http://arxiv.org/abs/2507.07356)|null|
|**2025-07-09**|**ULC: A Unified and Fine-Grained Controller for Humanoid Loco-Manipulation**|Zongwu Xie Team|[2507.06905](http://arxiv.org/abs/2507.06905)|null|
|**2025-07-08**|**Evaluating Robots Like Human Infants: A Case Study of Learned Bipedal Locomotion**|Alan Fern Team|[2507.06426](http://arxiv.org/abs/2507.06426)|null|
|**2025-07-08**|**Learning to Evaluate Autonomous Behaviour in Human-Robot Interaction**|Alessio Del Bue Team|[2507.06404](http://arxiv.org/abs/2507.06404)|null|
|**2025-07-05**|**Learning Humanoid Arm Motion via Centroidal Momentum Regularized Multi-Agent Reinforcement Learning**|Sangbae Kim Team|[2507.04140](http://arxiv.org/abs/2507.04140)|null|
|**2025-07-01**|**HumanoidGen: Data Generation for Bimanual Dexterous Manipulation via LLM Reasoning**|Chenjia Bai Team|[2507.00833](http://arxiv.org/abs/2507.00833)|**[link](https://openhumanoidgen.github.io)**|
|**2025-06-30**|**Mechanical Intelligence-Aware Curriculum Reinforcement Learning for Humanoids with Parallel Actuation**|Dennis Hong Team|[2507.00273](http://arxiv.org/abs/2507.00273)|null|
|**2025-06-29**|**DexH2R: A Benchmark for Dynamic Dexterous Grasping in Human-to-Robot Handover**|Yuexin Ma Team|[2506.23152](http://arxiv.org/abs/2506.23152)|**[link](https://dexh2r.github.io/)**|
|**2025-06-29**|**Learning Motion Skills with Adaptive Assistive Curriculum Force in Humanoid Robots**|Yue Gao Team|[2506.23125](http://arxiv.org/abs/2506.23125)|null|
|**2025-06-28**|**Hierarchical Vision-Language Planning for Multi-Step Humanoid Manipulation**|Navid Azizan Team|[2506.22827](http://arxiv.org/abs/2506.22827)|null|
|**2025-06-20**|**Unsupervised Discovery of Behavioral Primitives from Sensorimotor Dynamic Functional Connectivity**|Matej Hoffmann Team|[2506.22473](http://arxiv.org/abs/2506.22473)|null|
|**2025-06-24**|**Ark: An Open-source Python-based Framework for Robot Learning**|Haitham Bou-Ammar Team|[2506.21628](http://arxiv.org/abs/2506.21628)|null|
|**2025-06-25**|**A Survey of Behavior Foundation Model: Next-Generation Whole-Body Control System of Humanoid Robots**|Wenjun Zeng Team|[2506.20487](http://arxiv.org/abs/2506.20487)|null|
|**2025-06-19**|**DualTHOR: A Dual-Arm Humanoid Simulation Platform for Contingency-Aware Planning**|Zongqing Lu Team|[2506.16012](http://arxiv.org/abs/2506.16012)|null|
|**2025-06-18**|**TACT: Humanoid Whole-body Contact Manipulation through Deep Imitation Learning with Tactile Modality**|Eiichi Yoshida Team|[2506.15146](http://arxiv.org/abs/2506.15146)|null|
|**2025-06-18**|**Booster Gym: An End-to-End Reinforcement Learning Framework for Humanoid Robot Locomotion**|Mingguo Zhao Team|[2506.15132](http://arxiv.org/abs/2506.15132)|null|
|**2025-06-17**|**GMT: General Motion Tracking for Humanoid Whole-Body Control**|Xiaolong Wang Team|[2506.14770](http://arxiv.org/abs/2506.14770)|null|
|**2025-06-17**|**Whole-Body Control Framework for Humanoid Robots with Heavy Limbs: A Model-Based Approach**|Yun-Hui Liu Team|[2506.14278](http://arxiv.org/abs/2506.14278)|null|
|**2025-06-15**|**KungfuBot: Physics-Based Humanoid Whole-Body Control for Learning Highly-Dynamic Skills**|Xuelong Li Team|[2506.12851](http://arxiv.org/abs/2506.12851)|**[link](https://kungfu-bot.github.io/)**|
|**2025-06-15**|**From Experts to a Generalist: Toward General Whole-Body Control for Humanoid Robots**|Zongqing Lu Team|[2506.12779](http://arxiv.org/abs/2506.12779)|null|
|**2025-06-15**|**RL from Physical Feedback: Aligning Large Motion Models with Humanoid Control**|Zongqing Lu Team|[2506.12769](http://arxiv.org/abs/2506.12769)|null|
|**2025-06-14**|**Explosive Output to Enhance Jumping Ability: A Variable Reduction Ratio Design Paradigm for Humanoid Robots Knee Joint**|Qiang Huang Team|[2506.12314](http://arxiv.org/abs/2506.12314)|null|
|**2025-06-13**|**mimic-one: a Scalable Model Recipe for General Purpose Robot Dexterity**|Robert K. Katzschmann Team|[2506.11916](http://arxiv.org/abs/2506.11916)|null|
|**2025-06-11**|**Exploring EEG Responses during Observation of Actions Performed by Human Actor and Humanoid Robot**|Michelle J. Johnson Team|[2506.10170](http://arxiv.org/abs/2506.10170)|null|
|**2025-06-11**|**Locomotion on Constrained Footholds via Layered Architectures and Model Predictive Control**|Aaron D. Ames Team|[2506.09979](http://arxiv.org/abs/2506.09979)|null|
|**2025-06-11**|**Attention-Based Map Encoding for Learning Generalized Legged Locomotion**|Marco Hutter Team|[2506.09588](http://arxiv.org/abs/2506.09588)|null|
|**2025-06-11**|**Bipedal Balance Control with Whole-body Musculoskeletal Standing and Falling Simulations**|Yanan Sui Team|[2506.09383](http://arxiv.org/abs/2506.09383)|null|
|**2025-06-11**|**SkillBlender: Towards Versatile Humanoid Whole-Body Loco-Manipulation via Skill Blending**|Yue Wang Team|[2506.09366](http://arxiv.org/abs/2506.09366)|null|
|**2025-06-10**|**Fast Estimation of Globally Optimal Independent Contact Regions for Robust Grasping and Manipulation**|Nancy S. Pollard Team|[2506.08856](http://arxiv.org/abs/2506.08856)|null|
|**2025-06-10**|**MoRE: Mixture of Residual Experts for Humanoid Lifelike Gaits Learning on Complex Terrains**|Xuelong Li Team|[2506.08840](http://arxiv.org/abs/2506.08840)|null|
|**2025-06-10**|**Periodic Bipedal Gait Learning Using Reward Composition Based on a Novel Gait Planner for Humanoid Robots**|Lijun Zhu Team|[2506.08416](http://arxiv.org/abs/2506.08416)|null|
|**2025-06-08**|**Model Analysis And Design Of Ellipse Based Segmented Varying Curved Foot For Biped Robot Walking**|Jie Zhao Team|[2506.07283](http://arxiv.org/abs/2506.07283)|null|
|**2025-06-05**|**Realizing Text-Driven Motion Generation on NAO Robot: A Reinforcement Learning-Optimized Control Pipeline**|Qijun Chen Team|[2506.05117](http://arxiv.org/abs/2506.05117)|null|
|**2025-06-05**|**Application of SDRE to Achieve Gait Control in a Bipedal Robot for Knee-Type Exoskeleton Testing**|Chin-Tien Wu Team|[2506.04680](http://arxiv.org/abs/2506.04680)|null|
|**2025-06-04**|**Phase-based Nonlinear Model Predictive Control for Humanoid Walking Stabilization with Single and Double Support Time Adjustments**|Jaeheung Park Team|[2506.03856](http://arxiv.org/abs/2506.03856)|null|
|**2025-06-03**|**AURA: Autonomous Upskilling with Retrieval-Augmented Agents**|Dennis Hong Team|[2506.02507](http://arxiv.org/abs/2506.02507)|null|
|**2025-06-02**|**Reinforcement Learning with Data Bootstrapping for Dynamic Subgoal Pursuit in Humanoid Robot Navigation**|Ayonga Hereid Team|[2506.02206](http://arxiv.org/abs/2506.02206)|null|
|**2025-06-02**|**Learning with pyCub: A New Simulation and Exercise Framework for Humanoid Robotics**|Matej Hoffmann Team|[2506.01756](http://arxiv.org/abs/2506.01756)|null|
|**2025-06-02**|**Hierarchical Intention-Aware Expressive Motion Generation for Humanoid Robots**|Chengxu Zhou Team|[2506.01563](http://arxiv.org/abs/2506.01563)|null|
|**2025-06-01**|**Humanoid World Models: Open World Foundation Models for Humanoid Robotics**|Mohammad Al-Sharman Team|[2506.01182](http://arxiv.org/abs/2506.01182)|null|
|**2025-06-01**|**Standing Tall: Robust Fall Prediction for Bipedal Robots**|M. Eva Mungai Team|[2506.01141](http://arxiv.org/abs/2506.01141)|null|
|**2025-06-01**|**iRonCub 3: The Jet-Powered Flying Humanoid Robot**|Daniele Pucci Team|[2506.01125](http://arxiv.org/abs/2506.01125)|null|
|**2025-06-01**|**STATE-NAV: Stability-Aware Traversability Estimation for Bipedal Navigation on Rough Terrain**|Ye Zhao Team|[2506.01046](http://arxiv.org/abs/2506.01046)|null|
|**2025-05-30**|**Learning Aerodynamics for the Control of Flying Humanoid Robots**|Daniele Pucci Team|[2506.00305](http://arxiv.org/abs/2506.00305)|null|
|**2025-05-30**|**Interactive Imitation Learning for Dexterous Robotic Manipulation: Challenges and Perspectives -- A Survey**|Rania Rayyes Team|[2506.00098](http://arxiv.org/abs/2506.00098)|null|
|**2025-05-29**|**Human sensory-musculoskeletal modeling and control of whole-body movements**|Yanan Sui Team|[2506.00071](http://arxiv.org/abs/2506.00071)|null|
|**2025-05-30**|**SignBot: Learning Human-to-Humanoid Sign Language Interaction**|Guiliang Liu Team|[2505.24266](http://arxiv.org/abs/2505.24266)|null|
|**2025-05-30**|**Humanoid Loco-Manipulations Pattern Generation and Stabilization Control**|Abderrahmane Kheddar Team|[2505.24116](http://arxiv.org/abs/2505.24116)|null|
|**2025-05-29**|**Humanoid Loco-manipulation Planning based on Graph Search and Reachability Maps**|Abderrahmane Kheddar Team|[2505.23505](http://arxiv.org/abs/2505.23505)|null|
|**2025-05-29**|**Centroidal Trajectory Generation and Stabilization based on Preview Control for Humanoid Multi-contact Motion**|Fumio Kanehiro Team|[2505.23499](http://arxiv.org/abs/2505.23499)|null|
|**2025-05-28**|**FastTD3: Simple, Fast, and Capable Reinforcement Learning for Humanoid Control**|Pieter Abbeel Team|[2505.22642](http://arxiv.org/abs/2505.22642)|**[link](https://younggyo.me/fast_td3)**|
|**2025-05-27**|**Learning a Unified Policy for Position and Force Control in Legged Loco-Manipulation**|Siyuan Huang Team|[2505.20829](http://arxiv.org/abs/2505.20829)|**[link](https://unified-force.github.io/)**|
|**2025-05-27**|**Gait-Conditioned Reinforcement Learning with Multi-Phase Curriculum for Humanoid Locomotion**|Chengxu Zhou Team|[2505.20619](http://arxiv.org/abs/2505.20619)|null|
|**2025-05-26**|**Integrating emotional intelligence, memory architecture, and gestures to achieve empathetic humanoid robot interaction in an educational setting**|Paul Craig Team|[2505.19803](http://arxiv.org/abs/2505.19803)|null|
|**2025-05-26**|**Extremum Flow Matching for Offline Goal Conditioned Reinforcement Learning**|Jean-Baptiste Mouret Team|[2505.19717](http://arxiv.org/abs/2505.19717)|null|
|**2025-05-26**|**Whole-body Multi-contact Motion Control for Humanoid Robots Based on Distributed Tactile Sensors**|Eiichi Yoshida Team|[2505.19580](http://arxiv.org/abs/2505.19580)|null|
|**2025-05-26**|**Real-time Whole-body Model Predictive Control for Bipedal Locomotion with a Novel Kino-dynamic Model and Warm-start Method**|Jaeheung Park Team|[2505.19540](http://arxiv.org/abs/2505.19540)|null|
|**2025-05-26**|**Heavy lifting tasks via haptic teleoperation of a wheeled humanoid**|Joao Ramos Team|[2505.19530](http://arxiv.org/abs/2505.19530)|null|
|**2025-05-26**|**SMAP: Self-supervised Motion Adaptation for Physically Plausible Humanoid Whole-body Control**|Junting Dong Team|[2505.19463](http://arxiv.org/abs/2505.19463)|null|
|**2025-05-25**|**Towards Humanoid Robot Autonomy: A Dynamic Architecture Integrating Continuous thought Machines (CTM) and Model Context Protocol (MCP)**|Libo Wang Team|[2505.19339](http://arxiv.org/abs/2505.19339)|**[link](https://github.com/brucewang123456789/GeniusTrail/tree/main/CTM-MCP)**|
|**2025-05-25**|**Staircase Recognition and Location Based on Polarization Vision**|Zhiying Tan Team|[2505.19026](http://arxiv.org/abs/2505.19026)|null|
|**2025-05-23**|**HACL: History-Aware Curriculum Learning for Fast Locomotion**|Dinesh Manocha Team|[2505.18429](http://arxiv.org/abs/2505.18429)|null|
|**2025-05-23**|**DanceTogether! Identity-Preserving Multi-Person Interactive Video Generation**|Ruqi Huang Team|[2505.18078](http://arxiv.org/abs/2505.18078)|**[link](https://DanceTog.github.io/)**|
|**2025-05-22**|**Unified Multi-Rate Model Predictive Control for a Jet-Powered Humanoid Robot**|Daniele Pucci Team|[2505.16478](http://arxiv.org/abs/2505.16478)|null|
|**2025-05-19**|**Dynamic Bipedal MPC with Foot-level Obstacle Avoidance and Adjustable Step Timing**|Christian Hubicki Team|[2505.13715](http://arxiv.org/abs/2505.13715)|null|
|**2025-05-19**|**TD-GRPC: Temporal Difference Learning with Group Relative Policy Constraint for Humanoid Locomotion**|Minh Nhat Vu Team|[2505.13549](http://arxiv.org/abs/2505.13549)|null|
|**2025-05-19**|**DreamGen: Unlocking Generalization in Robot Learning through Video World Models**|Linxi Fan Team|[2505.12705](http://arxiv.org/abs/2505.12705)|**[link](https://research.nvidia.com/labs/gear/dreamgen)**|
|**2025-05-19**|**Dribble Master: Learning Agile Humanoid Dribbling Through Legged Locomotion**|Qi Wu Team|[2505.12679](http://arxiv.org/abs/2505.12679)|null|
|**2025-05-18**|**Design of a 3-DOF Hopping Robot with an Optimized Gearbox: An Intermediate Platform Toward Bipedal Robots**|Hae-Won Park Team|[2505.12231](http://arxiv.org/abs/2505.12231)|null|
|**2025-05-16**|**Bracing for Impact: Robust Humanoid Push Recovery and Locomotion with Reduced Order Models**|Aaron D. Ames Team|[2505.11495](http://arxiv.org/abs/2505.11495)|null|
|**2025-05-16**|**X2C: A Dataset Featuring Nuanced Facial Expressions for Realistic Humanoid Imitation**|Xiaohan Yu Team|[2505.11146](http://arxiv.org/abs/2505.11146)|null|
|**2025-05-13**|**NavDP: Learning Sim-to-Real Navigation Diffusion Policy with Privileged Information Guidance**|Jiangmiao Pang Team|[2505.08712](http://arxiv.org/abs/2505.08712)|**[link](https://wzcai99.github.io/navigation-diffusion-policy.github.io/)**|
|**2025-05-13**|**Rethink Repeatable Measures of Robot Performance with Statistical Query**|Dylan Khor Team|[2505.08216](http://arxiv.org/abs/2505.08216)|null|
|**2025-05-12**|**Neural Brain: A Neuroscience-inspired Framework for Embodied Agents**|Lin Wang Team|[2505.07634](http://arxiv.org/abs/2505.07634)|null|
|**2025-05-12**|**HuB: Learning Extreme Humanoid Balance**|Yang Gao Team|[2505.07294](http://arxiv.org/abs/2505.07294)|**[link](https://hub-robot.github.io)**|
|**2025-05-11**|**Dynamic Safety in Complex Environments: Synthesizing Safety Filters with Poisson's Equation**|Aaron D. Ames Team|[2505.06794](http://arxiv.org/abs/2505.06794)|null|
|**2025-05-10**|**JAEGER: Dual-Level Humanoid Whole-Body Controller**|Zongqing Lu Team|[2505.06584](http://arxiv.org/abs/2505.06584)|null|
|**2025-05-09**|**Let Humanoids Hike! Integrative Skill Development on Complex Trails**|Stella X. Yu Team|[2505.06218](http://arxiv.org/abs/2505.06218)|**[link](https://lego-h-humanoidrobothiking.github.io/)**|
|**2025-05-09**|**Safe-EF: Error Feedback for Nonsmooth Constrained Optimization**|Ilyas Fatkhullin Team|[2505.06053](http://arxiv.org/abs/2505.06053)|null|
|**2025-05-09**|**Human-Robot Collaboration for the Remote Control of Mobile Humanoid Robots with Torso-Arm Coordination**|Zhi Li Team|[2505.05773](http://arxiv.org/abs/2505.05773)|null|
|**2025-05-08**|**Zippy: The smallest power-autonomous bipedal robot**|Sarah Bergbreiter Team|[2505.05686](http://arxiv.org/abs/2505.05686)|null|
|**2025-05-07**|**Vision-Language-Action Models: Concepts, Progress, Applications and Challenges**|Manoj Karkee Team|[2505.04769](http://arxiv.org/abs/2505.04769)|null|
|**2025-05-06**|**AMO: Adaptive Motion Optimization for Hyper-Dexterous Humanoid Whole-Body Control**|Xiaolong Wang Team|[2505.03738](http://arxiv.org/abs/2505.03738)|**[link](https://amo-humanoid.github.io)**|
|**2025-05-06**|**Visual Imitation Enables Contextual Humanoid Control**|Angjoo Kanazawa Team|[2505.03729](http://arxiv.org/abs/2505.03729)|**[link](https://www.videomimic.net/)**|
|**2025-05-05**|**TWIST: Teleoperated Whole-Body Imitation System**|C. Karen Liu Team|[2505.02833](http://arxiv.org/abs/2505.02833)|**[link](https://humanoid-teleop.github.io)**|
|**2025-04-30**|**LangWBC: Language-directed Humanoid Whole-Body Control via End-to-end Learning**|Koushil Sreenath Team|[2504.21738](http://arxiv.org/abs/2504.21738)|null|
|**2025-04-29**|**SoccerDiffusion: Toward Learning End-to-End Humanoid Robot Soccer from Gameplay Recordings**|Jianwei Zhang Team|[2504.20808](http://arxiv.org/abs/2504.20808)|null|
|**2025-04-28**|**System Identification of Thrust and Torque Characteristics for a Bipedal Robot with Integrated Propulsion**|Thomas Cahill Team|[2504.20313](http://arxiv.org/abs/2504.20313)|null|
|**2025-04-27**|**Personalized Artificial General Intelligence (AGI) via Neuroscience-Inspired Continuous Learning Systems**|Jairaj Singh Shaktawat Team|[2504.20109](http://arxiv.org/abs/2504.20109)|null|
|**2025-04-25**|**Robust Push Recovery on Bipedal Robots: Leveraging Multi-Domain Hybrid Systems with Reduced-Order Model Predictive Control**|Aaron D. Ames Team|[2504.18698](http://arxiv.org/abs/2504.18698)|null|
|**2025-04-24**|**Demonstrating Berkeley Humanoid Lite: An Open-source, Accessible, and Customizable 3D-printed Humanoid Robot**|Koushil Sreenath Team|[2504.17249](http://arxiv.org/abs/2504.17249)|null|
|**2025-04-20**|**ExFace: Expressive Facial Control for Humanoid Robots with Diffusion Transformers and Bootstrap Training**|Jiahao Chen Team|[2504.14477](http://arxiv.org/abs/2504.14477)|null|
|**2025-04-19**|**Adversarial Locomotion and Motion Imitation for Humanoid Policy Learning**|Xuelong Li Team|[2504.14305](http://arxiv.org/abs/2504.14305)|**[link](https://github.com/TeleHuman/ALMI-Open)**|
|**2025-04-18**|**Robust Humanoid Walking on Compliant and Uneven Terrain with Deep Reinforcement Learning**|Fumio Kanehiro Team|[2504.13619](http://arxiv.org/abs/2504.13619)|null|
|**2025-04-16**|**EmoACT: a Framework to Embed Emotions into Artificial Agents Based on Affect Control Theory**|Carmine Tommaso Recchiuto Team|[2504.12125](http://arxiv.org/abs/2504.12125)|null|
|**2025-04-14**|**Teacher Motion Priors: Enhancing Robot Locomotion over Challenging Terrain**|Zhengtao Zhang Team|[2504.10390](http://arxiv.org/abs/2504.10390)|null|
|**2025-04-14**|**GenTe: Generative Real-world Terrains for General Legged Robot Locomotion Control**|Xiaoqiang Ji Team|[2504.09997](http://arxiv.org/abs/2504.09997)|null|
|**2025-04-14**|**PPF: Pre-training and Preservative Fine-tuning of Humanoid Locomotion via Model-Assumption-based Regularization**|Sehoon Ha Team|[2504.09833](http://arxiv.org/abs/2504.09833)|null|
|**2025-04-13**|**Humanoid Agent via Embodied Chain-of-Action Reasoning with Multimodal Foundation Models for Zero-Shot Loco-Manipulation**|Yi Fang Team|[2504.09532](http://arxiv.org/abs/2504.09532)|**[link](https://humanoid-coa.github.io/)**|
|**2025-04-11**|**Spectral Normalization for Lipschitz-Constrained Policies on Learning Humanoid Locomotion**|Jaeheung Park Team|[2504.08246](http://arxiv.org/abs/2504.08246)|null|
|**2025-04-10**|**TOCALib: Optimal control library with interpolation for bimanual manipulation and obstacles avoidance**|Aleksandr Panov Team|[2504.07708](http://arxiv.org/abs/2504.07708)|null|
|**2025-04-07**|**MotionPRO: Exploring the Role of Pressure in Human MoCap and Beyond**|Xun Cao Team|[2504.05046](http://arxiv.org/abs/2504.05046)|null|
|**2025-04-07**|**A High-Force Gripper with Embedded Multimodal Sensing for Powerful and Perception Driven Grasping**|Nikos G. Tsagarakis Team|[2504.04970](http://arxiv.org/abs/2504.04970)|null|
|**2025-04-06**|**Public speech recognition transcripts as a configuring parameter**|Christian Licoppe Team|[2504.04488](http://arxiv.org/abs/2504.04488)|null|
|**2025-04-03**|**Bipedal Robust Walking on Uneven Footholds: Piecewise Slope LIPM with Discrete Model Predictive Control**|Songhao Piao Team|[2504.02255](http://arxiv.org/abs/2504.02255)|null|
|**2025-04-03**|**Model Predictive Control with Visibility Graphs for Humanoid Path Planning and Tracking Against Adversarial Opponents**|Dennis W. Hong Team|[2504.02184](http://arxiv.org/abs/2504.02184)|null|
|**2025-04-02**|**The Social Life of Industrial Arms: How Arousal and Attention Shape Human-Robot Interaction**|Matthew K. X. J Pan Team|[2504.01260](http://arxiv.org/abs/2504.01260)|null|
|**2025-04-01**|**Extended Hybrid Zero Dynamics for Bipedal Walking of the Knee-less Robot SLIDER**|Petar Kormushev Team|[2504.01165](http://arxiv.org/abs/2504.01165)|null|
|**2025-04-01**|**Learning Bipedal Locomotion on Gear-Driven Humanoid Robot Using Foot-Mounted IMUs**|Masaya Kinoshita Team|[2504.00614](http://arxiv.org/abs/2504.00614)|**[link](https://sony.github.io/learning-feet-imu-locomotion/)**|
|**2025-03-30**|**Exploring GPT-4 for Robotic Agent Strategy with Real-Time State Feedback and a Reactive Behaviour Framework**|Ysobel Sims Team|[2503.23601](http://arxiv.org/abs/2503.23601)|null|
|**2025-03-28**|**Control of Humanoid Robots with Parallel Mechanisms using Differential Actuation Models**|Nicolas Mansard Team|[2503.22459](http://arxiv.org/abs/2503.22459)|null|
|**2025-03-28**|**FLAM: Foundation Model-Based Body Stabilization for Humanoid Locomotion and Manipulation**|Debin Zhao Team|[2503.22249](http://arxiv.org/abs/2503.22249)|null|
|**2025-03-27**|**OminiAdapt: Learning Cross-Task Invariance for Robust and Environment-Aware Robotic Manipulation**|Wanting Li Team|[2503.21257](http://arxiv.org/abs/2503.21257)|null|
|**2025-03-26**|**Anti Robot Speciesism**|Miklos Sarvary Team|[2503.20842](http://arxiv.org/abs/2503.20842)|null|
|**2025-03-25**|**Can Vision-Language Models Answer Face to Face Questions in the Real-World?**|Roland Memisevic Team|[2503.19356](http://arxiv.org/abs/2503.19356)|null|
|**2025-03-24**|**Inertial-Based LQG Control: A New Look at Inverted Pendulum Stabilization**|Itzik Klein Team|[2503.18926](http://arxiv.org/abs/2503.18926)|null|
|**2025-03-19**|**StyleLoco: Generative Adversarial Distillation for Natural Humanoid Robot Locomotion**|Siyuan Huang Team|[2503.15082](http://arxiv.org/abs/2503.15082)|null|
|**2025-03-18**|**GR00T N1: An Open Foundation Model for Generalist Humanoid Robots**|Yuke Zhu Team|[2503.14734](http://arxiv.org/abs/2503.14734)|**[link](https://developer.nvidia.com/isaac/gr00t)**|
|**2025-03-17**|**Humanoid Policy ~ Human Policy**|Xiaolong Wang Team|[2503.13441](http://arxiv.org/abs/2503.13441)|**[link](https://human-as-robot.github.io/)**|
|**2025-03-17**|**Layered Nonlinear Model Predictive Control for Robust Stabilization of Hybrid Systems**|Aaron D. Ames Team|[2503.12810](http://arxiv.org/abs/2503.12810)|null|
|**2025-03-17**|**Humanoids in Hospitals: A Technical Study of Humanoid Robot Surrogates for Dexterous Medical Interventions**|Michael Yip Team|[2503.12725](http://arxiv.org/abs/2503.12725)|null|
|**2025-03-16**|**Being-0: A Humanoid Robotic Agent with Vision-Language Models and Modular Skills**|Zongqing Lu Team|[2503.12533](http://arxiv.org/abs/2503.12533)|null|
|**2025-03-14**|**Fast and Robust Localization for Humanoid Soccer Robot via Iterative Landmark Matching**|Dennis W. Hong Team|[2503.11020](http://arxiv.org/abs/2503.11020)|null|
|**2025-03-13**|**NIL: No-data Imitation Learning by Leveraging Pre-trained Video Diffusion Models**|Michael Black Team|[2503.10626](http://arxiv.org/abs/2503.10626)|null|
|**2025-03-13**|**NuExo: A Wearable Exoskeleton Covering all Upper Limb ROM for Outdoor Data Collection and Teleoperation of Humanoid Robots**|Huimin Lu Team|[2503.10554](http://arxiv.org/abs/2503.10554)|null|
|**2025-03-12**|**Natural Humanoid Robot Locomotion with Generative Motion Prior**|Rong Xiong Team|[2503.09015](http://arxiv.org/abs/2503.09015)|null|
|**2025-03-13**|**HumanoidPano: Hybrid Spherical Panoramic-LiDAR Cross-Modal Perception for Humanoid Robots**|Renjing Xu Team|[2503.09010](http://arxiv.org/abs/2503.09010)|null|
|**2025-03-11**|**LiPS: Large-Scale Humanoid Robot Reinforcement Learning with Parallel-Series Structures**|Renjing Xu Team|[2503.08349](http://arxiv.org/abs/2503.08349)|null|
|**2025-04-29**|**Learning Getting-Up Policies for Real-World Humanoid Robots**|Saurabh Gupta Team|[2502.12152](http://arxiv.org/abs/2502.12152)|**[link](https://humanoid-getup.github.io/)**|
|**2024-10-17**|**Harmon: Whole-Body Motion Generation of Humanoid Robots from Language Descriptions**|Yuke Zhu Team|[2410.12773](http://arxiv.org/abs/2410.12773)|**[link](https://ut-austin-rpl.github.io/Harmon/)**|
|**2023-12-29**|**How to Raise a Robot -- A Case for Neuro-Symbolic AI in Constrained Task Planning for Humanoid Assistive Robots**|Hannes Hartenstein Team|[2312.08820](http://arxiv.org/abs/2312.08820)|**[link](https://dl.acm.org/doi/abs/10.1145/3589608.3595078)**|
|**2022-11-28**|**Optimization of Humanoid Robot Designs for Human-Robot Ergonomic Payload Lifting**|Daniele Pucci Team|[2211.13503](http://arxiv.org/abs/2211.13503)|null|
|**2022-10-20**|**Dialogue system with humanoid robot**|Naoki Igo Team|[2210.10151](http://arxiv.org/abs/2210.10151)|null|
|**2021-04-20**|**The MIT Humanoid Robot: Design, Motion Planning, and Control For Acrobatic Behaviors**|Sangbae Kim Team|[2104.09025](http://arxiv.org/abs/2104.09025)|null|
|**2019-09-24**|**Whole-Body Geometric Retargeting for Humanoid Robots**|Daniele Pucci Team|[1909.10080](http://arxiv.org/abs/1909.10080)|null|
|**2019-09-06**|**NimbRo Robots Winning RoboCup 2018 Humanoid AdultSize Soccer Competitions**|Sven Behnke Team|[1909.02385](http://arxiv.org/abs/1909.02385)|null|
|**2018-10-22**|**NimbRo-OP2X: Adult-sized Open-source 3D Printed Humanoid Robot**|Sven Behnke Team|[1810.08395](http://arxiv.org/abs/1810.08395)|null|
|**2018-10-22**|**Online Balanced Motion Generation for Humanoid Robots**|Sven Behnke Team|[1810.08388](http://arxiv.org/abs/1810.08388)|null|
|**2018-10-01**|**NimbRo-OP2: Grown-up 3D Printed Open Humanoid Platform for Research**|Sven Behnke Team|[1809.11144](http://arxiv.org/abs/1809.11144)|null|
|**2018-10-01**|**A ROS-based Software Framework for the NimbRo-OP Humanoid Open Platform**|Sven Behnke Team|[1809.11051](http://arxiv.org/abs/1809.11051)|null|
|**2017-01-11**|**Automatic Gain Tuning of a Momentum Based Balancing Controller for Humanoid Robots**|Francesco Nori Team|[1610.02849](http://arxiv.org/abs/1610.02849)|null|
|**2017-07-18**|**Walking of the iCub humanoid robot in different scenarios: implementation and performance analysis**|Katja Mombaur Team|[1607.08525](http://arxiv.org/abs/1607.08525)|null|
|**2017-01-16**|**Walking on Partial Footholds Including Line Contacts with the Humanoid Robot Atlas**|Jerry Pratt Team|[1607.08089](http://arxiv.org/abs/1607.08089)|null|
|**2016-07-19**|**Design and implementation of computational platform for social-humanoid robot Lumen as an exhibition guide in Electrical Engineering Days 2015**|Ary Setijadi Prihatmanto Team|[1607.04763](http://arxiv.org/abs/1607.04763)|null|
|**2016-11-18**|**Gaze Stabilization for Humanoid Robots: a Comprehensive Framework**|Lorenzo Natale Team|[1411.3525](http://arxiv.org/abs/1411.3525)|null|

<p align=right>(<a href=#updated-on-20251217>back to top</a>)</p>

## Dexterous

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-12-11**|**WholeBodyVLA: Towards Unified Latent VLA for Whole-Body Loco-Manipulation Control**|Hongyang Li Team|[2512.11047](http://arxiv.org/abs/2512.11047)|null|
|**2025-12-11**|**Design and Validation of an Under-actuated Robotic Finger with Synchronous Tendon Routing**|Weibang Bai Team|[2512.10349](http://arxiv.org/abs/2512.10349)|null|
|**2025-12-06**|**Vision-Guided Grasp Planning for Prosthetic Hands in Unstructured Environments**|Simon Bøgh Team|[2512.06517](http://arxiv.org/abs/2512.06517)|null|
|**2025-12-05**|**SIMPACT: Simulation-Enabled Action Planning using Vision-Language Models**|Yilun Du Team|[2512.05955](http://arxiv.org/abs/2512.05955)|null|
|**2025-12-04**|**STARE-VLA: Progressive Stage-Aware Reinforcement for Fine-Tuning Vision-Language-Action Models**|Benjamin Busam Team|[2512.05107](http://arxiv.org/abs/2512.05107)|null|
|**2025-12-04**|**BulletTime: Decoupled Control of Time and Camera Pose for Video Generation**|Gordon Wetzstein Team|[2512.05076](http://arxiv.org/abs/2512.05076)|**[link](https://19reborn.github.io/Bullet4D/)**|
|**2025-12-04**|**ASTRIDE: A Security Threat Modeling Platform for Agentic-AI Applications**|Nilaan Loganathan Team|[2512.04785](http://arxiv.org/abs/2512.04785)|null|
|**2025-12-04**|**Towards Cross-View Point Correspondence in Vision-Language Models**|Xiaolong Zheng Team|[2512.04686](http://arxiv.org/abs/2512.04686)|null|
|**2025-12-04**|**Vision-Language-Action Models for Selective Robotic Disassembly: A Case Study on Critical Component Extraction from Desktops**|Minghui Zheng Team|[2512.04446](http://arxiv.org/abs/2512.04446)|null|
|**2025-12-04**|**Development of a 15-Degree-of-Freedom Bionic Hand with Cable-Driven Transmission and Distributed Actuation**|Hesheng Wang Team|[2512.04399](http://arxiv.org/abs/2512.04399)|null|
|**2025-12-03**|**ResponsibleRobotBench: Benchmarking Responsible Robot Manipulation using Multi-modal Large Language Models**|Jianwei Zhang Team|[2512.04308](http://arxiv.org/abs/2512.04308)|**[link](https://sites.google.com/view/responsible-robotbench)**|
|**2025-12-03**|**Cross-embodied Co-design for Dexterous Hands**|Xiaolong Wang Team|[2512.03743](http://arxiv.org/abs/2512.03743)|null|
|**2025-12-03**|**SELF: A Robust Singular Value and Eigenvalue Approach for LLM Fingerprinting**|Yue Zheng Team|[2512.03620](http://arxiv.org/abs/2512.03620)|null|
|**2025-12-02**|**Experimental Characterization of Fingertip Trajectory following for a 3-DoF Series-Parallel Hybrid Robotic Finger**|Nilanjan Chakraborty Team|[2512.02951](http://arxiv.org/abs/2512.02951)|null|
|**2025-12-03**|**Diagnose, Correct, and Learn from Manipulation Failures via Visual Symbols**|Yong-Lu Li Team|[2512.02787](http://arxiv.org/abs/2512.02787)|null|
|**2025-12-02**|**RoboWheel: A Data Engine from Real-World Human Demonstrations for Cross-Embodiment Robotic Learning**|Haoqian Wang Team|[2512.02729](http://arxiv.org/abs/2512.02729)|null|
|**2025-12-02**|**Skywork-R1V4: Toward Agentic Multimodal Intelligence through Interleaved Thinking with Images and DeepResearch**|Yahui Zhou Team|[2512.02395](http://arxiv.org/abs/2512.02395)|null|
|**2025-12-01**|**Generative Video Motion Editing with 3D Point Tracks**|Zhengqi Li Team|[2512.02015](http://arxiv.org/abs/2512.02015)|**[link](https://edit-by-track.github.io)**|
|**2025-12-01**|**Learning Dexterous Manipulation Skills from Imperfect Simulations**|Haozhi Qi Team|[2512.02011](http://arxiv.org/abs/2512.02011)|null|
|**2025-12-02**|**Guardian: Detecting Robotic Planning and Execution Errors with Vision-Language Models**|Cordelia Schmid Team|[2512.01946](http://arxiv.org/abs/2512.01946)|**[link](https://www.di.ens.fr/willow/research/guardian/.)**|
|**2025-12-01**|**GR-RL: Going Dexterous and Precise for Long-Horizon Robotic Manipulation**|Yonghui Wu Team|[2512.01801](http://arxiv.org/abs/2512.01801)|null|
|**2025-12-01**|**FreqEdit: Preserving High-Frequency Features for Robust Multi-Turn Image Editing**|Xudong Mao Team|[2512.01755](http://arxiv.org/abs/2512.01755)|null|
|**2025-12-01**|**Open-world Hand-Object Interaction Video Generation Based on Structure and Contact-aware Representation**|Haoang Li Team|[2512.01677](http://arxiv.org/abs/2512.01677)|null|
|**2025-12-01**|**Modality-Augmented Fine-Tuning of Foundation Robot Policies for Cross-Embodiment Manipulation on GR1 and G1**|Songhwai Oh Team|[2512.01358](http://arxiv.org/abs/2512.01358)|null|
|**2025-11-30**|**OmniFD: A Unified Model for Versatile Face Forgery Detection**|Xiaobai Li Team|[2512.01128](http://arxiv.org/abs/2512.01128)|null|
|**2025-11-30**|**Tactile Robotics: Past and Future**|Nathan F. Lepora Team|[2512.01106](http://arxiv.org/abs/2512.01106)|null|
|**2025-11-30**|**Opening the Sim-to-Real Door for Humanoid Pixel-to-Action Policy Transfer**|Yuke Zhu Team|[2512.01061](http://arxiv.org/abs/2512.01061)|**[link](https://doorman-humanoid.github.io/)**|
|**2025-11-30**|**CycleManip: Enabling Cyclic Task Manipulation via Effective Historical Perception and Understanding**|Wei-Shi Zheng Team|[2512.01022](http://arxiv.org/abs/2512.01022)|**[link](https://isee-laboratory.github.io/OmniDexGrasp/)**|
|**2025-11-30**|**HanDyVQA: A Video QA Benchmark for Fine-Grained Hand-Object Interaction Dynamics**|Takuma Yagi Team|[2512.00885](http://arxiv.org/abs/2512.00885)|**[link](https://masatate.github.io/HanDyVQA-project-page/)**|
|**2025-11-29**|**MILE: A Mechanically Isomorphic Exoskeleton Data Collection System with Fingertip Visuotactile Sensing for Dexterous Manipulation**|Xiangyang Zhu Team|[2512.00324](http://arxiv.org/abs/2512.00324)|null|
|**2025-11-28**|**Video-CoM: Interactive Video Reasoning via Chain of Manipulations**|Salman Khan Team|[2511.23477](http://arxiv.org/abs/2511.23477)|null|
|**2025-11-28**|**NumeriKontrol: Adding Numeric Control to Diffusion Transformers for Instruction-based Image Editing**|Xinyu Zhang Team|[2511.23105](http://arxiv.org/abs/2511.23105)|null|
|**2025-11-28**|**Commanding Humanoid by Free-form Language: A Large Language Action Model with Unified Motion Vocabulary**|Jingya Wang Team|[2511.22963](http://arxiv.org/abs/2511.22963)|**[link](https://humanoidlla.github.io/)**|
|**2025-11-27**|**Design of an Adaptive Modular Anthropomorphic Dexterous Hand for Human-like Manipulation**|Yaonan Wang Team|[2511.22100](http://arxiv.org/abs/2511.22100)|null|
|**2025-11-26**|**Kinematics-Aware Multi-Policy Reinforcement Learning for Force-Capable Humanoid Loco-Manipulation**|Qijun Chen Team|[2511.21169](http://arxiv.org/abs/2511.21169)|null|
|**2025-11-25**|**ACE-F: A Cross Embodiment Foldable System with Force Feedback for Dexterous Teleoperation**|Xiaolong Wang Team|[2511.20887](http://arxiv.org/abs/2511.20887)|null|
|**2025-11-21**|**RoboCOIN: An Open-Sourced Bimanual Robotic Data COllection for INtegrated Manipulation**|Guocai Yao Team|[2511.17441](http://arxiv.org/abs/2511.17441)|null|
|**2025-11-21**|**METIS: Multi-Source Egocentric Training for Integrated Dexterous Vision-Language-Action Model**|Shanghang Zhang Team|[2511.17366](http://arxiv.org/abs/2511.17366)|null|
|**2025-11-20**|**Dexterity from Smart Lenses: Multi-Fingered Robot Manipulation with In-the-Wild Human Demonstrations**|Homanga Bharadhwaj Team|[2511.16661](http://arxiv.org/abs/2511.16661)|null|
|**2025-11-20**|**InternData-A1: Pioneering High-Fidelity Synthetic Data for Pre-training Generalist Policy**|Jiangmiao Pang Team|[2511.16651](http://arxiv.org/abs/2511.16651)|null|
|**2025-11-19**|**VIRAL: Visual Sim-to-Real at Scale for Humanoid Loco-Manipulation**|Yuke Zhu Team|[2511.15200](http://arxiv.org/abs/2511.15200)|**[link](https://viral-humanoid.github.io/)**|
|**2025-11-18**|**Toward Robust and Harmonious Adaptation for Cross-modal Retrieval**|Xi Peng Team|[2511.14416](http://arxiv.org/abs/2511.14416)|null|
|**2025-11-17**|**From Power to Precision: Learning Fine-grained Dexterity for Multi-fingered Robotic Hands**|Xiaolong Wang Team|[2511.13710](http://arxiv.org/abs/2511.13710)|**[link](https://jianglongye.com/power-to-precision)**|
|**2025-11-17**|**ZeroDexGrasp: Zero-Shot Task-Oriented Dexterous Grasp Synthesis with Prompt-Based Multi-Stage Semantic Reasoning**|Ruizhen Hu Team|[2511.13327](http://arxiv.org/abs/2511.13327)|null|
|**2025-11-17**|**DiffuDepGrasp: Diffusion-based Depth Noise Modeling Empowers Sim2Real Robotic Grasping**|Dongbin Zhao Team|[2511.12912](http://arxiv.org/abs/2511.12912)|null|
|**2025-11-14**|**Dexterous Manipulation Transfer via Progressive Kinematic-Dynamic Alignment**|Yi Sun Team|[2511.10987](http://arxiv.org/abs/2511.10987)|null|
|**2025-11-13**|**Opinion: Towards Unified Expressive Policy Optimization for Robust Robot Learning**|Xiaocong Li Team|[2511.10087](http://arxiv.org/abs/2511.10087)|null|
|**2025-11-12**|**ScaleADFG: Affordance-based Dexterous Functional Grasping via Scalable Dataset**|Peng Wang Team|[2511.09602](http://arxiv.org/abs/2511.09602)|null|
|**2025-11-12**|**IFG: Internet-Scale Guidance for Functional Grasping Generation**|Deepak Pathak Team|[2511.09558](http://arxiv.org/abs/2511.09558)|**[link](https://ifgrasping.github.io/)**|
|**2025-11-12**|**SPIDER: Scalable Physics-Informed Dexterous Retargeting**|Francois Hogan Team|[2511.09484](http://arxiv.org/abs/2511.09484)|**[link](https://jc-bao.github.io/spider-project/)**|
|**2025-11-12**|**RGMP: Recurrent Geometric-prior Multimodal Policy for Generalizable Humanoid Robot Manipulation**|Miao Li Team|[2511.09141](http://arxiv.org/abs/2511.09141)|null|
|**2025-11-12**|**MirrorLimb: Implementing hand pose acquisition and robot teleoperation based on RealMirror**|Tao Shen Team|[2511.08865](http://arxiv.org/abs/2511.08865)|null|
|**2025-11-10**|**Lightning Grasp: High Performance Procedural Grasp Synthesis with Contact Fields**|Pieter Abbeel Team|[2511.07418](http://arxiv.org/abs/2511.07418)|**[link](https://github.com/zhaohengyin/lightning-grasp)**|
|**2025-11-09**|**Robust Differentiable Collision Detection for General Objects**|He Wang Team|[2511.06267](http://arxiv.org/abs/2511.06267)|null|
|**2025-11-08**|**Adversarial Game-Theoretic Algorithm for Dexterous Grasp Synthesis**|Jeffrey Ichnowski Team|[2511.05809](http://arxiv.org/abs/2511.05809)|null|
|**2025-11-06**|**Isaac Lab: A GPU-Accelerated Simulation Framework for Multi-Modal Robot Learning**|Gavriel State Team|[2511.04831](http://arxiv.org/abs/2511.04831)|**[link](https://github.com/isaac-sim/IsaacLab)**|
|**2025-11-05**|**Dexterous Intramyocardial Needle Ablation (d-INA): Design, Fabrication, and In-Vivo Validation**|Yue Chen Team|[2511.03763](http://arxiv.org/abs/2511.03763)|null|
|**2025-11-05**|**Development of the Bioinspired Tendon-Driven DexHand 021 with Proprioceptive Compliance Control**|Sheng Yi Team|[2511.03481](http://arxiv.org/abs/2511.03481)|null|
|**2025-11-10**|**3D Cal: An Open-Source Software Library for Calibrating Tactile Sensors**|Gregory Reardon Team|[2511.03078](http://arxiv.org/abs/2511.03078)|null|
|**2025-11-04**|**TWIST2: Scalable, Portable, and Holistic Humanoid Data Collection System**|C. Karen Liu Team|[2511.02832](http://arxiv.org/abs/2511.02832)|**[link](https://yanjieze.com/TWIST2)**|
|**2025-11-04**|**Dexterous Robotic Piano Playing at Scale**|Dieter Büchler Team|[2511.02504](http://arxiv.org/abs/2511.02504)|null|
|**2025-11-10**|**Whole-body motion planning and safety-critical control for aerial manipulation**|Jeonghyun Byun Team|[2511.02342](http://arxiv.org/abs/2511.02342)|null|
|**2025-11-03**|**GenDexHand: Generative Simulation for Dexterous Hands**|Yi Ma Team|[2511.01791](http://arxiv.org/abs/2511.01791)|null|
|**2025-11-03**|**Scaling Cross-Embodiment World Models for Dexterous Manipulation**|Hao Su Team|[2511.01177](http://arxiv.org/abs/2511.01177)|null|
|**2025-10-31**|**End-to-End Dexterous Arm-Hand VLA Policies via Shared Autonomy: VR Teleoperation Augmented by Autonomous Hand VLA Policy for Efficient Data Collection**|Zhibin Li Team|[2511.00139](http://arxiv.org/abs/2511.00139)|null|
|**2025-10-31**|**Whole-Body Proprioceptive Morphing: A Modular Soft Gripper for Robust Cross-Scale Grasping**|Xiaonan Huang Team|[2510.27666](http://arxiv.org/abs/2510.27666)|null|
|**2025-10-30**|**SpikeATac: A Multimodal Tactile Finger with Taxelized Dynamic Sensing for Dexterous Manipulation**|Matei Ciocarlie Team|[2510.27048](http://arxiv.org/abs/2510.27048)|null|
|**2025-10-28**|**A Humanoid Visual-Tactile-Action Dataset for Contact-Rich Manipulation**|Kyung-Joong Kim Team|[2510.25725](http://arxiv.org/abs/2510.25725)|null|
|**2025-10-27**|**OmniDexGrasp: Generalizable Dexterous Grasping via Foundation Model and Force Feedback**|Wei-Shi Zheng Team|[2510.23119](http://arxiv.org/abs/2510.23119)|**[link](https://isee-laboratory.github.io/OmniDexGrasp/)**|
|**2025-10-24**|**Scalable Vision-Language-Action Model Pretraining for Robotic Manipulation with Real-Life Human Activity Videos**|Baining Guo Team|[2510.21571](http://arxiv.org/abs/2510.21571)|**[link](https://microsoft.github.io/VITRA/)**|
|**2025-10-23**|**SutureBot: A Precision Framework & Benchmark For Autonomous End-to-End Suturing**|Axel Krieger Team|[2510.20965](http://arxiv.org/abs/2510.20965)|null|
|**2025-10-23**|**FieldGen: From Teleoperated Pre-Manipulation Trajectories to Field-Guided Data Generation**|Yao Mu Team|[2510.20774](http://arxiv.org/abs/2510.20774)|**[link](https://fieldgen.github.io/)**|
|**2025-10-22**|**GRASPLAT: Enabling dexterous grasping through novel view synthesis**|Alessio Del Bue Team|[2510.19200](http://arxiv.org/abs/2510.19200)|null|
|**2025-10-19**|**RAPID Hand Prototype: Design of an Affordable, Fully-Actuated Biomimetic Hand for Dexterous Teleoperation**|Hui Cheng Team|[2510.16931](http://arxiv.org/abs/2510.16931)|null|
|**2025-10-17**|**DexCanvas: Bridging Human Demonstrations and Robot Learning for Dexterous Manipulation**|Yiwen Lu Team|[2510.15786](http://arxiv.org/abs/2510.15786)|null|
|**2025-10-16**|**Open TeleDex: A Hardware-Agnostic Teleoperation System for Imitation Learning based Dexterous Manipulation**|Shan An Team|[2510.14771](http://arxiv.org/abs/2510.14771)|null|
|**2025-10-16**|**Leveraging Neural Descriptor Fields for Learning Contact-Aware Dynamic Recovery**|Dmitry Berenson Team|[2510.14768](http://arxiv.org/abs/2510.14768)|null|
|**2025-10-16**|**Spatially anchored Tactile Awareness for Robust Dexterous Manipulation**|Kaifeng Zhang Team|[2510.14647](http://arxiv.org/abs/2510.14647)|null|
|**2025-10-16**|**Restoring Noisy Demonstration for Imitation Learning With Diffusion Models**|Shao-Hua Sun Team|[2510.14467](http://arxiv.org/abs/2510.14467)|null|
|**2025-10-14**|**Learning to Grasp Anything by Playing with Random Toys**|Roei Herzig Team|[2510.12866](http://arxiv.org/abs/2510.12866)|null|
|**2025-10-14**|**T(R,O) Grasp: Efficient Graph Diffusion of Robot-Object Spatial Transformation for Cross-Embodiment Dexterous Grasping**|Lin Shao Team|[2510.12724](http://arxiv.org/abs/2510.12724)|null|
|**2025-10-10**|**Glovity: Learning Dexterous Contact-Rich Manipulation via Spatial Wrench Feedback Teleoperation System**|Pai Zheng Team|[2510.09229](http://arxiv.org/abs/2510.09229)|null|
|**2025-10-10**|**PLEXUS Hand: Lightweight Four-Motor Prosthetic Hand Enabling Precision-Lateral Dexterous Manipulation**|Kazutoshi Tanaka Team|[2510.09209](http://arxiv.org/abs/2510.09209)|null|
|**2025-10-09**|**DexNDM: Closing the Reality Gap for Dexterous In-Hand Rotation via Joint-Wise Neural Dynamics Model**|Li Yi Team|[2510.08556](http://arxiv.org/abs/2510.08556)|**[link](https://meowuu7.github.io/DexNDM/)**|
|**2025-10-09**|**DexMan: Learning Bimanual Dexterous Manipulation from Human and Generated Videos**|Tsung-Wei Ke Team|[2510.08475](http://arxiv.org/abs/2510.08475)|**[link](https://embodiedai-ntu.github.io/dexman/index.html)**|
|**2025-10-08**|**AVO: Amortized Value Optimization for Contact Mode Switching in Multi-Finger Manipulation**|Dmitry Berenson Team|[2510.07548](http://arxiv.org/abs/2510.07548)|null|
|**2025-10-08**|**Diffusing Trajectory Optimization Problems for Recovery During Multi-Finger Manipulation**|Dmitry Berenson Team|[2510.07030](http://arxiv.org/abs/2510.07030)|null|
|**2025-10-07**|**Cross-Embodiment Dexterous Hand Articulation Generation via Morphology-Aware Learning**|Yan Wu Team|[2510.06068](http://arxiv.org/abs/2510.06068)|null|
|**2025-10-06**|**A multi-modal tactile fingertip design for robotic hands to enhance dexterous manipulation**|Zeynep Temel Team|[2510.05382](http://arxiv.org/abs/2510.05382)|null|
|**2025-09-30**|**ISyHand: A Dexterous Multi-finger Robot Hand with an Articulated Palm**|Katherine J. Kuchenbecker Team|[2509.26236](http://arxiv.org/abs/2509.26236)|null|
|**2025-09-28**|**DexFlyWheel: A Scalable and Self-improving Data Generation Framework for Dexterous Manipulation**|Yuanpei Chen Team|[2509.23829](http://arxiv.org/abs/2509.23829)|null|
|**2025-09-27**|**In-Hand Manipulation of Articulated Tools with Dexterous Robot Hands with Sim-to-Real Transfer**|Michael Yip Team|[2509.23075](http://arxiv.org/abs/2509.23075)|null|
|**2025-09-26**|**DemoGrasp: Universal Dexterous Grasping from a Single Demonstration**|Zongqing Lu Team|[2509.22149](http://arxiv.org/abs/2509.22149)|null|
|**2025-09-23**|**Residual Off-Policy RL for Finetuning Behavior Cloning Policies**|Anusha Nagabandi Team|[2509.19301](http://arxiv.org/abs/2509.19301)|**[link](https://residual-offpolicy-rl.github.io)**|
|**2025-09-23**|**Lang2Morph: Language-Driven Morphological Design of Robotic Hands**|Josie Hughes Team|[2509.18937](http://arxiv.org/abs/2509.18937)|null|
|**2025-09-23**|**DexSkin: High-Coverage Conformable Robotic Skin for Learning Contact-Rich Manipulation**|Jiajun Wu Team|[2509.18830](http://arxiv.org/abs/2509.18830)|null|
|**2025-09-22**|**Learning Geometry-Aware Nonprehensile Pushing and Pulling with Dexterous Hands**|Daniel Seita Team|[2509.18455](http://arxiv.org/abs/2509.18455)|null|
|**2025-09-22**|**Learning Dexterous Manipulation with Quantized Hand State**|Cewu Lu Team|[2509.17450](http://arxiv.org/abs/2509.17450)|null|
|**2025-09-18**|**A Novel Task-Driven Diffusion-Based Policy with Affordance Learning for Generalizable Manipulation of Articulated Objects**|Yongduan Song Team|[2509.14939](http://arxiv.org/abs/2509.14939)|null|
|**2025-09-18**|**Learning to Pick: A Visuomotor Policy for Clustered Strawberry Picking**|Chen Peng Team|[2509.14530](http://arxiv.org/abs/2509.14530)|null|
|**2025-09-17**|**LeVR: A Modular VR Teleoperation Framework for Imitation Learning in Dexterous Manipulation**|Han Liu Team|[2509.14349](http://arxiv.org/abs/2509.14349)|null|
|**2025-09-16**|**\textsc{Gen2Real}: Towards Demo-Free Dexterous Manipulation by Harnessing Generated Video**|Rui Huang Team|[2509.14178](http://arxiv.org/abs/2509.14178)|null|
|**2025-09-17**|**Whole-body Motion Control of an Omnidirectional Wheel-Legged Mobile Manipulator via Contact-Aware Dynamic Optimization**|Yiqun Li Team|[2509.14010](http://arxiv.org/abs/2509.14010)|null|
|**2025-09-16**|**Beyond Anthropomorphism: Enhancing Grasping and Eliminating a Degree of Freedom by Fusing the Abduction of Digits Four and Five**|Robert K. Katzschmann Team|[2509.13074](http://arxiv.org/abs/2509.13074)|null|
|**2025-09-16**|**MoiréTac: A Dual-Mode Visuotactile Sensor for Multidimensional Perception Using Moiré Pattern Amplification**|Wenbo Ding Team|[2509.12714](http://arxiv.org/abs/2509.12714)|null|
|**2025-09-11**|**Dexplore: Scalable Neural Control for Dexterous Manipulation from Reference-Scoped Exploration**|Wei Yang Team|[2509.09671](http://arxiv.org/abs/2509.09671)|null|
|**2025-09-10**|**RoboMatch: A Unified Mobile-Manipulation Teleoperation Platform with Auto-Matching Network Architecture for Long-Horizon Tasks**|Zhigong Song Team|[2509.08522](http://arxiv.org/abs/2509.08522)|null|
|**2025-09-10**|**Grasp Like Humans: Learning Generalizable Multi-Fingered Grasping from Human Proprioceptive Sensorimotor Integration**|Huimin Lu Team|[2509.08354](http://arxiv.org/abs/2509.08354)|null|
|**2025-09-09**|**Graph-Fused Vision-Language-Action for Policy Reasoning in Multi-Arm Robotic Manipulation**|Yingbai Hu Team|[2509.07957](http://arxiv.org/abs/2509.07957)|null|
|**2025-09-09**|**Text2Touch: Tactile In-Hand Manipulation with LLM-Designed Reward Functions**|Nathan F. Lepora Team|[2509.07445](http://arxiv.org/abs/2509.07445)|null|
|**2025-09-05**|**OpenEgo: A Large-Scale Multimodal Egocentric Dataset for Dexterous Manipulation**|Yu Xiang Team|[2509.05513](http://arxiv.org/abs/2509.05513)|null|
|**2025-09-04**|**DEXOP: A Device for Robotic Transfer of Dexterous Human Manipulation**|Pulkit Agrawal Team|[2509.04441](http://arxiv.org/abs/2509.04441)|**[link](https://dex-op.github.io)**|
|**2025-08-28**|**EO-1: Interleaved Vision-Text-Action Pretraining for General Robot Control**|Dong Wang Team|[2508.21112](http://arxiv.org/abs/2508.21112)|null|
|**2025-08-27**|**HERMES: Human-to-Robot Embodied Learning from Multi-Source Motion Data for Mobile Dexterous Manipulation**|Huazhe Xu Team|[2508.20085](http://arxiv.org/abs/2508.20085)|null|
|**2025-08-24**|**LodeStar: Long-horizon Dexterity via Synthetic Data Augmentation from Human Demonstrations**|Hao Su Team|[2508.17547](http://arxiv.org/abs/2508.17547)|null|
|**2025-08-21**|**Exploiting Policy Idling for Dexterous Manipulation**|Dushyant Rao Team|[2508.15669](http://arxiv.org/abs/2508.15669)|null|
|**2025-08-20**|**GraspQP: Differentiable Optimization of Force Closure for Diverse and Robust Dexterous Grasping**|Marco Hutter Team|[2508.15002](http://arxiv.org/abs/2508.15002)|null|
|**2025-08-20**|**FBI: Learning Dexterous In-hand Manipulation with Dynamic Visuotactile Shortcut Policy**|Cewu Lu Team|[2508.14441](http://arxiv.org/abs/2508.14441)|null|
|**2025-08-18**|**Precise Action-to-Video Generation Through Visual Action Prompts**|Ruizhen Hu Team|[2508.13104](http://arxiv.org/abs/2508.13104)|**[link](https://zju3dv.github.io/VAP/)**|
|**2025-08-17**|**Geodesic Tracing-Based Kinematic Integration of Rolling and Sliding Contact on Manifold Meshes for Dexterous In-Hand Manipulation**|Nancy S. Pollard Team|[2508.12439](http://arxiv.org/abs/2508.12439)|null|
|**2025-08-13**|**Embodied Tactile Perception of Soft Objects Properties**|Etienne Burdet Team|[2508.09836](http://arxiv.org/abs/2508.09836)|null|
|**2025-08-12**|**Towards Affordance-Aware Robotic Dexterous Grasping with Human-like Priors**|Hua Zou Team|[2508.08896](http://arxiv.org/abs/2508.08896)|null|
|**2025-08-12**|**OmniVTLA: Vision-Tactile-Language-Action Model with Semantic-Aligned Tactile Sensing**|Hengdi Zhang Team|[2508.08706](http://arxiv.org/abs/2508.08706)|**[link](https://readerek.github.io/Objtac.github.io)**|
|**2025-07-29**|**emg2tendon: From sEMG Signals to Tendon Control in Musculoskeletal Hands**|Sagar Verma Team|[2508.08269](http://arxiv.org/abs/2508.08269)|null|
|**2025-08-11**|**PCHands: PCA-based Hand Pose Synergy Representation on Manipulators with N-DoF**|Lorenzo Natale Team|[2508.07945](http://arxiv.org/abs/2508.07945)|null|
|**2025-08-09**|**DexFruit: Dexterous Manipulation and Gaussian Splatting Inspection of Fruit**|Monroe Kennedy Team|[2508.07118](http://arxiv.org/abs/2508.07118)|null|
|**2025-08-05**|**UniFucGrasp: Human-Hand-Inspired Unified Functional Grasp Annotation Strategy and Dataset for Diverse Dexterous Hands**|Yaonan Wang Team|[2508.03339](http://arxiv.org/abs/2508.03339)|**[link](https://haochen611.github.io/UFG)**|
|**2025-08-03**|**DexReMoE:In-hand Reorientation of General Object via Mixtures of Experts**|Yunlong Dong Team|[2508.01695](http://arxiv.org/abs/2508.01695)|null|
|**2025-08-01**|**Video Generators are Robot Policies**|Carl Vondrick Team|[2508.00795](http://arxiv.org/abs/2508.00795)|null|
|**2025-07-31**|**XRoboToolkit: A Cross-Platform Framework for Robot Teleoperation**|Ning Yang Team|[2508.00097](http://arxiv.org/abs/2508.00097)|**[link](http://xr-robotics.github.io/)**|
|**2025-07-31**|**villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models**|Jiang Bian Team|[2507.23682](http://arxiv.org/abs/2507.23682)|**[link](https://aka.ms/villa-x)**|
|**2025-07-19**|**A 21-DOF Humanoid Dexterous Hand with Hybrid SMA-Motor Actuation: CYJ Hand-0**|Erbao Dong Team|[2507.14538](http://arxiv.org/abs/2507.14538)|null|
|**2025-07-18**|**Control Modes of Teleoperated Surgical Robotic System's Tools in Ophthalmic Surgery**|Jacob Rosen Team|[2507.13654](http://arxiv.org/abs/2507.13654)|null|
|**2025-07-18**|**Improving Low-Cost Teleoperation: Augmenting GELLO with Force**|Kai Arulkumaran Team|[2507.13602](http://arxiv.org/abs/2507.13602)|null|
|**2025-07-16**|**The Developments and Challenges towards Dexterous and Embodied Robotic Manipulation: A Survey**|Jiming Chen Team|[2507.11840](http://arxiv.org/abs/2507.11840)|null|
|**2025-07-14**|**rt-RISeg: Real-Time Model-Free Robot Interactive Segmentation for Active Instance-Level Object Understanding**|Kaiyu Hang Team|[2507.10776](http://arxiv.org/abs/2507.10776)|null|
|**2025-07-14**|**Demonstrating the Octopi-1.5 Visual-Tactile-Language Model**|Harold Soh Team|[2507.09985](http://arxiv.org/abs/2507.09985)|null|
|**2025-07-09**|**Hierarchical Reinforcement Learning for Articulated Tool Manipulation with Multifingered Hand**|Xinjun Sheng Team|[2507.06822](http://arxiv.org/abs/2507.06822)|null|
|**2025-07-07**|**A Careful Examination of Large Behavior Models for Multitask Dexterous Manipulation**|Russ Tedrake Team|[2507.05331](http://arxiv.org/abs/2507.05331)|null|
|**2025-07-06**|**SimLauncher: Launching Sample-Efficient Real-world Robotic Reinforcement Learning via Simulation Pre-training**|Hao Dong Team|[2507.04452](http://arxiv.org/abs/2507.04452)|null|
|**2025-07-06**|**TeleSim: A Network-Aware Testbed and Benchmark Dataset for Telerobotic Applications**|Longhao Zou Team|[2507.04425](http://arxiv.org/abs/2507.04425)|null|
|**2025-07-03**|**DexVLG: Dexterous Vision-Language-Grasp Model at Scale**|He Wang Team|[2507.02747](http://arxiv.org/abs/2507.02747)|null|
|**2025-07-02**|**TypeTele: Releasing Dexterity in Teleoperation by Dexterous Manipulation Types**|Wei-Shi Zheng Team|[2507.01857](http://arxiv.org/abs/2507.01857)|**[link](https://isee-laboratory.github.io/TypeTele)**|
|**2025-07-01**|**DexWrist: A Robotic Wrist for Constrained and Dynamic Manipulation**|Pulkit Agrawal Team|[2507.01008](http://arxiv.org/abs/2507.01008)|null|
|**2025-07-01**|**HumanoidGen: Data Generation for Bimanual Dexterous Manipulation via LLM Reasoning**|Chenjia Bai Team|[2507.00833](http://arxiv.org/abs/2507.00833)|**[link](https://openhumanoidgen.github.io)**|
|**2025-06-29**|**DexH2R: A Benchmark for Dynamic Dexterous Grasping in Human-to-Robot Handover**|Yuexin Ma Team|[2506.23152](http://arxiv.org/abs/2506.23152)|**[link](https://dexh2r.github.io/)**|
|**2025-06-26**|**Lightweight Fingernail Haptic Device: Unobstructed Fingerpad Force and Vibration Feedback for Enhanced Virtual Dexterous Manipulation**|Shoichi Hasegawa Team|[2506.21417](http://arxiv.org/abs/2506.21417)|null|
|**2025-06-24**|**Scaffolding Dexterous Manipulation with Vision-Language Models**|Dorsa Sadigh Team|[2506.19212](http://arxiv.org/abs/2506.19212)|null|
|**2025-06-24**|**The MOTIF Hand: A Robotic Hand for Multimodal Observations with Thermal, Inertial, and Force Sensors**|Daniel Seita Team|[2506.19201](http://arxiv.org/abs/2506.19201)|null|
|**2025-06-21**|**VLA-OS: Structuring and Dissecting Planning Representations and Paradigms in Vision-Language-Action Models**|Lin Shao Team|[2506.17561](http://arxiv.org/abs/2506.17561)|null|
|**2025-06-20**|**Dex1B: Learning with 1B Demonstrations for Dexterous Manipulation**|Xiaolong Wang Team|[2506.17198](http://arxiv.org/abs/2506.17198)|**[link](https://jianglongye.com/dex1b)**|
|**2025-06-19**|**ViTacFormer: Learning Cross-Modal Representation for Visuo-Tactile Dexterous Manipulation**|Jitendra Malik Team|[2506.15953](http://arxiv.org/abs/2506.15953)|null|
|**2025-06-17**|**Tactile Beyond Pixels: Multisensory Touch Representations for Robot Manipulation**|Mustafa Mukadam Team|[2506.14754](http://arxiv.org/abs/2506.14754)|null|
|**2025-06-16**|**CEED-VLA: Consistency Vision-Language-Action Model with Early-Exit Decoding**|Haoang Li Team|[2506.13725](http://arxiv.org/abs/2506.13725)|null|
|**2025-06-13**|**ViTaSCOPE: Visuo-tactile Implicit Representation for In-hand Pose and Extrinsic Contact Estimation**|Nima Fazeli Team|[2506.12239](http://arxiv.org/abs/2506.12239)|**[link](https://jayjunlee.github.io/vitascope/)**|
|**2025-06-13**|**mimic-one: a Scalable Model Recipe for General Purpose Robot Dexterity**|Robert K. Katzschmann Team|[2506.11916](http://arxiv.org/abs/2506.11916)|null|
|**2025-06-13**|**ExoStart: Efficient learning for dexterous manipulation with sensorized exoskeleton demonstrations**|Maria Bauza Team|[2506.11775](http://arxiv.org/abs/2506.11775)|null|
|**2025-06-11**|**Adaptive event-triggered robust tracking control of soft robots**|Marios M. Polycarpou Team|[2506.09523](http://arxiv.org/abs/2506.09523)|null|
|**2025-06-11**|**Analyzing Key Objectives in Human-to-Robot Retargeting for Dexterous Manipulation**|Xiang Li Team|[2506.09384](http://arxiv.org/abs/2506.09384)|null|
|**2025-06-09**|**TensorTouch: Calibration of Tactile Sensors for High Resolution Stress Tensor and Deformation for Dexterous Manipulation**|Monroe Kennedy Team|[2506.08291](http://arxiv.org/abs/2506.08291)|null|
|**2025-06-09**|**RAPID Hand: A Robust, Affordable, Perception-Integrated, Dexterous Manipulation Platform for Generalist Robot Autonomy**|Hui Cheng Team|[2506.07490](http://arxiv.org/abs/2506.07490)|null|
|**2025-06-03**|**Tactile MNIST: Benchmarking Active Tactile Perception**|Jan Peters Team|[2506.06361](http://arxiv.org/abs/2506.06361)|null|
|**2025-06-05**|**GEX: Democratizing Dexterity with Fully-Actuated Dexterous Hand and Exoskeleton Glove**|Zelin Deng Team|[2506.04982](http://arxiv.org/abs/2506.04982)|null|
|**2025-06-05**|**ArtVIP: Articulated Digital Assets of Visual Realism, Modular Interaction, and Physical Fidelity for Robot Learning**|Jian Tang Team|[2506.04941](http://arxiv.org/abs/2506.04941)|null|
|**2025-06-03**|**Reachability Weighted Offline Goal-conditioned Resampling**|Joni Pajarinen Team|[2506.02577](http://arxiv.org/abs/2506.02577)|null|
|**2025-05-30**|**Interactive Imitation Learning for Dexterous Robotic Manipulation: Challenges and Perspectives -- A Survey**|Rania Rayyes Team|[2506.00098](http://arxiv.org/abs/2506.00098)|null|
|**2025-05-30**|**DexMachina: Functional Retargeting for Bimanual Dexterous Manipulation**|Shuran Song Team|[2505.24853](http://arxiv.org/abs/2505.24853)|null|
|**2025-05-28**|**ForceVLA: Enhancing VLA Models with a Force-aware MoE for Contact-rich Manipulation**|Wenqiang Zhang Team|[2505.22159](http://arxiv.org/abs/2505.22159)|null|
|**2025-05-28**|**DexUMI: Using Human Hand as the Universal Manipulation Interface for Dexterous Manipulation**|Shuran Song Team|[2505.21864](http://arxiv.org/abs/2505.21864)|null|
|**2025-05-27**|**Hume: Introducing System-2 Thinking in Visual-Language-Action Model**|Xuelong Li Team|[2505.21432](http://arxiv.org/abs/2505.21432)|null|
|**2025-05-27**|**Learning Generalizable Robot Policy with Human Demonstration Video as a Prompt**|Jianyu Chen Team|[2505.20795](http://arxiv.org/abs/2505.20795)|null|
|**2025-05-25**|**MaskedManipulator: Versatile Whole-Body Control for Loco-Manipulation**|Xue Bin Peng Team|[2505.19086](http://arxiv.org/abs/2505.19086)|null|
|**2025-05-25**|**OpenHOI: Open-World Hand-Object Interaction Synthesis with Multimodal Large Language Model**|Jingya Wang Team|[2505.18947](http://arxiv.org/abs/2505.18947)|null|
|**2025-05-24**|**Beyond Domain Randomization: Event-Inspired Perception for Visually Robust Adversarial Imitation from Videos**|Mario Bijelic Team|[2505.18899](http://arxiv.org/abs/2505.18899)|null|
|**2025-05-24**|**DiffusionRL: Efficient Training of Diffusion Policies for Robotic Grasping Using RL-Adapted Large-Scale Datasets**|Dzmitry Tsetserukou Team|[2505.18876](http://arxiv.org/abs/2505.18876)|null|
|**2025-05-24**|**GenPO: Generative Diffusion Models Meet On-Policy Reinforcement Learning**|Ye Shi Team|[2505.18763](http://arxiv.org/abs/2505.18763)|null|
|**2025-05-23**|**Bootstrapping Imitation Learning for Long-horizon Manipulation via Hierarchical Data Collection Space**|Hui Cheng Team|[2505.17389](http://arxiv.org/abs/2505.17389)|null|
|**2025-05-22**|**TacCompress: A Benchmark for Multi-Point Tactile Data Compression in Dexterous Hand**|Li Song Team|[2505.16289](http://arxiv.org/abs/2505.16289)|null|
|**2025-05-21**|**Object-Focus Actor for Data-efficient Robot Generalization Dexterous Manipulation**|Xiaodong He Team|[2505.15098](http://arxiv.org/abs/2505.15098)|null|
|**2025-05-20**|**DORA: Object Affordance-Guided Reinforcement Learning for Dexterous Robotic Manipulation**|Jianwei Zhang Team|[2505.14819](http://arxiv.org/abs/2505.14819)|null|
|**2025-05-20**|**Adaptive Visuo-Tactile Fusion with Predictive Force Attention for Dexterous Manipulation**|Hao Dong Team|[2505.13982](http://arxiv.org/abs/2505.13982)|null|
|**2025-05-19**|**Approximating Global Contact-Implicit MPC via Sampling and Local Complementarity**|Michael Posa Team|[2505.13350](http://arxiv.org/abs/2505.13350)|**[link](https://approximating-global-ci-mpc.github.io)**|
|**2025-05-19**|**Policy Contrastive Decoding for Robotic Foundation Models**|Lianli Gao Team|[2505.13255](http://arxiv.org/abs/2505.13255)|null|
|**2025-05-19**|**TeleOpBench: A Simulator-Centric Benchmark for Dual-Arm Dexterous Teleoperation**|Jiangmiao Pang Team|[2505.12748](http://arxiv.org/abs/2505.12748)|**[link](https://gorgeous2002.github.io/TeleOpBench/)**|
|**2025-05-18**|**PartDexTOG: Generating Dexterous Task-Oriented Grasping via Language-driven Part Analysis**|Zhipong Cai Team|[2505.12294](http://arxiv.org/abs/2505.12294)|null|
|**2025-05-17**|**OneTwoVLA: A Unified Vision-Language-Action Model with Adaptive Reasoning**|Yang Gao Team|[2505.11917](http://arxiv.org/abs/2505.11917)|null|
|**2025-05-16**|**EgoDex: Learning Dexterous Manipulation from Large-Scale Egocentric Video**|Jian Zhang Team|[2505.11709](http://arxiv.org/abs/2505.11709)|null|
|**2025-05-16**|**Self-supervised perception for tactile skin covered dexterous hands**|Mustafa Mukadam Team|[2505.11420](http://arxiv.org/abs/2505.11420)|null|
|**2025-05-16**|**Learning Multimodal AI Algorithms for Amplifying Limited User Input into High-dimensional Control Space**|Reza Abiri Team|[2505.11366](http://arxiv.org/abs/2505.11366)|null|
|**2025-05-16**|**Estimating Deformable-Rigid Contact Interactions for a Deformable Tool via Learning and Model-Based Optimization**|Nima Fazeli Team|[2505.10884](http://arxiv.org/abs/2505.10884)|null|
|**2025-05-15**|**SRT-H: A Hierarchical Framework for Autonomous Surgery via Language Conditioned Imitation Learning**|Axel Krieger Team|[2505.10251](http://arxiv.org/abs/2505.10251)|null|
|**2025-05-13**|**HandCept: A Visual-Inertial Fusion Framework for Accurate Proprioception in Dexterous Hands**|Yunhui Liu Team|[2505.08213](http://arxiv.org/abs/2505.08213)|null|
|**2025-05-12**|**DexWild: Dexterous Human Interactions for In-the-Wild Robot Policies**|Deepak Pathak Team|[2505.07813](http://arxiv.org/abs/2505.07813)|**[link](https://dexwild.github.io)**|
|**2025-05-08**|**Morphologically Symmetric Reinforcement Learning for Ambidextrous Bimanual Manipulation**|Georgia Chalvatzaki Team|[2505.05287](http://arxiv.org/abs/2505.05287)|null|
|**2025-05-04**|**Prompt-responsive Object Retrieval with Memory-augmented Student-Teacher Learning**|Sven Behnke Team|[2505.02232](http://arxiv.org/abs/2505.02232)|null|
|**2025-05-04**|**KineDex: Learning Tactile-Informed Visuomotor Policies via Kinesthetic Teaching for Dexterous Manipulation**|Yang Gao Team|[2505.01974](http://arxiv.org/abs/2505.01974)|null|
|**2025-05-02**|**DexFlow: A Unified Approach for Dexterous Hand Pose Retargeting and Interaction**|Miao Li Team|[2505.01083](http://arxiv.org/abs/2505.01083)|null|
|**2025-05-02**|**DexCtrl: Towards Sim-to-Real Dexterity with Adaptive Controller Learning**|Masayoshi Tomizuka Team|[2505.00991](http://arxiv.org/abs/2505.00991)|null|
|**2025-04-30**|**Multi-Goal Dexterous Hand Manipulation using Probabilistic Model-based Reinforcement Learning**|Yunduan Cui Team|[2504.21585](http://arxiv.org/abs/2504.21585)|null|
|**2025-04-28**|**Tendon-Actuated Concentric Tube Endonasal Robot (TACTER)**|Yash Chitalia Team|[2504.19948](http://arxiv.org/abs/2504.19948)|null|
|**2025-04-27**|**PolyTouch: A Robust Multi-Modal Tactile Sensor for Contact-rich Manipulation Using Tactile-Diffusion Policies**|Edward Adelson Team|[2504.19341](http://arxiv.org/abs/2504.19341)|null|
|**2025-04-23**|**PP-Tac: Paper Picking Using Tactile Feedback in Dexterous Robotic Hands**|Ziyuan Jiao Team|[2504.16649](http://arxiv.org/abs/2504.16649)|**[link](https://peilin-666.github.io/projects/PP-Tac/)**|
|**2025-04-22**|**$π_{0.5}$ : a Vision-Language-Action Model with Open-World Generalization**|Ury Zhilinsky Team|[2504.16054](http://arxiv.org/abs/2504.16054)|null|
|**2025-04-21**|**LAPP: Large Language Model Feedback for Preference-Driven Reinforcement Learning**|Boyuan Chen Team|[2504.15472](http://arxiv.org/abs/2504.15472)|null|
|**2025-04-21**|**SuFIA-BC: Generating High Quality Demonstration Data for Visuomotor Policy Learning in Surgical Subtasks**|Animesh Garg Team|[2504.14857](http://arxiv.org/abs/2504.14857)|null|
|**2025-04-20**|**BiDexHand: Design and Evaluation of an Open-Source 16-DoF Biomimetic Dexterous Hand**|Zhengyang Kris Weng Team|[2504.14712](http://arxiv.org/abs/2504.14712)|null|
|**2025-04-18**|**On the Importance of Tactile Sensing for Imitation Learning: A Case Study on Robotic Match Lighting**|Jan Peters Team|[2504.13618](http://arxiv.org/abs/2504.13618)|null|
|**2025-04-17**|**RUKA: Rethinking the Design of Humanoid Hands with Learning**|Lerrel Pinto Team|[2504.13165](http://arxiv.org/abs/2504.13165)|**[link](https://ruka-hand.github.io/)**|
|**2025-04-17**|**Adaptive Task Space Non-Singular Terminal Super-Twisting Sliding Mode Control of a 7-DOF Robotic Manipulator**|E. Witrant Team|[2504.13056](http://arxiv.org/abs/2504.13056)|null|
|**2025-04-17**|**Krysalis Hand: A Lightweight, High-Payload, 18-DoF Anthropomorphic End-Effector for Robotic Learning and Dexterous Manipulation**|Iman Soltani Team|[2504.12967](http://arxiv.org/abs/2504.12967)|null|
|**2025-04-17**|**Crossing the Human-Robot Embodiment Gap with Sim-to-Real RL using One Human Demonstration**|Jeannette Bohg Team|[2504.12609](http://arxiv.org/abs/2504.12609)|null|
|**2025-04-14**|**Look-to-Touch: A Vision-Enhanced Proximity and Tactile Sensor for Distance and Geometry Perception in Robotic Manipulation**|Guoying Gu Team|[2504.10280](http://arxiv.org/abs/2504.10280)|null|
|**2025-04-13**|**Humanoid Agent via Embodied Chain-of-Action Reasoning with Multimodal Foundation Models for Zero-Shot Loco-Manipulation**|Yi Fang Team|[2504.09532](http://arxiv.org/abs/2504.09532)|**[link](https://humanoid-coa.github.io/)**|
|**2025-04-08**|**Functionally graded keratin facilitates tactile sensing in elephant whiskers**|Katherine J. Kuchenbecker Team|[2504.07143](http://arxiv.org/abs/2504.07143)|null|
|**2025-04-08**|**ViTaMIn: Learning Contact-Rich Tasks Through Robot-Free Visuo-Tactile Manipulation Interface**|Rui Chen Team|[2504.06156](http://arxiv.org/abs/2504.06156)|null|
|**2025-04-08**|**MAPLE: Encoding Dexterous Robotic Manipulation Priors Learned From Egocentric Videos**|Marc Pollefeys Team|[2504.06084](http://arxiv.org/abs/2504.06084)|null|
|**2025-04-07**|**RobustDexGrasp: Robust Dexterous Grasping of General Objects**|Jie Song Team|[2504.05287](http://arxiv.org/abs/2504.05287)|**[link](https://zdchan.github.io/Robust_DexGrasp/)**|
|**2025-04-06**|**DexTOG: Learning Task-Oriented Dexterous Grasp with Language**|Cewu Lu Team|[2504.04573](http://arxiv.org/abs/2504.04573)|null|
|**2025-04-06**|**DexSinGrasp: Learning a Unified Policy for Dexterous Object Singulation and Grasping in Densely Cluttered Environments**|Lin Shao Team|[2504.04516](http://arxiv.org/abs/2504.04516)|null|
|**2025-04-05**|**ORCA: An Open-Source, Reliable, Cost-Effective, Anthropomorphic Robotic Hand for Uninterrupted Dexterous Task Learning**|Robert K. Katzschmann Team|[2504.04259](http://arxiv.org/abs/2504.04259)|null|
|**2025-04-04**|**Dexterous Manipulation through Imitation Learning: A Survey**|Hong Zhang Team|[2504.03515](http://arxiv.org/abs/2504.03515)|null|
|**2025-03-29**|**Dexterous Non-Prehensile Manipulation for Ungraspable Object via Extrinsic Dexterity**|Yuanpei Chen Team|[2503.23120](http://arxiv.org/abs/2503.23120)|null|
|**2025-03-27**|**ManipTrans: Efficient Dexterous Bimanual Manipulation Transfer via Residual Learning**|Siyuan Huang Team|[2503.21860](http://arxiv.org/abs/2503.21860)|null|
|**2025-03-27**|**Haptic bilateral teleoperation system for free-hand dental procedures**|Giovanni Russo Team|[2503.21288](http://arxiv.org/abs/2503.21288)|null|
|**2025-03-25**|**G-DexGrasp: Generalizable Dexterous Grasping Synthesis Via Part-Aware Prior Retrieval and Prior-Assisted Generation**|Ruizhen Hu Team|[2503.19457](http://arxiv.org/abs/2503.19457)|null|
|**2025-03-24**|**Evolutionary Policy Optimization**|Deepak Pathak Team|[2503.19037](http://arxiv.org/abs/2503.19037)|**[link](https://yifansu1301.github.io/EPO/)**|
|**2025-03-19**|**Learning to Play Piano in the Real World**|Roberto Calandra Team|[2503.15481](http://arxiv.org/abs/2503.15481)|null|
|**2025-03-17**|**PANDORA: Diffusion Policy Learning for Dexterous Robotic Piano Playing**|Zhengzhong Tu Team|[2503.14545](http://arxiv.org/abs/2503.14545)|null|
|**2025-03-18**|**EvolvingGrasp: Evolutionary Grasp Generation via Efficient Preference Alignment**|Yuexin Ma Team|[2503.14329](http://arxiv.org/abs/2503.14329)|null|
|**2025-03-16**|**Being-0: A Humanoid Robotic Agent with Vision-Language Models and Modular Skills**|Zongqing Lu Team|[2503.12533](http://arxiv.org/abs/2503.12533)|null|
|**2025-03-14**|**Is Your Imitation Learning Policy Better than Mine? Policy Comparison with Near-Optimal Stopping**|Haruki Nishimura Team|[2503.10966](http://arxiv.org/abs/2503.10966)|null|
|**2025-03-12**|**Sequential Multi-Object Grasping with One Dexterous Hand**|Daniel Seita Team|[2503.09078](http://arxiv.org/abs/2503.09078)|**[link](https://hesic73.github.io/SeqMultiGrasp/)**|
|**2025-03-11**|**Cross-Embodiment Robotic Manipulation Synthesis via Guided Demonstrations through CycleVAE and Human Behavior Transformer**|Mingjie Lin Team|[2503.08622](http://arxiv.org/abs/2503.08622)|null|
|**2025-03-11**|**DexGrasp Anything: Towards Universal Robotic Dexterous Grasping with Physics Awareness**|Yuexin Ma Team|[2503.08257](http://arxiv.org/abs/2503.08257)|null|
|**2025-03-09**|**AgiBot World Colosseo: A Large-scale Manipulation Platform for Scalable and Intelligent Embodied Systems**|Jianchao Zhu Team|[2503.06669](http://arxiv.org/abs/2503.06669)|**[link](https://agibot-world.com/.)**|
|**2025-03-08**|**ReJSHand: Efficient Real-Time Hand Pose Estimation and Mesh Reconstruction Using Refined Joint and Skeleton Features**|Hong Zhang Team|[2503.05995](http://arxiv.org/abs/2503.05995)|null|
|**2025-03-07**|**Kaiwu: A Multimodal Manipulation Dataset and Framework for Robot Learning and Human-Robot Interaction**|Bin He Team|[2503.05231](http://arxiv.org/abs/2503.05231)|null|
|**2025-03-07**|**Perceiving, Reasoning, Adapting: A Dual-Layer Framework for VLM-Guided Precision Robotic Manipulation**|Gang Chen Team|[2503.05064](http://arxiv.org/abs/2503.05064)|null|
|**2025-03-06**|**Dexterous Hand Manipulation via Efficient Imitation-Bootstrapped Online Reinforcement Learning**|Xiaodong He Team|[2503.04014](http://arxiv.org/abs/2503.04014)|null|
|**2025-03-05**|**LensDFF: Language-enhanced Sparse Feature Distillation for Efficient Few-Shot Dexterous Manipulation**|Alois Knoll Team|[2503.03890](http://arxiv.org/abs/2503.03890)|null|
|**2025-03-05**|**Selective Tweezing and Immobilization of Colloids for Dexterous Manipulation of Biological Materials**|Kimani C. Toussaint Team|[2503.03102](http://arxiv.org/abs/2503.03102)|null|
|**2025-03-03**|**TacCap: A Wearable FBG-Based Tactile Sensor for Seamless Human-to-Robot Skill Transfer**|Mark R. Cutkosky Team|[2503.01789](http://arxiv.org/abs/2503.01789)|null|
|**2025-03-03**|**RoboDexVLM: Visual Language Model-Enabled Task Planning and Motion Control for Dexterous Robot Manipulation**|Jun Ma Team|[2503.01616](http://arxiv.org/abs/2503.01616)|null|
|**2025-03-03**|**Exo-ViHa: A Cross-Platform Exoskeleton System with Visual and Haptic Feedback for Efficient Dexterous Skill Learning**|Wenbo Ding Team|[2503.01543](http://arxiv.org/abs/2503.01543)|null|
|**2025-03-03**|**KineSoft: Learning Proprioceptive Manipulation Policies with Soft Robot Hands**|Jeffrey Ichnowski Team|[2503.01078](http://arxiv.org/abs/2503.01078)|null|
|**2025-02-27**|**Sim-to-Real Reinforcement Learning for Vision-Based Dexterous Manipulation on Humanoids**|Yuke Zhu Team|[2502.20396](http://arxiv.org/abs/2502.20396)|**[link](https://toruowo.github.io/recipe/)**|
|**2025-02-27**|**Multi-Keypoint Affordance Representation for Functional Dexterous Grasping**|Yaonan Wang Team|[2502.20018](http://arxiv.org/abs/2502.20018)|**[link](https://github.com/PopeyePxx/MKA)**|
|**2025-02-26**|**ObjectVLA: End-to-End Open-World Object Manipulation Without Demonstration**|Feifei Feng Team|[2502.19250](http://arxiv.org/abs/2502.19250)|**[link](https://objectvla.github.io/)**|
|**2025-02-25**|**Retrieval Dexterity: Efficient Object Retrieval in Clutters with Dexterous Hand**|Yuanpei Chen Team|[2502.18423](http://arxiv.org/abs/2502.18423)|null|
|**2025-02-24**|**TDMPBC: Self-Imitative Reinforcement Learning for Humanoid Robot Control**|Donglin Wang Team|[2502.17322](http://arxiv.org/abs/2502.17322)|null|
|**2025-02-24**|**DemoGen: Synthetic Demonstration Generation for Data-Efficient Visuomotor Policy Learning**|Huazhe Xu Team|[2502.16932](http://arxiv.org/abs/2502.16932)|**[link](https://demo-generation.github.io)**|
|**2025-02-18**|**HOMIE: Humanoid Loco-Manipulation with Isomorphic Exoskeleton Cockpit**|Jiangmiao Pang Team|[2502.13013](http://arxiv.org/abs/2502.13013)|null|
|**2025-02-14**|**Global-Local Interface for On-Demand Teleoperation**|Masayoshi Tomizuka Team|[2502.09960](http://arxiv.org/abs/2502.09960)|null|
|**2025-02-13**|**DexTrack: Towards Generalizable Neural Tracking Control for Dexterous Manipulation from Human References**|Li Yi Team|[2502.09614](http://arxiv.org/abs/2502.09614)|**[link](https://meowuu7.github.io/DexTrack/)**|
|**2025-02-12**|**MuJoCo Playground**|Pieter Abbeel Team|[2502.08844](http://arxiv.org/abs/2502.08844)|null|
|**2025-02-12**|**CordViP: Correspondence-based Visuomotor Policy for Dexterous Manipulation in Real-World**|Shanghang Zhang Team|[2502.08449](http://arxiv.org/abs/2502.08449)|**[link](https://aureleopku.github.io/CordViP)**|
|**2025-02-11**|**DOGlove: Dexterous Manipulation with a Low-Cost Open-Source Haptic Force Feedback Glove**|Huazhe Xu Team|[2502.07730](http://arxiv.org/abs/2502.07730)|null|
|**2025-02-09**|**DexVLA: Vision-Language Model with Plug-In Diffusion Expert for General Robot Control**|Feifei Feng Team|[2502.05855](http://arxiv.org/abs/2502.05855)|**[link](https://dex-vla.github.io/.)**|
|**2025-02-06**|**DexterityGen: Foundation Controller for Unprecedented Dexterity**|Mustafa Mukadam Team|[2502.04307](http://arxiv.org/abs/2502.04307)|**[link](https://zhaohengyin.github.io/dexteritygen)**|
|**2025-02-04**|**MuST: Multi-Head Skill Transformer for Long-Horizon Dexterous Manipulation with Skill Progress**|Jane Shi Team|[2502.02753](http://arxiv.org/abs/2502.02753)|null|
|**2025-02-04**|**Rapidly Adapting Policies to the Real World via Simulation-Guided Fine-Tuning**|Abhishek Gupta Team|[2502.02705](http://arxiv.org/abs/2502.02705)|null|
|**2025-02-01**|**Dexterous Cable Manipulation: Taxonomy, Multi-Fingered Hand Design, and Long-Horizon Manipulation**|Robert B. Fisher Team|[2502.00396](http://arxiv.org/abs/2502.00396)|**[link](https://sites.google.com/view/dexterous-cable-manipulation/home)**|
|**2025-01-28**|**Strawberry Robotic Operation Interface: An Open-Source Device for Collecting Dexterous Manipulation Data in Robotic Strawberry Farming**|Zhenghao Fei Team|[2501.16717](http://arxiv.org/abs/2501.16717)|null|
|**2025-01-27**|**Underactuated dexterous robotic grasping with reconfigurable passive joints**|Piotr Skrzypczyński Team|[2501.16006](http://arxiv.org/abs/2501.16006)|null|
|**2025-01-17**|**DexForce: Extracting Force-informed Actions from Kinesthetic Demonstrations for Dexterous Manipulation**|Jeannette Bohg Team|[2501.10356](http://arxiv.org/abs/2501.10356)|**[link](https://clairelc.github.io/dexforce.github.io/)**|
|**2025-01-12**|**Shake-VLA: Vision-Language-Action Model-Based System for Bimanual Robotic Manipulations and Liquid Mixing**|Dzmitry Tsetserukou Team|[2501.06919](http://arxiv.org/abs/2501.06919)|null|
|**2025-01-09**|**From Simple to Complex Skills: The Case of In-Hand Object Reorientation**|Jitendra Malik Team|[2501.05439](http://arxiv.org/abs/2501.05439)|**[link](https://dexhier.github.io)**|
|**2025-01-09**|**Integrated Shape-Force Estimation for Continuum Robots: A Virtual-Work and Polynomial-Curvature Framework**|Long Wang Team|[2501.05418](http://arxiv.org/abs/2501.05418)|null|
|**2025-01-09**|**Dexterous Manipulation of Deformable Objects via Pneumatic Gripping: Lifting by One End**|Ann Majewicz Fey Team|[2501.05198](http://arxiv.org/abs/2501.05198)|null|
|**2025-01-08**|**A Survey on Path Planning Problem of Rolling Contacts: Approaches, Applications and Future Challenges**|Kenji Tahara Team|[2501.04442](http://arxiv.org/abs/2501.04442)|null|
|**2025-01-07**|**Learning to Transfer Human Hand Skills for Robot Manipulations**|Hanbyul Joo Team|[2501.04169](http://arxiv.org/abs/2501.04169)|null|
|**2025-01-07**|**VTAO-BiManip: Masked Visual-Tactile-Action Pre-training with Object Understanding for Bimanual Dexterous Manipulation**|Jiming Chen Team|[2501.03606](http://arxiv.org/abs/2501.03606)|null|
|**2025-01-06**|**Sim-to-Real Transfer for Mobile Robots with Reinforcement Learning: from NVIDIA Isaac Sim to Gazebo and Real ROS 2 Robots**|Tomi Westerlund Team|[2501.02902](http://arxiv.org/abs/2501.02902)|null|
|**2025-01-01**|**An Immersive Virtual Reality Bimanual Telerobotic System With Haptic Feedback**|Qiang Li Team|[2501.00822](http://arxiv.org/abs/2501.00822)|null|
|**2024-12-25**|**GeoMatch++: Morphology Conditioned Geometry Matching for Multi-Embodiment Grasping**|Igor Gilitschenski Team|[2412.18998](http://arxiv.org/abs/2412.18998)|null|
|**2024-12-23**|**Online Adaptation for Myographic Control of Natural Dexterous Hand and Finger Movements**|Nitish V. Thakor Team|[2412.17991](http://arxiv.org/abs/2412.17991)|null|
|**2024-12-18**|**ManiVideo: Generating Hand-Object Manipulation Video with Dexterous and Generalizable Grasping**|Yebin Liu Team|[2412.16212](http://arxiv.org/abs/2412.16212)|null|
|**2024-12-20**|**Dexterous Manipulation Based on Prior Dexterous Grasp Pose Knowledge**|Cewu Lu Team|[2412.15587](http://arxiv.org/abs/2412.15587)|null|
|**2024-12-19**|**Video Prediction Policy: A Generalist Robot Policy with Predictive Visual Representations**|Jianyu Chen Team|[2412.14803](http://arxiv.org/abs/2412.14803)|null|
|**2024-12-18**|**RoboMIND: Benchmark on Multi-embodiment Intelligence Normative Data for Robot Manipulation**|Jian Tang Team|[2412.13877](http://arxiv.org/abs/2412.13877)|null|
|**2024-12-18**|**TelePreview: A User-Friendly Teleoperation System with Virtual Arm Assistance for Enhanced Effectiveness**|Lin Shao Team|[2412.13548](http://arxiv.org/abs/2412.13548)|null|
|**2024-12-17**|**Learning Visuotactile Estimation and Control for Non-prehensile Manipulation under Occlusions**|Sethu Vijayakumar Team|[2412.13157](http://arxiv.org/abs/2412.13157)|null|
|**2024-12-15**|**Modality-Driven Design for Multi-Step Dexterous Manipulation: Insights from Neuroscience**|Katsushi Ikeuchi Team|[2412.11337](http://arxiv.org/abs/2412.11337)|null|
|**2024-12-12**|**Should We Learn Contact-Rich Manipulation Policies from Sampling-Based Planners?**|Tao Pang Team|[2412.09743](http://arxiv.org/abs/2412.09743)|null|
|**2024-12-05**|**Learning Dual-Arm Push and Grasp Synergy in Dense Clutter**|Hamidreza Kasaei Team|[2412.04052](http://arxiv.org/abs/2412.04052)|null|
|**2024-12-03**|**UniGraspTransformer: Simplified Policy Distillation for Scalable Dexterous Robotic Grasping**|Baining Guo Team|[2412.02699](http://arxiv.org/abs/2412.02699)|**[link](https://dexhand.github.io/UniGraspTransformer)**|
|**2024-12-03**|**Leveraging Tactile Sensing to Render both Haptic Feedback and Virtual Reality 3D Object Reconstruction in Robotic Telemanipulation**|Lorenzo Jamone Team|[2412.02644](http://arxiv.org/abs/2412.02644)|null|
|**2024-12-03**|**Haptic Stiffness Perception Using Hand Exoskeletons in Tactile Robotic Telemanipulation**|Lorenzo Jamone Team|[2412.02613](http://arxiv.org/abs/2412.02613)|null|
|**2024-11-27**|**DextrAH-RGB: Visuomotor Policies to Grasp Anything with Dexterous Hands**|Karl Van Wyk Team|[2412.01791](http://arxiv.org/abs/2412.01791)|null|
|**2024-12-02**|**On the Surprising Effectiveness of Spectral Clipping in Learning Stable Linear and Latent-Linear Dynamical Systems**|Harish Ravichandar Team|[2412.01168](http://arxiv.org/abs/2412.01168)|null|
|**2024-11-29**|**Robust Bayesian Scene Reconstruction with Retrieval-Augmented Priors for Precise Grasping and Planning**|Tucker Hermans Team|[2411.19461](http://arxiv.org/abs/2411.19461)|null|
|**2024-11-27**|**DexHandDiff: Interaction-aware Diffusion Planning for Adaptive Dexterous Manipulation**|Mingyu Ding Team|[2411.18562](http://arxiv.org/abs/2411.18562)|**[link](https://dexdiffuser.github.io/)**|
|**2024-11-24**|**FunGrasp: Functional Grasping for Diverse Dexterous Hands**|Jie Song Team|[2411.16755](http://arxiv.org/abs/2411.16755)|**[link](https://hly-123.github.io/FunGrasp/)**|
|**2024-11-24**|**Bimanual Grasp Synthesis for Dexterous Robot Hands**|Chenxi Xiao Team|[2411.15903](http://arxiv.org/abs/2411.15903)|null|
|**2024-11-21**|**Learning thin deformable object manipulation with a multi-sensory integrated soft hand**|Hongyu Yu Team|[2411.13952](http://arxiv.org/abs/2411.13952)|null|
|**2024-11-20**|**Bimanual Dexterity for Complex Tasks**|Deepak Pathak Team|[2411.13677](http://arxiv.org/abs/2411.13677)|**[link](https://bidex-teleop.github.io/)**|
|**2024-11-20**|**Tactile-based force estimation for interaction control with robot fingers**|Mahdi Khoramshahi Team|[2411.13335](http://arxiv.org/abs/2411.13335)|null|
|**2024-11-20**|**AsymDex: Asymmetry and Relative Coordinates for RL-based Bimanual Dexterity**|Harish Ravichandar Team|[2411.13020](http://arxiv.org/abs/2411.13020)|null|
|**2024-11-19**|**GLOVER: Generalizable Open-Vocabulary Affordance Reasoning for Task-Oriented Grasping**|Junwei Liang Team|[2411.12286](http://arxiv.org/abs/2411.12286)|null|
|**2024-11-09**|**Sampling-Based Model Predictive Control for Dexterous Manipulation on a Biomimetic Tendon-Driven Hand**|Robert K. Katzschmann Team|[2411.06183](http://arxiv.org/abs/2411.06183)|**[link](https://youtu.be/u4d6v3ohsOI)**|
|**2024-11-07**|**Fingernail-Based Tangential Force Simulation for Enhanced Dexterous Manipulation in Virtual Reality**|Shoichi Hasegawa Team|[2411.05100](http://arxiv.org/abs/2411.05100)|null|
|**2024-11-07**|**TacEx: GelSight Tactile Simulation in Isaac Sim -- Combining Soft-Body and Visuotactile Simulators**|Jan Peters Team|[2411.04776](http://arxiv.org/abs/2411.04776)|null|
|**2024-11-07**|**DexH2R: Task-oriented Dexterous Manipulation from Human to Robots**|Masayoshi Tomizuka Team|[2411.04428](http://arxiv.org/abs/2411.04428)|null|
|**2024-11-06**|**Object-Centric Dexterous Manipulation from Human Motion Data**|C. Karen Liu Team|[2411.04005](http://arxiv.org/abs/2411.04005)|null|
|**2024-11-05**|**VQ-ACE: Efficient Policy Search for Dexterous Robotic Manipulation via Action Chunking Embedding**|Robert K. Katzschmann Team|[2411.03556](http://arxiv.org/abs/2411.03556)|null|
|**2024-10-31**|**DexMimicGen: Automated Data Generation for Bimanual Dexterous Manipulation via Imitation Learning**|Yuke Zhu Team|[2410.24185](http://arxiv.org/abs/2410.24185)|**[link](https://dexmimicgen.github.io/)**|
|**2024-10-31**|**$π_0$ : A Vision-Language-Action Flow Model for General Robot Control**|Ury Zhilinsky Team|[2410.24164](http://arxiv.org/abs/2410.24164)|**[link](https://physicalintelligence.company/blog/pi0)**|
|**2024-10-31**|**SceneComplete: Open-World 3D Scene Completion in Cluttered Real World Environments for Robot Manipulation**|Leslie Pack Kaelbling Team|[2410.23643](http://arxiv.org/abs/2410.23643)|null|
|**2024-10-30**|**DexGraspNet 2.0: Learning Generative Dexterous Grasping in Large-scale Synthetic Cluttered Scenes**|He Wang Team|[2410.23004](http://arxiv.org/abs/2410.23004)|null|
|**2024-10-29**|**Precise and Dexterous Robotic Manipulation via Human-in-the-Loop Reinforcement Learning**|Sergey Levine Team|[2410.21845](http://arxiv.org/abs/2410.21845)|null|
|**2024-10-29**|**DOFS: A Real-world 3D Deformable Object Dataset with Full Spatial Information for Dynamics Model Learning**|K. W. Samuel Au Team|[2410.21758](http://arxiv.org/abs/2410.21758)|null|
|**2024-10-24**|**Embodied Manipulation with Past and Future Morphologies through an Open Parametric Hand Design**|Josie Hughes Team|[2410.18633](http://arxiv.org/abs/2410.18633)|null|
|**2024-10-17**|**Vision-Language-Action Model and Diffusion Policy Switching Enables Dexterous Control of an Anthropomorphic Hand**|Josie Hughes Team|[2410.14022](http://arxiv.org/abs/2410.14022)|null|
|**2024-10-17**|**ALOHA Unleashed: A Simple Recipe for Robot Dexterity**|Ayzaan Wahid Team|[2410.13126](http://arxiv.org/abs/2410.13126)|null|
|**2024-10-15**|**Mitigating Suboptimality of Deterministic Policy Gradients in Complex Q-functions**|Joseph J. Lim Team|[2410.11833](http://arxiv.org/abs/2410.11833)|null|
|**2024-10-14**|**HumanFT: A Human-like Fingertip Multimodal Visuo-Tactile Sensor**|Chenxi Xiao Team|[2410.10353](http://arxiv.org/abs/2410.10353)|null|
|**2024-10-14**|**The Ingredients for Robotic Diffusion Transformers**|Sergey Levine Team|[2410.10088](http://arxiv.org/abs/2410.10088)|null|
|**2024-10-09**|**On the Feasibility of A Mixed-Method Approach for Solving Long Horizon Task-Oriented Dexterous Manipulation**|Rana Soltani Zarrin Team|[2410.07403](http://arxiv.org/abs/2410.07403)|null|
|**2024-10-08**|**FürElise: Capturing and Physically Synthesizing Hand Motions of Piano Performance**|C. Karen Liu Team|[2410.05791](http://arxiv.org/abs/2410.05791)|**[link](https://for-elise.github.io/)**|
|**2024-10-03**|**Cross-Embodiment Dexterous Grasping with Reinforcement Learning**|Zongqing Lu Team|[2410.02479](http://arxiv.org/abs/2410.02479)|null|
|**2024-10-03**|**Learning Diverse Bimanual Dexterous Manipulation Skills from Human Demonstrations**|Zongqing Lu Team|[2410.02477](http://arxiv.org/abs/2410.02477)|null|
|**2024-10-03**|**Capturing complex hand movements and object interactions using machine learning-powered stretchable smart textile gloves**|Peyman Servati Team|[2410.02221](http://arxiv.org/abs/2410.02221)|null|
|**2024-09-26**|**Target Pose Guided Whole-body Grasping Motion Generation for Digital Humans**|Yi Fang Team|[2410.01840](http://arxiv.org/abs/2410.01840)|null|
|**2024-10-02**|**$\mathcal{D(R,O)}$ Grasp: A Unified Representation of Robot and Object Interaction for Cross-Embodiment Dexterous Grasping**|Lin Shao Team|[2410.01702](http://arxiv.org/abs/2410.01702)|**[link](https://nus-lins-lab.github.io/drograspweb/)**|
|**2024-09-30**|**Learning with Less: Optimizing Tactile Sensor Configurations for Dexterous Manipulation**|Lingfeng Tao Team|[2409.20473](http://arxiv.org/abs/2409.20473)|null|
|**2024-09-30**|**Design and validation of a fuzzy logic controller for multi-section continuum robots**|Dragos Axinte Team|[2409.20242](http://arxiv.org/abs/2409.20242)|null|
|**2024-09-26**|**Canonical Representation and Force-Based Pretraining of 3D Tactile for Dexterous Visuo-Tactile Policy Learning**|Hao Dong Team|[2409.17549](http://arxiv.org/abs/2409.17549)|null|
|**2024-09-23**|**Bimanual In-hand Manipulation using Dual Limit Surfaces**|Nima Fazeli Team|[2409.14698](http://arxiv.org/abs/2409.14698)|null|
|**2024-09-19**|**Fine Manipulation Using a Tactile Skin: Learning in Simulation and Sim-to-Real Transfer**|Berthold Bäuml Team|[2409.12735](http://arxiv.org/abs/2409.12735)|null|
|**2024-09-19**|**MuxHand: A Cable-driven Dexterous Robotic Hand Using Time-division Multiplexing Motors**|Chongkun Xia Team|[2409.12455](http://arxiv.org/abs/2409.12455)|null|
|**2024-09-18**|**A Learning-based Controller for Multi-Contact Grasps on Unknown Objects with a Dexterous Hand**|Berthold Bäuml Team|[2409.12339](http://arxiv.org/abs/2409.12339)|null|
|**2024-09-18**|**GauTOAO: Gaussian-based Task-Oriented Affordance of Objects**|Dingsheng Luo Team|[2409.11941](http://arxiv.org/abs/2409.11941)|null|
|**2024-09-17**|**MoDex: Planning High-Dimensional Dexterous Control via Learning Neural Internal Models**|Wenbo Ding Team|[2409.10983](http://arxiv.org/abs/2409.10983)|null|
|**2024-09-16**|**Catch It! Learning to Catch in Flight with Mobile Dexterous Hands**|Huazhe Xu Team|[2409.10319](http://arxiv.org/abs/2409.10319)|null|
|**2024-09-14**|**ManiDext: Hand-Object Manipulation Synthesis via Continuous Correspondence Embeddings and Residual-Guided Diffusion**|Yebin Liu Team|[2409.09300](http://arxiv.org/abs/2409.09300)|null|
|**2024-09-13**|**ResPilot: Teleoperated Finger Gaiting via Gaussian Process Residual Learning**|Soshi Iba Team|[2409.09140](http://arxiv.org/abs/2409.09140)|null|
|**2024-08-22**|**Tilde: Teleoperation for Dexterous In-Hand Manipulation Learning with a DeltaHand**|Oliver Kroemer Team|[2405.18804](http://arxiv.org/abs/2405.18804)|null|
|**2023-12-13**|**DEFT: Dexterous Fine-Tuning for Real-World Hand Policies**|Deepak Pathak Team|[2310.19797](http://arxiv.org/abs/2310.19797)|**[link](https://dexterous-finetuning.github.io/)**|
|**2023-12-27**|**DELTAHANDS: A Synergistic Dexterous Hand Framework Based on Delta Robots**|F. Zeynep Temel Team|[2310.05266](http://arxiv.org/abs/2310.05266)|null|
|**2023-10-17**|**Sequential Dexterity: Chaining Dexterous Policies for Long-Horizon Manipulation**|C. Karen Liu Team|[2309.00987](http://arxiv.org/abs/2309.00987)|null|
|**2023-08-23**|**Dexterous Soft Hands Linearize Feedback-Control for In-Hand Manipulation**|Oliver Brock Team|[2308.10691](http://arxiv.org/abs/2308.10691)|null|
|**2023-04-20**|**Progressive Transfer Learning for Dexterous In-Hand Manipulation with Multi-Fingered Anthropomorphic Hand**|Jia Sun Team|[2304.09526](http://arxiv.org/abs/2304.09526)|null|
|**2022-03-25**|**Dexterous Imitation Made Easy: A Learning-Based Framework for Efficient Dexterous Manipulation**|Lerrel Pinto Team|[2203.13251](http://arxiv.org/abs/2203.13251)|null|
|**2022-05-11**|**RBO Hand 3 -- A Platform for Soft Dexterous Manipulation**|Oliver Brock Team|[2201.10883](http://arxiv.org/abs/2201.10883)|null|
|**2019-01-23**|**Learning Dexterous In-Hand Manipulation**|Wojciech Zaremba Team|[1808.00177](http://arxiv.org/abs/1808.00177)|null|
|**2018-06-27**|**Learning Complex Dexterous Manipulation with Deep Reinforcement Learning and Demonstrations**|Sergey Levine Team|[1709.10087](http://arxiv.org/abs/1709.10087)|**[link](https://sites.google.com/view/deeprl-dexterous-manipulation)**|
|**2017-03-21**|**Learning Dexterous Manipulation for a Soft Robotic Hand from Human Demonstration**|Pieter Abbeel Team|[1603.06348](http://arxiv.org/abs/1603.06348)|null|

<p align=right>(<a href=#updated-on-20251217>back to top</a>)</p>

## Perception

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-12-12**|**ProbeMDE: Uncertainty-Guided Active Proprioception for Monocular Depth Estimation in Surgical Robotics**|James Ferguson Team|[2512.11773](http://arxiv.org/abs/2512.11773)|null|
|**2025-12-12**|**SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder**|Jiwen Lu Team|[2512.11749](http://arxiv.org/abs/2512.11749)|**[link](https://github.com/KlingTeam/SVG-T2I)**|
|**2025-12-12**|**Evaluating Foundation Models' 3D Understanding Through Multi-View Correspondence Analysis**|Mohammadreza Salehi Team|[2512.11574](http://arxiv.org/abs/2512.11574)|null|
|**2025-12-12**|**DentalGPT: Incentivizing Multimodal Complex Reasoning in Dentistry**|Benyou Wang Team|[2512.11558](http://arxiv.org/abs/2512.11558)|null|
|**2025-12-12**|**Reconstruction as a Bridge for Event-Based Visual Question Answering**|Boxin Shi Team|[2512.11510](http://arxiv.org/abs/2512.11510)|null|
|**2025-12-12**|**VLM2GeoVec: Toward Universal Multimodal Embeddings for Remote Sensing**|Michael Felsberg Team|[2512.11490](http://arxiv.org/abs/2512.11490)|null|
|**2025-12-12**|**Exploring MLLM-Diffusion Information Transfer with MetaCanvas**|Chu Wang Team|[2512.11464](http://arxiv.org/abs/2512.11464)|**[link](https://metacanvas.github.io)**|
|**2025-12-11**|**SoccerMaster: A Vision Foundation Model for Soccer Understanding**|Weidi Xie Team|[2512.11016](http://arxiv.org/abs/2512.11016)|null|
|**2025-12-11**|**Video Depth Propagation**|Luc Van Gool Team|[2512.10725](http://arxiv.org/abs/2512.10725)|null|
|**2025-12-11**|**SpaceDrive: Infusing Spatial Awareness into VLM-based Autonomous Driving**|Andreas Zell Team|[2512.10719](http://arxiv.org/abs/2512.10719)|null|
|**2025-12-11**|**Blink: Dynamic Visual Token Resolution for Enhanced Multimodal Understanding**|Haifeng Wang Team|[2512.10548](http://arxiv.org/abs/2512.10548)|null|
|**2025-12-11**|**Physically Aware 360 $^\circ$ View Generation from a Single Image using Disentangled Scene Embeddings**|Narendra Bandaru Team|[2512.10293](http://arxiv.org/abs/2512.10293)|null|
|**2025-12-10**|**Token Expand-Merge: Training-Free Token Compression for Vision-Language-Action Models**|Zhihe Lu Team|[2512.09927](http://arxiv.org/abs/2512.09927)|null|
|**2025-12-10**|**LISN: Language-Instructed Social Navigation with VLM-based Controller Modulating**|Lin Shao Team|[2512.09920](http://arxiv.org/abs/2512.09920)|null|
|**2025-12-10**|**Simultaneous Tactile-Visual Perception for Learning Multimodal Robot Manipulation**|Yixin Zhu Team|[2512.09851](http://arxiv.org/abs/2512.09851)|null|
|**2025-12-10**|**Investigate the Low-level Visual Perception in Vision-Language based Image Quality Assessment**|Shin'ya Nishida Team|[2512.09573](http://arxiv.org/abs/2512.09573)|null|
|**2025-12-10**|**Building Reasonable Inference for Vision-Language Models in Blind Image Quality Assessment**|Shin'ya Nishida Team|[2512.09555](http://arxiv.org/abs/2512.09555)|null|
|**2025-12-10**|**Efficiency-Aware Computational Intelligence for Resource-Constrained Manufacturing Toward Edge-Ready Deployment**|Qianyu Zhou Team|[2512.09319](http://arxiv.org/abs/2512.09319)|null|
|**2025-12-09**|**SIP: Site in Pieces- A Dataset of Disaggregated Construction-Phase 3D Scans for Semantic Segmentation and Scene Understanding**|Yong Kwon Cho Team|[2512.09062](http://arxiv.org/abs/2512.09062)|null|
|**2025-12-09**|**LiDAS: Lighting-driven Dynamic Active Sensing for Nighttime Perception**|Fabien Moutarde Team|[2512.08912](http://arxiv.org/abs/2512.08912)|**[link](https://simondemoreau.github.io/LiDAS/)**|
|**2025-12-09**|**Generation is Required for Data-Efficient Perception**|Wieland Brendel Team|[2512.08854](http://arxiv.org/abs/2512.08854)|null|
|**2025-12-09**|**LapFM: A Laparoscopic Segmentation Foundation Model via Hierarchical Concept Evolving Pre-training**|Zhen Chen Team|[2512.08439](http://arxiv.org/abs/2512.08439)|null|
|**2025-12-09**|**VisKnow: Constructing Visual Knowledge Base for Object Understanding**|Xilin Chen Team|[2512.08221](http://arxiv.org/abs/2512.08221)|null|
|**2025-12-09**|**Fourier-RWKV: A Multi-State Perception Network for Efficient Image Dehazing**|Kaihao Zhang Team|[2512.08161](http://arxiv.org/abs/2512.08161)|null|
|**2025-12-09**|**CVP: Central-Peripheral Vision-Inspired Multimodal Model for Spatial Reasoning**|Zhuowen Tu Team|[2512.08135](http://arxiv.org/abs/2512.08135)|null|
|**2025-12-08**|**Sparse Variable Projection in Robotic Perception: Exploiting Separable Structure for Efficient Nonlinear Optimization**|Michael Everett Team|[2512.07969](http://arxiv.org/abs/2512.07969)|null|
|**2025-12-08**|**SpatialDreamer: Incentivizing Spatial Reasoning via Active Mental Imagery**|Xiaodan Liang Team|[2512.07733](http://arxiv.org/abs/2512.07733)|null|
|**2025-12-08**|**SAVE: Sparse Autoencoder-Driven Visual Information Enhancement for Mitigating Object Hallucination**|Sungroh Yoon Team|[2512.07730](http://arxiv.org/abs/2512.07730)|null|
|**2025-12-08**|**KAN-Dreamer: Benchmarking Kolmogorov-Arnold Networks as Function Approximators in World Models**|Xueyu Luan Team|[2512.07437](http://arxiv.org/abs/2512.07437)|null|
|**2025-12-08**|**Zero-Shot Textual Explanations via Translating Decision-Critical Features**|Kazuhiko Kawamoto Team|[2512.07245](http://arxiv.org/abs/2512.07245)|null|
|**2025-12-08**|**STRinGS: Selective Text Refinement in Gaussian Splatting**|Makarand Tapaswi Team|[2512.07230](http://arxiv.org/abs/2512.07230)|**[link](https://STRinGS-official.github.io)**|
|**2025-12-08**|**Object Pose Distribution Estimation for Determining Revolution and Reflection Uncertainty in Point Clouds**|Thorbjørn Mosekjær Iversen Team|[2512.07211](http://arxiv.org/abs/2512.07211)|null|
|**2025-12-08**|**MMRPT: MultiModal Reinforcement Pre-Training via Masked Vision-Dependent Reasoning**|Yichao Wu Team|[2512.07203](http://arxiv.org/abs/2512.07203)|null|
|**2025-12-08**|**A Large-Scale Multimodal Dataset and Benchmarks for Human Activity Scene Understanding and Reasoning**|Guoliang Xing Team|[2512.07136](http://arxiv.org/abs/2512.07136)|null|
|**2025-12-05**|**Physics-Grounded Attached Shadow Detection Using Approximate 3D Geometry and Light Direction**|Hieu Le Team|[2512.06179](http://arxiv.org/abs/2512.06179)|null|
|**2025-12-05**|**BeLLA: End-to-End Birds Eye View Large Language Assistant for Autonomous Driving**|Amit Arvind Kale Team|[2512.06096](http://arxiv.org/abs/2512.06096)|null|
|**2025-12-03**|**VAT: Vision Action Transformer by Unlocking Full Representation of ViT**|Weixin Mao Team|[2512.06013](http://arxiv.org/abs/2512.06013)|null|
|**2025-12-01**|**FishDetector-R1: Unified MLLM-Based Framework with Reinforcement Fine-Tuning for Weakly Supervised Fish Detection, Segmentation, and Counting**|Katherine A. Skinner Team|[2512.05996](http://arxiv.org/abs/2512.05996)|null|
|**2025-12-05**|**SIMPACT: Simulation-Enabled Action Planning using Vision-Language Models**|Yilun Du Team|[2512.05955](http://arxiv.org/abs/2512.05955)|null|
|**2025-12-05**|**Synset Signset Germany: a Synthetic Dataset for German Traffic Sign Recognition**|Jens Ziehn Team|[2512.05936](http://arxiv.org/abs/2512.05936)|null|
|**2025-12-05**|**PRiSM: An Agentic Multimodal Benchmark for Scientific Reasoning via Python-Grounded Evaluation**|Babak Damavandi Team|[2512.05930](http://arxiv.org/abs/2512.05930)|null|
|**2025-12-05**|**VRSA: Jailbreaking Multimodal Large Language Models through Visual Reasoning Sequential Attack**|Xingxing Wei Team|[2512.05853](http://arxiv.org/abs/2512.05853)|null|
|**2025-12-05**|**Time-Temperature-Transformation (TTT) Diagrams to rationalize the nucleation and quenchability of metastable $α$-Li$_3$PS$_4$**|Wenhao Sun Team|[2512.05841](http://arxiv.org/abs/2512.05841)|null|
|**2025-12-05**|**Toward Efficient and Robust Behavior Models for Multi-Agent Driving Simulation**|Christoph Stiller Team|[2512.05812](http://arxiv.org/abs/2512.05812)|null|
|**2025-12-05**|**Curvature-Regularized Variational Autoencoder for 3D Scene Reconstruction from Sparse Depth**|Soodeh Bakhshandeh Team|[2512.05783](http://arxiv.org/abs/2512.05783)|null|
|**2025-12-05**|**Distilling Expert Surgical Knowledge: How to train local surgical VLMs for anatomy explanation in Complete Mesocolic Excision**|Alexander Schlaefer Team|[2512.05740](http://arxiv.org/abs/2512.05740)|null|
|**2025-12-05**|**Interleaved Latent Visual Reasoning with Selective Perceptual Modeling**|Zhongyu Wei Team|[2512.05665](http://arxiv.org/abs/2512.05665)|**[link](https://github.com/XD111ds/ILVR)**|
|**2025-12-05**|**Self-Supervised AI-Generated Image Detection: A Camera Metadata Perspective**|Kede Ma Team|[2512.05651](http://arxiv.org/abs/2512.05651)|null|
|**2025-12-05**|**Fast SceneScript: Accurate and Efficient Structured Language Model via Multi-Token Prediction**|Theo Gevers Team|[2512.05597](http://arxiv.org/abs/2512.05597)|null|
|**2025-12-05**|**2K-Characters-10K-Stories: A Quality-Gated Stylized Narrative Dataset with Disentangled Control and Sequence Consistency**|Yin Zhang Team|[2512.05557](http://arxiv.org/abs/2512.05557)|null|
|**2025-12-05**|**Ideal Observer for Segmentation of Dead Leaves Images**|Malte Ott Team|[2512.05539](http://arxiv.org/abs/2512.05539)|null|
|**2025-12-05**|**See in Depth: Training-Free Surgical Scene Segmentation with Monocular Depth Priors**|Yutong Ban Team|[2512.05529](http://arxiv.org/abs/2512.05529)|null|
|**2025-12-05**|**VOST-SGG: VLM-Aided One-Stage Spatio-Temporal Scene Graph Generation**|Basura Fernando Team|[2512.05524](http://arxiv.org/abs/2512.05524)|null|
|**2025-12-05**|**Know-Show: Benchmarking Video-Language Models on Spatio-Temporal Grounded Reasoning**|Basura Fernando Team|[2512.05513](http://arxiv.org/abs/2512.05513)|null|
|**2025-12-05**|**Concept-based Explainable Data Mining with VLM for 3D Detection**|Mai Tsujimoto Team|[2512.05482](http://arxiv.org/abs/2512.05482)|**[link](https://github.com/mm1129/concept_based_rare_detector_2025)**|
|**2025-12-05**|**TED-4DGS: Temporally Activated and Embedding-based Deformation for 4DGS Compression**|Wen-Hsiao Peng Team|[2512.05446](http://arxiv.org/abs/2512.05446)|null|
|**2025-12-05**|**From Vision to Touch: Bridging Visual and Tactile Principles for Accessible Data Representation**|Danielle Albers Szafir Team|[2512.05433](http://arxiv.org/abs/2512.05433)|null|
|**2025-12-05**|**The Dynamic Prior: Understanding 3D Structures for Casual Dynamic Videos**|Jun Gao Team|[2512.05398](http://arxiv.org/abs/2512.05398)|**[link](https://github.com/wuzy2115/DYNAPO)**|
|**2025-12-05**|**Simulating Life Paths with Digital Twins: AI-Generated Future Selves Influence Decision-Making and Expand Human Choice**|Pat Pataranutaporn Team|[2512.05397](http://arxiv.org/abs/2512.05397)|null|
|**2025-12-05**|**LoC-Path: Learning to Compress for Pathology Multimodal Large Language Models**|Chao Chen Team|[2512.05391](http://arxiv.org/abs/2512.05391)|null|
|**2025-12-05**|**ShaRP: SHAllow-LayeR Pruning for Video Large Language Models Acceleration**|Xi Wang Team|[2512.05385](http://arxiv.org/abs/2512.05385)|null|
|**2025-12-05**|**PoolNet: Deep Learning for 2D to 3D Video Process Validation**|Shray Arora Team|[2512.05362](http://arxiv.org/abs/2512.05362)|**[link](https://github.com/sanchitkaul/PoolNet.git)**|
|**2025-12-04**|**From Segments to Scenes: Temporal Understanding in Autonomous Driving via Vision-Language Model**|Mohammad Akbari Team|[2512.05277](http://arxiv.org/abs/2512.05277)|null|
|**2025-12-04**|**Inferring Compositional 4D Scenes without Ever Seeing One**|Danda Pani Paudel Team|[2512.05272](http://arxiv.org/abs/2512.05272)|**[link](https://github.com/insait-institute/COM4D)**|
|**2025-12-04**|**Splannequin: Freezing Monocular Mannequin-Challenge Footage with Dual-Detection Splatting**|Yu-Lun Liu Team|[2512.05113](http://arxiv.org/abs/2512.05113)|**[link](https://chien90190.github.io/splannequin/)**|
|**2025-12-04**|**DraCo: Draft as CoT for Text-to-Image Preview and Rare Concept Generation**|Hongsheng Li Team|[2512.05112](http://arxiv.org/abs/2512.05112)|**[link](https://github.com/CaraJ7/DraCo)**|
|**2025-12-04**|**ARM-Thinker: Reinforcing Multimodal Generative Reward Models with Agentic Tool Use and Visual Reasoning**|Jiaqi Wang Team|[2512.05111](http://arxiv.org/abs/2512.05111)|null|
|**2025-12-04**|**ShadowDraw: From Any Object to Shadow-Drawing Compositional Art**|Wei-Chiu Ma Team|[2512.05110](http://arxiv.org/abs/2512.05110)|**[link](https://red-fairy.github.io/ShadowDraw/)**|
|**2025-12-04**|**4DLangVGGT: 4D Language-Visual Geometry Grounded Transformer**|Xinggang Wang Team|[2512.05060](http://arxiv.org/abs/2512.05060)|**[link](https://github.com/hustvl/4DLangVGGT)**|
|**2025-12-04**|**EMMA: Efficient Multimodal Understanding, Generation, and Editing with a Unified Architecture**|Qi Tian Team|[2512.04810](http://arxiv.org/abs/2512.04810)|**[link](https://emma-umm.github.io/emma/)**|
|**2025-12-04**|**MemLoRA: Distilling Expert Adapters for On-Device Memory Systems**|Taha Ceritli Team|[2512.04763](http://arxiv.org/abs/2512.04763)|null|
|**2025-12-03**|**ResponsibleRobotBench: Benchmarking Responsible Robot Manipulation using Multi-modal Large Language Models**|Jianwei Zhang Team|[2512.04308](http://arxiv.org/abs/2512.04308)|**[link](https://sites.google.com/view/responsible-robotbench)**|
|**2025-12-03**|**SpaceTools: Tool-Augmented Spatial Reasoning via Double Interactive RL**|Jonathan Tremblay Team|[2512.04069](http://arxiv.org/abs/2512.04069)|null|
|**2025-12-03**|**C3G: Learning Compact 3D Representations with 2K Gaussians**|Seungryong Kim Team|[2512.04021](http://arxiv.org/abs/2512.04021)|**[link](https://cvlab-kaist.github.io/C3G/)**|
|**2025-12-03**|**Active Visual Perception: Opportunities and Challenges**|Xiaowei Dai Team|[2512.03687](http://arxiv.org/abs/2512.03687)|null|
|**2025-12-03**|**Motion4D: Learning 3D-Consistent Motion and Semantics for 4D Scene Understanding**|Gim Hee Lee Team|[2512.03601](http://arxiv.org/abs/2512.03601)|null|
|**2025-12-03**|**What Is The Best 3D Scene Representation for Robotics? From Geometric to Foundation Models**|Weidong Chen Team|[2512.03422](http://arxiv.org/abs/2512.03422)|null|
|**2025-12-03**|**ShelfGaussian: Shelf-Supervised Open-Vocabulary Gaussian-based 3D Scene Understanding**|Lu Gan Team|[2512.03370](http://arxiv.org/abs/2512.03370)|null|
|**2025-12-03**|**SeeU: Seeing the Unseen World via 4D Dynamics-aware Generation**|Stanley H. Chan Team|[2512.03350](http://arxiv.org/abs/2512.03350)|**[link](https://yuyuanspace.com/SeeU/)**|
|**2025-12-02**|**SpatialReasoner: Active Perception for Large-Scale 3D Scene Understanding**|Hujun Yin Team|[2512.03284](http://arxiv.org/abs/2512.03284)|null|
|**2025-12-02**|**Mitigating Intra- and Inter-modal Forgetting in Continual Learning of Unified Multimodal Models**|Radu Marculescu Team|[2512.03125](http://arxiv.org/abs/2512.03125)|null|
|**2025-11-29**|**When Harmful Content Gets Camouflaged: Unveiling Perception Failure of LVLMs with CamHarmTI**|Dongxia Wang Team|[2512.03087](http://arxiv.org/abs/2512.03087)|null|
|**2025-12-02**|**OneThinker: All-in-one Reasoning Model for Image and Video**|Xiangyu Yue Team|[2512.03043](http://arxiv.org/abs/2512.03043)|**[link](https://github.com/tulerfeng/OneThinker)**|
|**2025-12-02**|**BOOM: Beyond Only One Modality KIT's Multimodal Multilingual Lecture Companion**|Jan Niehues Team|[2512.02817](http://arxiv.org/abs/2512.02817)|null|
|**2025-12-02**|**RULER-Bench: Probing Rule-based Reasoning Abilities of Next-level Video Generation Models for Vision Foundation Intelligence**|Boxi Wu Team|[2512.02622](http://arxiv.org/abs/2512.02622)|null|
|**2025-12-02**|**Masking Matters: Unlocking the Spatial Reasoning Capabilities of LLMs for 3D Scene-Language Understanding**|Jae-Pil Heo Team|[2512.02487](http://arxiv.org/abs/2512.02487)|null|
|**2025-12-02**|**See, Think, Learn: A Self-Taught Multimodal Reasoner**|Sadbhawna Team|[2512.02456](http://arxiv.org/abs/2512.02456)|null|
|**2025-12-02**|**HouseLayout3D: A Benchmark and Training-Free Baseline for 3D Layout Estimation in the Wild**|Leonidas Guibas Team|[2512.02450](http://arxiv.org/abs/2512.02450)|**[link](https://houselayout3d.github.io)**|
|**2025-12-01**|**See, Hear, and Understand: Benchmarking Audiovisual Human Speech Understanding in Multimodal Large Language Models**|Yong Jae Lee Team|[2512.02231](http://arxiv.org/abs/2512.02231)|null|
|**2025-12-01**|**ManualVLA: A Unified VLA Model for Chain-of-Thought Manual Generation and Robotic Manipulation**|Shanghang Zhang Team|[2512.02013](http://arxiv.org/abs/2512.02013)|null|
|**2025-12-01**|**Artemis: Structured Visual Reasoning for Perception Policy Learning**|Zechao Li Team|[2512.01988](http://arxiv.org/abs/2512.01988)|null|
|**2025-12-01**|**SARL: Spatially-Aware Self-Supervised Representation Learning for Visuo-Tactile Perception**|Dandan Zhang Team|[2512.01908](http://arxiv.org/abs/2512.01908)|null|
|**2025-12-01**|**OpenREAD: Reinforced Open-Ended Reasoning for End-to-End Autonomous Driving with LLM-as-Critic**|Chen Lv Team|[2512.01830](http://arxiv.org/abs/2512.01830)|null|
|**2025-12-01**|**IGen: Scalable Data Generation for Robot Learning from Open-World Images**|Zhi Wang Team|[2512.01773](http://arxiv.org/abs/2512.01773)|null|
|**2025-12-01**|**SPARK: Sim-ready Part-level Articulated Reconstruction with VLM Knowledge**|Chenfanfu Jiang Team|[2512.01629](http://arxiv.org/abs/2512.01629)|**[link](https://heyumeng.com/SPARK/index.html.)**|
|**2025-12-01**|**Integrated YOLOP Perception and Lyapunov-based Control for Autonomous Mobile Robot Navigation on Track**|Mo Chen Team|[2512.01608](http://arxiv.org/abs/2512.01608)|null|
|**2025-12-01**|**VSRD++: Autolabeling for 3D Object Detection via Instance-Aware Volumetric Silhouette Rendering**|Masatoshi Okutomi Team|[2512.01178](http://arxiv.org/abs/2512.01178)|null|
|**2025-11-30**|**FOM-Nav: Frontier-Object Maps for Object Goal Navigation**|Cordelia Schmid Team|[2512.01009](http://arxiv.org/abs/2512.01009)|**[link](https://www.di.ens.fr/willow/research/fom-nav/)**|
|**2025-11-30**|**Look, Recite, Then Answer: Enhancing VLM Performance via Self-Generated Knowledge Hints**|Xisheng Feng Team|[2512.00882](http://arxiv.org/abs/2512.00882)|null|
|**2025-11-30**|**Smol-GS: Compact Representations for Abstract 3D Gaussian Splatting**|Arno Solin Team|[2512.00850](http://arxiv.org/abs/2512.00850)|null|
|**2025-11-30**|**Med-CMR: A Fine-Grained Benchmark Integrating Visual Evidence and Clinical Logic for Medical Complex Multimodal Reasoning**|Hongwei Bran Li Team|[2512.00818](http://arxiv.org/abs/2512.00818)|null|
|**2025-11-29**|**Describe Anything Anywhere At Any Moment**|Luca Carlone Team|[2512.00565](http://arxiv.org/abs/2512.00565)|null|
|**2025-11-29**|**ChartPoint: Guiding MLLMs with Grounding Reflection for Chart Reasoning**|Jian Guo Team|[2512.00305](http://arxiv.org/abs/2512.00305)|null|
|**2025-11-29**|**Words into World: A Task-Adaptive Agent for Language-Guided Spatial Retrieval in AR**|Tobias Höllerer Team|[2512.00294](http://arxiv.org/abs/2512.00294)|null|
|**2025-11-28**|**DenseScan: Advancing 3D Scene Understanding with 2D Dense Annotation**|Tao Zhang Team|[2512.00226](http://arxiv.org/abs/2512.00226)|null|
|**2025-11-26**|**Exploring Diagnostic Prompting Approach for Multimodal LLM-based Visual Complexity Assessment: A Case Study of Amazon Search Result Pages**|Trilokya Akula Team|[2512.00082](http://arxiv.org/abs/2512.00082)|null|
|**2025-10-28**|**A Comprehensive Survey on Surgical Digital Twin**|Bernard Zeigler Team|[2512.00019](http://arxiv.org/abs/2512.00019)|null|
|**2025-11-28**|**VQRAE: Representation Quantization Autoencoders for Multimodal Understanding, Generation and Reconstruction**|Chun Yuan Team|[2511.23386](http://arxiv.org/abs/2511.23386)|null|
|**2025-11-28**|**DualCamCtrl: Dual-Branch Diffusion Model for Geometry-Aware Camera-Controlled Video Generation**|Yingcong Chen Team|[2511.23127](http://arxiv.org/abs/2511.23127)|null|
|**2025-11-28**|**MathSight: A Benchmark Exploring Have Vision-Language Models Really Seen in University-Level Mathematical Reasoning?**|Zhenzhou Shao Team|[2511.23112](http://arxiv.org/abs/2511.23112)|**[link](https://cnu-bot-group.github.io/MathSight/)**|
|**2025-11-28**|**HMR3D: Hierarchical Multimodal Representation for 3D Scene Understanding with Large Vision-Language Model**|Basura Fernando Team|[2511.22961](http://arxiv.org/abs/2511.22961)|null|
|**2025-11-28**|**RobotSeg: A Model and Dataset for Segmenting Robots in Image and Video**|Mike Zheng Shou Team|[2511.22950](http://arxiv.org/abs/2511.22950)|**[link](https://github.com/showlab/RobotSeg)**|
|**2025-11-28**|**See, Rank, and Filter: Important Word-Aware Clip Filtering via Scene Understanding for Moment Retrieval and Highlight Detection**|Jung Uk Kim Team|[2511.22906](http://arxiv.org/abs/2511.22906)|null|
|**2025-11-27**|**GeoZero: Incentivizing Reasoning from Scratch on Geospatial Scenes**|Liangpei Zhang Team|[2511.22645](http://arxiv.org/abs/2511.22645)|**[link](https://github.com/MiliLab/GeoZero)**|
|**2025-11-27**|**CoT4AD: A Vision-Language-Action Model with Explicit Chain-of-Thought Reasoning for Autonomous Driving**|Hao Tang Team|[2511.22532](http://arxiv.org/abs/2511.22532)|null|
|**2025-11-27**|**RoadSceneBench: A Lightweight Benchmark for Mid-Level Road Scene Understanding**|Zhen Lu Team|[2511.22466](http://arxiv.org/abs/2511.22466)|null|
|**2025-11-21**|**HUMORCHAIN: Theory-Guided Multi-Stage Reasoning for Interpretable Multimodal Humor Generation**|Qi Su Team|[2511.21732](http://arxiv.org/abs/2511.21732)|null|
|**2025-11-26**|**$\mathcal{E}_0$ : Enhancing Generalization and Fine-Grained Control in VLA Models via Continuized Discrete Diffusion**|Guangrun Wang Team|[2511.21542](http://arxiv.org/abs/2511.21542)|null|
|**2025-11-26**|**SurgMLLMBench: A Multimodal Large Language Model Benchmark Dataset for Surgical Scene Understanding**|Juyoun Park Team|[2511.21339](http://arxiv.org/abs/2511.21339)|null|
|**2025-11-26**|**Scenes as Tokens: Multi-Scale Normal Distributions Transform Tokenizer for General 3D Vision-Language Understanding**|Mei Chen Team|[2511.21191](http://arxiv.org/abs/2511.21191)|null|
|**2025-11-26**|**Scaling Foundation Models for Radar Scene Understanding**|Dinesh Bharadia Team|[2511.21105](http://arxiv.org/abs/2511.21105)|null|
|**2025-11-26**|**Beyond Realism: Learning the Art of Expressive Composition with StickerNet**|Humphrey Shi Team|[2511.20957](http://arxiv.org/abs/2511.20957)|null|
|**2025-11-25**|**Estimating Fog Parameters from a Sequence of Stereo Images**|Sen Wang Team|[2511.20865](http://arxiv.org/abs/2511.20865)|null|
|**2025-11-25**|**SPHINX: A Synthetic Environment for Visual Perception and Reasoning**|Nidhi Rastogi Team|[2511.20814](http://arxiv.org/abs/2511.20814)|null|
|**2025-11-25**|**Inferix: A Block-Diffusion based Next-Generation Inference Engine for World Simulation**|Bohan Zhuang Team|[2511.20714](http://arxiv.org/abs/2511.20714)|null|
|**2025-11-25**|**3D-Aware Multi-Task Learning with Cross-View Correlations for Dense Scene Understanding**|Wei-Hong Li Team|[2511.20646](http://arxiv.org/abs/2511.20646)|**[link](https://github.com/WeiHongLee/CrossView3DMTL)**|
|**2025-11-25**|**Fighting AI with AI: Leveraging Foundation Models for Assuring AI-Enabled Safety-Critical Systems**|Corina S. Păsăreanu Team|[2511.20627](http://arxiv.org/abs/2511.20627)|null|
|**2025-11-25**|**ScenarioCLIP: Pretrained Transferable Visual Language Models and Action-Genome Dataset for Natural Scene Analysis**|Abhijit Das Team|[2511.20274](http://arxiv.org/abs/2511.20274)|null|
|**2025-11-25**|**Towards Benign Memory Forgetting for Selective Multimodal Large Language Model Unlearning**|Meng Wang Team|[2511.20196](http://arxiv.org/abs/2511.20196)|null|
|**2025-11-25**|**Active3D: Active High-Fidelity 3D Reconstruction via Hierarchical Uncertainty Quantification**|Gim Hee Lee Team|[2511.20050](http://arxiv.org/abs/2511.20050)|null|
|**2025-11-25**|**Tell Model Where to Look: Mitigating Hallucinations in MLLMs by Vision-Guided Attention**|Zhixing Tan Team|[2511.20032](http://arxiv.org/abs/2511.20032)|null|
|**2025-11-25**|**Coupled Physics-Gated Adaptation: Spatially Decoding Volumetric Photochemical Conversion in Complex 3D-Printed Objects**|Hossein Heidari Team|[2511.19913](http://arxiv.org/abs/2511.19913)|null|
|**2025-11-25**|**It Hears, It Sees too: Multi-Modal LLM for Depression Detection By Integrating Visual Understanding into Audio Language Models**|Zongyuan Ge Team|[2511.19877](http://arxiv.org/abs/2511.19877)|null|
|**2025-11-24**|**Perceptual Taxonomy: Evaluating and Guiding Hierarchical Scene Reasoning in Vision-Language Models**|Alan Yuille Team|[2511.19526](http://arxiv.org/abs/2511.19526)|null|
|**2025-11-24**|**Chain-of-Visual-Thought: Teaching VLMs to See and Think Better with Continuous Visual Tokens**|XuDong Wang Team|[2511.19418](http://arxiv.org/abs/2511.19418)|**[link](https://wakalsprojectpage.github.io/covt-website/)**|
|**2025-11-24**|**Syn-GRPO: Self-Evolving Data Synthesis for MLLM Perception Reasoning**|Jie Song Team|[2511.19343](http://arxiv.org/abs/2511.19343)|null|
|**2025-11-24**|**Percept-WAM: Perception-Enhanced World-Awareness-Action Model for Robust End-to-End Autonomous Driving**|Hang Xu Team|[2511.19221](http://arxiv.org/abs/2511.19221)|null|
|**2025-11-24**|**EEG-VLM: A Hierarchical Vision-Language Model with Multi-Level Feature Alignment and Visually Enhanced Language-Guided Reasoning for EEG Image-Based Sleep Stage Prediction**|Shuo Li Team|[2511.19155](http://arxiv.org/abs/2511.19155)|null|
|**2025-11-24**|**Autonomous Docking of Multi-Rotor UAVs on Blimps under the Influence of Wind Gusts**|Aamir Ahmad Team|[2511.19135](http://arxiv.org/abs/2511.19135)|null|
|**2025-11-24**|**Understanding Task Transfer in Vision-Language Models**|Vineeth N. Balasubramanian Team|[2511.18787](http://arxiv.org/abs/2511.18787)|null|
|**2025-11-24**|**AIRHILT: A Human-in-the-Loop Testbed for Multimodal Conflict Detection in Aviation**|Dimitri N. Mavris Team|[2511.18718](http://arxiv.org/abs/2511.18718)|null|
|**2025-11-24**|**Autonomous Surface Selection For Manipulator-Based UV Disinfection In Hospitals Using Foundation Models**|U-Xuan Tan Team|[2511.18709](http://arxiv.org/abs/2511.18709)|null|
|**2025-11-23**|**Health system learning achieves generalist neuroimaging models**|Todd Hollon Team|[2511.18640](http://arxiv.org/abs/2511.18640)|null|
|**2025-11-23**|**Multimodal Continual Learning with MLLMs from Multi-scenario Perspectives**|Xuelong Li Team|[2511.18507](http://arxiv.org/abs/2511.18507)|null|
|**2025-11-23**|**Gaze Beyond the Frame: Forecasting Egocentric 3D Visual Span**|Gunhee Kim Team|[2511.18470](http://arxiv.org/abs/2511.18470)|null|
|**2025-11-23**|**Alternating Perception-Reasoning for Hallucination-Resistant Video Understanding**|Hongtao Xie Team|[2511.18463](http://arxiv.org/abs/2511.18463)|null|
|**2025-11-23**|**Perceptual-Evidence Anchored Reinforced Learning for Multimodal Reasoning**|Jing Zhang Team|[2511.18437](http://arxiv.org/abs/2511.18437)|null|
|**2025-11-23**|**ConsistCompose: Unified Multimodal Layout Control for Image Composition**|Quan Wang Team|[2511.18333](http://arxiv.org/abs/2511.18333)|null|
|**2025-11-23**|**AnyExperts: On-Demand Expert Allocation for Multimodal Language Models with Mixture of Expert**|Qingpei Guo Team|[2511.18314](http://arxiv.org/abs/2511.18314)|null|
|**2025-11-22**|**Plan-X: Instruct Video Generation via Semantic Planning**|Guillermo Sapiro Team|[2511.17986](http://arxiv.org/abs/2511.17986)|**[link](https://byteaigc.github.io/Plan-X)**|
|**2025-11-21**|**CORA: Consistency-Guided Semi-Supervised Framework for Reasoning Segmentation**|Dimitris Samaras Team|[2511.17755](http://arxiv.org/abs/2511.17755)|null|
|**2025-11-21**|**VisReason: A Large-Scale Dataset for Visual Chain-of-Thought Reasoning**|Chenyu You Team|[2511.17731](http://arxiv.org/abs/2511.17731)|null|
|**2025-11-18**|**Unified Low-Light Traffic Image Enhancement via Multi-Stage Illumination Recovery and Adaptive Noise Suppression**|Siddiqua Namrah Team|[2511.17612](http://arxiv.org/abs/2511.17612)|null|
|**2025-11-21**|**RynnVLA-002: A Unified Vision-Language-Action and World Model**|Hao Chen Team|[2511.17502](http://arxiv.org/abs/2511.17502)|null|
|**2025-11-21**|**Downscaling Intelligence: Exploring Perception and Reasoning Bottlenecks in Small Multimodal Models**|Serena Yeung-Levy Team|[2511.17487](http://arxiv.org/abs/2511.17487)|**[link](https://web.stanford.edu/~markendo/projects/downscaling_intelligence)**|
|**2025-11-21**|**SuperQuadricOcc: Multi-Layer Gaussian Approximation of Superquadrics for Real-Time Self-Supervised Occupancy Estimation**|Ciaran Eising Team|[2511.17361](http://arxiv.org/abs/2511.17361)|null|
|**2025-11-21**|**DSeq-JEPA: Discriminative Sequential Joint-Embedding Predictive Architecture**|Leonid Sigal Team|[2511.17354](http://arxiv.org/abs/2511.17354)|**[link](https://github.com/SkyShunsuke/DSeq-JEPA)**|
|**2025-11-21**|**Robot Confirmation Generation and Action Planning Using Long-context Q-Former Integrated with Multimodal LLM**|Jonathan Le Roux Team|[2511.17335](http://arxiv.org/abs/2511.17335)|null|
|**2025-11-21**|**VLM-Augmented Degradation Modeling for Image Restoration Under Adverse Weather Conditions**|Liang Hu Team|[2511.16998](http://arxiv.org/abs/2511.16998)|null|
|**2025-11-21**|**FingerCap: Fine-grained Finger-level Hand Motion Captioning**|Xin Yu Team|[2511.16951](http://arxiv.org/abs/2511.16951)|null|
|**2025-11-21**|**UniModel: A Visual-Only Framework for Unified Multimodal Understanding and Generation**|Xuelong Li Team|[2511.16917](http://arxiv.org/abs/2511.16917)|null|
|**2025-11-20**|**POMA-3D: The Point Map Way to 3D Scene Understanding**|Krystian Mikolajczyk Team|[2511.16567](http://arxiv.org/abs/2511.16567)|null|
|**2025-11-20**|**LLaVA $^3$ : Representing 3D Scenes like a Cubist Painter to Boost 3D Scene Understanding of VLMs**|Loïc Barthe Team|[2511.16454](http://arxiv.org/abs/2511.16454)|null|
|**2025-11-20**|**Building temporally coherent 3D maps with VGGT for memory-efficient Semantic SLAM**|Anna Gelencsér-Horváth Team|[2511.16282](http://arxiv.org/abs/2511.16282)|null|
|**2025-11-20**|**How Robot Dogs See the Unseeable**|Jeremy E. Niven Team|[2511.16262](http://arxiv.org/abs/2511.16262)|null|
|**2025-11-20**|**ChemLabs on ChemO: A Multi-Agent System for Multimodal Reasoning on IChO 2025**|Yu Li Team|[2511.16205](http://arxiv.org/abs/2511.16205)|null|
|**2025-11-20**|**Real-Time 3D Object Detection with Inference-Aligned Learning**|Nan Xue Team|[2511.16140](http://arxiv.org/abs/2511.16140)|null|
|**2025-11-20**|**Click2Graph: Interactive Panoptic Video Scene Graphs from a Single Click**|B. S. Manjunath Team|[2511.15948](http://arxiv.org/abs/2511.15948)|null|
|**2025-11-20**|**Boosting Medical Visual Understanding From Multi-Granular Language Learning**|Paul Kinahan Team|[2511.15943](http://arxiv.org/abs/2511.15943)|null|
|**2025-11-19**|**WALDO: Where Unseen Model-based 6D Pose Estimation Meets Occlusion**|Tongtong Cao Team|[2511.15874](http://arxiv.org/abs/2511.15874)|null|
|**2025-11-19**|**EfficientSAM3: Progressive Hierarchical Distillation for Video Concept Segmentation from SAM1, 2, and 3**|Aaron Zhang Team|[2511.15833](http://arxiv.org/abs/2511.15833)|**[link](https://github.com/SimonZeng7108/efficientsam3)**|
|**2025-11-19**|**ShelfOcc: Native 3D Supervision beyond LiDAR for Vision-Based Occupancy Estimation**|Benjamin Risse Team|[2511.15396](http://arxiv.org/abs/2511.15396)|null|
|**2025-11-19**|**Look, Zoom, Understand: The Robotic Eyeball for Embodied Perception**|Wenzhao Lian Team|[2511.15279](http://arxiv.org/abs/2511.15279)|null|
|**2025-11-18**|**RocSync: Millisecond-Accurate Temporal Synchronization for Heterogeneous Camera Systems**|Lilian Calvet Team|[2511.14948](http://arxiv.org/abs/2511.14948)|null|
|**2025-11-18**|**Orion: A Unified Visual Agent for Multimodal Perception, Advanced Visual Reasoning and Execution**|Sudeep Pillai Team|[2511.14210](http://arxiv.org/abs/2511.14210)|null|
|**2025-11-18**|**MVI-Bench: A Comprehensive Benchmark for Evaluating Robustness to Misleading Visual Inputs in LVLMs**|Lu Cheng Team|[2511.14159](http://arxiv.org/abs/2511.14159)|null|
|**2025-11-18**|**Multi-view Phase-aware Pedestrian-Vehicle Incident Reasoning Framework with Vision-Language Models**|Jidong J. Yang Team|[2511.14120](http://arxiv.org/abs/2511.14120)|null|
|**2025-11-18**|**Error-Driven Scene Editing for 3D Grounding in Large Language Models**|Mohit Bansal Team|[2511.14086](http://arxiv.org/abs/2511.14086)|**[link](https://github.com/zhangyuejoslin/Deer-3D)**|
|**2025-11-18**|**RISE: Single Static Radar-based Indoor Scene Understanding**|Fadel Adib Team|[2511.14019](http://arxiv.org/abs/2511.14019)|null|
|**2025-11-17**|**VLMs Guided Interpretable Decision Making for Autonomous Driving**|Zhengming Ding Team|[2511.13881](http://arxiv.org/abs/2511.13881)|null|
|**2025-11-17**|**Scaling Spatial Intelligence with Multimodal Foundation Models**|Lei Yang Team|[2511.13719](http://arxiv.org/abs/2511.13719)|**[link](https://github.com/OpenSenseNova/SenseNova-SI)**|
|**2025-11-17**|**OpenRoboCare: A Multimodal Multi-Task Expert Demonstration Dataset for Robot Caregiving**|Tapomayukh Bhattacharjee Team|[2511.13707](http://arxiv.org/abs/2511.13707)|null|
|**2025-11-17**|**What Color Is It? A Text-Interference Multimodal Hallucination Benchmark**|Wenjun Wu Team|[2511.13400](http://arxiv.org/abs/2511.13400)|null|
|**2025-11-17**|**Is your VLM Sky-Ready? A Comprehensive Spatial Intelligence Benchmark for UAV Navigation**|Wenbo Ding Team|[2511.13269](http://arxiv.org/abs/2511.13269)|null|
|**2025-11-17**|**Skeletons Speak Louder than Text: A Motion-Aware Pretraining Paradigm for Video-Based Person Re-Identification**|Min Li Team|[2511.13150](http://arxiv.org/abs/2511.13150)|null|
|**2025-11-17**|**Learning Implicit Neural Degradation Representation for Unpaired Image Dehazing**|Minglong Xue Team|[2511.13110](http://arxiv.org/abs/2511.13110)|null|
|**2025-11-17**|**Decoupling Scene Perception and Ego Status: A Multi-Context Fusion Approach for Enhanced Generalization in End-to-End Autonomous Driving**|Jian Pu Team|[2511.13079](http://arxiv.org/abs/2511.13079)|null|
|**2025-11-17**|**Visual Room 2.0: Seeing is Not Understanding for MLLMs**|Peng Zhang Team|[2511.12928](http://arxiv.org/abs/2511.12928)|null|
|**2025-11-17**|**Video Finetuning Improves Reasoning Between Frames**|Ellie Pavlick Team|[2511.12868](http://arxiv.org/abs/2511.12868)|null|
|**2025-11-16**|**DensePercept-NCSSD: Vision Mamba towards Real-time Dense Visual Perception with Non-Causal State Space Duality**|Abhijit Das Team|[2511.12671](http://arxiv.org/abs/2511.12671)|null|
|**2025-11-16**|**RoboAfford++: A Generative AI-Enhanced Dataset for Multimodal Affordance Learning in Robotic Manipulation and Navigation**|Long Chen Team|[2511.12436](http://arxiv.org/abs/2511.12436)|null|
|**2025-11-15**|**Adaptive Diagnostic Reasoning Framework for Pathology with Multimodal Large Language Models**|Neil Y. C. Lin Team|[2511.12008](http://arxiv.org/abs/2511.12008)|null|
|**2025-11-14**|**TopoPerception: A Shortcut-Free Evaluation of Global Visual Perception in Large Vision-Language Models**|Rong Zhao Team|[2511.11831](http://arxiv.org/abs/2511.11831)|null|
|**2025-11-14**|**Large Language Models and 3D Vision for Intelligent Robotic Perception and Autonomy**|Karthick Thiyagarajan Team|[2511.11777](http://arxiv.org/abs/2511.11777)|null|
|**2025-11-13**|**ExpertAD: Enhancing Autonomous Driving Systems with Mixture of Experts**|Xin Peng Team|[2511.11740](http://arxiv.org/abs/2511.11740)|null|
|**2025-11-14**|**AirCopBench: A Benchmark for Multi-drone Collaborative Embodied Perception and Reasoning**|Xinlei Chen Team|[2511.11025](http://arxiv.org/abs/2511.11025)|null|
|**2025-11-13**|**DBGroup: Dual-Branch Point Grouping for Weakly Supervised 3D Semantic Instance Segmentation**|Xu Wang Team|[2511.10003](http://arxiv.org/abs/2511.10003)|null|
|**2025-11-12**|**Spatio-Temporal Data Enhanced Vision-Language Model for Traffic Scene Understanding**|Xiang Wen Team|[2511.08978](http://arxiv.org/abs/2511.08978)|null|
|**2025-11-11**|**OTSNet: A Neurocognitive-Inspired Observation-Thinking-Spelling Pipeline for Scene Text Recognition**|Wushour Silamu Team|[2511.08133](http://arxiv.org/abs/2511.08133)|null|
|**2025-11-11**|**HD $^2$ -SSC: High-Dimension High-Density Semantic Scene Completion for Autonomous Driving**|Yuxin Peng Team|[2511.07925](http://arxiv.org/abs/2511.07925)|null|
|**2025-11-11**|**Visual Bridge: Universal Visual Perception Representations Generating**|Shugong Xu Team|[2511.07877](http://arxiv.org/abs/2511.07877)|null|
|**2025-11-11**|**Sparse3DPR: Training-Free 3D Hierarchical Scene Parsing and Task-Adaptive Subgraph Reasoning from Sparse RGB Views**|Yihong Wu Team|[2511.07813](http://arxiv.org/abs/2511.07813)|null|
|**2025-11-10**|**Inference-Time Scaling of Diffusion Models for Infrared Data Generation**|Kia Khezeli Team|[2511.07362](http://arxiv.org/abs/2511.07362)|null|
|**2025-11-10**|**PlanT 2.0: Exposing Biases and Structural Flaws in Closed-Loop Driving**|Katrin Renz Team|[2511.07292](http://arxiv.org/abs/2511.07292)|null|
|**2025-11-10**|**Omni-View: Unlocking How Generation Facilitates Understanding in Unified 3D Model based on Multiview images**|Yanye Lu Team|[2511.07222](http://arxiv.org/abs/2511.07222)|null|
|**2025-11-10**|**TrueCity: Real and Simulated Urban Data for Cross-Domain 3D Scene Understanding**|Thomas H. Kolbe Team|[2511.07007](http://arxiv.org/abs/2511.07007)|null|
|**2025-11-09**|**Video Dataset for Surgical Phase, Keypoint, and Instrument Recognition in Laparoscopic Surgery (PhaKIR)**|Christoph Palm Team|[2511.06549](http://arxiv.org/abs/2511.06549)|null|
|**2025-11-09**|**FractalBench: Diagnosing Visual-Mathematical Reasoning Through Recursive Program Synthesis**|Marek Šuppa Team|[2511.06522](http://arxiv.org/abs/2511.06522)|**[link](https://github.com/NaiveNeuron/FractalBench)**|
|**2025-11-09**|**SportR: A Benchmark for Multimodal Large Language Model Reasoning in Sports**|Hanjie Chen Team|[2511.06499](http://arxiv.org/abs/2511.06499)|null|
|**2025-11-09**|**VDNeRF: Vision-only Dynamic Neural Radiance Field for Urban Scenes**|Dingwen Zhang Team|[2511.06408](http://arxiv.org/abs/2511.06408)|null|
|**2025-11-09**|**A Visual Perception-Based Tunable Framework and Evaluation Benchmark for H.265/HEVC ROI Encryption**|Zhangjie Fu Team|[2511.06394](http://arxiv.org/abs/2511.06394)|null|
|**2025-11-09**|**Learning-Based Vision Systems for Semi-Autonomous Forklift Operation in Industrial Warehouse Environments**|Archak Mittal Team|[2511.06295](http://arxiv.org/abs/2511.06295)|null|
|**2025-11-09**|**TinyChemVL: Advancing Chemical Vision-Language Models via Efficient Visual Token Reduction and Complex Reaction Tasks**|Bo Xu Team|[2511.06283](http://arxiv.org/abs/2511.06283)|null|
|**2025-11-08**|**Open-World 3D Scene Graph Generation for Retrieval-Augmented Reasoning**|Lechao Cheng Team|[2511.05894](http://arxiv.org/abs/2511.05894)|null|
|**2025-11-07**|**VLM-driven Skill Selection for Robotic Assembly Tasks**|Chang-Hyun Kim Team|[2511.05680](http://arxiv.org/abs/2511.05680)|null|
|**2025-11-07**|**Lite VLA: Efficient Vision-Language-Action Control on CPU-Bound Edge Robots**|Mrinmoy Sarkar Team|[2511.05642](http://arxiv.org/abs/2511.05642)|null|
|**2025-11-03**|**EVLP:Learning Unified Embodied Vision-Language Planner with Reinforced Supervised Fine-Tuning**|Qiang Guan Team|[2511.05553](http://arxiv.org/abs/2511.05553)|null|
|**2025-11-07**|**Real-World Adverse Weather Image Restoration via Dual-Level Reinforcement Learning with High-Quality Cold Start**|Xiaowei Hu Team|[2511.05095](http://arxiv.org/abs/2511.05095)|null|
|**2025-11-06**|**Benchmark Designers Should "Train on the Test Set" to Expose Exploitable Non-Visual Shortcuts**|Saining Xie Team|[2511.04655](http://arxiv.org/abs/2511.04655)|**[link](https://cambrian-mllm.github.io)**|
|**2025-11-06**|**ThaiOCRBench: A Task-Diverse Benchmark for Vision-Language Understanding in Thai**|Kunat Pipatanakul Team|[2511.04479](http://arxiv.org/abs/2511.04479)|null|
|**2025-11-06**|**Learning Vision-Driven Reactive Soccer Skills for Humanoid Robots**|Mingguo Zhao Team|[2511.03996](http://arxiv.org/abs/2511.03996)|**[link](https://humanoid-kick.github.io)**|
|**2025-11-06**|**CaRF: Enhancing Multi-View Consistency in Referring 3D Gaussian Splatting Segmentation**|Yuan Xie Team|[2511.03992](http://arxiv.org/abs/2511.03992)|null|
|**2025-11-06**|**Simple 3D Pose Features Support Human and Machine Social Scene Understanding**|Leyla Isik Team|[2511.03988](http://arxiv.org/abs/2511.03988)|null|
|**2025-11-05**|**SurgViVQA: Temporally-Grounded Video Question Answering for Surgical Scene Understanding**|Mobarak I. Hoque Team|[2511.03325](http://arxiv.org/abs/2511.03325)|null|
|**2025-11-05**|**ISC-Perception: A Hybrid Computer Vision Dataset for Object Detection in Novel Steel Assembly**|Debra F. Laefer Team|[2511.03098](http://arxiv.org/abs/2511.03098)|null|
|**2025-11-04**|**CoCoVa: Chain of Continuous Vision-Language Thought for Latent Space Reasoning**|Han Yan Team|[2511.02360](http://arxiv.org/abs/2511.02360)|null|
|**2025-11-03**|**SciTextures: Collecting and Connecting Visual Patterns, Models, and Code Across Science and Art**|Alona Strugatski Team|[2511.01817](http://arxiv.org/abs/2511.01817)|null|
|**2025-11-03**|**Actial: Activate Spatial Reasoning Ability of Multimodal Large Language Models**|Yanwen Guo Team|[2511.01618](http://arxiv.org/abs/2511.01618)|null|
|**2025-11-03**|**MARS: Multi-Agent Robotic System with Multimodal Large Language Models for Assistive Intelligence**|Peiyan Zhong Team|[2511.01594](http://arxiv.org/abs/2511.01594)|null|
|**2025-11-03**|**PixelVLA: Advancing Pixel-level Understanding in Vision-Language-Action Model**|Yang Cong Team|[2511.01571](http://arxiv.org/abs/2511.01571)|null|
|**2025-11-03**|**Analyzing Sustainability Messaging in Large-Scale Corporate Social Media**|Marcel Worring Team|[2511.01550](http://arxiv.org/abs/2511.01550)|null|
|**2025-11-03**|**Towards General Auditory Intelligence: Large Multimodal Models for Machine Listening and Speaking**|Chao Zhang Team|[2511.01299](http://arxiv.org/abs/2511.01299)|null|
|**2025-11-03**|**LiDAR-VGGT: Cross-Modal Coarse-to-Fine Fusion for Globally Consistent and Metric-Scale Dense Mapping**|Xieyuanli Chen Team|[2511.01186](http://arxiv.org/abs/2511.01186)|null|
|**2025-11-02**|**GauDP: Reinventing Multi-Agent Collaboration through Gaussian-Image Synergy in Diffusion Policies**|Ruimao Zhang Team|[2511.00998](http://arxiv.org/abs/2511.00998)|**[link](https://ziyeeee.github.io/gaudp.io/)**|
|**2025-11-02**|**Fleming-VL: Towards Universal Medical Visual Reasoning with Multimodal LLMs**|Bryan Dai Team|[2511.00916](http://arxiv.org/abs/2511.00916)|null|
|**2025-11-01**|**Grounding Surgical Action Triplets with Instrument Instance Segmentation: A Dataset and Target-Aware Fusion Approach**|Miaojing Shi Team|[2511.00643](http://arxiv.org/abs/2511.00643)|null|
|**2025-10-30**|**AI Powered High Quality Text to Video Generation with Enhanced Temporal Consistency**|Piyushkumar Patel Team|[2511.00107](http://arxiv.org/abs/2511.00107)|null|
|**2025-10-29**|**Bridging Vision, Language, and Mathematics: Pictographic Character Reconstruction with Bézier Curves**|Yang Liu Team|[2511.00076](http://arxiv.org/abs/2511.00076)|null|
|**2025-10-31**|**NAUTILUS: A Large Multimodal Model for Underwater Scene Understanding**|Xiang Bai Team|[2510.27481](http://arxiv.org/abs/2510.27481)|**[link](https://github.com/H-EmbodVis/NAUTILUS)**|
|**2025-10-31**|**From Pixels to Paths: A Multi-Agent Framework for Editable Scientific Illustration**|Kaipeng Zhang Team|[2510.27452](http://arxiv.org/abs/2510.27452)|null|
|**2025-10-31**|**AFM-Net: Advanced Fusing Hierarchical CNN Visual Priors with Global Sequence Modeling for Remote Sensing Image Scene Classification**|Jianqiang Huang Team|[2510.27155](http://arxiv.org/abs/2510.27155)|null|
|**2025-10-30**|**Leveraging Foundation Models for Enhancing Robot Perception and Action**|Reihaneh Mirjalili Team|[2510.26855](http://arxiv.org/abs/2510.26855)|null|
|**2025-10-30**|**Are Video Models Ready as Zero-Shot Reasoners? An Empirical Study with the MME-CoF Benchmark**|Pheng-Ann Heng Team|[2510.26802](http://arxiv.org/abs/2510.26802)|**[link](https://video-cof.github.io)**|
|**2025-10-30**|**OmniX: From Unified Panoramic Generation and Perception to Graphics-Ready 3D Scenes**|Xihui Liu Team|[2510.26800](http://arxiv.org/abs/2510.26800)|**[link](https://yukun-huang.github.io/OmniX/)**|
|**2025-10-30**|**Dynamic Context-Aware Scene Reasoning Using Vision-Language Alignment in Zero-Shot Real-World Scenarios**|B. M. Vidyavathi Team|[2510.26580](http://arxiv.org/abs/2510.26580)|null|
|**2025-10-30**|**AgriGS-SLAM: Orchard Mapping Across Seasons via Multi-View Gaussian Splatting SLAM**|Matteo Matteucci Team|[2510.26358](http://arxiv.org/abs/2510.26358)|null|
|**2025-10-30**|**Contribution-Guided Asymmetric Learning for Robust Multimodal Fusion under Imbalance and Noise**|Hong Liu Team|[2510.26289](http://arxiv.org/abs/2510.26289)|null|
|**2025-10-29**|**Efficient Online Learning with Predictive Coding Networks: Exploiting Temporal Correlations**|Eyke Hüllermeier Team|[2510.25993](http://arxiv.org/abs/2510.25993)|null|
|**2025-10-29**|**EA3D: Online Open-World 3D Object Extraction from Streaming Videos**|Ming-Hsuan Yang Team|[2510.25146](http://arxiv.org/abs/2510.25146)|null|
|**2025-10-29**|**Vision-Language Integration for Zero-Shot Scene Understanding in Real-World Environments**|B. M. Vidyavathi Team|[2510.25070](http://arxiv.org/abs/2510.25070)|null|
|**2025-10-27**|**The Underappreciated Power of Vision Models for Graph Structural Understanding**|Tianshu Yu Team|[2510.24788](http://arxiv.org/abs/2510.24788)|null|
|**2025-10-28**|**Latent Sketchpad: Sketching Visual Thoughts to Elicit Multimodal Reasoning in MLLMs**|Furu Wei Team|[2510.24514](http://arxiv.org/abs/2510.24514)|null|
|**2025-10-28**|**Sound Source Localization for Spatial Mapping of Surgical Actions in Dynamic Scenes**|Matthias Seibold Team|[2510.24332](http://arxiv.org/abs/2510.24332)|null|
|**2025-10-28**|**ViPER: Empowering the Self-Evolution of Visual Perception Abilities in Vision-Language Model**|Rui Yan Team|[2510.24285](http://arxiv.org/abs/2510.24285)|null|
|**2025-10-28**|**Benchmarking Microsaccade Recognition with Event Cameras: A Novel Dataset and Evaluation**|Peter Corcoran Team|[2510.24231](http://arxiv.org/abs/2510.24231)|null|
|**2025-10-28**|**Enhancing Vision-Language Models for Autonomous Driving through Task-Specific Prompting and Spatial Reasoning**|Xubo Luo Team|[2510.24152](http://arxiv.org/abs/2510.24152)|null|
|**2025-10-27**|**Improving Visual Discriminability of CLIP for Training-Free Open-Vocabulary Semantic Segmentation**|Zhihui Zhu Team|[2510.23894](http://arxiv.org/abs/2510.23894)|null|
|**2025-10-27**|**Concerto: Joint 2D-3D Self-Supervised Learning Emerges Spatial Representations**|Hengshuang Zhao Team|[2510.23607](http://arxiv.org/abs/2510.23607)|**[link](https://pointcept.github.io/Concerto)**|
|**2025-10-27**|**Localising under the drape: proprioception in the era of distributed surgical robotic system**|Tom Vercauteren Team|[2510.23512](http://arxiv.org/abs/2510.23512)|null|
|**2025-10-27**|**UrbanIng-V2X: A Large-Scale Multi-Vehicle, Multi-Infrastructure Dataset Across Multiple Intersections for Cooperative Perception**|Torsten Schön Team|[2510.23478](http://arxiv.org/abs/2510.23478)|**[link](https://github.com/thi-ad/UrbanIng-V2X)**|
|**2025-10-26**|**Cross-view Localization and Synthesis -- Datasets, Challenges and Opportunities**|Rongjun Qin Team|[2510.22736](http://arxiv.org/abs/2510.22736)|null|
|**2025-10-26**|**FastVLM: Self-Speculative Decoding for Fast Vision-Language Model Inference**|Manjesh Kumar Hanawal Team|[2510.22641](http://arxiv.org/abs/2510.22641)|null|
|**2025-10-25**|**BLIP-FusePPO: A Vision-Language Deep Reinforcement Learning Framework for Lane Keeping in Autonomous Vehicles**|Farzaneh Abdollahi Team|[2510.22370](http://arxiv.org/abs/2510.22370)|**[link](https://github.com/Amin-A96/BLIP-FusePPO-A-Vision-Language-Deep-Reinforcement-Learning-Framework-for-Lane-Keeping-in-Autonomous.git)**|
|**2025-10-25**|**Moving Beyond Diffusion: Hierarchy-to-Hierarchy Autoregression for fMRI-to-Image Reconstruction**|Yi Yang Team|[2510.22335](http://arxiv.org/abs/2510.22335)|null|
|**2025-10-25**|**MOGRAS: Human Motion with Grasping in 3D Scenes**|Charu Sharma Team|[2510.22199](http://arxiv.org/abs/2510.22199)|null|
|**2025-10-25**|**HARMONY: Hidden Activation Representations and Model Output-Aware Uncertainty Estimation for Vision-Language Models**|Salman Avestimehr Team|[2510.22171](http://arxiv.org/abs/2510.22171)|null|
|**2025-10-25**|**LOC: A General Language-Guided Framework for Open-Set 3D Occupancy Prediction**|Guoyou Wang Team|[2510.22141](http://arxiv.org/abs/2510.22141)|null|
|**2025-10-25**|**CogStereo: Neural Stereo Matching with Implicit Spatial Cognition Embedding**|Hong Zhang Team|[2510.22119](http://arxiv.org/abs/2510.22119)|null|
|**2025-10-13**|**J-ORA: A Framework and Multimodal Dataset for Japanese Object Identification, Reference, Action Prediction in Robot Perception**|Koichiro Yoshino Team|[2510.21761](http://arxiv.org/abs/2510.21761)|null|
|**2025-10-24**|**MATrack: Efficient Multiscale Adaptive Tracker for Real-Time Nighttime UAV Operations**|Shiyu Hu Team|[2510.21586](http://arxiv.org/abs/2510.21586)|null|
|**2025-10-24**|**AURASeg: Attention Guided Upsampling with Residual Boundary-Assistive Refinement for Drivable-Area Segmentation**|Sridevi. M Team|[2510.21536](http://arxiv.org/abs/2510.21536)|null|
|**2025-10-24**|**OpenHype: Hyperbolic Embeddings for Hierarchical Open-Vocabulary Radiance Fields**|Pedro Hermosilla Team|[2510.21441](http://arxiv.org/abs/2510.21441)|null|
|**2025-10-23**|**GenColorBench: A Color Evaluation Benchmark for Text-to-Image Generation Models**|Kai Wang Team|[2510.20586](http://arxiv.org/abs/2510.20586)|null|
|**2025-10-23**|**GhostEI-Bench: Do Mobile Agents Resilience to Environmental Injection in Dynamic On-Device Environments?**|Yingchun Wang Team|[2510.20333](http://arxiv.org/abs/2510.20333)|null|
|**2025-10-23**|**Physics-Guided Fusion for Robust 3D Tracking of Fast Moving Small Objects**|Vijaya Gopu Team|[2510.20126](http://arxiv.org/abs/2510.20126)|null|
|**2025-10-22**|**Semantic Communication for Task Execution and Data Reconstruction in Multi-User Scenarios**|Armin Dekorsy Team|[2510.20067](http://arxiv.org/abs/2510.20067)|null|
|**2025-10-22**|**Uncertainty evaluation of segmentation models for Earth observation**|Drew Purves Team|[2510.19586](http://arxiv.org/abs/2510.19586)|null|
|**2025-10-22**|**Seeing Across Views: Benchmarking Spatial Reasoning of Vision-Language Models in Robotic Scenes**|Baining Guo Team|[2510.19400](http://arxiv.org/abs/2510.19400)|**[link](https://github.com/microsoft/MV-RoboBench)**|
|**2025-10-22**|**Exploring Scale Shift in Crowd Localization under the Context of Domain Generalization**|Shujun Wang Team|[2510.19330](http://arxiv.org/abs/2510.19330)|null|
|**2025-10-22**|**See, Think, Act: Online Shopper Behavior Simulation with VLM Agents**|Dakuo Wang Team|[2510.19245](http://arxiv.org/abs/2510.19245)|null|
|**2025-10-21**|**Macroscopic EEG Reveals Discriminative Low-Frequency Oscillations in Plan-to-Grasp Visuomotor Tasks**|Reza Abiri Team|[2510.19057](http://arxiv.org/abs/2510.19057)|null|
|**2025-10-21**|**Grasp Any Region: Towards Precise, Contextual Pixel Understanding for Multimodal LLMs**|Zhaoxiang Zhang Team|[2510.18876](http://arxiv.org/abs/2510.18876)|null|
|**2025-10-21**|**Event-Grounding Graph: Unified Spatio-Temporal Scene Graph from Robotic Observations**|Ville Kyrki Team|[2510.18697](http://arxiv.org/abs/2510.18697)|null|
|**2025-10-21**|**MoTVLA: A Vision-Language-Action Model with Unified Fast-Slow Reasoning**|Heng Yang Team|[2510.18337](http://arxiv.org/abs/2510.18337)|null|
|**2025-10-21**|**UWBench: A Comprehensive Vision-Language Benchmark for Underwater Understanding**|Xuelong Li Team|[2510.18262](http://arxiv.org/abs/2510.18262)|null|
|**2025-10-21**|**OpenInsGaussian: Open-vocabulary Instance Gaussian Segmentation with Context-aware Cross-view Fusion**|Tongliang Liu Team|[2510.18253](http://arxiv.org/abs/2510.18253)|null|
|**2025-10-20**|**Enhanced Motion Forecasting with Plug-and-Play Multimodal Large Language Models**|Mingxing Tan Team|[2510.17274](http://arxiv.org/abs/2510.17274)|null|
|**2025-10-19**|**SceneCOT: Eliciting Grounded Chain-of-Thought Reasoning in 3D Scenes**|Siyuan Huang Team|[2510.16714](http://arxiv.org/abs/2510.16714)|**[link](https://scenecot.github.io/)**|
|**2025-10-18**|**Learning to Optimize Edge Robotics: A Fast Integrated Perception-Motion-Communication Approach**|Chengzhong Xu Team|[2510.16424](http://arxiv.org/abs/2510.16424)|null|
|**2025-10-17**|**UniMedVL: Unifying Medical Multimodal Understanding And Generation Through Observation-Knowledge-Analysis**|Junjun He Team|[2510.15710](http://arxiv.org/abs/2510.15710)|null|
|**2025-10-17**|**VERITAS: Leveraging Vision Priors and Expert Fusion to Improve Multimodal Data**|Jiayu Chen Team|[2510.15317](http://arxiv.org/abs/2510.15317)|null|
|**2025-10-17**|**CuSfM: CUDA-Accelerated Structure-from-Motion**|Di Zeng Team|[2510.15271](http://arxiv.org/abs/2510.15271)|null|
|**2025-10-16**|**From Pixels to Words -- Towards Native Vision-Language Primitives at Scale**|Ziwei Liu Team|[2510.14979](http://arxiv.org/abs/2510.14979)|null|
|**2025-10-16**|**Knowledge-based Visual Question Answer with Multimodal Processing, Retrieval and Filtering**|Jieping Ye Team|[2510.14605](http://arxiv.org/abs/2510.14605)|null|
|**2025-10-16**|**QuASH: Using Natural-Language Heuristics to Query Visual-Language Robotic Maps**|Ville Kyrki Team|[2510.14546](http://arxiv.org/abs/2510.14546)|null|
|**2025-10-16**|**Exploring Image Representation with Decoupled Classical Visual Descriptors**|Jianbo Jiao Team|[2510.14536](http://arxiv.org/abs/2510.14536)|null|
|**2025-10-15**|**Efficient Few-Shot Learning in Remote Sensing: Fusing Vision and Vision-Language Models**|Miguel Arana-Catania Team|[2510.13993](http://arxiv.org/abs/2510.13993)|null|
|**2025-10-15**|**Uni-MMMU: A Massive Multi-discipline Multimodal Unified Benchmark**|Ziwei Liu Team|[2510.13759](http://arxiv.org/abs/2510.13759)|**[link](https://vchitect.github.io/Uni-MMMU-Project/)**|
|**2025-10-15**|**RECODE: Reasoning Through Code Generation for Visual Question Answering**|Alireza Fathi Team|[2510.13756](http://arxiv.org/abs/2510.13756)|null|
|**2025-10-15**|**Speculating a Tactile Grammar: Toward Task-Aligned Chart Design for Non-Visual Perception**|Dylan Cashman Team|[2510.13731](http://arxiv.org/abs/2510.13731)|null|
|**2025-10-15**|**Beyond Pixels: A Differentiable Pipeline for Probing Neuronal Selectivity in 3D**|Fabian H. Sinz Team|[2510.13433](http://arxiv.org/abs/2510.13433)|null|
|**2025-10-15**|**SWIR-LightFusion: Multi-spectral Semantic Fusion of Synthetic SWIR with Thermal IR (LWIR/MWIR) and RGB**|Moongu Jeon Team|[2510.13404](http://arxiv.org/abs/2510.13404)|null|
|**2025-10-15**|**FlyAwareV2: A Multimodal Cross-Domain UAV Dataset for Urban Scene Understanding**|Pietro Zanuttigh Team|[2510.13243](http://arxiv.org/abs/2510.13243)|null|
|**2025-10-15**|**UniVector: Unified Vector Extraction via Instance-Geometry Interaction**|Leyuan Fang Team|[2510.13234](http://arxiv.org/abs/2510.13234)|null|
|**2025-10-14**|**Scope: Selective Cross-modal Orchestration of Visual Perception Experts**|Perouz Taslakian Team|[2510.12974](http://arxiv.org/abs/2510.12974)|null|
|**2025-10-14**|**VLURes: Benchmarking VLM Visual and Linguistic Understanding in Low-Resource Languages**|Tatsuya Hiraoka Team|[2510.12845](http://arxiv.org/abs/2510.12845)|null|
|**2025-10-14**|**Detect Anything via Next Point Prediction**|Lei Zhang Team|[2510.12798](http://arxiv.org/abs/2510.12798)|**[link](https://rex-omni.github.io/)**|
|**2025-10-14**|**SRUM: Fine-Grained Self-Rewarding for Unified Multimodal Models**|Xihui Liu Team|[2510.12784](http://arxiv.org/abs/2510.12784)|**[link](https://waynejin0918.github.io/srum_web/)**|
|**2025-10-14**|**VQArt-Bench: A semantically rich VQA Benchmark for Art and Cultural Heritage**|D. Negueruela del Castillo Team|[2510.12750](http://arxiv.org/abs/2510.12750)|null|
|**2025-10-14**|**SPORTS: Simultaneous Panoptic Odometry, Rendering, Tracking and Segmentation for Urban Scenes Understanding**|Zhu Yang Team|[2510.12749](http://arxiv.org/abs/2510.12749)|null|
|**2025-10-14**|**Beyond Seeing: Evaluating Multimodal LLMs on Tool-Enabled Image Perception, Transformation, and Reasoning**|Rakshith Sharma Srinivasa Team|[2510.12712](http://arxiv.org/abs/2510.12712)|null|
|**2025-10-14**|**Towards General Urban Monitoring with Vision-Language Models: A Review, Evaluation, and a Research Agenda**|Nuno F. Rodrigues Team|[2510.12400](http://arxiv.org/abs/2510.12400)|null|
|**2025-10-14**|**HackWorld: Evaluating Computer-Use Agents on Exploiting Web Application Vulnerabilities**|Terry Yue Zhuo Team|[2510.12200](http://arxiv.org/abs/2510.12200)|null|
|**2025-10-14**|**CompoDistill: Attention Distillation for Compositional Reasoning in Multimodal LLMs**|Chanyoung Park Team|[2510.12184](http://arxiv.org/abs/2510.12184)|null|
|**2025-10-13**|**Task-Specific Dual-Model Framework for Comprehensive Traffic Safety Video Description and Analysis**|Armstrong Aboah Team|[2510.11907](http://arxiv.org/abs/2510.11907)|null|
|**2025-10-13**|**Audio-Guided Visual Perception for Audio-Visual Navigation**|Wendong Zheng Team|[2510.11760](http://arxiv.org/abs/2510.11760)|null|
|**2025-10-13**|**PhySIC: Physically Plausible 3D Human-Scene Interaction and Contact from a Single Image**|Gerard Pons-Moll Team|[2510.11649](http://arxiv.org/abs/2510.11649)|**[link](https://yuxuan-xue.com/physic)**|
|**2025-10-13**|**A Framework for Low-Effort Training Data Generation for Urban Semantic Segmentation**|Carsten Rother Team|[2510.11567](http://arxiv.org/abs/2510.11567)|null|
|**2025-10-13**|**Robot Soccer Kit: Omniwheel Tracked Soccer Robots for Education**|Olivier Ly Team|[2510.11552](http://arxiv.org/abs/2510.11552)|null|
|**2025-10-13**|**mmWalk: Towards Multi-modal Multi-view Walking Assistance**|Rainer Stiefelhagen Team|[2510.11520](http://arxiv.org/abs/2510.11520)|**[link](https://github.com/KediYing/mmWalk)**|
|**2025-10-13**|**REACT3D: Recovering Articulations for Interactive Physical 3D Scenes**|Marc Pollefeys Team|[2510.11340](http://arxiv.org/abs/2510.11340)|null|
|**2025-10-13**|**BLEnD-Vis: Benchmarking Multimodal Cultural Understanding in Vision Language Models**|Roy Ka-Wei Lee Team|[2510.11178](http://arxiv.org/abs/2510.11178)|null|
|**2025-10-12**|**Real2USD: Scene Representations in Universal Scene Description Language**|Pratik Chaudhari Team|[2510.10778](http://arxiv.org/abs/2510.10778)|null|
|**2025-10-12**|**OmniVideoBench: Towards Audio-Visual Understanding Evaluation for Omni MLLMs**|Jiaheng Liu Team|[2510.10689](http://arxiv.org/abs/2510.10689)|null|
|**2025-10-12**|**UniFlow: A Unified Pixel Flow Tokenizer for Visual Understanding and Generation**|Yali Wang Team|[2510.10575](http://arxiv.org/abs/2510.10575)|null|
|**2025-10-12**|**SuperEx: Enhancing Indoor Mapping and Exploration using Non-Line-of-Sight Perception**|Akshat Dave Team|[2510.10506](http://arxiv.org/abs/2510.10506)|**[link](https://super-ex.github.io/)**|
|**2025-10-11**|**B2N3D: Progressive Learning from Binary to N-ary Relationships for 3D Object Grounding**|Wenxiong Kang Team|[2510.10194](http://arxiv.org/abs/2510.10194)|null|
|**2025-10-10**|**VisRAG 2.0: Evidence-Guided Multi-Image Reasoning in Visual Retrieval-Augmented Generation**|Maosong Sun Team|[2510.09733](http://arxiv.org/abs/2510.09733)|null|
|**2025-10-10**|**BLINK-Twice: You see, but do you observe? A Reasoning Benchmark on Visual Perception**|Weijia Li Team|[2510.09361](http://arxiv.org/abs/2510.09361)|null|
|**2025-10-10**|**Spotlight on Token Perception for Multimodal Reinforcement Learning**|Yu Cheng Team|[2510.09285](http://arxiv.org/abs/2510.09285)|**[link](https://github.com/huaixuheqing/VPPO-RL)**|
|**2025-10-10**|**CFVBench: A Comprehensive Video Benchmark for Fine-grained Multimodal Retrieval-Augmented Generation**|Yingchao Feng Team|[2510.09266](http://arxiv.org/abs/2510.09266)|null|
|**2025-10-10**|**Synthetic Object Compositions for Scalable and Accurate Learning in Detection, Segmentation, and Grounding**|Ranjay Krishna Team|[2510.09110](http://arxiv.org/abs/2510.09110)|**[link](https://github.com/weikaih04/Synthetic-Detection-Segmentation-Grounding-Data)**|
|**2025-10-10**|**HandEval: Taking the First Step Towards Hand Quality Evaluation in Generated Images**|Jing Dong Team|[2510.08978](http://arxiv.org/abs/2510.08978)|null|
|**2025-10-10**|**Unleashing Perception-Time Scaling to Multimodal Reasoning Models**|Minghui Qiu Team|[2510.08964](http://arxiv.org/abs/2510.08964)|null|
|**2025-10-10**|**LM Fight Arena: Benchmarking Large Multimodal Models via Game Competition**|Guangtao Zhai Team|[2510.08928](http://arxiv.org/abs/2510.08928)|null|
|**2025-10-09**|**InstructX: Towards Unified Visual Editing with MLLM Guidance**|Qian He Team|[2510.08485](http://arxiv.org/abs/2510.08485)|null|
|**2025-10-09**|**Biology-driven assessment of deep learning super-resolution imaging of the porosity network in dentin**|Aurélien Gourrier Team|[2510.08407](http://arxiv.org/abs/2510.08407)|null|
|**2025-10-09**|**Practicing a Second Language Without Fear: Mixed Reality Agents for Interactive Group Conversation**|Diego Gomez-Zara Team|[2510.08227](http://arxiv.org/abs/2510.08227)|null|
|**2025-10-09**|**RayFusion: Ray Fusion Enhanced Collaborative Visual Perception**|Eryun Liu Team|[2510.08017](http://arxiv.org/abs/2510.08017)|null|
|**2025-10-09**|**The impact of abstract and object tags on image privacy classification**|Andrea Cavallaro Team|[2510.07976](http://arxiv.org/abs/2510.07976)|null|
|**2025-10-09**|**CVD-STORM: Cross-View Video Diffusion with Spatial-Temporal Reconstruction Model for Autonomous Driving**|Zehuan Wu Team|[2510.07944](http://arxiv.org/abs/2510.07944)|null|

<p align=right>(<a href=#updated-on-20251217>back to top</a>)</p>

## Planning

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-12-12**|**Two-dimensional Decompositions of High-dimensional Configurations for Efficient Multi-vehicle Coordination at Intelligent Intersections**|Johan Thunberg Team|[2512.11713](http://arxiv.org/abs/2512.11713)|null|
|**2025-12-12**|**Cross-Entropy Optimization of Physically Grounded Task and Motion Plans**|Javier Alonso-Mora Team|[2512.11571](http://arxiv.org/abs/2512.11571)|null|
|**2025-12-12**|**FutureX: Enhance End-to-End Autonomous Driving via Latent Chain-of-Thought World Model**|Zhen Li Team|[2512.11226](http://arxiv.org/abs/2512.11226)|null|
|**2025-12-11**|**Your plan may succeed, but what about failure? Investigating how people use ChatGPT for long-term life task planning**|Jiqun Liu Team|[2512.11096](http://arxiv.org/abs/2512.11096)|null|
|**2025-12-11**|**LEO-RobotAgent: A General-purpose Robotic Agent for Language-driven Embodied Operator**|Jun Meng Team|[2512.10605](http://arxiv.org/abs/2512.10605)|null|
|**2025-12-11**|**Motion Planning for Safe Landing of a Human-Piloted Parafoil**|Anna Clarke Team|[2512.10595](http://arxiv.org/abs/2512.10595)|null|
|**2025-12-11**|**T-SKM-Net: Trainable Neural Network Framework for Linear Constraint Satisfaction via Sampling Kaczmarz-Motzkin Method**|Qingchun Hou Team|[2512.10461](http://arxiv.org/abs/2512.10461)|null|
|**2025-12-10**|**Fast Functionally Redundant Inverse Kinematics for Robotic Toolpath Optimisation in Manufacturing Tasks**|Tirthankar Bandyopadhyay Team|[2512.10116](http://arxiv.org/abs/2512.10116)|**[link](https://ssl.linklings.net/conferences/acra/acra2025_proceedings/views/includes/files/pap149s2.pdf)**|
|**2025-12-10**|**YOPO-Nav: Visual Navigation using 3DGS Graphs from One-Pass Videos**|Kristin Dana Team|[2512.09903](http://arxiv.org/abs/2512.09903)|null|
|**2025-12-10**|**UniUGP: Unifying Understanding, Generation, and Planing For End-to-end Autonomous Driving**|Ying-Cong Chen Team|[2512.09864](http://arxiv.org/abs/2512.09864)|**[link](https://seed-uniugp.github.io/)**|
|**2025-12-10**|**Scene-agnostic Hierarchical Bimanual Task Planning via Visual Affordance Reasoning**|Sung-Hee Lee Team|[2512.09310](http://arxiv.org/abs/2512.09310)|null|
|**2025-12-09**|**Ergodic Trajectory Planning with Dynamic Sensor Footprints**|Zhongqiang Ren Team|[2512.08661](http://arxiv.org/abs/2512.08661)|null|
|**2025-12-09**|**Aerial Vision-Language Navigation with a Unified Framework for Spatial, Temporal and Embodied Reasoning**|Feng Xu Team|[2512.08639](http://arxiv.org/abs/2512.08639)|null|
|**2025-12-09**|**Semantic-Metric Bayesian Risk Fields: Learning Robot Safety from Human Videos with a VLM Prior**|Mac Schwager Team|[2512.08233](http://arxiv.org/abs/2512.08233)|null|
|**2025-12-09**|**High-Performance Dual-Arm Task and Motion Planning for Tabletop Rearrangement**|Jingjin Yu Team|[2512.08206](http://arxiv.org/abs/2512.08206)|null|
|**2025-12-09**|**Chat with UAV -- Human-UAV Interaction Based on Large Language Models**|Chuanghuang Li Team|[2512.08145](http://arxiv.org/abs/2512.08145)|null|
|**2025-12-08**|**DiffusionDriveV2: Reinforcement Learning-Constrained Truncated Diffusion Modeling in End-to-End Autonomous Driving**|Xinggang Wang Team|[2512.07745](http://arxiv.org/abs/2512.07745)|null|
|**2025-12-08**|**Efficient Computation of a Continuous Topological Model of the Configuration Space of Tethered Mobile Robots**|Bart De Schutter Team|[2512.07303](http://arxiv.org/abs/2512.07303)|null|
|**2025-12-08**|**TrajMoE: Scene-Adaptive Trajectory Planning with Mixture of Experts and Reinforcement Learning**|Dongbin Zhao Team|[2512.07135](http://arxiv.org/abs/2512.07135)|null|
|**2025-12-07**|**A Hetero-Associative Sequential Memory Model Utilizing Neuromorphic Signals: Validated on a Mobile Manipulator**|Gordon Cheng Team|[2512.07032](http://arxiv.org/abs/2512.07032)|null|
|**2025-12-07**|**Khalasi: Energy-Efficient Navigation for Surface Vehicles in Vortical Flow Fields**|Sandeep Manjanna Team|[2512.06912](http://arxiv.org/abs/2512.06912)|null|
|**2025-12-07**|**db-LaCAM: Fast and Scalable Multi-Robot Kinodynamic Motion Planning with Discontinuity-Bounded Search and Lightweight MAPF**|Wolfgang Hönig Team|[2512.06796](http://arxiv.org/abs/2512.06796)|null|
|**2025-12-07**|**FEALPy v3: A Cross-platform Intelligent Numerical Simulation Engine**|Liang He Team|[2512.06632](http://arxiv.org/abs/2512.06632)|null|
|**2025-12-07**|**MIND-V: Hierarchical Video Generation for Long-Horizon Robotic Manipulation with RL-based Physical Alignment**|Xiu Li Team|[2512.06628](http://arxiv.org/abs/2512.06628)|null|
|**2025-12-06**|**General Computation using Slidable Tiles with Deterministic Global Forces**|Tim Wylie Team|[2512.06574](http://arxiv.org/abs/2512.06574)|null|
|**2025-12-06**|**Hankel-FNO: Fast Underwater Acoustic Charting Via Physics-Encoded Fourier Neural Operator**|Peter Gerstoft Team|[2512.06417](http://arxiv.org/abs/2512.06417)|null|
|**2025-12-06**|**JEEVHITAA -- An End-to-End HCAI System to Support Collective Care**|Pushpendra Singh Team|[2512.06364](http://arxiv.org/abs/2512.06364)|null|
|**2025-12-05**|**A Nonlinear Observer for Air-Velocity and Attitude Estimation Using Pitot and Barometric Measurements**|Tarek Hamel Team|[2512.06133](http://arxiv.org/abs/2512.06133)|null|
|**2025-12-05**|**WAM-Flow: Parallel Coarse-to-Fine Motion Planning via Discrete Flow Matching for Autonomous Driving**|Siyu Zhu Team|[2512.06112](http://arxiv.org/abs/2512.06112)|**[link](https://github.com/fudan-generative-vision/WAM-Flow)**|
|**2025-12-05**|**SIMPACT: Simulation-Enabled Action Planning using Vision-Language Models**|Yilun Du Team|[2512.05955](http://arxiv.org/abs/2512.05955)|null|
|**2025-12-05**|**Speech World Model: Causal State-Action Planning with Explicit Reasoning for Speech**|Gopala Anumanchipalli Team|[2512.05933](http://arxiv.org/abs/2512.05933)|null|
|**2025-12-05**|**World Models That Know When They Don't Know: Controllable Video Generation with Calibrated Uncertainty**|Anirudha Majumdar Team|[2512.05927](http://arxiv.org/abs/2512.05927)|null|
|**2025-12-05**|**Optimal Safety-Aware Scheduling for Multi-Agent Aerial 3D Printing with Utility Maximization under Dependency Constraints**|George Nikolakopoulos Team|[2512.05815](http://arxiv.org/abs/2512.05815)|null|
|**2025-12-05**|**Real-time Remote Tracking and Autonomous Planning for Whale Rendezvous using Robots**|Stephanie Gil Team|[2512.05808](http://arxiv.org/abs/2512.05808)|null|
|**2025-12-05**|**3D Path Planning for Robot-assisted Vertebroplasty from Arbitrary Bi-plane X-ray via Differentiable Rendering**|Mathias Unberath Team|[2512.05803](http://arxiv.org/abs/2512.05803)|null|
|**2025-12-05**|**Task-Specific Trust Evaluation for Multi-Hop Collaborator Selection via GNN-Aided Distributed Agentic AI**|Dusit Niyato Team|[2512.05788](http://arxiv.org/abs/2512.05788)|null|
|**2025-12-05**|**The Missing Layer of AGI: From Pattern Alchemy to Coordination Physics**|Edward Y. Chang Team|[2512.05765](http://arxiv.org/abs/2512.05765)|null|
|**2025-12-05**|**Teaching Language Models Mechanistic Explainability Through Arrow-Pushing**|Philippe Schwaller Team|[2512.05722](http://arxiv.org/abs/2512.05722)|null|
|**2025-12-05**|**Bayesian Active Inference for Intelligent UAV Anti-Jamming and Adaptive Trajectory Planning**|Carlo Regazzoni Team|[2512.05711](http://arxiv.org/abs/2512.05711)|null|
|**2025-12-05**|**Scenario-aware Uncertainty Quantification for Trajectory Prediction with Statistical Guarantees**|Chen Sun Team|[2512.05682](http://arxiv.org/abs/2512.05682)|null|
|**2025-12-05**|**The Topology of Hardship: Empirical Curriculum Graphs and Structural Bottlenecks in Engineering Degrees**|H. R. Paz Team|[2512.05561](http://arxiv.org/abs/2512.05561)|null|
|**2025-12-05**|**Distributed scalable coupled policy algorithm for networked multi-agent reinforcement learning**|Wei Ren Team|[2512.05447](http://arxiv.org/abs/2512.05447)|null|
|**2025-12-05**|**Bita: A Conversational Assistant for Fairness Testing**|Ronnie de Souza Santos Team|[2512.05428](http://arxiv.org/abs/2512.05428)|null|
|**2025-12-04**|**Two-Stage Camera Calibration Method for Multi-Camera Systems Using Scene Geometry**|Aleksandr Abramov Team|[2512.05171](http://arxiv.org/abs/2512.05171)|null|
|**2025-12-04**|**Algorithmic Thinking Theory**|Christopher Mohri Team|[2512.04923](http://arxiv.org/abs/2512.04923)|null|
|**2025-12-04**|**On Disturbance-Aware Minimum-Time Trajectory Planning: Evidence from Tests on a Dynamic Driving Simulator**|Massimo Guiggiani Team|[2512.04917](http://arxiv.org/abs/2512.04917)|null|
|**2025-12-04**|**The Stagnant Persistence Paradox: Survival Analysis and Temporal Efficiency in Exact Sciences and Engineering Education**|H. R. Paz Team|[2512.04828](http://arxiv.org/abs/2512.04828)|null|
|**2025-12-04**|**Neural Policy Composition from Free Energy Minimization**|Giovanni Russo Team|[2512.04745](http://arxiv.org/abs/2512.04745)|null|
|**2025-12-04**|**E3AD: An Emotion-Aware Vision-Language-Action Model for Human-Centric End-to-End Autonomous Driving**|Chengzhong Xu Team|[2512.04733](http://arxiv.org/abs/2512.04733)|null|
|**2025-12-04**|**POLARIS: Is Multi-Agentic Reasoning the Next Wave in Engineering Self-Adaptive Systems?**|Karthik Vaidhyanathan Team|[2512.04702](http://arxiv.org/abs/2512.04702)|null|
|**2025-12-04**|**Quantised Academic Mobility: Network and Cluster Analysis of Degree Switching, Plan Changes, and Re-entries in an Engineering Faculty (1980-2019)**|H. R. Paz Team|[2512.04652](http://arxiv.org/abs/2512.04652)|null|
|**2025-12-04**|**BioMedGPT-Mol: Multi-task Learning for Molecular Understanding and Generation**|Zaiqing Nie Team|[2512.04629](http://arxiv.org/abs/2512.04629)|null|
|**2025-12-04**|**SlideGen: Collaborative Multimodal Agents for Scientific Slide Generation**|Chenyu You Team|[2512.04529](http://arxiv.org/abs/2512.04529)|null|
|**2025-12-04**|**Auto3R: Automated 3D Reconstruction and Scanning via Data-driven Uncertainty Quantification**|Xiangru Huang Team|[2512.04528](http://arxiv.org/abs/2512.04528)|null|
|**2025-12-04**|**A Modular Cognitive Architecture for Assisted Reasoning: The Nemosine Framework**|Edervaldo Melo Team|[2512.04500](http://arxiv.org/abs/2512.04500)|null|
|**2025-12-04**|**dVLM-AD: Enhance Diffusion Vision-Language-Model for Driving via Controllable Reasoning**|Chaowei Xiao Team|[2512.04459](http://arxiv.org/abs/2512.04459)|null|
|**2025-12-04**|**Open-Ended Goal Inference through Actions and Language for Human-Robot Collaboration**|Brian Scassellati Team|[2512.04453](http://arxiv.org/abs/2512.04453)|null|
|**2025-12-04**|**StreamEQA: Towards Streaming Video Understanding for Embodied Scenarios**|Xiaoling Wang Team|[2512.04451](http://arxiv.org/abs/2512.04451)|null|
|**2025-12-04**|**Vision-Language-Action Models for Selective Robotic Disassembly: A Case Study on Critical Component Extraction from Desktops**|Minghui Zheng Team|[2512.04446](http://arxiv.org/abs/2512.04446)|null|
|**2025-12-04**|**MindDrive: An All-in-One Framework Bridging World Models and Vision-Language Model for End-to-End Autonomous Driving**|Ziying Song Team|[2512.04441](http://arxiv.org/abs/2512.04441)|null|
|**2025-12-03**|**Gamma-from-Mono: Road-Relative, Metric, Self-Supervised Monocular Geometry for Vehicular Applications**|Olaf Hellwich Team|[2512.04303](http://arxiv.org/abs/2512.04303)|null|
|**2025-12-03**|**A Modular Architecture Design for Autonomous Driving Racing in Controlled Environments**|Javier Perez-Robles Team|[2512.03886](http://arxiv.org/abs/2512.03886)|null|
|**2025-12-03**|**Safety Reinforced Model Predictive Control (SRMPC): Improving MPC with Reinforcement Learning for Motion Planning in Autonomous Driving**|Christoph Stiller Team|[2512.03774](http://arxiv.org/abs/2512.03774)|null|
|**2025-12-03**|**Prediction-Driven Motion Planning: Route Integration Strategies in Attention-Based Prediction Models**|Christoph Stiller Team|[2512.03756](http://arxiv.org/abs/2512.03756)|null|
|**2025-12-03**|**ContactRL: Safe Reinforcement Learning based Motion Planning for Contact based Human Robot Collaboration**|Emma Li Team|[2512.03707](http://arxiv.org/abs/2512.03707)|null|
|**2025-12-03**|**A Novel Approach to Tomato Harvesting Using a Hybrid Gripper with Semantic Segmentation and Keypoint Detection**|Bishakh Bhattacharya Team|[2512.03684](http://arxiv.org/abs/2512.03684)|null|
|**2025-12-03**|**Multimodal Control of Manipulators: Coupling Kinematics and Vision for Self-Driving Laboratory Operations**|Naresh Marturi Team|[2512.03630](http://arxiv.org/abs/2512.03630)|null|
|**2025-12-03**|**LAMP: Language-Assisted Motion Planning for Controllable Video Generation**|Duygu Ceylan Team|[2512.03619](http://arxiv.org/abs/2512.03619)|**[link](https://cyberiada.github.io/LAMP/)**|
|**2025-12-03**|**Parameter Optimization in Trajectory Planning via Differentiable Convex Programming**|Shengping Gong Team|[2512.03557](http://arxiv.org/abs/2512.03557)|null|
|**2025-12-03**|**PARC: An Autonomous Self-Reflective Coding Agent for Robust Execution of Long-Horizon Tasks**|Daisuke Okanohara Team|[2512.03549](http://arxiv.org/abs/2512.03549)|null|
|**2025-12-03**|**PerFACT: Motion Policy with LLM-Powered Dataset Synthesis and Fusion Action-Chunking Transformers**|Minghui Zheng Team|[2512.03444](http://arxiv.org/abs/2512.03444)|null|
|**2025-12-02**|**Multi-Agent Reinforcement Learning and Real-Time Decision-Making in Robotic Soccer for Virtual Environments**|Md Sohag Mia Team|[2512.03166](http://arxiv.org/abs/2512.03166)|null|
|**2025-12-02**|**AID: Agent Intent from Diffusion for Multi-Agent Informative Path Planning**|Guillaume Sartoretti Team|[2512.02535](http://arxiv.org/abs/2512.02535)|null|
|**2025-12-02**|**Nav- $R^2$ Dual-Relation Reasoning for Generalizable Open-Vocabulary Object-Goal Navigation**|Yujiu Yang Team|[2512.02400](http://arxiv.org/abs/2512.02400)|null|
|**2025-12-02**|**On-the-fly Feedback SfM: Online Explore-and-Exploit UAV Photogrammetry with Incremental Mesh Quality-Aware Indicator and Predictive Path Planning**|Zongqian Zhan Team|[2512.02375](http://arxiv.org/abs/2512.02375)|null|
|**2025-12-01**|**Guardian: Detecting Robotic Planning and Execution Errors with Vision-Language Models**|Cordelia Schmid Team|[2512.01946](http://arxiv.org/abs/2512.01946)|**[link](https://www.di.ens.fr/willow/research/guardian/.)**|
|**2025-12-01**|**OpenREAD: Reinforced Open-Ended Reasoning for End-to-End Autonomous Driving with LLM-as-Critic**|Chen Lv Team|[2512.01830](http://arxiv.org/abs/2512.01830)|null|
|**2025-12-01**|**Modality-Augmented Fine-Tuning of Foundation Robot Policies for Cross-Embodiment Manipulation on GR1 and G1**|Songhwai Oh Team|[2512.01358](http://arxiv.org/abs/2512.01358)|null|
|**2025-11-30**|**MM-ACT: Learn from Multimodal Parallel Generation to Act**|Ping Luo Team|[2512.00975](http://arxiv.org/abs/2512.00975)|null|
|**2025-11-30**|**Constant-Time Motion Planning with Manipulation Behaviors**|Maxim Likhachev Team|[2512.00939](http://arxiv.org/abs/2512.00939)|null|
|**2025-11-29**|**HAVEN: Hierarchical Adversary-aware Visibility-Enabled Navigation with Cover Utilization using Deep Transformer Q-Networks**|Aniket Bera Team|[2512.00592](http://arxiv.org/abs/2512.00592)|null|
|**2025-11-29**|**Balancing Efficiency and Fairness: An Iterative Exchange Framework for Multi-UAV Cooperative Path Planning**|Shiqin Tang Team|[2512.00410](http://arxiv.org/abs/2512.00410)|null|
|**2025-11-29**|**DPNet: Doppler LiDAR Motion Planning for Highly-Dynamic Environments**|Chengzhong Xu Team|[2512.00375](http://arxiv.org/abs/2512.00375)|null|
|**2025-11-02**|**XFlowMP: Task-Conditioned Motion Fields for Generative Robot Planning with Schrodinger Bridges**|Minh Nhat Vu Team|[2512.00022](http://arxiv.org/abs/2512.00022)|null|
|**2025-10-31**|**Foundation Models for Trajectory Planning in Autonomous Driving: A Review of Progress and Open Challenges**|Puneet K. Dokania Team|[2512.00021](http://arxiv.org/abs/2512.00021)|null|
|**2025-11-28**|**From CAD to POMDP: Probabilistic Planning for Robotic Disassembly of End-of-Life Products**|Jürgen Fleischer Team|[2511.23407](http://arxiv.org/abs/2511.23407)|null|
|**2025-11-28**|**Closed-Loop Control Law for Low Thrust Orbit Transfer with Guaranteed Stability**|Ravi Kumar L Team|[2511.23014](http://arxiv.org/abs/2511.23014)|null|
|**2025-11-28**|**ORION: Teaching Language Models to Reason Efficiently in the Language of Thought**|Subhabrata Mukherjee Team|[2511.22891](http://arxiv.org/abs/2511.22891)|null|
|**2025-11-28**|**SUPER-AD: Semantic Uncertainty-aware Planning for End-to-End Robust Autonomous Driving**|Hyunjung Shim Team|[2511.22865](http://arxiv.org/abs/2511.22865)|null|
|**2025-11-28**|**Safe Autonomous Lane Changing: Planning with Dynamic Risk Fields and Time-Varying Convex Space Generation**|Zhihao Lin Team|[2511.22829](http://arxiv.org/abs/2511.22829)|null|
|**2025-11-27**|**An Efficient Privacy-preserving Intrusion Detection Scheme for UAV Swarm Networks**|Shafika Showkat Moni Team|[2511.22791](http://arxiv.org/abs/2511.22791)|null|
|**2025-11-27**|**CAPE: Context-Aware Diffusion Policy Via Proximal Mode Expansion for Collision Avoidance**|Amir Rasouli Team|[2511.22773](http://arxiv.org/abs/2511.22773)|null|
|**2025-11-27**|**Deadlock-Free Hybrid RL-MAPF Framework for Zero-Shot Multi-Robot Navigation**|Mingyu Cai Team|[2511.22685](http://arxiv.org/abs/2511.22685)|null|
|**2025-11-27**|**CoT4AD: A Vision-Language-Action Model with Explicit Chain-of-Thought Reasoning for Autonomous Driving**|Hao Tang Team|[2511.22532](http://arxiv.org/abs/2511.22532)|null|
|**2025-11-27**|**BINDER: Instantly Adaptive Mobile Manipulation with Open-Vocabulary Commands**|Jonghyun Choi Team|[2511.22364](http://arxiv.org/abs/2511.22364)|null|
|**2025-11-27**|**LLM-Based Generalizable Hierarchical Task Planning and Execution for Heterogeneous Robot Teams with Event-Driven Replanning**|Madhu Vadali Team|[2511.22354](http://arxiv.org/abs/2511.22354)|null|
|**2025-11-27**|**MTR-VP: Towards End-to-End Trajectory Planning through Context-Driven Image Encoding and Multiple Trajectory Prediction**|Ross Greer Team|[2511.22181](http://arxiv.org/abs/2511.22181)|null|
|**2025-11-27**|**Model Predictive Path Planning in Navier-Stokes Flow with POD-Based Reduced-Order Models**|Martin Guay Team|[2511.22123](http://arxiv.org/abs/2511.22123)|null|
|**2025-11-27**|**SwordRiding: A Unified Navigation Framework for Quadrotors in Unknown Complex Environments via Online Guiding Vector Fields**|Jie Chen Team|[2511.22043](http://arxiv.org/abs/2511.22043)|**[link](https://www.youtube.com/watch?v=tKYCg266c4o.)**|
|**2025-11-26**|**MADRA: Multi-Agent Debate for Risk-Aware Embodied Planning**|Xi Sheryl Zhang Team|[2511.21460](http://arxiv.org/abs/2511.21460)|null|
|**2025-11-26**|**AVFakeBench: A Comprehensive Audio-Video Forgery Detection Benchmark for AV-LMMs**|Zekun Li Team|[2511.21251](http://arxiv.org/abs/2511.21251)|null|
|**2025-11-26**|**AerialMind: Towards Referring Multi-Object Tracking in UAV Scenarios**|Qing-Long Han Team|[2511.21053](http://arxiv.org/abs/2511.21053)|null|
|**2025-11-25**|**Image2Gcode: Image-to-G-code Generation for Additive Manufacturing Using Diffusion-Transformer Model**|Amir Barati Farimani Team|[2511.20636](http://arxiv.org/abs/2511.20636)|null|
|**2025-11-25**|**Safe and Stable Neural Network Dynamical Systems for Robot Motion Planning**|Abdalla Swikir Team|[2511.20593](http://arxiv.org/abs/2511.20593)|null|
|**2025-11-25**|**BRIC: Bridging Kinematic Plans and Physical Control at Test Time**|Sungchan Kim Team|[2511.20431](http://arxiv.org/abs/2511.20431)|null|
|**2025-11-25**|**Improved adaptive wind driven optimization algorithm for real-time path planning**|Le-le Mao Team|[2511.20394](http://arxiv.org/abs/2511.20394)|null|
|**2025-11-25**|**Accelerating Time-Optimal Trajectory Planning for Connected and Automated Vehicles with Graph Neural Networks**|Andreas A. Malikopoulos Team|[2511.20383](http://arxiv.org/abs/2511.20383)|null|
|**2025-11-25**|**Map-World: Masked Action planning and Path-Integral World Model for Autonomous Driving**|Zhenning Li Team|[2511.20156](http://arxiv.org/abs/2511.20156)|null|
|**2025-11-25**|**GigaWorld-0: World Models as Data Engine to Empower Embodied AI**|Zheng Zhu Team|[2511.19861](http://arxiv.org/abs/2511.19861)|**[link](https://giga-world-0.github.io/)**|
|**2025-11-25**|**Unifying Perception and Action: A Hybrid-Modality Pipeline with Implicit Visual Chain-of-Thought for Robotic Action Generation**|Sanglu Lu Team|[2511.19859](http://arxiv.org/abs/2511.19859)|null|
|**2025-11-24**|**Flow-Based Path Planning for Multiple Homogenous UAVs for Outdoor Formation-Flying**|Abdullah Abrar Team|[2511.19653](http://arxiv.org/abs/2511.19653)|null|
|**2025-11-19**|**Strong Duality and Dual Ascent Approach to Continuous-Time Chance-Constrained Stochastic Optimal Control**|Takashi Tanaka Team|[2511.19451](http://arxiv.org/abs/2511.19451)|null|
|**2025-11-24**|**Cook and Clean Together: Teaching Embodied Agents for Parallel Task Execution**|Xiang Bai Team|[2511.19430](http://arxiv.org/abs/2511.19430)|**[link](https://github.com/H-EmbodVis/GRANT})**|
|**2025-11-24**|**Asynchronous Distributed Multi-Robot Motion Planning Under Imperfect Communication**|Aaron M. Johnson Team|[2511.18703](http://arxiv.org/abs/2511.18703)|null|
|**2025-11-24**|**CNN-Based Camera Pose Estimation and Localisation of Scan Images for Aircraft Visual Inspection**|U-Xuan Tan Team|[2511.18702](http://arxiv.org/abs/2511.18702)|null|
|**2025-11-23**|**An Analysis of Constraint-Based Multi-Agent Pathfinding Algorithms**|Nancy M. Amato Team|[2511.18604](http://arxiv.org/abs/2511.18604)|null|
|**2025-11-23**|**Skypilot: Fine-Tuning LLM with Physical Grounding for AAV Coverage Search**|Jie Jiang Team|[2511.18270](http://arxiv.org/abs/2511.18270)|null|
|**2025-11-22**|**Time-aware Motion Planning in Dynamic Environments with Conformal Prediction**|Cristian Ioan Vasile Team|[2511.18170](http://arxiv.org/abs/2511.18170)|null|
|**2025-11-22**|**Anti-Jamming based on Null-Steering Antennas and Intelligent UAV Swarm Behavior**|António Grilo Team|[2511.18086](http://arxiv.org/abs/2511.18086)|null|
|**2025-11-21**|**Target-Bench: Can World Models Achieve Mapless Path Planning with Semantic Targets?**|Johannes Betz Team|[2511.17792](http://arxiv.org/abs/2511.17792)|null|
|**2025-11-21**|**RynnVLA-002: A Unified Vision-Language-Action and World Model**|Hao Chen Team|[2511.17502](http://arxiv.org/abs/2511.17502)|null|
|**2025-11-21**|**MDG: Masked Denoising Generation for Multi-Agent Behavior Modeling in Traffic Environments**|Jiaqi Ma Team|[2511.17496](http://arxiv.org/abs/2511.17496)|null|
|**2025-11-21**|**Planning with Sketch-Guided Verification for Physics-Aware Video Generation**|Mohit Bansal Team|[2511.17450](http://arxiv.org/abs/2511.17450)|**[link](https://sketchverify.github.io/)**|
|**2025-11-21**|**IndustryNav: Exploring Spatial Reasoning of Embodied Agents in Dynamic Industrial Navigation**|Yu Kong Team|[2511.17384](http://arxiv.org/abs/2511.17384)|null|
|**2025-11-21**|**Vector Cost Behavioral Planning for Autonomous Robotic Systems with Contemporary Validation Strategies**|Metin Gökaşan Team|[2511.17375](http://arxiv.org/abs/2511.17375)|null|
|**2025-11-21**|**Robot Confirmation Generation and Action Planning Using Long-context Q-Former Integrated with Multimodal LLM**|Jonathan Le Roux Team|[2511.17335](http://arxiv.org/abs/2511.17335)|null|
|**2025-11-21**|**DiffRefiner: Coarse to Fine Trajectory Planning via Diffusion Refinement with Semantic Interaction for End to End Autonomous Driving**|Erkang Cheng Team|[2511.17150](http://arxiv.org/abs/2511.17150)|null|
|**2025-11-21**|**Asymptotics of motion planning complexity for control-affine systems**|Dario Prandi Team|[2511.17130](http://arxiv.org/abs/2511.17130)|null|
|**2025-11-21**|**Multi-UAV Swarm Obstacle Avoidance Based on Potential Field Optimization**|Weican Chen Team|[2511.16911](http://arxiv.org/abs/2511.16911)|null|
|**2025-11-20**|**BOP-ASK: Object-Interaction Reasoning for Vision-Language Models**|Jonathan Tremblay Team|[2511.16857](http://arxiv.org/abs/2511.16857)|null|
|**2025-11-20**|**A*-based Temporal Logic Path Planning with User Preferences on Relaxed Task Satisfaction**|Cristian-Ioan Vasile Team|[2511.16844](http://arxiv.org/abs/2511.16844)|null|
|**2025-11-20**|**MiMo-Embodied: X-Embodied Foundation Model Technical Report**|Long Chen Team|[2511.16518](http://arxiv.org/abs/2511.16518)|**[link](https://github.com/XiaomiMiMo/MiMo-Embodied)**|
|**2025-11-19**|**Real-Time Optimal Control via Transformer Networks and Bernstein Polynomials**|Irene Gregory Team|[2511.15588](http://arxiv.org/abs/2511.15588)|null|
|**2025-11-19**|**NMPC-based Motion Planning with Adaptive Weighting for Dynamic Object Interception**|Steven Liu Team|[2511.15532](http://arxiv.org/abs/2511.15532)|null|
|**2025-11-19**|**RRT*former: Environment-Aware Sampling-Based Motion Planning using Transformer**|Xiang Yin Team|[2511.15414](http://arxiv.org/abs/2511.15414)|null|
|**2025-11-19**|**Path Planning through Multi-Agent Reinforcement Learning in Dynamic Environments**|Moharram Challenger Team|[2511.15284](http://arxiv.org/abs/2511.15284)|null|
|**2025-11-19**|**Communication-Aware Asynchronous Distributed Trajectory Optimization for UAV Swarm**|Shaoming He Team|[2511.14994](http://arxiv.org/abs/2511.14994)|null|
|**2025-11-18**|**A PDE-constrained Optimization Approach to Optimal Trajectory Planning under Uncertainty via Reflected Schrödinger Bridges**|Wenxin Liu Team|[2511.14355](http://arxiv.org/abs/2511.14355)|null|
|**2025-11-18**|**PAVE: An End-to-End Dataset for Production Autonomous Vehicle Evaluation**|Ke Ma Team|[2511.14185](http://arxiv.org/abs/2511.14185)|null|
|**2025-11-17**|**TiViBench: Benchmarking Think-in-Video Reasoning for Video Generative Models**|Ying-Cong Chen Team|[2511.13704](http://arxiv.org/abs/2511.13704)|**[link](https://haroldchen19.github.io/TiViBench-Page/)**|
|**2025-11-17**|**Handover-Aware URLLC UAV Trajectory Planning: A Continuous-Time Trajectory Optimization via Graphs of Convex Sets**|Tianhao Liang Team|[2511.13429](http://arxiv.org/abs/2511.13429)|null|
|**2025-11-17**|**Informative Communication of Robot Plans**|Thomas Hellstrom Team|[2511.13226](http://arxiv.org/abs/2511.13226)|null|
|**2025-11-17**|**Unidirectional-Road-Network-Based Global Path Planning for Cleaning Robots in Semi-Structured Environments**|Hui Cheng Team|[2511.13048](http://arxiv.org/abs/2511.13048)|null|
|**2025-11-17**|**Cooperative ISAC for LAE: Joint Trajectory Planning, Power allocation, and Dynamic Time Division**|Jiangzhou Wang Team|[2511.13006](http://arxiv.org/abs/2511.13006)|null|
|**2025-11-16**|**Approximate Tracking Controllability of Systems with Quadratic Nonlinearities**|Marius Tucsnak Team|[2511.12634](http://arxiv.org/abs/2511.12634)|null|
|**2025-11-16**|**EcoFlight: Finding Low-Energy Paths Through Obstacles for Autonomous Sensing Drones**|Roberto Rojas-Cessa Team|[2511.12618](http://arxiv.org/abs/2511.12618)|null|
|**2025-11-16**|**A New Perspective on Double-S Curve Motions of Higher Order and Optimal Motion Planning**|Rico Zöllner Team|[2511.12615](http://arxiv.org/abs/2511.12615)|null|
|**2025-11-16**|**RoboAfford++: A Generative AI-Enhanced Dataset for Multimodal Affordance Learning in Robotic Manipulation and Navigation**|Long Chen Team|[2511.12436](http://arxiv.org/abs/2511.12436)|null|
|**2025-11-15**|**Mobile-Agent-RAG: Driving Smart Multi-Agent Coordination with Contextual Knowledge Empowerment for Long-Horizon Mobile Automation**|Guanbin Li Team|[2511.12254](http://arxiv.org/abs/2511.12254)|null|
|**2025-11-15**|**Game-Theoretic Safe Multi-Agent Motion Planning with Reachability Analysis for Dynamic and Uncertain Environments (Extended Version)**|Xianbin Wang Team|[2511.12160](http://arxiv.org/abs/2511.12160)|null|
|**2025-11-15**|**SBAMP: Sampling Based Adaptive Motion Planning**|Shreyas Raorane Team|[2511.12022](http://arxiv.org/abs/2511.12022)|null|
|**2025-11-15**|**Bootstrapped LLM Semantics for Context-Aware Path Planning**|Reza Akhavian Team|[2511.11967](http://arxiv.org/abs/2511.11967)|null|
|**2025-11-14**|**Who Moved My Distribution? Conformal Prediction for Interactive Multi-Agent Systems**|Anushri Dixit Team|[2511.11567](http://arxiv.org/abs/2511.11567)|null|
|**2025-11-14**|**Terrain Costmap Generation via Scaled Preference Conditioning**|Joydeep Biswas Team|[2511.11529](http://arxiv.org/abs/2511.11529)|null|
|**2025-11-14**|**Scalable Coverage Trajectory Synthesis on GPUs as Statistical Inference**|Todd Murphey Team|[2511.11514](http://arxiv.org/abs/2511.11514)|**[link](https://sites.google.com/rice.edu/parallelized-planning-control/)**|
|**2025-11-14**|**Policy Optimization for Unknown Systems using Differentiable Model Predictive Control**|John Lygeros Team|[2511.11308](http://arxiv.org/abs/2511.11308)|null|
|**2025-11-14**|**Numerical Discretization Schemes that Preserve Flatness**|Ravi Banavar Team|[2511.11183](http://arxiv.org/abs/2511.11183)|null|
|**2025-11-14**|**AdaptPNP: Integrating Prehensile and Non-Prehensile Skills for Adaptive Robotic Manipulation**|Lin Shao Team|[2511.11052](http://arxiv.org/abs/2511.11052)|null|
|**2025-11-14**|**Autonomous Vehicle Path Planning by Searching With Differentiable Simulation**|Luc Van Gool Team|[2511.11043](http://arxiv.org/abs/2511.11043)|null|
|**2025-11-14**|**Latent-Space Autoregressive World Model for Efficient and Robust Image-Goal Navigation**|Huimin Lu Team|[2511.11011](http://arxiv.org/abs/2511.11011)|null|
|**2025-11-14**|**Collaborative Multi-Robot Non-Prehensile Manipulation via Flow-Matching Co-Generation**|Jiaoyang Li Team|[2511.10874](http://arxiv.org/abs/2511.10874)|null|
|**2025-11-14**|**WetExplorer: Automating Wetland Greenhouse-Gas Surveys with an Autonomous Mobile Robot**|Xuping Zhang Team|[2511.10864](http://arxiv.org/abs/2511.10864)|null|
|**2025-11-13**|**MIGHTY: Hermite Spline-based Efficient Trajectory Planning**|Jonathan P. How Team|[2511.10822](http://arxiv.org/abs/2511.10822)|null|
|**2025-11-12**|**A Robust Task-Level Control Architecture for Learned Dynamical Systems**|Naira Hovakimyan Team|[2511.09790](http://arxiv.org/abs/2511.09790)|null|
|**2025-11-12**|**A Quantum Tunneling and Bio-Phototactic Driven Enhanced Dwarf Mongoose Optimizer for UAV Trajectory Planning and Engineering Problem**|Jing Xu Team|[2511.09020](http://arxiv.org/abs/2511.09020)|null|
|**2025-11-11**|**Dual-Arm Whole-Body Motion Planning: Leveraging Overlapping Kinematic Chains**|Carolyn Matl Team|[2511.08778](http://arxiv.org/abs/2511.08778)|null|
|**2025-11-11**|**Intuitive Programming, Adaptive Task Planning, and Dynamic Role Allocation in Human-Robot Collaboration**|Arash Ajoudani Team|[2511.08732](http://arxiv.org/abs/2511.08732)|**[link](https://www.annualreviews.org)**|
|**2025-11-11**|**Simulating the Visual World with Artificial Intelligence: A Roadmap**|Ziwei Liu Team|[2511.08585](http://arxiv.org/abs/2511.08585)|**[link](https://world-model-roadmap.github.io/)**|
|**2025-11-11**|**HardFlow: Hard-Constrained Sampling for Flow-Matching Models via Trajectory Optimization**|Navid Azizan Team|[2511.08425](http://arxiv.org/abs/2511.08425)|null|
|**2025-11-11**|**Effective Game-Theoretic Motion Planning via Nested Search**|Kiril Solovey Team|[2511.08001](http://arxiv.org/abs/2511.08001)|null|
|**2025-11-11**|**An Image-Based Path Planning Algorithm Using a UAV Equipped with Stereo Vision**|Mustafa Unel Team|[2511.07928](http://arxiv.org/abs/2511.07928)|null|
|**2025-11-11**|**Local Path Planning with Dynamic Obstacle Avoidance in Unstructured Environments**|Mustafa Unel Team|[2511.07927](http://arxiv.org/abs/2511.07927)|null|
|**2025-11-11**|**Occlusion-Aware Ground Target Search by a UAV in an Urban Environment**|Artur Wolek Team|[2511.07822](http://arxiv.org/abs/2511.07822)|null|
|**2025-11-11**|**Virtual Traffic Lights for Multi-Robot Navigation: Decentralized Planning with Centralized Conflict Resolution**|Akansel Cosgun Team|[2511.07811](http://arxiv.org/abs/2511.07811)|null|
|**2025-11-11**|**LLM-GROP: Visually Grounded Robot Task and Motion Planning with Large Language Models**|Shiqi Zhang Team|[2511.07727](http://arxiv.org/abs/2511.07727)|null|
|**2025-11-10**|**ARGUS: A Framework for Risk-Aware Path Planning in Tactical UGV Operations**|António Grilo Team|[2511.07565](http://arxiv.org/abs/2511.07565)|null|
|**2025-11-10**|**Using Vision Language Models as Closed-Loop Symbolic Planners for Robotic Applications: A Control-Theoretic Perspective**|Somil Bansal Team|[2511.07410](http://arxiv.org/abs/2511.07410)|null|
|**2025-11-10**|**Exact Smooth Reformulations for Trajectory Optimization Under Signal Temporal Logic Specifications**|Jana Tumova Team|[2511.07375](http://arxiv.org/abs/2511.07375)|null|
|**2025-11-10**|**Dynamics-Decoupled Trajectory Alignment for Sim-to-Real Transfer in Reinforcement Learning for Autonomous Driving**|Mirko Maehlisch Team|[2511.07155](http://arxiv.org/abs/2511.07155)|null|
|**2025-11-10**|**Koopman-Based Dynamic Environment Prediction for Safe UAV Navigation**|Lorenzo Fagiano Team|[2511.06990](http://arxiv.org/abs/2511.06990)|null|
|**2025-11-10**|**Radio-Coverage-Aware Path Planning for Cooperative Autonomous Vehicles**|Renzo Perfetti Team|[2511.06874](http://arxiv.org/abs/2511.06874)|null|
|**2025-11-10**|**Vision-Aided Online A* Path Planning for Efficient and Safe Navigation of Service Robots**|Tushar Sandhan Team|[2511.06801](http://arxiv.org/abs/2511.06801)|null|
|**2025-11-09**|**CoFineLLM: Conformal Finetuning of LLMs for Language-Instructed Robot Planning**|Yiannis Kantaros Team|[2511.06575](http://arxiv.org/abs/2511.06575)|null|
|**2025-11-09**|**GHOST: Solving the Traveling Salesman Problem on Graphs of Convex Sets**|Hang Ma Team|[2511.06471](http://arxiv.org/abs/2511.06471)|null|
|**2025-11-09**|**LaneDiffusion: Improving Centerline Graph Learning via Prior Injected BEV Feature Generation**|Guanbin Li Team|[2511.06272](http://arxiv.org/abs/2511.06272)|null|
|**2025-11-09**|**OpenVLN: Open-world Aerial Vision-Language Navigation**|Yang Cong Team|[2511.06182](http://arxiv.org/abs/2511.06182)|null|
|**2025-11-08**|**PlaCo: a QP-based robot planning and control framework**|Olivier Ly Team|[2511.06141](http://arxiv.org/abs/2511.06141)|null|
|**2025-11-08**|**Open-World 3D Scene Graph Generation for Retrieval-Augmented Reasoning**|Lechao Cheng Team|[2511.05894](http://arxiv.org/abs/2511.05894)|null|
|**2025-11-08**|**An Open-Source, Reproducible Tensegrity Robot that can Navigate Among Obstacles**|Kostas E. Bekris Team|[2511.05798](http://arxiv.org/abs/2511.05798)|null|
|**2025-11-07**|**TAPOM: Task-Space Topology-Guided Motion Planning for Manipulating Elongated Object in Cluttered Environments**|Yijiang Huang Team|[2511.05052](http://arxiv.org/abs/2511.05052)|null|
|**2025-11-07**|**iFlyBot-VLM Technical Report**|Jia Pan Team|[2511.04976](http://arxiv.org/abs/2511.04976)|null|
|**2025-11-06**|**Conformalized Non-uniform Sampling Strategies for Accelerated Sampling-based Motion Planning**|Yiannis Kantaros Team|[2511.04835](http://arxiv.org/abs/2511.04835)|null|
|**2025-11-06**|**ScheduleStream: Temporal Planning with Samplers for GPU-Accelerated Multi-Arm Task and Motion Planning & Scheduling**|Fabio Ramos Team|[2511.04758](http://arxiv.org/abs/2511.04758)|**[link](https://schedulestream.github.io)**|
|**2025-11-06**|**DR. WELL: Dynamic Reasoning and Learning with Symbolic World Model for Embodied LLM-Based Multi-Agent Collaboration**|Carlee Joe-Wong Team|[2511.04646](http://arxiv.org/abs/2511.04646)|null|
|**2025-11-05**|**Motion Planning Under Temporal Logic Specifications In Semantically Unknown Environments**|Derya Aksaray Team|[2511.03652](http://arxiv.org/abs/2511.03652)|null|
|**2025-11-05**|**Flying Robotics Art: ROS-based Drone Draws the Record-Breaking Mural**|Georgii E. Bondar Team|[2511.03651](http://arxiv.org/abs/2511.03651)|null|
|**2025-11-05**|**Generalized k-Cell Decomposition for Visibility Planning in Polygons**|Roni Sherman Team|[2511.03642](http://arxiv.org/abs/2511.03642)|null|
|**2025-11-05**|**Manifold-constrained Hamilton-Jacobi Reachability Learning for Decentralized Multi-Agent Motion Planning**|Ahmed H. Qureshi Team|[2511.03591](http://arxiv.org/abs/2511.03591)|null|
|**2025-11-05**|**Let the Bees Find the Weak Spots: A Path Planning Perspective on Multi-Turn Jailbreak Attacks against LLMs**|Aina Sui Team|[2511.03271](http://arxiv.org/abs/2511.03271)|null|
|**2025-11-04**|**Proportionate Cybersecurity for Micro-SMEs: A Governance Design Model under NIS2**|Roberto Garrone Team|[2511.02898](http://arxiv.org/abs/2511.02898)|null|
|**2025-11-04**|**ISAC Empowered Air-Sea Collaborative System: A UAV-USV Joint Inspection Framework**|Wei Wang Team|[2511.02592](http://arxiv.org/abs/2511.02592)|null|
|**2025-11-04**|**ReAcTree: Hierarchical LLM Agent Trees with Control Flow for Long-Horizon Task Planning**|Youngwoo Yoon Team|[2511.02424](http://arxiv.org/abs/2511.02424)|null|
|**2025-11-04**|**Self-Supervised Moving Object Segmentation of Sparse and Noisy Radar Point Clouds**|Cyrill Stachniss Team|[2511.02395](http://arxiv.org/abs/2511.02395)|null|
|**2025-11-04**|**Whole-body motion planning and safety-critical control for aerial manipulation**|Jeonghyun Byun Team|[2511.02342](http://arxiv.org/abs/2511.02342)|null|
|**2025-11-03**|**TPS-Bench: Evaluating AI Agents' Tool Planning \& Scheduling Abilities in Compounding Tasks**|Zhijie Deng Team|[2511.01527](http://arxiv.org/abs/2511.01527)|null|
|**2025-11-03**|**Floor Plan-Guided Visual Navigation Incorporating Depth and Directional Cues**|Zhu Yang Team|[2511.01493](http://arxiv.org/abs/2511.01493)|null|
|**2025-11-03**|**MO-SeGMan: Rearrangement Planning Framework for Multi Objective Sequential and Guided Manipulation in Constrained Environments**|Ozgur S. Oguz Team|[2511.01476](http://arxiv.org/abs/2511.01476)|**[link](https://sites.google.com/view/mo-segman/)**|
|**2025-11-03**|**Edge-Enabled UAV Swarm Deployment for Rapid Post-Disaster Search and Rescue**|Rui Campos Team|[2511.01459](http://arxiv.org/abs/2511.01459)|null|
|**2025-11-03**|**CaRLi-V: Camera-RADAR-LiDAR Point-Wise 3D Velocity Estimation**|Cesar Cadena Team|[2511.01383](http://arxiv.org/abs/2511.01383)|null|
|**2025-11-03**|**Kinematify: Open-Vocabulary Synthesis of High-DoF Articulated Objects**|Lan Xu Team|[2511.01294](http://arxiv.org/abs/2511.01294)|**[link](https://sites.google.com/deemos.com/kinematify)**|
|**2025-11-03**|**Don't Just Search, Understand: Semantic Path Planning Agent for Spherical Tensegrity Robots in Unknown Environments**|Hanzhi Ma Team|[2511.01236](http://arxiv.org/abs/2511.01236)|null|
|**2025-11-02**|**SLAP: Shortcut Learning for Abstract Planning**|Tom Silver Team|[2511.01107](http://arxiv.org/abs/2511.01107)|null|
|**2025-11-02**|**Real-Time Learning of Predictive Dynamic Obstacle Models for Robotic Motion Planning**|Joel W. Burdick Team|[2511.00814](http://arxiv.org/abs/2511.00814)|null|
|**2025-10-30**|**Alpamayo-R1: Bridging Reasoning and Action Prediction for Generalizable Autonomous Driving in the Long Tail**|Marco Pavone Team|[2511.00088](http://arxiv.org/abs/2511.00088)|null|
|**2025-10-27**|**AeroResQ: Edge-Accelerated UAV Framework for Scalable, Resilient and Collaborative Escape Route Planning in Wildfire Scenarios**|Ewa Deelman Team|[2511.00038](http://arxiv.org/abs/2511.00038)|null|
|**2025-10-30**|**Hybrid DQN-TD3 Reinforcement Learning for Autonomous Navigation in Dynamic Environments**|Zimeng Bai Team|[2510.26646](http://arxiv.org/abs/2510.26646)|**[link](https://github.com/MayaCHEN-github/HierarchicalRL-robot-navigation)**|
|**2025-10-30**|**Adaptive Trajectory Refinement for Optimization-based Local Planning in Narrow Passages**|Young J. Kim Team|[2510.26142](http://arxiv.org/abs/2510.26142)|null|
|**2025-10-30**|**Kinodynamic Task and Motion Planning using VLM-guided and Interleaved Sampling**|Young J. Kim Team|[2510.26139](http://arxiv.org/abs/2510.26139)|null|
|**2025-10-29**|**Collision avoidance and path finding in a robotic mobile fulfillment system using multi-objective meta-heuristics**|Mary Kurz Team|[2510.25650](http://arxiv.org/abs/2510.25650)|null|
|**2025-10-29**|**Communication and Verification in LLM Agents towards Collaboration under Information Asymmetry**|Joyce Chai Team|[2510.25595](http://arxiv.org/abs/2510.25595)|null|
|**2025-10-29**|**Using VLM Reasoning to Constrain Task and Motion Planning**|Zachary Kingston Team|[2510.25548](http://arxiv.org/abs/2510.25548)|null|
|**2025-10-29**|**Tight Collision Avoidance for Stochastic Optimal Control: with Applications in Learning-based, Interactive Motion Planning**|Leo Laine Team|[2510.25324](http://arxiv.org/abs/2510.25324)|null|
|**2025-10-29**|**Time-Optimal Transport of Loosely Placed Liquid Filled Cups along Prescribed Paths**|Andreas Mueller Team|[2510.25255](http://arxiv.org/abs/2510.25255)|null|
|**2025-10-28**|**Defect Mitigation for Robot Arm-based Additive Manufacturing Utilizing Intelligent Control and IOT**|Sen Liu Team|[2510.24994](http://arxiv.org/abs/2510.24994)|null|
|**2025-10-28**|**Smooth path planning with safety margins using Piece-Wise Bezier curves**|Catalin Dosoftei Team|[2510.24972](http://arxiv.org/abs/2510.24972)|null|
|**2025-10-28**|**Generative View Stitching**|Vincent Sitzmann Team|[2510.24718](http://arxiv.org/abs/2510.24718)|**[link](https://andrewsonga.github.io/gvs)**|
|**2025-10-28**|**Flatness-based trajectory planning for 3D overhead cranes with friction compensation and collision avoidance**|Edgar Ramirez-Laboreo Team|[2510.24457](http://arxiv.org/abs/2510.24457)|null|
|**2025-10-28**|**UniPlanner: A Unified Motion Planning Framework for Autonomous Vehicle Decision-Making Systems via Multi-Dataset Integration**|Chen Xu Team|[2510.24166](http://arxiv.org/abs/2510.24166)|null|
|**2025-10-28**|**PFEA: An LLM-based High-Level Natural Language Planning and Feedback Embodied Agent for Human-Centered AI**|Philip Dames Team|[2510.24109](http://arxiv.org/abs/2510.24109)|null|
|**2025-10-27**|**Decentralized Multi-Agent Goal Assignment for Path Planning using Large Language Models**|Gregory Dudek Team|[2510.23824](http://arxiv.org/abs/2510.23824)|null|
|**2025-10-27**|**Deductive Chain-of-Thought Augmented Socially-aware Robot Navigation World Model**|Byung-Cheol Min Team|[2510.23509](http://arxiv.org/abs/2510.23509)|null|
|**2025-10-27**|**Large language model-based task planning for service robots: A review**|Changchun Hua Team|[2510.23357](http://arxiv.org/abs/2510.23357)|null|
|**2025-10-27**|**Payload trajectory tracking control for aerial transportation systems with cable length online optimization**|Xiao Liang Team|[2510.23296](http://arxiv.org/abs/2510.23296)|null|
|**2025-10-27**|**Workspace Registration and Collision Detection for Industrial Robotics Applications**|Andreas Mueller Team|[2510.23227](http://arxiv.org/abs/2510.23227)|null|
|**2025-10-27**|**Finding 3D Scene Analogies with Multimodal Foundation Models**|Young Min Kim Team|[2510.23184](http://arxiv.org/abs/2510.23184)|null|
|**2025-10-27**|**AirFed: A Federated Graph-Enhanced Multi-Agent Reinforcement Learning Framework for Multi-UAV Cooperative Mobile Edge Computing**|Rajkumar Buyya Team|[2510.23053](http://arxiv.org/abs/2510.23053)|null|
|**2025-10-27**|**Planning Oriented Integrated Sensing and Communication**|Chengzhong Xu Team|[2510.23021](http://arxiv.org/abs/2510.23021)|null|
|**2025-10-27**|**Motion Planning on One-Dimensional Peano Continua**|Petar Pavesic Team|[2510.22901](http://arxiv.org/abs/2510.22901)|null|
|**2025-10-26**|**Learning Neural Observer-Predictor Models for Limb-level Sampling-based Locomotion Planning**|Guoquan Huang Team|[2510.22789](http://arxiv.org/abs/2510.22789)|null|
|**2025-10-26**|**PIP-LLM: Integrating PDDL-Integer Programming with LLMs for Coordinating Multi-Robot Teams Using Natural Language**|Gaurav S. Sukhatme Team|[2510.22784](http://arxiv.org/abs/2510.22784)|null|
|**2025-10-26**|**Environment-aware Motion Matching**|Nuria Pelechano Team|[2510.22632](http://arxiv.org/abs/2510.22632)|**[link](https://upc-virvig.github.io/Environment-aware-Motion-Matching/)**|
|**2025-10-26**|**Robust Multi-Agent Safety via Tube-Based Tightened Exponential Barrier Functions**|Ali Pakniyat Team|[2510.22514](http://arxiv.org/abs/2510.22514)|null|
|**2025-10-25**|**LT-Exosense: A Vision-centric Multi-session Mapping System for Lifelong Safe Navigation of Exoskeletons**|Maurice Fallon Team|[2510.22164](http://arxiv.org/abs/2510.22164)|null|
|**2025-10-24**|**Motion Planning with Precedence Specifications via Augmented Graphs of Convex Sets**|Tyler Summers Team|[2510.22015](http://arxiv.org/abs/2510.22015)|null|
|**2025-10-23**|**A Physics-Informed Neural Network Approach for UAV Path Planning in Dynamic Environments**|Shuning Zhang Team|[2510.21874](http://arxiv.org/abs/2510.21874)|null|
|**2025-10-17**|**Real-Time QP Solvers: A Concise Review and Practical Guide Towards Legged Robots**|Van Nam Dinh Team|[2510.21773](http://arxiv.org/abs/2510.21773)|null|
|**2025-10-10**|**Real-time Mixed-Integer Quadratic Programming for Driving Behavior-Inspired Speed Bump Optimal Trajectory Planning**|Hung Cuong Ta Team|[2510.21751](http://arxiv.org/abs/2510.21751)|null|
|**2025-10-24**|**A Knowledge-Graph Translation Layer for Mission-Aware Multi-Agent Path Planning in Spatiotemporal Dynamics**|Mahdi Abdelguerfi Team|[2510.21695](http://arxiv.org/abs/2510.21695)|null|
|**2025-10-24**|**Near-Optimal Min-Sum Motion Planning in a Planar Polygonal Environment**|Alex Steiger Team|[2510.21639](http://arxiv.org/abs/2510.21639)|null|
|**2025-10-24**|**Cost Minimization for Space-Air-Ground Integrated Multi-Access Edge Computing Systems**|Zhu Han Team|[2510.21541](http://arxiv.org/abs/2510.21541)|null|
|**2025-10-24**|**Load-bearing Assessment for Safe Locomotion of Quadruped Robots on Collapsing Terrain**|Victor Barasuol Team|[2510.21369](http://arxiv.org/abs/2510.21369)|null|
|**2025-10-24**|**Towards Reliable Code-as-Policies: A Neuro-Symbolic Framework for Embodied Task Planning**|Honguk Woo Team|[2510.21302](http://arxiv.org/abs/2510.21302)|null|
|**2025-10-23**|**EmbodiedBrain: Expanding Performance Boundaries of Task Planning for Embodied Intelligence**|Yurui Zhu Team|[2510.20578](http://arxiv.org/abs/2510.20578)|null|
|**2025-10-23**|**Robot Path and Trajectory Planning Considering a Spatially Fixed TCP**|Ronald Naderer Team|[2510.20473](http://arxiv.org/abs/2510.20473)|null|
|**2025-10-23**|**Dino-Diffusion Modular Designs Bridge the Cross-Domain Gap in Autonomous Parking**|Liu Ren Team|[2510.20335](http://arxiv.org/abs/2510.20335)|**[link](https://github.com/ChampagneAndfragrance/Dino_Diffusion_Parking_Official)**|
|**2025-10-23**|**PathFormer: A Transformer with 3D Grid Constraints for Digital Twin Robot-Arm Trajectory Generation**|Yugyung Lee Team|[2510.20161](http://arxiv.org/abs/2510.20161)|null|
|**2025-10-22**|**Benchmarking World-Model Learning**|Zenna Tavares Team|[2510.19788](http://arxiv.org/abs/2510.19788)|null|
|**2025-10-22**|**From Forecasting to Planning: Policy World Model for Collaborative State-Action Prediction**|Huchuan Lu Team|[2510.19654](http://arxiv.org/abs/2510.19654)|null|
|**2025-10-21**|**A Cross-Environment and Cross-Embodiment Path Planning Framework via a Conditional Diffusion Model**|Homayoun Najjaran Team|[2510.19128](http://arxiv.org/abs/2510.19128)|null|
|**2025-10-21**|**Motion Planning and Control of an Overactuated 4-Wheel Drive with Constrained Independent Steering**|Aliasghar Arab Team|[2510.19054](http://arxiv.org/abs/2510.19054)|**[link](https://youtu.be/8l9s2Wb_vec)**|
|**2025-10-21**|**$\nabla$ -SDF: Learning Euclidean Signed Distance Functions Online with Gradient-Augmented Octree Interpolation and Neural Residual**|Nikolay Atanasov Team|[2510.18999](http://arxiv.org/abs/2510.18999)|null|
|**2025-10-21**|**SHRUMS: Sensor Hallucination for Real-time Underwater Motion Planning with a Compact 3D Sonar**|Marios Xanthidis Team|[2510.18996](http://arxiv.org/abs/2510.18996)|null|
|**2025-10-21**|**MPC-based motion planning for non-holonomic systems in non-convex domains**|Fabrizio Dabbene Team|[2510.18402](http://arxiv.org/abs/2510.18402)|null|
|**2025-10-20**|**A Mimamsa Inspired Framework For Instruction Sequencing In AI Agents**|Bama Srinivasan Team|[2510.17691](http://arxiv.org/abs/2510.17691)|null|
|**2025-10-20**|**Intent-Driven LLM Ensemble Planning for Flexible Multi-Robot Disassembly: Demonstration on EV Batteries**|Rustam Stolkin Team|[2510.17576](http://arxiv.org/abs/2510.17576)|null|
|**2025-10-20**|**High-Level Multi-Robot Trajectory Planning And Spurious Behavior Detection**|Eduardo Montijano Team|[2510.17261](http://arxiv.org/abs/2510.17261)|null|
|**2025-10-19**|**DiRAC - Distributed Robot Awareness and Consensus**|Rameshwar DL Team|[2510.16850](http://arxiv.org/abs/2510.16850)|null|
|**2025-10-19**|**T3 Planner: A Self-Correcting LLM Framework for Robotic Motion Planning with Temporal Logic**|Guoxiang Zhao Team|[2510.16767](http://arxiv.org/abs/2510.16767)|null|
|**2025-10-19**|**Vision-Centric 4D Occupancy Forecasting and Planning via Implicit Residual World Models**|Yong Liu Team|[2510.16729](http://arxiv.org/abs/2510.16729)|null|
|**2025-10-18**|**Asymptotically Stable Quaternion-valued Hopfield-structured Neural Network with Periodic Projection-based Supervised Learning Rules**|Wei Pang Team|[2510.16607](http://arxiv.org/abs/2510.16607)|null|
|**2025-10-18**|**Semi-Peaucellier Linkage and Differential Mechanism for Linear Pinching and Self-Adaptive Grasping**|Wenzeng Zhang Team|[2510.16524](http://arxiv.org/abs/2510.16524)|null|
|**2025-10-18**|**Advancing Off-Road Autonomous Driving: The Large-Scale ORAD-3D Dataset and Comprehensive Benchmarks**|Yu Hu Team|[2510.16500](http://arxiv.org/abs/2510.16500)|null|
|**2025-10-18**|**Manual2Skill++: Connector-Aware General Robotic Assembly from Instruction Manuals via Vision-Language Models**|Lin Shao Team|[2510.16344](http://arxiv.org/abs/2510.16344)|null|
|**2025-10-18**|**SPOT: Sensing-augmented Trajectory Planning via Obstacle Threat Modeling**|Wei Dong Team|[2510.16308](http://arxiv.org/abs/2510.16308)|null|
|**2025-10-15**|**InfraGPT Smart Infrastructure: An End-to-End VLM-Based Framework for Detecting and Managing Urban Defects**|Abdullah Yahya Abdullah Omaisan Team|[2510.16017](http://arxiv.org/abs/2510.16017)|null|
|**2025-10-14**|**MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents**|Wenjun Xu Team|[2510.15994](http://arxiv.org/abs/2510.15994)|null|
|**2025-10-17**|**Hypergame-based Cognition Modeling and Intention Interpretation for Human-Driven Vehicles in Connected Mixed Traffic**|Hong Chen Team|[2510.15573](http://arxiv.org/abs/2510.15573)|null|
|**2025-10-17**|**Adaptive Cost-Map-based Path Planning in Partially Unknown Environments with Movable Obstacles**|Kazunori Ohno Team|[2510.15336](http://arxiv.org/abs/2510.15336)|null|
|**2025-10-16**|**Finding geodesics with the Deep Ritz method**|Conor Rowan Team|[2510.15177](http://arxiv.org/abs/2510.15177)|null|
|**2025-10-16**|**STITCHER: Constrained Trajectory Planning in Complex Environments with Real-Time Motion Primitive Search**|Brett T. Lopez Team|[2510.14893](http://arxiv.org/abs/2510.14893)|null|
|**2025-10-16**|**RoboGPT-R1: Enhancing Robot Planning with Reinforcement Learning**|Haoran Li Team|[2510.14828](http://arxiv.org/abs/2510.14828)|null|
|**2025-10-16**|**Active Jammer Localization via Acquisition-Aware Path Planning**|Tales Imbiriba Team|[2510.14790](http://arxiv.org/abs/2510.14790)|null|
|**2025-10-16**|**Accelerated Multi-Modal Motion Planning Using Context-Conditioned Diffusion Models**|Wilm Decré Team|[2510.14615](http://arxiv.org/abs/2510.14615)|null|
|**2025-10-16**|**Learning Human-Humanoid Coordination for Collaborative Object Carrying**|Siyuan Huang Team|[2510.14293](http://arxiv.org/abs/2510.14293)|null|
|**2025-10-15**|**Optimistic Reinforcement Learning-Based Skill Insertions for Task and Motion Planning**|Bram Vanderborght Team|[2510.14065](http://arxiv.org/abs/2510.14065)|null|
|**2025-10-15**|**Hierarchical Discrete Lattice Assembly: An Approach for the Digital Fabrication of Scalable Macroscale Structures**|Neil Gershenfeld Team|[2510.13686](http://arxiv.org/abs/2510.13686)|null|
|**2025-10-15**|**Personalized Learning Path Planning with Goal-Driven Learner State Modeling**|Bin Xu Team|[2510.13215](http://arxiv.org/abs/2510.13215)|null|
|**2025-10-14**|**SENTINEL: A Multi-Level Formal Framework for Safety Evaluation of LLM-based Embodied Agents**|Qi Zhu Team|[2510.12985](http://arxiv.org/abs/2510.12985)|null|
|**2025-10-14**|**Enhancing Sampling-based Planning with a Library of Paths**|Robert Pěnička Team|[2510.12962](http://arxiv.org/abs/2510.12962)|null|
|**2025-10-14**|**HYPE: Hybrid Planning with Ego Proposal-Conditioned Predictions**|Wilhelm Stork Team|[2510.12733](http://arxiv.org/abs/2510.12733)|null|
|**2025-10-14**|**Maximal Adaptation, Minimal Guidance: Permissive Reactive Robot Task Planning with Humans in the Loop**|Anne-Kathrin Schmuck Team|[2510.12662](http://arxiv.org/abs/2510.12662)|null|
|**2025-10-14**|**A Task-Efficient Reinforcement Learning Task-Motion Planner for Safe Human-Robot Cooperation**|Bram Vanderborght Team|[2510.12477](http://arxiv.org/abs/2510.12477)|null|
|**2025-10-14**|**PolygMap: A Perceptive Locomotion Framework for Humanoid Robot Stair Climbing**|Yucong Wu Team|[2510.12346](http://arxiv.org/abs/2510.12346)|null|
|**2025-10-14**|**Hybrid Terrain-Aware Path Planning: Integrating VD-RRT* Exploration and VD-D* Lite Repair**|Ahmet Soylemezoglu Team|[2510.12169](http://arxiv.org/abs/2510.12169)|null|
|**2025-10-13**|**Analysis of the Geometric Heat Flow Equation: Computing Geodesics in Real-Time with Convergence Guarantees**|Brett T. Lopez Team|[2510.11692](http://arxiv.org/abs/2510.11692)|null|
|**2025-10-13**|**ManiAgent: An Agentic Framework for General Robotic Manipulation**|Xudong Liu Team|[2510.11660](http://arxiv.org/abs/2510.11660)|null|
|**2025-10-13**|**Enhancing Long Chain-of-Thought Reasoning through Multi-Path Plan Aggregation**|Faramarz Fekri Team|[2510.11620](http://arxiv.org/abs/2510.11620)|null|
|**2025-10-13**|**NaviGait: Navigating Dynamically Feasible Gait Libraries using Deep Reinforcement Learning**|Maegan Tucker Team|[2510.11542](http://arxiv.org/abs/2510.11542)|null|
|**2025-10-13**|**Rotor-Failure-Aware Quadrotors Flight in Unknown Environments**|Fei Gao Team|[2510.11306](http://arxiv.org/abs/2510.11306)|null|
|**2025-10-13**|**Hadamard-Lévy theorems for maps taking values in a finite dimensional space**|Emmanuel Trélat Team|[2510.11206](http://arxiv.org/abs/2510.11206)|null|
|**2025-10-13**|**Future-Aware End-to-End Driving: Bidirectional Modeling of Trajectory Planning and Scene Evolution**|Li Zhang Team|[2510.11092](http://arxiv.org/abs/2510.11092)|null|
|**2025-10-13**|**Unveiling Uncertainty-Aware Autonomous Cooperative Learning Based Planning Strategy**|Hong Zhang Team|[2510.11041](http://arxiv.org/abs/2510.11041)|null|
|**2025-10-13**|**Vlaser: Vision-Language-Action Model with Synergistic Embodied Reasoning**|Zhi Hou Team|[2510.11027](http://arxiv.org/abs/2510.11027)|null|
|**2025-10-13**|**Into the Unknown: Towards using Generative Models for Sampling Priors of Environment Uncertainty for Planning in Configuration Spaces**|Rahul Shome Team|[2510.11014](http://arxiv.org/abs/2510.11014)|null|
|**2025-10-12**|**Deployment and Development of a Cognitive Teleoreactive Framework for Deep Sea Autonomy**|Christopher Thierauf Team|[2510.10716](http://arxiv.org/abs/2510.10716)|null|
|**2025-10-12**|**Reinforcement Learning-based Dynamic Adaptation for Sampling-Based Motion Planning in Agile Autonomous Driving**|Johannes Betz Team|[2510.10567](http://arxiv.org/abs/2510.10567)|null|
|**2025-10-12**|**Align2Act: Instruction-Tuned Models for Human-Aligned Autonomous Driving**|Sunidhi Tandel Team|[2510.10503](http://arxiv.org/abs/2510.10503)|null|
|**2025-10-12**|**Hierarchical Planning for Long-Horizon Multi-Target Tracking Under Target Motion Uncertainty**|Sebastian Scherer Team|[2510.10421](http://arxiv.org/abs/2510.10421)|null|
|**2025-10-12**|**RobotFleet: An Open-Source Framework for Centralized Multi-Robot Task Planning**|Jesse Thomason Team|[2510.10379](http://arxiv.org/abs/2510.10379)|null|
|**2025-10-10**|**Scalable Multi-Agent Path Finding using Collision-Aware Dynamic Alert Mask and a Hybrid Execution Strategy**|Vignesh Narayanan Team|[2510.09469](http://arxiv.org/abs/2510.09469)|null|
|**2025-10-10**|**Parametrized Topological Complexity for a Multi-Robot System with Variable Tasks**|Subhankar Sau Team|[2510.09323](http://arxiv.org/abs/2510.09323)|null|
|**2025-10-10**|**Obstacle Avoidance using Dynamic Movement Primitives and Reinforcement Learning**|Michael Suppa Team|[2510.09254](http://arxiv.org/abs/2510.09254)|null|
|**2025-10-10**|**Sensing, Detection and Localization for Low Altitude UAV: A RF-Based Framework via Multiple BSs Collaboration**|Pooi-Yuen Kam Team|[2510.09055](http://arxiv.org/abs/2510.09055)|null|
|**2025-10-09**|**Adaptive Motion Planning via Contact-Based Intent Inference for Human-Robot Collaboration**|Minghui Zheng Team|[2510.08811](http://arxiv.org/abs/2510.08811)|null|
|**2025-10-09**|**Assurance of Frontier AI Built for National Security**|Charlotte Stix Team|[2510.08792](http://arxiv.org/abs/2510.08792)|null|
|**2025-10-09**|**NovaFlow: Zero-Shot Manipulation via Actionable Flow from Generated Videos**|Jiahui Fu Team|[2510.08568](http://arxiv.org/abs/2510.08568)|null|
|**2025-10-09**|**Satellite Navigation and Control using Physics-Informed Artificial Potential Field and Sliding Mode Controller**|Manoranjan Sinha Team|[2510.08184](http://arxiv.org/abs/2510.08184)|null|
|**2025-10-09**|**Towards Reliable LLM-based Robot Planning via Combined Uncertainty Estimation**|Xuelong Li Team|[2510.08044](http://arxiv.org/abs/2510.08044)|null|
|**2025-10-09**|**Executable Analytic Concepts as the Missing Link Between VLM Insight and Precise Manipulation**|Jianhua Sun Team|[2510.07975](http://arxiv.org/abs/2510.07975)|null|
|**2025-10-08**|**Inspection Planning Primitives with Implicit Models**|Lashika Medagoda Team|[2510.07611](http://arxiv.org/abs/2510.07611)|null|
|**2025-10-08**|**Quantum Grid Path Planning Using Parallel QAOA Circuits Based on Minimum Energy Principle**|Jun Liu Team|[2510.07413](http://arxiv.org/abs/2510.07413)|null|
|**2025-10-08**|**Agent Bain vs. Agent McKinsey: A New Text-to-SQL Benchmark for the Business Domain**|Unso Eun Seo Jo Team|[2510.07309](http://arxiv.org/abs/2510.07309)|null|
|**2025-10-08**|**Falsification-Driven Reinforcement Learning for Maritime Motion Planning**|Matthias Althoff Team|[2510.06970](http://arxiv.org/abs/2510.06970)|null|
|**2025-10-08**|**Adaptive Semantic Communication for UAV/UGV Cooperative Path Planning**|Muhammad Ali Imran Team|[2510.06901](http://arxiv.org/abs/2510.06901)|null|
|**2025-10-07**|**Active Next-Best-View Optimization for Risk-Averse Path Planning**|Nader Motee Team|[2510.06481](http://arxiv.org/abs/2510.06481)|null|
|**2025-10-07**|**R3R: Decentralized Multi-Agent Collision Avoidance with Infinite-Horizon Safety**|Dimitra Panagou Team|[2510.06436](http://arxiv.org/abs/2510.06436)|null|
|**2025-10-07**|**Constrained Natural Language Action Planning for Resilient Embodied Systems**|Mathias Unberath Team|[2510.06357](http://arxiv.org/abs/2510.06357)|null|
|**2025-10-07**|**Precise and Efficient Collision Prediction under Uncertainty in Autonomous Driving**|Johannes Betz Team|[2510.05729](http://arxiv.org/abs/2510.05729)|null|
|**2025-10-07**|**Stable Robot Motions on Manifolds: Learning Lyapunov-Constrained Neural Manifold ODEs**|Fares J. Abu-Dakka Team|[2510.05707](http://arxiv.org/abs/2510.05707)|null|
|**2025-10-07**|**ARRC: Advanced Reasoning Robot Control - Knowledge-Driven Autonomous Manipulation Using Retrieval-Augmented Generation**|Robin Chhabra Team|[2510.05547](http://arxiv.org/abs/2510.05547)|null|
|**2025-10-07**|**Correlation-Aware Dual-View Pose and Velocity Estimation for Dynamic Robotic Manipulation**|Farrokh Janabi-Sharifi Team|[2510.05536](http://arxiv.org/abs/2510.05536)|null|
|**2025-10-06**|**Efficient Probabilistic Planning with Maximum-Coverage Distributionally Robust Backward Reachable Trees**|Jonathan P. How Team|[2510.04807](http://arxiv.org/abs/2510.04807)|null|
|**2025-10-06**|**Hands-Free Heritage: Automated 3D Scanning for Cultural Heritage Digitization**|Arianna Traviglia Team|[2510.04781](http://arxiv.org/abs/2510.04781)|null|

<p align=right>(<a href=#updated-on-20251217>back to top</a>)</p>

## RL/IL

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-12-12**|**AnchorDream: Repurposing Video Diffusion for Embodiment-Aware Robot Data Synthesis**|Vitor Guizilini Team|[2512.11797](http://arxiv.org/abs/2512.11797)|**[link](https://jay-ye.github.io/AnchorDream/)**|
|**2025-12-12**|**Agile Flight Emerges from Multi-Agent Competitive Racing**|Antonio Loquercio Team|[2512.11781](http://arxiv.org/abs/2512.11781)|null|
|**2025-12-12**|**SUMFORU: An LLM-Based Review Summarization Framework for Personalized Purchase Decision Support**|Xinrui Jiang Team|[2512.11755](http://arxiv.org/abs/2512.11755)|**[link](https://github.com/Harry20030331/SumForU)**|
|**2025-12-12**|**UniBYD: A Unified Framework for Learning Robotic Manipulation Across Embodiments Beyond Imitation of Human Demonstrations**|Jinqiao Wang Team|[2512.11609](http://arxiv.org/abs/2512.11609)|null|
|**2025-12-12**|**DentalGPT: Incentivizing Multimodal Complex Reasoning in Dentistry**|Benyou Wang Team|[2512.11558](http://arxiv.org/abs/2512.11558)|null|
|**2025-12-12**|**Rethinking Expert Trajectory Utilization in LLM Post-training**|Tao Lin Team|[2512.11470](http://arxiv.org/abs/2512.11470)|null|
|**2025-12-12**|**Three methods, one problem: Classical and AI approaches to no-three-in-line**|Sreedath Panat Team|[2512.11469](http://arxiv.org/abs/2512.11469)|null|
|**2025-12-11**|**Motif-2-12.7B-Reasoning: A Practitioner's Guide to RL Training Recipes**|Dongjoo Weon Team|[2512.11463](http://arxiv.org/abs/2512.11463)|null|
|**2025-12-12**|**Towards Trustworthy Multi-Turn LLM Agents via Behavioral Guidance**|Gonca Gürsun Team|[2512.11421](http://arxiv.org/abs/2512.11421)|null|
|**2025-12-12**|**Mitigating the Safety Alignment Tax with Null-Space Constrained Policy Optimization**|Jia Li Team|[2512.11391](http://arxiv.org/abs/2512.11391)|null|
|**2025-12-12**|**Symmetry-Aware Steering of Equivariant Diffusion Policies: Benefits and Limits**|Roberto Horowitz Team|[2512.11345](http://arxiv.org/abs/2512.11345)|null|
|**2025-12-12**|**DAPO: Design Structure-Aware Pass Ordering in High-Level Synthesis with Graph Contrastive and Reinforcement Learning**|Wei Zhang Team|[2512.11342](http://arxiv.org/abs/2512.11342)|null|
|**2025-12-12**|**RollMux: Phase-Level Multiplexing for Disaggregated RL Post-Training**|Wei Wang Team|[2512.11306](http://arxiv.org/abs/2512.11306)|null|
|**2025-12-12**|**When Actions Teach You to Think: Reasoning-Action Synergy via Reinforcement Learning in Conversational Agents**|Roberto Pieraccini Team|[2512.11277](http://arxiv.org/abs/2512.11277)|null|
|**2025-12-12**|**A-LAMP: Agentic LLM-Based Framework for Automated MDP Modeling and Policy Generation**|Hyun-Suk Lee Team|[2512.11270](http://arxiv.org/abs/2512.11270)|null|
|**2025-12-12**|**Multi-Objective Reinforcement Learning for Large-Scale Mixed Traffic Control**|Weizi Li Team|[2512.11247](http://arxiv.org/abs/2512.11247)|null|
|**2025-12-11**|**Bandwidth-constrained Variational Message Encoding for Cooperative Multi-agent Reinforcement Learning**|Junyu Xuan Team|[2512.11179](http://arxiv.org/abs/2512.11179)|null|
|**2025-12-11**|**Learning Category-level Last-meter Navigation from RGB Demonstrations of a Single-instance**|Karthik Desingh Team|[2512.11173](http://arxiv.org/abs/2512.11173)|null|
|**2025-12-11**|**CORL: Reinforcement Learning of MILP Policies Solved via Branch and Bound**|Sebastien Gros Team|[2512.11169](http://arxiv.org/abs/2512.11169)|null|
|**2025-12-11**|**Benchmarking RL-Enhanced Spatial Indices Against Traditional, Advanced, and Learned Counterparts**|Zhifeng Bao Team|[2512.11161](http://arxiv.org/abs/2512.11161)|null|
|**2025-12-11**|**In-Context Multi-Objective Optimization**|Samuel Kaski Team|[2512.11114](http://arxiv.org/abs/2512.11114)|null|
|**2025-12-10**|**KBQA-R1: Reinforcing Large Language Models for Knowledge Base Question Answering**|Liang Wang Team|[2512.10999](http://arxiv.org/abs/2512.10999)|null|
|**2025-12-05**|**Marti-5: A Mathematical Model of "Self in the World" as a First Step Toward Self-Awareness**|Sergey Shumsky Team|[2512.10985](http://arxiv.org/abs/2512.10985)|null|
|**2025-12-11**|**Are We Ready for RL in Text-to-3D Generation? A Progressive Investigation**|Bin Zhao Team|[2512.10949](http://arxiv.org/abs/2512.10949)|**[link](https://github.com/Ivan-Tang-3D/3DGen-R1)**|
|**2025-12-11**|**Curriculum-Based Reinforcement Learning for Autonomous UAV Navigation in Unknown Curved Tubular Conduit**|Julien Seinturier Team|[2512.10934](http://arxiv.org/abs/2512.10934)|null|
|**2025-12-11**|**Digital Twin Supervised Reinforcement Learning Framework for Autonomous Underwater Navigation**|Pierre Drap Team|[2512.10925](http://arxiv.org/abs/2512.10925)|null|
|**2025-12-11**|**Reinforcement Learning in Financial Decision Making: A Systematic Review of Performance, Challenges, and Implementation Strategies**|M. Kabir Hassan Team|[2512.10913](http://arxiv.org/abs/2512.10913)|null|
|**2025-12-11**|**Iterative Compositional Data Generation for Robot Control**|Eric Eaton Team|[2512.10891](http://arxiv.org/abs/2512.10891)|null|
|**2025-12-11**|**Learning Controllable and Diverse Player Behaviors in Multi-Agent Environments**|Atay Özgövde Team|[2512.10835](http://arxiv.org/abs/2512.10835)|null|
|**2025-12-11**|**OPV: Outcome-based Process Verifier for Efficient Long Chain-of-Thought Verification**|Kai Chen Team|[2512.10756](http://arxiv.org/abs/2512.10756)|null|
|**2025-12-11**|**Learning to Split: A Reinforcement-Learning-Guided Splitting Heuristic for Neural Network Verification**|Guy Katz Team|[2512.10747](http://arxiv.org/abs/2512.10747)|null|
|**2025-12-11**|**Long-horizon Reasoning Agent for Olympiad-Level Mathematical Problem Solving**|Kai Chen Team|[2512.10739](http://arxiv.org/abs/2512.10739)|null|
|**2025-12-11**|**How to Brake? Ethical Emergency Braking with Deep Reinforcement Learning**|Johan Thunberg Team|[2512.10698](http://arxiv.org/abs/2512.10698)|null|
|**2025-12-11**|**Enhancing Radiology Report Generation and Visual Grounding using Reinforcement Learning**|Michael Krauthammer Team|[2512.10691](http://arxiv.org/abs/2512.10691)|null|
|**2025-12-11**|**AgriGPT-Omni: A Unified Speech-Vision-Text Framework for Multilingual Agricultural Intelligence**|Shijian Li Team|[2512.10624](http://arxiv.org/abs/2512.10624)|null|
|**2025-12-11**|**Multi-Objective Reward and Preference Optimization: Theory and Algorithms**|Akhil Agnihotri Team|[2512.10601](http://arxiv.org/abs/2512.10601)|null|
|**2025-12-11**|**Grounding Everything in Tokens for Multimodal Large Language Models**|Chao Ma Team|[2512.10554](http://arxiv.org/abs/2512.10554)|null|
|**2025-12-11**|**Achieving Olympia-Level Geometry Large Language Model Agent via Complexity Boosting Reinforcement Learning**|Kai Chen Team|[2512.10534](http://arxiv.org/abs/2512.10534)|null|
|**2025-12-11**|**Adaptive Replay Buffer for Offline-to-Online Reinforcement Learning**|Jinkyoo Park Team|[2512.10510](http://arxiv.org/abs/2512.10510)|null|
|**2025-12-11**|**UACER: An Uncertainty-Aware Critic Ensemble Framework for Robust Adversarial Reinforcement Learning**|Xueqian Wang Team|[2512.10492](http://arxiv.org/abs/2512.10492)|null|
|**2025-12-11**|**Shot and Architecture Adaptive Subspace Variational Quantum Eigensolver for Microwave Simulation**|Zaichen Zhang Team|[2512.10458](http://arxiv.org/abs/2512.10458)|null|
|**2025-12-11**|**HypeR Adaptivity: Joint $hr$ -Adaptive Meshing via Hypergraph Multi-Agent Deep Reinforcement Learning**|Stefania Fresca Team|[2512.10439](http://arxiv.org/abs/2512.10439)|null|
|**2025-12-11**|**Boosting RL-Based Visual Reasoning with Selective Adversarial Entropy Intervention**|Xiaomeng Li Team|[2512.10414](http://arxiv.org/abs/2512.10414)|null|
|**2025-12-11**|**A Privacy-Preserving Cloud Architecture for Distributed Machine Learning at Scale**|Kabilan Kannan Team|[2512.10341](http://arxiv.org/abs/2512.10341)|null|
|**2025-12-11**|**Hybrid Learning and Optimization-Based Dynamic Scheduling for DL Workloads on Heterogeneous GPU Clusters**|Ali R. Butt Team|[2512.10271](http://arxiv.org/abs/2512.10271)|null|
|**2025-12-11**|**Multi-dimensional Preference Alignment by Conditioning Reward Itself**|Nojun Kwak Team|[2512.10237](http://arxiv.org/abs/2512.10237)|null|
|**2025-12-11**|**Task-Oriented Grasping Using Reinforcement Learning with a Contextual Reward Machine**|Hongsheng He Team|[2512.10235](http://arxiv.org/abs/2512.10235)|null|
|**2025-12-11**|**Latent Chain-of-Thought World Modeling for End-to-End Driving**|Boris Ivanovic Team|[2512.10226](http://arxiv.org/abs/2512.10226)|null|
|**2025-12-11**|**An exploration for higher efficiency in multi objective optimisation with reinforcement learning**|Mehmet Emin Aydin Team|[2512.10208](http://arxiv.org/abs/2512.10208)|null|
|**2025-12-10**|**Explicit Control Barrier Function-based Safety Filters and their Resource-Aware Computation**|Aaron D. Ames Team|[2512.10118](http://arxiv.org/abs/2512.10118)|null|
|**2025-12-10**|**Push Smarter, Not Harder: Hierarchical RL-Diffusion Policy for Efficient Nonprehensile Manipulation**|Stephen L. Smith Team|[2512.10099](http://arxiv.org/abs/2512.10099)|null|
|**2025-12-10**|**SEMDICE: Off-policy State Entropy Maximization via Stationary Distribution Correction Estimation**|Pieter Abbeel Team|[2512.10042](http://arxiv.org/abs/2512.10042)|null|
|**2025-12-10**|**Diffusion Is Your Friend in Show, Suggest and Tell**|Alessandro Capotondi Team|[2512.10038](http://arxiv.org/abs/2512.10038)|null|
|**2025-12-10**|**Latent Action World Models for Control with Unlabeled Trajectories**|Philip Becker-Ehmck Team|[2512.10016](http://arxiv.org/abs/2512.10016)|null|
|**2025-12-10**|**TDC-Cache: A Trustworthy Decentralized Cooperative Caching Framework for Web3.0**|Wei Zhang Team|[2512.09961](http://arxiv.org/abs/2512.09961)|null|
|**2025-12-10**|**STACHE: Local Black-Box Explanations for Reinforcement Learning Policies**|Orna Grumberg Team|[2512.09909](http://arxiv.org/abs/2512.09909)|null|
|**2025-12-10**|**FlipLLM: Efficient Bit-Flip Attacks on Multimodal LLMs using Reinforcement Learning**|Khaza Anuarul Hoque Team|[2512.09872](http://arxiv.org/abs/2512.09872)|null|
|**2025-12-10**|**Simultaneous Tactile-Visual Perception for Learning Multimodal Robot Manipulation**|Yixin Zhu Team|[2512.09851](http://arxiv.org/abs/2512.09851)|null|
|**2025-12-10**|**ChronusOmni: Improving Time Awareness of Omni Large Language Models**|Liyun Ru Team|[2512.09841](http://arxiv.org/abs/2512.09841)|**[link](https://github.com/YJCX330/Chronus/)**|
|**2025-12-10**|**RIFT: A Scalable Methodology for LLM Accelerator Fault Assessment using Reinforcement Learning**|Khaza Anuarul Hoque Team|[2512.09829](http://arxiv.org/abs/2512.09829)|null|
|**2025-12-10**|**Prefrontal scaling of reward prediction error readout gates reinforcement-derived adaptive behavior in primates**|Zheng Wang Team|[2512.09761](http://arxiv.org/abs/2512.09761)|null|
|**2025-12-10**|**MOA: Multi-Objective Alignment for Role-Playing Agents**|Yongbin Li Team|[2512.09756](http://arxiv.org/abs/2512.09756)|null|
|**2025-12-10**|**Flexible Reconfigurable Intelligent Surface-Aided Covert Communications in UAV Networks**|Wei Huang Team|[2512.09714](http://arxiv.org/abs/2512.09714)|null|
|**2025-12-10**|**Training One Model to Master Cross-Level Agentic Actions via Reinforcement Learning**|Yitao Liang Team|[2512.09706](http://arxiv.org/abs/2512.09706)|null|
|**2025-12-10**|**Dynamic one-time delivery of critical data by small and sparse UAV swarms: a model problem for MARL scaling studies**|Adam Andersson Team|[2512.09682](http://arxiv.org/abs/2512.09682)|null|
|**2025-12-10**|**d-TreeRPO: Towards More Reliable Policy Optimization for Diffusion Language Models**|Lijie Wen Team|[2512.09675](http://arxiv.org/abs/2512.09675)|null|
|**2025-12-10**|**SynthPix: A lightspeed PIV images generator**|Raffaello D'Andrea Team|[2512.09664](http://arxiv.org/abs/2512.09664)|**[link](https://github.com/antonioterpin/synthpix)**|
|**2025-12-10**|**Mastering Diverse, Unknown, and Cluttered Tracks for Robust Vision-Based Drone Racing**|Danping Zou Team|[2512.09571](http://arxiv.org/abs/2512.09571)|null|
|**2025-12-10**|**Toward Closed-loop Molecular Discovery via Language Model, Property Alignment and Strategic Search**|Zexuan Zhu Team|[2512.09566](http://arxiv.org/abs/2512.09566)|null|
|**2025-12-10**|**REASAN: Learning Reactive Safe Navigation for Legged Robots**|Kailai Li Team|[2512.09537](http://arxiv.org/abs/2512.09537)|null|
|**2025-12-10**|**RouteRAG: Efficient Retrieval-Augmented Generation from Text and Graph via Reinforcement Learning**|Xueqi Cheng Team|[2512.09487](http://arxiv.org/abs/2512.09487)|null|
|**2025-12-10**|**Generalizable Collaborative Search-and-Capture in Cluttered Environments via Path-Guided MAPPO and Directional Frontier Allocation**|Yihuan Liao Team|[2512.09410](http://arxiv.org/abs/2512.09410)|null|
|**2025-12-10**|**H2R-Grounder: A Paired-Data-Free Paradigm for Translating Human Interaction Videos into Physically Grounded Robot Videos**|Mike Zheng Shou Team|[2512.09406](http://arxiv.org/abs/2512.09406)|null|
|**2025-12-10**|**CFLight: Enhancing Safety with Traffic Signal Control through Counterfactual Learning**|Qiang Wu Team|[2512.09368](http://arxiv.org/abs/2512.09368)|null|
|**2025-12-10**|**COVLM-RL: Critical Object-Oriented Reasoning for Autonomous Driving Using VLM-Guided Reinforcement Learning**|Chen Lv Team|[2512.09349](http://arxiv.org/abs/2512.09349)|null|
|**2025-12-10**|**Tyche: A Hybrid Computation Framework of Illumination Pattern for Satellite Beam Hopping**|Yue Gao Team|[2512.09312](http://arxiv.org/abs/2512.09312)|null|
|**2025-12-10**|**One-Shot Real-World Demonstration Synthesis for Scalable Bimanual Manipulation**|Kui Jia Team|[2512.09297](http://arxiv.org/abs/2512.09297)|null|
|**2025-12-10**|**Electric Arc Furnaces Scheduling under Electricity Price Volatility with Reinforcement Learning**|Bolun Xu Team|[2512.09293](http://arxiv.org/abs/2512.09293)|null|
|**2025-12-10**|**Exploratory Mean-Variance with Jumps: An Equilibrium Approach**|David Saunders Team|[2512.09224](http://arxiv.org/abs/2512.09224)|null|
|**2025-12-09**|**Learning Unmasking Policies for Diffusion Language Models**|Marco Cuturi Team|[2512.09106](http://arxiv.org/abs/2512.09106)|null|
|**2025-12-09**|**Masked Generative Policy for Robotic Control**|Paul Henderson Team|[2512.09101](http://arxiv.org/abs/2512.09101)|null|
|**2025-12-05**|**Training Multi-Image Vision Agents via End2End Reinforcement Learning**|Guojun Yin Team|[2512.08980](http://arxiv.org/abs/2512.08980)|null|
|**2025-12-09**|**No Labels, No Problem: Training Visual Reasoners with Multimodal Verifiers**|Georgia Gkioxari Team|[2512.08889](http://arxiv.org/abs/2512.08889)|**[link](https://glab-caltech.github.io/valor/)**|
|**2025-12-09**|**IPPO Learns the Game, Not the Team: A Study on Generalization in Heterogeneous Agent Teams**|Jack Kolb Team|[2512.08877](http://arxiv.org/abs/2512.08877)|null|
|**2025-12-09**|**Reinforcement Learning From State and Temporal Differences**|Jonathan Baxter Team|[2512.08855](http://arxiv.org/abs/2512.08855)|null|
|**2025-12-09**|**Optimal navigation in two-dimensional regular and turbulent flows**|Vladimir Parfenyev Team|[2512.08766](http://arxiv.org/abs/2512.08766)|null|
|**2025-12-09**|**Learning and Editing Universal Graph Prompt Tuning via Reinforcement Learning**|Edith C. H. Ngai Team|[2512.08763](http://arxiv.org/abs/2512.08763)|null|
|**2025-12-09**|**Direct transfer of optimized controllers to similar systems using dimensionless MPC**|Sébastien Gros Team|[2512.08667](http://arxiv.org/abs/2512.08667)|null|
|**2025-12-09**|**Sim2Swim: Zero-Shot Velocity Control for Agile AUV Maneuvering in 3 Minutes**|Sveinung Johan Ohrem Team|[2512.08656](http://arxiv.org/abs/2512.08656)|null|
|**2025-12-09**|**Heuristics for Combinatorial Optimization via Value-based Reinforcement Learning: A Unified Framework and Analysis**|Nimrod Megiddo Team|[2512.08601](http://arxiv.org/abs/2512.08601)|null|
|**2025-12-09**|**Mind to Hand: Purposeful Robotic Control via Embodied Reasoning**|Jianan Wang Team|[2512.08580](http://arxiv.org/abs/2512.08580)|null|
|**2025-12-09**|**Thinking with Images via Self-Calling Agent**|Qixiang Ye Team|[2512.08511](http://arxiv.org/abs/2512.08511)|**[link](https://github.com/YWenxi/think-with-images-through-self-calling)**|
|**2025-12-09**|**Optimal Perturbation Budget Allocation for Data Poisoning in Offline Reinforcement Learning**|Jie Li Team|[2512.08485](http://arxiv.org/abs/2512.08485)|null|
|**2025-12-09**|**Using reinforcement learning to probe the role of feedback in skill acquisition**|Raffaello D'Andrea Team|[2512.08463](http://arxiv.org/abs/2512.08463)|**[link](https://antonioterpin.com/fluids-control)**|
|**2025-12-09**|**From Accuracy to Impact: The Impact-Driven AI Framework (IDAIF) for Aligning Engineering Architecture with Theory of Change**|Yong-Woon Kim Team|[2512.08449](http://arxiv.org/abs/2512.08449)|null|
|**2025-12-09**|**Learning Robot Manipulation from Audio World Models**|Michael Gienger Team|[2512.08405](http://arxiv.org/abs/2512.08405)|null|
|**2025-12-09**|**Turning Threat into Opportunity: DRL-Powered Anti-Jamming via Energy Harvesting in UAV-Disrupted Channels**|Thai-Duong Nguyen Team|[2512.08351](http://arxiv.org/abs/2512.08351)|null|
|**2025-12-09**|**Multi-Agent Deep Reinforcement Learning for Collaborative UAV Relay Networks under Jamming Atatcks**|Symeon Chatzinotas Team|[2512.08341](http://arxiv.org/abs/2512.08341)|null|
|**2025-12-09**|**Collaborative Intelligence for UAV-Satellite Network Slicing: Towards a Joint QoS-Energy-Fairness MADRL Optimization**|Symeon Chatzinotas Team|[2512.08322](http://arxiv.org/abs/2512.08322)|null|
|**2025-12-09**|**rSIM: Incentivizing Reasoning Capabilities of LLMs via Reinforced Strategy Injection**|Di Niu Team|[2512.08300](http://arxiv.org/abs/2512.08300)|null|
|**2025-12-09**|**Empowerment Gain and Causal Model Construction: Children and adults are sensitive to controllability and variability in their causal interventions**|Alison Gopnik Team|[2512.08230](http://arxiv.org/abs/2512.08230)|null|
|**2025-12-09**|**Primal-dual policy learning for mean-field stochastic LQR problem**|Yuanqing Wu Team|[2512.08205](http://arxiv.org/abs/2512.08205)|null|
|**2025-12-09**|**TreeGRPO: Tree-Advantage GRPO for Online RL Post-Training of Diffusion Models**|Weirui Ye Team|[2512.08153](http://arxiv.org/abs/2512.08153)|null|
|**2025-12-09**|**Robust Agents in Open-Ended Worlds**|Mikayel Samvelyan Team|[2512.08139](http://arxiv.org/abs/2512.08139)|null|
|**2025-12-09**|**Universal Adversarial Suffixes for Language Models Using Reinforcement Learning with Calibrated Reward**|Arijit Sur Team|[2512.08131](http://arxiv.org/abs/2512.08131)|null|
|**2025-12-08**|**Scalable Offline Model-Based RL with Action Chunks**|Sergey Levine Team|[2512.08108](http://arxiv.org/abs/2512.08108)|null|
|**2025-12-08**|**Training LLMs for Honesty via Confessions**|Amelia Glaese Team|[2512.08093](http://arxiv.org/abs/2512.08093)|null|
|**2025-12-08**|**An Introduction to Deep Reinforcement and Imitation Learning**|Pedro Santana Team|[2512.08052](http://arxiv.org/abs/2512.08052)|null|
|**2025-12-08**|**F2: Offline Reinforcement Learning for Hamiltonian Simulation via Free-Fermionic Subroutine Compilation**|Samuel Stein Team|[2512.08023](http://arxiv.org/abs/2512.08023)|null|
|**2025-12-08**|**Benchmarking Offline Multi-Objective Reinforcement Learning in Critical Care**|Divya Sharma Team|[2512.08012](http://arxiv.org/abs/2512.08012)|null|
|**2025-12-08**|**VLD: Visual Language Goal Distance for Reinforcement Learning Navigation**|Jonas Frey Team|[2512.07976](http://arxiv.org/abs/2512.07976)|null|
|**2025-12-08**|**Agentic Artificial Intelligence for Ethical Cybersecurity in Uganda: A Reinforcement Learning Framework for Threat Detection in Resource-Constrained Environments**|Mutebi Joe Team|[2512.07909](http://arxiv.org/abs/2512.07909)|null|
|**2025-12-08**|**An Adaptive Multi-Layered Honeynet Architecture for Threat Behavior Analysis via Deep Learning**|Lukas Johannes Möller Team|[2512.07827](http://arxiv.org/abs/2512.07827)|null|
|**2025-12-08**|**On the Interplay of Pre-Training, Mid-Training, and RL on Reasoning Language Models**|Xiang Yue Team|[2512.07783](http://arxiv.org/abs/2512.07783)|null|
|**2025-12-08**|**RL-MTJail: Reinforcement Learning for Automated Black-Box Multi-Turn Jailbreaking of Large Language Models**|Xiangnan He Team|[2512.07761](http://arxiv.org/abs/2512.07761)|null|
|**2025-12-08**|**DiffusionDriveV2: Reinforcement Learning-Constrained Truncated Diffusion Modeling in End-to-End Autonomous Driving**|Xinggang Wang Team|[2512.07745](http://arxiv.org/abs/2512.07745)|null|
|**2025-12-08**|**SpatialDreamer: Incentivizing Spatial Reasoning via Active Mental Imagery**|Xiaodan Liang Team|[2512.07733](http://arxiv.org/abs/2512.07733)|null|
|**2025-12-08**|**Each Prompt Matters: Scaling Reinforcement Learning Without Wasting Rollouts on Hundred-Billion-Scale MoE**|Ziqin Liew Team|[2512.07710](http://arxiv.org/abs/2512.07710)|null|
|**2025-12-08**|**Delay-Aware Diffusion Policy: Bridging the Observation-Execution Gap in Dynamic Tasks**|Shayegan Omidshafiei Team|[2512.07697](http://arxiv.org/abs/2512.07697)|null|
|**2025-12-08**|**The Agent Capability Problem: Predicting Solvability Through Information-Theoretic Bounds**|Shahar Lutati Team|[2512.07631](http://arxiv.org/abs/2512.07631)|null|
|**2025-12-08**|**Comparative Analysis and Parametric Tuning of PPO, GRPO, and DAPO for LLM Reasoning Enhancement**|Yongsheng Lian Team|[2512.07611](http://arxiv.org/abs/2512.07611)|null|
|**2025-12-08**|**Understanding Individual Decision-Making in Multi-Agent Reinforcement Learning: A Dynamical Systems Approach**|Mirco Musolesi Team|[2512.07588](http://arxiv.org/abs/2512.07588)|null|
|**2025-12-08**|**ReLaX: Reasoning with Latent Exploration for Large Reasoning Models**|Jibin Wu Team|[2512.07558](http://arxiv.org/abs/2512.07558)|null|
|**2025-12-08**|**Model-Based Reinforcement Learning Under Confounding**|Andreas A. Malikopoulos Team|[2512.07528](http://arxiv.org/abs/2512.07528)|null|
|**2025-12-08**|**How Do LLMs Fail In Agentic Scenarios? A Qualitative Analysis of Success and Failure Scenarios of Various LLMs in Agentic Simulations**|JV Roig Team|[2512.07497](http://arxiv.org/abs/2512.07497)|null|
|**2025-12-08**|**Enhancing Agentic RL with Progressive Reward Shaping and Value-based Sampling Policy Optimization**|Xia Zeng Team|[2512.07478](http://arxiv.org/abs/2512.07478)|null|
|**2025-12-08**|**Gait-Adaptive Perceptive Humanoid Locomotion with Real-Time Under-Base Terrain Reconstruction**|Houqiang Li Team|[2512.07464](http://arxiv.org/abs/2512.07464)|null|
|**2025-12-08**|**Native Parallel Reasoner: Reasoning in Parallelism via Self-Distilled Reinforcement Learning**|Zilong Zheng Team|[2512.07461](http://arxiv.org/abs/2512.07461)|null|
|**2025-12-08**|**From Show Programmes to Data: Designing a Workflow to Make Performing Arts Ephemera Accessible Through Language Models**|Jeanne Fras Team|[2512.07452](http://arxiv.org/abs/2512.07452)|null|
|**2025-12-08**|**KAN-Dreamer: Benchmarking Kolmogorov-Arnold Networks as Function Approximators in World Models**|Xueyu Luan Team|[2512.07437](http://arxiv.org/abs/2512.07437)|null|
|**2025-12-08**|**Revolutionizing Mixed Precision Quantization: Towards Training-free Automatic Proxy Discovery via Large Language Models**|Lihong Lin Team|[2512.07419](http://arxiv.org/abs/2512.07419)|null|
|**2025-12-08**|**Adaptive Tuning of Parameterized Traffic Controllers via Multi-Agent Reinforcement Learning**|Bart De Schutter Team|[2512.07417](http://arxiv.org/abs/2512.07417)|null|
|**2025-12-08**|**Training Language Models to Use Prolog as a Tool**|Lukas Galke Poech Team|[2512.07407](http://arxiv.org/abs/2512.07407)|null|
|**2025-12-08**|**Control and Reinforcement Learning through the Lens of Optimization: An Algorithmic Perspective**|Peyman Mohajerin Esfahani Team|[2512.07377](http://arxiv.org/abs/2512.07377)|null|
|**2025-12-08**|**ESPADA: Execution Speedup via Semantics Aware Demonstration Data Downsampling for Imitation Learning**|Byoung-Tak Zhang Team|[2512.07371](http://arxiv.org/abs/2512.07371)|**[link](https://project-espada.github.io/espada/)**|
|**2025-12-08**|**Multi-Rigid-Body Approximation of Human Hands with Application to Digital Twin**|Sheng Yi Team|[2512.07359](http://arxiv.org/abs/2512.07359)|null|
|**2025-12-08**|**PrivORL: Differentially Private Synthetic Dataset for Offline Reinforcement Learning**|Tianhao Wang Team|[2512.07342](http://arxiv.org/abs/2512.07342)|**[link](https://github.com/2019ChenGong/PrivORL)**|
|**2025-12-08**|**RVLF: A Reinforcing Vision-Language Framework for Gloss-Free Sign Language Translation**|Jun Wan Team|[2512.07273](http://arxiv.org/abs/2512.07273)|null|
|**2025-12-08**|**SINRL: Socially Integrated Navigation with Reinforcement Learning using Spiking Neural Networks**|Sören Hohmann Team|[2512.07266](http://arxiv.org/abs/2512.07266)|null|
|**2025-12-08**|**Benchmarking Humanoid Imitation Learning with Motion Difficulty**|Yipeng Qin Team|[2512.07248](http://arxiv.org/abs/2512.07248)|null|
|**2025-12-08**|**Towards Robust Protective Perturbation against DeepFake Face Swapping**|Huiping Chen Team|[2512.07228](http://arxiv.org/abs/2512.07228)|null|
|**2025-12-08**|**Sample from What You See: Visuomotor Policy Learning via Diffusion Bridge with Observation-Embedded Stochastic Differential Equation**|Ye Shi Team|[2512.07212](http://arxiv.org/abs/2512.07212)|null|
|**2025-12-08**|**MMRPT: MultiModal Reinforcement Pre-Training via Masked Vision-Dependent Reasoning**|Yichao Wu Team|[2512.07203](http://arxiv.org/abs/2512.07203)|null|
|**2025-12-08**|**Less is More: Non-uniform Road Segments are Efficient for Bus Arrival Prediction**|Haitao Yu Team|[2512.07200](http://arxiv.org/abs/2512.07200)|null|
|**2025-12-08**|**Think-Reflect-Revise: A Policy-Guided Reflective Framework for Safety Alignment in Large Vision Language Models**|Wenjie Wang Team|[2512.07141](http://arxiv.org/abs/2512.07141)|null|
|**2025-12-08**|**TrajMoE: Scene-Adaptive Trajectory Planning with Mixture of Experts and Reinforcement Learning**|Dongbin Zhao Team|[2512.07135](http://arxiv.org/abs/2512.07135)|null|
|**2025-12-08**|**Surrogate compliance modeling enables reinforcement learned locomotion gaits for soft robots**|Rebecca Kramer-Bottiglio Team|[2512.07114](http://arxiv.org/abs/2512.07114)|null|
|**2025-12-07**|**A Hetero-Associative Sequential Memory Model Utilizing Neuromorphic Signals: Validated on a Mobile Manipulator**|Gordon Cheng Team|[2512.07032](http://arxiv.org/abs/2512.07032)|null|
|**2025-12-07**|**Utilizing Multi-Agent Reinforcement Learning with Encoder-Decoder Architecture Agents to Identify Optimal Resection Location in Glioblastoma Multiforme Patients**|Paras Goel Team|[2512.06990](http://arxiv.org/abs/2512.06990)|null|
|**2025-12-07**|**LLM-Driven Composite Neural Architecture Search for Multi-Source RL State Encoding**|Li Jin Team|[2512.06982](http://arxiv.org/abs/2512.06982)|null|
|**2025-12-07**|**Neuro-Vesicles: Neuromodulation Should Be a Dynamical System, Not a Tensor Decoration**|Vicki Kane Team|[2512.06966](http://arxiv.org/abs/2512.06966)|null|
|**2025-12-07**|**VideoVLA: Video Generators Can Be Generalizable Robot Manipulators**|Baining Guo Team|[2512.06963](http://arxiv.org/abs/2512.06963)|**[link](https://videovla-nips2025.github.io)**|
|**2025-12-07**|**Statistical analysis of Inverse Entropy-regularized Reinforcement Learning**|Sergey Samsonov Team|[2512.06956](http://arxiv.org/abs/2512.06956)|null|
|**2025-12-07**|**Deep Reinforcement Learning for Phishing Detection with Transformer-Based Semantic Features**|Aseer Al Faisal Team|[2512.06925](http://arxiv.org/abs/2512.06925)|null|
|**2025-12-07**|**Parent-Guided Semantic Reward Model (PGSRM): Embedding-Based Reward Functions for Reinforcement Learning of Transformer Language Models**|Alexandr Plashchinsky Team|[2512.06920](http://arxiv.org/abs/2512.06920)|null|
|**2025-12-07**|**Know your Trajectory -- Trustworthy Reinforcement Learning deployment through Importance-Based Trajectory Analysis**|Balaraman Ravindran Team|[2512.06917](http://arxiv.org/abs/2512.06917)|null|
|**2025-12-07**|**Khalasi: Energy-Efficient Navigation for Surface Vehicles in Vortical Flow Fields**|Sandeep Manjanna Team|[2512.06912](http://arxiv.org/abs/2512.06912)|null|
|**2025-12-07**|**An Analysis of Large Language Models for Simulating User Responses in Surveys**|Hongyi Wen Team|[2512.06874](http://arxiv.org/abs/2512.06874)|null|
|**2025-12-07**|**JT-DA: Enhancing Data Analysis with Tool-Integrated Table Reasoning Large Language Models**|Junlan Feng Team|[2512.06859](http://arxiv.org/abs/2512.06859)|null|
|**2025-12-07**|**Decouple to Generalize: Context-First Self-Evolving Learning for Data-Scarce Vision-Language Reasoning**|Cheng Tan Team|[2512.06835](http://arxiv.org/abs/2512.06835)|null|
|**2025-12-07**|**MMDuet2: Enhancing Proactive Interaction of Video MLLMs with Multi-Turn Reinforcement Learning**|Dongyan Zhao Team|[2512.06810](http://arxiv.org/abs/2512.06810)|null|
|**2025-12-07**|**PrivLLMSwarm: Privacy-Preserving LLM-Driven UAV Swarms for Secure IoT Surveillance**|Huang Qiming Team|[2512.06747](http://arxiv.org/abs/2512.06747)|null|
|**2025-12-07**|**The Role of Entropy in Visual Grounding: Analysis and Optimization**|Xuanjing Huang Team|[2512.06726](http://arxiv.org/abs/2512.06726)|null|
|**2025-12-07**|**RunawayEvil: Jailbreaking the Image-to-Video Generative Models**|Caifeng Shan Team|[2512.06674](http://arxiv.org/abs/2512.06674)|null|
|**2025-12-07**|**LightSearcher: Efficient DeepSearch via Experiential Memory**|Ting Bai Team|[2512.06653](http://arxiv.org/abs/2512.06653)|null|
|**2025-12-07**|**Analyzing Collision Rates in Large-Scale Mixed Traffic Control via Multi-Agent Reinforcement Learning**|Muyang Fan Team|[2512.06645](http://arxiv.org/abs/2512.06645)|null|
|**2025-12-07**|**Learning to Hedge Swaptions**|Frédéric Godin Team|[2512.06639](http://arxiv.org/abs/2512.06639)|null|
|**2025-12-07**|**MIND-V: Hierarchical Video Generation for Long-Horizon Robotic Manipulation with RL-based Physical Alignment**|Xiu Li Team|[2512.06628](http://arxiv.org/abs/2512.06628)|null|
|**2025-12-07**|**A New Trajectory-Oriented Approach to Enhancing Comprehensive Crowd Navigation Performance**|Liguo Chen Team|[2512.06608](http://arxiv.org/abs/2512.06608)|null|
|**2025-12-06**|**MedGRPO: Multi-Task Reinforcement Learning for Heterogeneous Medical Video Understanding**|Ziyan Wu Team|[2512.06581](http://arxiv.org/abs/2512.06581)|null|
|**2025-12-06**|**Learning Agile Striker Skills for Humanoid Soccer Robots from Noisy Sensory Input**|Peter Stone Team|[2512.06571](http://arxiv.org/abs/2512.06571)|null|
|**2025-12-06**|**A-3PO: Accelerating Asynchronous LLM Training with Staleness-aware Proximal Policy Approximation**|Zheng Shen Team|[2512.06547](http://arxiv.org/abs/2512.06547)|null|
|**2025-12-06**|**Beyond Token-level Supervision: Unlocking the Potential of Decoding-based Regression via Reinforcement Learning**|Chao Qian Team|[2512.06533](http://arxiv.org/abs/2512.06533)|null|
|**2025-12-06**|**Entropy-Controlled Intrinsic Motivation Reinforcement Learning for Quadruped Robot Locomotion in Complex Terrains**|Xiaoqing Zhu Team|[2512.06486](http://arxiv.org/abs/2512.06486)|null|
|**2025-12-06**|**Why Goal-Conditioned Reinforcement Learning Works: Relation to Dual Control**|Ali Mesbah Team|[2512.06471](http://arxiv.org/abs/2512.06471)|null|
|**2025-12-06**|**RLAX: Large-Scale, Distributed Reinforcement Learning for Large Language Models on TPUs**|Cheng Leong Team|[2512.06392](http://arxiv.org/abs/2512.06392)|null|
|**2025-12-06**|**VG-Refiner: Towards Tool-Refined Referring Grounded Reasoning via Agentic Reinforcement Learning**|Yansong Tang Team|[2512.06373](http://arxiv.org/abs/2512.06373)|**[link](https://github.com/VoyageWang/VG-Refiner))**|
|**2025-12-06**|**LLM-Upgraded Graph Reinforcement Learning for Carbon-Aware Job Scheduling in Smart Manufacturing**|Boon Ping Gan Team|[2512.06351](http://arxiv.org/abs/2512.06351)|null|
|**2025-12-06**|**ReCAD: Reinforcement Learning Enhanced Parametric CAD Model Generation with Vision-Language Models**|Xiangdong Zhou Team|[2512.06328](http://arxiv.org/abs/2512.06328)|null|
|**2025-12-06**|**A Hybrid Physics-Based and Reinforcement Learning Framework for Electric Vehicle Charging Time Prediction**|Andreas A. Malikopoulos Team|[2512.06287](http://arxiv.org/abs/2512.06287)|null|
|**2025-12-06**|**Networked Restless Multi-Arm Bandits with Reinforcement Learning**|Kai Wang Team|[2512.06274](http://arxiv.org/abs/2512.06274)|null|
|**2025-12-06**|**Nanbeige4-3B Technical Report: Exploring the Frontier of Small Language Models**|Zongchao Chen Team|[2512.06266](http://arxiv.org/abs/2512.06266)|null|
|**2025-12-06**|**Learning Without Time-Based Embodiment Resets in Soft-Actor Critic**|A. Rupam Mahmood Team|[2512.06252](http://arxiv.org/abs/2512.06252)|null|
|**2025-12-06**|**Learning When to Switch: Adaptive Policy Selection via Reinforcement Learning**|Chris Tava Team|[2512.06250](http://arxiv.org/abs/2512.06250)|null|
|**2025-12-06**|**Auto-exploration for online reinforcement learning**|Guanghui Lan Team|[2512.06244](http://arxiv.org/abs/2512.06244)|null|
|**2025-12-06**|**AI Application in Anti-Money Laundering for Sustainable and Transparent Financial Systems**|Chao Wang Team|[2512.06240](http://arxiv.org/abs/2512.06240)|null|
|**2025-12-05**|**Average-reward reinforcement learning in semi-Markov decision processes via relative value iteration**|Richard S. Sutton Team|[2512.06218](http://arxiv.org/abs/2512.06218)|null|
|**2025-12-05**|**Quantifying Memory Use in Reinforcement Learning with Temporal Range**|T. Konstantin Rusch Team|[2512.06204](http://arxiv.org/abs/2512.06204)|null|
|**2025-12-05**|**JaxWildfire: A GPU-Accelerated Wildfire Simulator for Reinforcement Learning**|Nick Hawes Team|[2512.06102](http://arxiv.org/abs/2512.06102)|null|
|**2025-12-05**|**Empathy by Design: Aligning Large Language Models for Healthcare Dialogue**|Aritran Piplai Team|[2512.06097](http://arxiv.org/abs/2512.06097)|null|
|**2025-12-05**|**Comparative Analysis of Autonomous and Systematic Control Strategies for Hole-Doped Hubbard Clusters: Reinforcement Learning versus Physics-Guided Design**|Kalum Palandage Team|[2512.06095](http://arxiv.org/abs/2512.06095)|null|
|**2025-12-05**|**Reinforcement Learning Integrated Agentic RAG for Software Test Cases Authoring**|Mohanakrishnan Hariharan Team|[2512.06060](http://arxiv.org/abs/2512.06060)|null|
|**2025-12-03**|**VAT: Vision Action Transformer by Unlocking Full Representation of ViT**|Weixin Mao Team|[2512.06013](http://arxiv.org/abs/2512.06013)|null|
|**2025-12-01**|**FishDetector-R1: Unified MLLM-Based Framework with Reinforcement Fine-Tuning for Weakly Supervised Fish Detection, Segmentation, and Counting**|Katherine A. Skinner Team|[2512.05996](http://arxiv.org/abs/2512.05996)|null|
|**2025-12-05**|**EditThinker: Unlocking Iterative Reasoning for Any Image Editor**|Si Liu Team|[2512.05965](http://arxiv.org/abs/2512.05965)|**[link](https://appletea233.github.io/think-while-edit)**|
|**2025-12-05**|**Whatever Remains Must Be True: Filtering Drives Reasoning in LLMs, Shaping Diversity**|Marc Dymetman Team|[2512.05962](http://arxiv.org/abs/2512.05962)|null|
|**2025-12-05**|**Correspondence-Oriented Imitation Learning: Flexible Visuomotor Control with 3D Conditioning**|Kuan Fang Team|[2512.05953](http://arxiv.org/abs/2512.05953)|null|
|**2025-12-05**|**Variational Quantum Rainbow Deep Q-Network for Optimizing Resource Allocation Problem**|Hung Cao Team|[2512.05946](http://arxiv.org/abs/2512.05946)|null|
|**2025-12-05**|**World Models That Know When They Don't Know: Controllable Video Generation with Calibrated Uncertainty**|Anirudha Majumdar Team|[2512.05927](http://arxiv.org/abs/2512.05927)|null|
|**2025-12-05**|**Toward Efficient and Robust Behavior Models for Multi-Agent Driving Simulation**|Christoph Stiller Team|[2512.05812](http://arxiv.org/abs/2512.05812)|null|
|**2025-12-05**|**Real-time Remote Tracking and Autonomous Planning for Whale Rendezvous using Robots**|Stephanie Gil Team|[2512.05808](http://arxiv.org/abs/2512.05808)|null|
|**2025-12-05**|**3D Path Planning for Robot-assisted Vertebroplasty from Arbitrary Bi-plane X-ray via Differentiable Rendering**|Mathias Unberath Team|[2512.05803](http://arxiv.org/abs/2512.05803)|null|
|**2025-12-05**|**Curvature-Regularized Variational Autoencoder for 3D Scene Reconstruction from Sparse Depth**|Soodeh Bakhshandeh Team|[2512.05783](http://arxiv.org/abs/2512.05783)|null|
|**2025-12-05**|**USV: Unified Sparsification for Accelerating Video Diffusion Models**|Qinglin Lu Team|[2512.05754](http://arxiv.org/abs/2512.05754)|null|
|**2025-12-05**|**A Fast Anti-Jamming Cognitive Radar Deployment Algorithm Based on Reinforcement Learning**|Tiande Guo Team|[2512.05753](http://arxiv.org/abs/2512.05753)|null|
|**2025-12-05**|**A High-Order Immersed Boundary Method for Fluid-Structure Interaction Problems**|Esteban Ferrer Team|[2512.05733](http://arxiv.org/abs/2512.05733)|null|
|**2025-12-05**|**Bayesian Active Inference for Intelligent UAV Anti-Jamming and Adaptive Trajectory Planning**|Carlo Regazzoni Team|[2512.05711](http://arxiv.org/abs/2512.05711)|null|
|**2025-12-05**|**LA-RL: Language Action-guided Reinforcement Learning with Safety Guarantees for Autonomous Highway Driving**|Chen Sun Team|[2512.05686](http://arxiv.org/abs/2512.05686)|null|
|**2025-12-05**|**MedTutor-R1: Socratic Personalized Medical Teaching with Multi-Agent Simulation**|Yi R Fung Team|[2512.05671](http://arxiv.org/abs/2512.05671)|null|
|**2025-12-05**|**Entropy Ratio Clipping as a Soft Global Constraint for Stable Reinforcement Learning**|Guorui Zhou Team|[2512.05591](http://arxiv.org/abs/2512.05591)|null|
|**2025-12-05**|**A Comprehensive Framework for Automated Quality Control in the Automotive Industry**|Panagiotis Chatzakos Team|[2512.05579](http://arxiv.org/abs/2512.05579)|null|
|**2025-12-05**|**MIND: Multi-rationale INtegrated Discriminative Reasoning Framework for Multi-modal Large Models**|Xiangyu Yue Team|[2512.05530](http://arxiv.org/abs/2512.05530)|null|
|**2025-12-05**|**Distributed scalable coupled policy algorithm for networked multi-agent reinforcement learning**|Wei Ren Team|[2512.05447](http://arxiv.org/abs/2512.05447)|null|
|**2025-12-05**|**ParaUni: Enhance Generation in Unified Multimodal Model with Reinforcement-driven Hierarchical Parallel Information Interaction**|Feng Zhao Team|[2512.05422](http://arxiv.org/abs/2512.05422)|null|
|**2025-12-05**|**State-Conditional Adversarial Learning: An Off-Policy Visual Domain Transfer Method for End-to-End Imitation Learning**|Shengfan Cao Team|[2512.05335](http://arxiv.org/abs/2512.05335)|null|
|**2025-12-04**|**Enhancing Deep Deterministic Policy Gradients on Continuous Control Tasks with Decoupled Prioritized Experience Replay**|Suleyman Serdar Kozat Team|[2512.05320](http://arxiv.org/abs/2512.05320)|null|
|**2025-12-04**|**Bridging Interpretability and Optimization: Provably Attribution-Weighted Actor-Critic in Reproducing Kernel Hilbert Spaces**|Xinyu Li Team|[2512.05291](http://arxiv.org/abs/2512.05291)|null|
|**2025-12-04**|**Uncertainty-Aware Data-Efficient AI: An Information-Theoretic Perspective**|Yaniv Romano Team|[2512.05267](http://arxiv.org/abs/2512.05267)|null|
|**2025-12-04**|**Age-Inclusive 3D Human Mesh Recovery for Action-Preserving Data Anonymization**|Petros Maragos Team|[2512.05259](http://arxiv.org/abs/2512.05259)|null|
|**2025-12-04**|**IE2Video: Adapting Pretrained Diffusion Models for Event-Based Video Reconstruction**|Yihui Ren Team|[2512.05240](http://arxiv.org/abs/2512.05240)|null|
|**2025-12-04**|**Hierarchical Reinforcement Learning for the Dynamic VNE with Alternatives Problem**|Omran Ayoub Team|[2512.05207](http://arxiv.org/abs/2512.05207)|null|
|**2025-12-04**|**Semore: VLM-guided Enhanced Semantic Motion Representations for Visual Reinforcement Learning**|Yan Wang Team|[2512.05172](http://arxiv.org/abs/2512.05172)|null|
|**2025-12-04**|**A Mutual Information-based Metric for Temporal Expressivity and Trainability Estimation in Quantum Policy Gradient Pipelines**|Kabgyun Jeong Team|[2512.05157](http://arxiv.org/abs/2512.05157)|null|
|**2025-12-04**|**ARM-Thinker: Reinforcing Multimodal Generative Reward Models with Agentic Tool Use and Visual Reasoning**|Jiaqi Wang Team|[2512.05111](http://arxiv.org/abs/2512.05111)|null|
|**2025-12-04**|**STARE-VLA: Progressive Stage-Aware Reinforcement for Fine-Tuning Vision-Language-Action Models**|Benjamin Busam Team|[2512.05107](http://arxiv.org/abs/2512.05107)|null|
|**2025-12-04**|**Semantic Soft Bootstrapping: Long Context Reasoning in LLMs without Reinforcement Learning**|Sennur Ulukus Team|[2512.05105](http://arxiv.org/abs/2512.05105)|null|
|**2025-12-04**|**Structured Document Translation via Format Reinforcement Learning**|Masao Utiyama Team|[2512.05100](http://arxiv.org/abs/2512.05100)|null|
|**2025-12-04**|**SA-IQA: Redefining Image Quality Assessment for Spatial Aesthetics with Multi-Dimensional Rewards**|Jin Song Team|[2512.05098](http://arxiv.org/abs/2512.05098)|null|
|**2025-12-04**|**From Generated Human Videos to Physically Plausible Robot Trajectories**|Roei Herzig Team|[2512.05094](http://arxiv.org/abs/2512.05094)|**[link](https://genmimic.github.io)**|
|**2025-12-04**|**Hybrid-Diffusion Models: Combining Open-loop Routines with Visuomotor Diffusion Policies**|Danica Kragic Team|[2512.04960](http://arxiv.org/abs/2512.04960)|null|
|**2025-12-04**|**Realizable Abstractions: Near-Optimal Hierarchical Reinforcement Learning**|Matteo Leonetti Team|[2512.04958](http://arxiv.org/abs/2512.04958)|null|
|**2025-12-04**|**FASTer: Toward Efficient Autoregressive Vision Language Action Modeling via Neural Action Tokenization**|Hang Zhao Team|[2512.04952](http://arxiv.org/abs/2512.04952)|null|
|**2025-12-04**|**CARL: Critical Action Focused Reinforcement Learning for Multi-Step Agent**|Tat-Seng Chua Team|[2512.04949](http://arxiv.org/abs/2512.04949)|null|
|**2025-12-04**|**Multi-Agent Reinforcement Learning for Intraday Operating Rooms Scheduling under Uncertainty**|Thorsten Koch Team|[2512.04918](http://arxiv.org/abs/2512.04918)|null|
|**2025-12-04**|**Safe model-based Reinforcement Learning via Model Predictive Control and Control Barrier Functions**|Azita Dabiri Team|[2512.04856](http://arxiv.org/abs/2512.04856)|null|
|**2025-12-04**|**MOVE: A Simple Motion-Based Data Collection Paradigm for Spatial Generalization in Robotic Manipulation**|Gao Huang Team|[2512.04813](http://arxiv.org/abs/2512.04813)|null|
|**2025-12-04**|**YingMusic-SVC: Real-World Robust Zero-Shot Singing Voice Conversion with Flow-GRPO and Singing-Specific Inductive Biases**|Zihao Chen Team|[2512.04793](http://arxiv.org/abs/2512.04793)|null|
|**2025-12-02**|**PaCo-RL: Advancing Reinforcement Learning for Consistent Image Generation with Pairwise Reward Modeling**|Hangwei Qian Team|[2512.04784](http://arxiv.org/abs/2512.04784)|null|
|**2025-12-04**|**YingMusic-Singer: Zero-shot Singing Voice Synthesis and Editing with Annotation-free Melody Guidance**|Lei Xie Team|[2512.04779](http://arxiv.org/abs/2512.04779)|null|
|**2025-12-04**|**Using Machine Learning to Take Stay-or-Go Decisions in Data-driven Drone Missions**|Spyros Lalis Team|[2512.04773](http://arxiv.org/abs/2512.04773)|null|
|**2025-12-04**|**RLHFSpec: Breaking the Efficiency Bottleneck in RLHF Training via Adaptive Drafting**|Depei Qian Team|[2512.04752](http://arxiv.org/abs/2512.04752)|null|
|**2025-12-04**|**Continuous-time reinforcement learning for optimal switching over multiple regimes**|Zhou Zhou Team|[2512.04697](http://arxiv.org/abs/2512.04697)|null|
|**2025-12-04**|**TRINITY: An Evolved LLM Coordinator**|Yujin Tang Team|[2512.04695](http://arxiv.org/abs/2512.04695)|null|
|**2025-12-04**|**Semi Centralized Training Decentralized Execution Architecture for Multi Agent Deep Reinforcement Learning in Traffic Signal Control**|Monireh Abdoos Team|[2512.04653](http://arxiv.org/abs/2512.04653)|null|
|**2025-12-04**|**Gauss-Newton accelerated MPPI Control**|Johannes Reuter Team|[2512.04579](http://arxiv.org/abs/2512.04579)|null|
|**2025-12-04**|**COOPER: A Unified Model for Cooperative Perception and Reasoning in Spatial Intelligence**|Tingwen Liu Team|[2512.04563](http://arxiv.org/abs/2512.04563)|null|
|**2025-12-04**|**Omniscient Attacker in Stochastic Security Games with Interdependent Nodes**|Muhammed O. Sayin Team|[2512.04561](http://arxiv.org/abs/2512.04561)|null|
|**2025-12-04**|**RRPO: Robust Reward Policy Optimization for LLM-based Emotional TTS**|Ya Li Team|[2512.04552](http://arxiv.org/abs/2512.04552)|null|
|**2025-12-04**|**GTM: Simulating the World of Tools for AI Agents**|Jiyan He Team|[2512.04535](http://arxiv.org/abs/2512.04535)|null|
|**2025-12-04**|**MARL Warehouse Robots**|Salmon Riaz Team|[2512.04463](http://arxiv.org/abs/2512.04463)|**[link](https://pallman14.github.io/MARL-QMIX-Warehouse-Robots/)**|
|**2025-12-04**|**Quantum-Accelerated Deep Reinforcement Learning for Frequency Regulation Enhancement**|Mert Korkali Team|[2512.04439](http://arxiv.org/abs/2512.04439)|null|
|**2025-12-04**|**Towards 6G Native-AI Edge Networks: A Semantic-Aware and Agentic Intelligence Paradigm**|Xiaohu You Team|[2512.04405](http://arxiv.org/abs/2512.04405)|null|
|**2025-12-04**|**Learning to Orchestrate Agents in Natural Language with the Conductor**|Yujin Tang Team|[2512.04388](http://arxiv.org/abs/2512.04388)|null|
|**2025-12-04**|**LangSAT: A Novel Framework Combining NLP and Reinforcement Learning for SAT Solving**|Mahfuza Farooque Team|[2512.04374](http://arxiv.org/abs/2512.04374)|null|
|**2025-12-04**|**AutoGuard: A Self-Healing Proactive Security Layer for DevSecOps Pipelines Using Reinforcement Learning**|Piyush Ranjan Team|[2512.04368](http://arxiv.org/abs/2512.04368)|null|
|**2025-12-04**|**Efficient Reinforcement Learning with Semantic and Token Entropy for LLM Reasoning**|Yang Gao Team|[2512.04359](http://arxiv.org/abs/2512.04359)|null|
|**2025-12-04**|**Long-Horizon Model-Based Offline Reinforcement Learning Without Conservatism**|Pierre-Luc Bacon Team|[2512.04341](http://arxiv.org/abs/2512.04341)|null|
|**2025-12-03**|**Data-regularized Reinforcement Learning for Diffusion Models at Scale**|Stefano Ermon Team|[2512.04332](http://arxiv.org/abs/2512.04332)|null|
|**2025-12-03**|**Towards better dense rewards in Reinforcement Learning Applications**|Shuyuan Zhang Team|[2512.04302](http://arxiv.org/abs/2512.04302)|null|
|**2025-12-03**|**Driving Beyond Privilege: Distilling Dense-Reward Knowledge into Sparse-Reward Policies**|Jaerock Kwon Team|[2512.04279](http://arxiv.org/abs/2512.04279)|null|
|**2025-12-03**|**Bootstrapped Mixed Rewards for RL Post-Training: Injecting Canonical Action Order**|Vaibhav Gupta Team|[2512.04277](http://arxiv.org/abs/2512.04277)|null|
|**2025-12-03**|**The Geometry of Benchmarks: A New Path Toward AGI**|Przemyslaw Chojecki Team|[2512.04276](http://arxiv.org/abs/2512.04276)|null|
|**2025-12-03**|**Toward Virtuous Reinforcement Learning**|Mark Crowley Team|[2512.04246](http://arxiv.org/abs/2512.04246)|null|
|**2025-12-03**|**On GRPO Collapse in Search-R1: The Lazy Likelihood-Displacement Death Spiral**|Xiaoxiao Li Team|[2512.04220](http://arxiv.org/abs/2512.04220)|null|
|**2025-12-02**|**When AI Takes the Couch: Psychometric Jailbreaks Reveal Internal Conflict in Frontier Models**|Gilbert Fridgen Team|[2512.04124](http://arxiv.org/abs/2512.04124)|null|
|**2025-12-03**|**PosterCopilot: Toward Layout Reasoning and Controllable Editing for Professional Graphic Design**|Chenyang Si Team|[2512.04082](http://arxiv.org/abs/2512.04082)|**[link](https://postercopilot.github.io/)**|
|**2025-12-03**|**SkillFactory: Self-Distillation For Learning Cognitive Behaviors**|Greg Durrett Team|[2512.04072](http://arxiv.org/abs/2512.04072)|null|
|**2025-12-03**|**SpaceTools: Tool-Augmented Spatial Reasoning via Double Interactive RL**|Jonathan Tremblay Team|[2512.04069](http://arxiv.org/abs/2512.04069)|null|
|**2025-12-03**|**Guided Flow Policy: Learning from High-Value Actions in Offline Reinforcement Learning**|Justin Carpentier Team|[2512.03973](http://arxiv.org/abs/2512.03973)|null|
|**2025-12-03**|**TempR1: Improving Temporal Understanding of MLLMs via Temporal-Aware Multi-Task Reinforcement Learning**|Limin Wang Team|[2512.03963](http://arxiv.org/abs/2512.03963)|null|
|**2025-12-03**|**Hierarchical Vision Language Action Model Using Success and Failure Demonstrations**|Sungjoon Choi Team|[2512.03913](http://arxiv.org/abs/2512.03913)|**[link](https://vine-vla.github.io/)**|
|**2025-12-03**|**Autonomous Reinforcement Learning Robot Control with Intel's Loihi 2 Neuromorphic Hardware**|Carl Glen Henshaw Team|[2512.03911](http://arxiv.org/abs/2512.03911)|null|
|**2025-12-03**|**Digital Twin-based Control Co-Design of Full Vehicle Active Suspensions via Deep Reinforcement Learning**|Wei Chen Team|[2512.03891](http://arxiv.org/abs/2512.03891)|null|
|**2025-12-03**|**Automatic Attack Discovery for Few-Shot Class-Incremental Learning via Large Language Models**|Hanling Wang Team|[2512.03882](http://arxiv.org/abs/2512.03882)|null|
|**2025-12-03**|**DVPO: Distributional Value Modeling-based Policy Optimization for LLM Post-Training**|Tao Gui Team|[2512.03847](http://arxiv.org/abs/2512.03847)|null|
|**2025-12-03**|**Multi-Agent Deep Reinforcement Learning for UAV-Assisted 5G Network Slicing: A Comparative Study of MAPPO, MADDPG, and MADQN**|Abdulhalim Dandoush Team|[2512.03835](http://arxiv.org/abs/2512.03835)|null|
|**2025-12-03**|**First Experimental Demonstration of Machine Learning-Based Tuning on the PSI Injector 2 Cyclotron**|M. Schneider Team|[2512.03829](http://arxiv.org/abs/2512.03829)|null|
|**2025-12-03**|**Deep Reinforcement Learning for Dynamic Algorithm Configuration: A Case Study on Optimizing OneMax with the (1+( $λ$,$λ$ ))-GA**|Nguyen Dang Team|[2512.03805](http://arxiv.org/abs/2512.03805)|null|
|**2025-12-03**|**MPCFormer: A physics-informed data-driven approach for explainable socially-aware autonomous driving**|Haoran Wang Team|[2512.03795](http://arxiv.org/abs/2512.03795)|null|
|**2025-12-03**|**AdaptVision: Efficient Vision-Language Models via Adaptive Visual Acquisition**|Deheng Ye Team|[2512.03794](http://arxiv.org/abs/2512.03794)|null|
|**2025-12-03**|**Omni-AutoThink: Adaptive Multimodal Reasoning via Reinforcement Learning**|Helen Meng Team|[2512.03783](http://arxiv.org/abs/2512.03783)|null|
|**2025-12-03**|**Safety Reinforced Model Predictive Control (SRMPC): Improving MPC with Reinforcement Learning for Motion Planning in Autonomous Driving**|Christoph Stiller Team|[2512.03774](http://arxiv.org/abs/2512.03774)|null|
|**2025-12-03**|**Sample-Efficient Model-Free Policy Gradient Methods for Stochastic LQR via Robust Linear Regression**|Andrea Iannelli Team|[2512.03764](http://arxiv.org/abs/2512.03764)|null|
|**2025-12-03**|**Principled RL for Diffusion LLMs Emerges from a Sequence-Level Perspective**|Chongxuan Li Team|[2512.03759](http://arxiv.org/abs/2512.03759)|null|
|**2025-12-03**|**Thinking with Programming Vision: Towards a Unified View for Thinking with Images**|Tao Jin Team|[2512.03746](http://arxiv.org/abs/2512.03746)|null|
|**2025-12-03**|**Crossing the Sim2Real Gap Between Simulation and Ground Testing to Space Deployment of Autonomous Free-flyer Control**|Carl Glen Henshaw Team|[2512.03736](http://arxiv.org/abs/2512.03736)|null|
|**2025-12-03**|**Autonomous Planning In-space Assembly Reinforcement-learning free-flYer (APIARY) International Space Station Astrobee Testing**|Carl Glen Henshaw Team|[2512.03729](http://arxiv.org/abs/2512.03729)|null|
|**2025-12-03**|**Tutorial on Large Language Model-Enhanced Reinforcement Learning for Wireless Networks**|Xuemin Shen Team|[2512.03722](http://arxiv.org/abs/2512.03722)|null|
|**2025-12-03**|**ContactRL: Safe Reinforcement Learning based Motion Planning for Contact based Human Robot Collaboration**|Emma Li Team|[2512.03707](http://arxiv.org/abs/2512.03707)|null|
|**2025-12-03**|**A Descriptive Model for Modelling Attacker Decision-Making in Cyber-Deception**|Y. Yan Team|[2512.03641](http://arxiv.org/abs/2512.03641)|null|
|**2025-12-03**|**Accelerating Detailed Routing Convergence through Offline Reinforcement Learning**|Austin Rovinski Team|[2512.03594](http://arxiv.org/abs/2512.03594)|null|
|**2025-12-03**|**RoboScape-R: Unified Reward-Observation World Models for Generalizable Robotics Training via RL**|Yong Li Team|[2512.03556](http://arxiv.org/abs/2512.03556)|null|
|**2025-12-03**|**A Learning-based Control Methodology for Transitioning VTOL UAVs**|Xiaoqiang Ji Team|[2512.03548](http://arxiv.org/abs/2512.03548)|null|
|**2025-12-03**|**Multi-Agent Reinforcement Learning with Communication-Constrained Priors**|Yang Gao Team|[2512.03528](http://arxiv.org/abs/2512.03528)|null|
|**2025-12-03**|**Adaptive sampling using variational autoencoder and reinforcement learning**|Muhammad Faisal Aftab Team|[2512.03525](http://arxiv.org/abs/2512.03525)|null|
|**2025-12-03**|**Variable-Impedance Muscle Coordination under Slow-Rate Control Frequencies and Limited Observation Conditions Evaluated through Legged Locomotion**|Jun Morimoto Team|[2512.03459](http://arxiv.org/abs/2512.03459)|null|
|**2025-12-03**|**PretrainZero: Reinforcement Active Pretraining**|Debing Zhang Team|[2512.03442](http://arxiv.org/abs/2512.03442)|null|
|**2025-12-03**|**Multimodal Reinforcement Learning with Agentic Verifier for AI Agents**|Jianfeng Gao Team|[2512.03438](http://arxiv.org/abs/2512.03438)|null|
|**2025-12-03**|**World Models for Autonomous Navigation of Terrestrial Robots from LIDAR Observations**|Daniel Fernando Tello Gamarra Team|[2512.03429](http://arxiv.org/abs/2512.03429)|null|
|**2025-12-03**|**Better World Models Can Lead to Better Post-Training Performance**|Andrew Lee Team|[2512.03400](http://arxiv.org/abs/2512.03400)|null|
|**2025-12-03**|**GOMP: Grasped Object Manifold Projection for Multimodal Imitation Learning of Manipulation**|Nima Fazeli Team|[2512.03347](http://arxiv.org/abs/2512.03347)|null|
|**2025-12-02**|**SpatialReasoner: Active Perception for Large-Scale 3D Scene Understanding**|Hujun Yin Team|[2512.03284](http://arxiv.org/abs/2512.03284)|null|
|**2025-12-02**|**SPARK: Stepwise Process-Aware Rewards for Reference-Free Reinforcement Learning**|Yang Liu Team|[2512.03244](http://arxiv.org/abs/2512.03244)|null|
|**2025-12-02**|**A Multi-Agent, Policy-Gradient approach to Network Routing**|Lex Weaver Team|[2512.03211](http://arxiv.org/abs/2512.03211)|null|
|**2025-12-02**|**Uncertainty Quantification for Large Language Model Reward Learning under Heterogeneous Human Feedback**|Will Wei Sun Team|[2512.03208](http://arxiv.org/abs/2512.03208)|null|
|**2025-12-02**|**GRAND: Guidance, Rebalancing, and Assignment for Networked Dispatch in Multi-Agent Path Finding**|Gioele Zardini Team|[2512.03194](http://arxiv.org/abs/2512.03194)|null|
|**2025-12-02**|**Multi-Agent Reinforcement Learning and Real-Time Decision-Making in Robotic Soccer for Virtual Environments**|Md Sohag Mia Team|[2512.03166](http://arxiv.org/abs/2512.03166)|null|
|**2025-12-02**|**Hierarchical Process Reward Models are Symbolic Vision Learners**|Anton van den Hengel Team|[2512.03126](http://arxiv.org/abs/2512.03126)|null|
|**2025-12-01**|**Dynamic Correction of Erroneous State Estimates via Diffusion Bayesian Exploration**|Weiru Liu Team|[2512.03102](http://arxiv.org/abs/2512.03102)|null|
|**2025-12-02**|**OneThinker: All-in-one Reasoning Model for Image and Video**|Xiangyu Yue Team|[2512.03043](http://arxiv.org/abs/2512.03043)|**[link](https://github.com/tulerfeng/OneThinker)**|
|**2025-12-02**|**SMP: Reusable Score-Matching Motion Priors for Physics-Based Character Control**|Xue Bin Peng Team|[2512.03028](http://arxiv.org/abs/2512.03028)|null|
|**2025-12-02**|**MindGPT-4ov: An Enhanced MLLM via a Multi-Stage Post-Training Paradigm**|Xuhan Zhu Team|[2512.02895](http://arxiv.org/abs/2512.02895)|null|
|**2025-12-02**|**Taming Camera-Controlled Video Generation with Verifiable Geometry Reward**|Changhu Wang Team|[2512.02870](http://arxiv.org/abs/2512.02870)|null|
|**2025-12-02**|**ReVSeg: Incentivizing the Reasoning Chain for Video Segmentation with Reinforcement Learning**|Yanwei Fu Team|[2512.02835](http://arxiv.org/abs/2512.02835)|null|
|**2025-12-02**|**Steering Vision-Language-Action Models as Anti-Exploration: A Test-Time Scaling Approach**|Xuelong Li Team|[2512.02834](http://arxiv.org/abs/2512.02834)|null|
|**2025-12-02**|**Phase-Adaptive LLM Framework with Multi-Stage Validation for Construction Robot Task Allocation: A Systematic Benchmark Against Traditional Optimization Algorithms**|Hongrui Yu Team|[2512.02810](http://arxiv.org/abs/2512.02810)|null|
|**2025-12-02**|**SR-GRPO: Stable Rank as an Intrinsic Geometric Reward for Large Language Model Alignment**|Yi Yang Team|[2512.02807](http://arxiv.org/abs/2512.02807)|null|
|**2025-12-01**|**IC-World: In-Context Generation for Shared World Modeling**|Guosheng Lin Team|[2512.02793](http://arxiv.org/abs/2512.02793)|**[link](https://github.com/wufan-cse/IC-World)**|
|**2025-12-02**|**Reinforcement learning for irreversible reinsurance problems: the randomized singular control approach**|Xiang Yu Team|[2512.02769](http://arxiv.org/abs/2512.02769)|null|
|**2025-12-02**|**RoboWheel: A Data Engine from Real-World Human Demonstrations for Cross-Embodiment Robotic Learning**|Haoqian Wang Team|[2512.02729](http://arxiv.org/abs/2512.02729)|null|
|**2025-12-02**|**Zero-Shot Instruction Following in RL via Structured LTL Representations**|Alessandro Abate Team|[2512.02633](http://arxiv.org/abs/2512.02633)|null|
|**2025-12-02**|**SeeNav-Agent: Enhancing Vision-Language Navigation with Visual Prompt and Step-Level Policy Optimization**|Deheng Ye Team|[2512.02631](http://arxiv.org/abs/2512.02631)|null|
|**2025-12-02**|**Harnessing swarms for directed migration of interacting active particles via optimal global control**|Jérémie Bec Team|[2512.02627](http://arxiv.org/abs/2512.02627)|null|
|**2025-12-02**|**SAM2Grasp: Resolve Multi-modal Grasping via Prompt-conditioned Temporal Action Prediction**|Yong Zhao Team|[2512.02609](http://arxiv.org/abs/2512.02609)|null|
|**2025-12-02**|**GoRL: An Algorithm-Agnostic Framework for Online Reinforcement Learning with Generative Policies**|Bo An Team|[2512.02581](http://arxiv.org/abs/2512.02581)|null|
|**2025-12-02**|**From Imitation to Discrimination: Toward A Generalized Curriculum Advantage Mechanism Enhancing Cross-Domain Reasoning Tasks**|Guoquan Zhang Team|[2512.02580](http://arxiv.org/abs/2512.02580)|null|
|**2025-12-02**|**DeepSeek-V3.2: Pushing the Frontier of Open Large Language Models**|Zihua Qu Team|[2512.02556](http://arxiv.org/abs/2512.02556)|null|
|**2025-12-02**|**CUDA-L2: Surpassing cuBLAS Performance for Matrix Multiplication through Reinforcement Learning**|Chris Shum Team|[2512.02551](http://arxiv.org/abs/2512.02551)|null|
|**2025-12-02**|**AID: Agent Intent from Diffusion for Multi-Agent Informative Path Planning**|Guillaume Sartoretti Team|[2512.02535](http://arxiv.org/abs/2512.02535)|null|
|**2025-12-02**|**Dual-Robust Cross-Domain Offline Reinforcement Learning Against Dynamics Shifts**|Shuang Qiu Team|[2512.02486](http://arxiv.org/abs/2512.02486)|null|
|**2025-12-02**|**QJoin: Transformation-aware Joinable Data Discovery Using Reinforcement Learning**|Sainyam Galhotra Team|[2512.02444](http://arxiv.org/abs/2512.02444)|null|
|**2025-12-02**|**A Visual Analytics System to Understand Behaviors of Multi Agents in Reinforcement Learning**|DongHwa Shin Team|[2512.02442](http://arxiv.org/abs/2512.02442)|null|
|**2025-12-02**|**Cross-Domain Offline Policy Adaptation with Dynamics- and Value-Aligned Data Filtering**|Shuang Qiu Team|[2512.02435](http://arxiv.org/abs/2512.02435)|null|
|**2025-12-02**|**GUI Exploration Lab: Enhancing Screen Navigation in Agents via Multi-Turn Reinforcement Learning**|Daxin Jiang Team|[2512.02423](http://arxiv.org/abs/2512.02423)|null|
|**2025-12-02**|**Data Curation Through the Lens of Spectral Dynamics: Static Limits, Dynamic Acceleration, and Practical Oracles**|Lun Du Team|[2512.02409](http://arxiv.org/abs/2512.02409)|null|
|**2025-12-02**|**Dynamic Configuration of On-Street Parking Spaces using Multi Agent Reinforcement Learning**|Shanika Karunasekera Team|[2512.02406](http://arxiv.org/abs/2512.02406)|null|
|**2025-12-02**|**Skywork-R1V4: Toward Agentic Multimodal Intelligence through Interleaved Thinking with Images and DeepResearch**|Yahui Zhou Team|[2512.02395](http://arxiv.org/abs/2512.02395)|null|
|**2025-12-02**|**Synthetic Error Injection Fails to Elicit Self-Correction In Language Models**|Stuart Russell Team|[2512.02389](http://arxiv.org/abs/2512.02389)|null|
|**2025-12-02**|**Risk-Sensitive Q-Learning in Continuous Time with Application to Dynamic Portfolio Selection**|Chuhan Xie Team|[2512.02386](http://arxiv.org/abs/2512.02386)|null|
|**2025-12-02**|**Reinforcement Learning in POMDP's via Direct Gradient Ascent**|Peter L. Bartlett Team|[2512.02383](http://arxiv.org/abs/2512.02383)|null|
|**2025-12-02**|**VACoT: Rethinking Visual Data Augmentation with VLMs**|Chun Yuan Team|[2512.02361](http://arxiv.org/abs/2512.02361)|null|
|**2025-12-02**|**Beyond Playtesting: A Generative Multi-Agent Simulation System for Massively Multiplayer Online Games**|Dong Fang Team|[2512.02358](http://arxiv.org/abs/2512.02358)|null|
|**2025-12-02**|**FOVA: Offline Federated Reinforcement Learning with Mixed-Quality Data**|Yaoxue Zhang Team|[2512.02350](http://arxiv.org/abs/2512.02350)|null|
|**2025-12-01**|**CAIRNS: Balancing Readability and Scientific Accuracy in Climate Adaptation Question Answering**|Sarvnaz Karimi Team|[2512.02251](http://arxiv.org/abs/2512.02251)|null|
|**2025-12-01**|**Lightweight Latent Reasoning for Narrative Tasks**|Mirella Lapata Team|[2512.02240](http://arxiv.org/abs/2512.02240)|null|
|**2025-12-01**|**Improved Training Mechanism for Reinforcement Learning via Online Model Selection**|Aldo Pacchiano Team|[2512.02214](http://arxiv.org/abs/2512.02214)|null|
|**2025-12-01**|**Modelling the Doughnut of social and planetary boundaries with frugal machine learning**|Daniel W. O'Neill Team|[2512.02200](http://arxiv.org/abs/2512.02200)|null|
|**2025-12-01**|**How Market Volatility Shapes Algorithmic Collusion: A Comparative Analysis of Learning-Based Pricing Algorithms**|Ridwan Al Aziz Team|[2512.02134](http://arxiv.org/abs/2512.02134)|null|
|**2025-12-01**|**A Diffusion Model Framework for Maximum Entropy Reinforcement Learning**|Alois Knoll Team|[2512.02019](http://arxiv.org/abs/2512.02019)|null|
|**2025-12-01**|**Learning Dexterous Manipulation Skills from Imperfect Simulations**|Haozhi Qi Team|[2512.02011](http://arxiv.org/abs/2512.02011)|null|
|**2025-12-01**|**Learning Sim-to-Real Humanoid Locomotion in 15 Minutes**|Pieter Abbeel Team|[2512.01996](http://arxiv.org/abs/2512.01996)|**[link](https://younggyo.me/fastsac-humanoid)**|
|**2025-12-01**|**RoaD: Rollouts as Demonstrations for Closed-Loop Supervised Fine-Tuning of Autonomous Driving Policies**|Marco Pavone Team|[2512.01993](http://arxiv.org/abs/2512.01993)|null|
|**2025-12-01**|**Artemis: Structured Visual Reasoning for Perception Policy Learning**|Zechao Li Team|[2512.01988](http://arxiv.org/abs/2512.01988)|null|
|**2025-12-01**|**Forecasting in Offline Reinforcement Learning for Non-stationary Environments**|Erhan Oztop Team|[2512.01987](http://arxiv.org/abs/2512.01987)|null|
|**2025-12-01**|**From Atomic to Composite: Reinforcement Learning Enables Generalization in Complementary Reasoning**|Victor Zhong Team|[2512.01970](http://arxiv.org/abs/2512.01970)|**[link](https://github.com/sitaocheng/from_atomic_to_composite)**|
|**2025-12-01**|**Learned-Rule-Augmented Large Language Model Evaluators**|Jin Mao Team|[2512.01958](http://arxiv.org/abs/2512.01958)|null|
|**2025-12-01**|**GrndCtrl: Grounding World Models via Self-Supervised Reward Alignment**|Sebastian Scherer Team|[2512.01952](http://arxiv.org/abs/2512.01952)|null|
|**2025-12-01**|**Agentic Policy Optimization via Instruction-Policy Co-Evolution**|Anna Korhonen Team|[2512.01945](http://arxiv.org/abs/2512.01945)|null|
|**2025-12-01**|**Rectifying LLM Thought from Lens of Optimization**|Kai Chen Team|[2512.01925](http://arxiv.org/abs/2512.01925)|null|
|**2025-12-01**|**New Spiking Architecture for Multi-Modal Decision-Making in Autonomous Vehicles**|Nagarajan Kandasamy Team|[2512.01882](http://arxiv.org/abs/2512.01882)|null|
|**2025-12-01**|**Graph Distance as Surprise: Free Energy Minimization in Knowledge Graph Reasoning**|Fuhua Lin Team|[2512.01878](http://arxiv.org/abs/2512.01878)|null|
|**2025-12-01**|**Beyond SFT: Reinforcement Learning for Safer Large Reasoning Models with Better Reasoning Ability**|Sijia Liu Team|[2512.01848](http://arxiv.org/abs/2512.01848)|null|
|**2025-12-01**|**CauSight: Learning to Supersense for Visual Causal Discovery**|Chaochao Lu Team|[2512.01827](http://arxiv.org/abs/2512.01827)|**[link](https://github.com/OpenCausaLab/CauSight)**|
|**2025-12-01**|**GR-RL: Going Dexterous and Precise for Long-Horizon Robotic Manipulation**|Yonghui Wu Team|[2512.01801](http://arxiv.org/abs/2512.01801)|null|
|**2025-12-01**|**How Does RL Post-training Induce Skill Composition? A Case Study on Countdown**|Sanjeev Arora Team|[2512.01775](http://arxiv.org/abs/2512.01775)|null|
|**2025-12-01**|**IGen: Scalable Data Generation for Robot Learning from Open-World Images**|Zhi Wang Team|[2512.01773](http://arxiv.org/abs/2512.01773)|null|
|**2025-12-01**|**Learning the Boundary of Solvability: Aligning LLMs to Detect Unsolvable Problems**|Wanxiang Che Team|[2512.01661](http://arxiv.org/abs/2512.01661)|null|
|**2025-12-01**|**CLIP-RL: Aligning Language and Policy Representations for Task Transfer in Reinforcement Learning**|Raghuram Bharadwaj Diddigi Team|[2512.01616](http://arxiv.org/abs/2512.01616)|null|
|**2025-12-01**|**End-to-end Deep Reinforcement Learning for Stochastic Multi-objective Optimization in C-VRPTW**|Yingqian Zhang Team|[2512.01518](http://arxiv.org/abs/2512.01518)|null|
|**2025-12-01**|**Formal Verification of Noisy Quantum Reinforcement Learning Policies**|Dennis Gross Team|[2512.01502](http://arxiv.org/abs/2512.01502)|null|
|**2025-12-01**|**Multi-Path Collaborative Reasoning via Reinforcement Learning**|Jiancheng Lv Team|[2512.01485](http://arxiv.org/abs/2512.01485)|null|
|**2025-12-01**|**PointNet4D: A Lightweight 4D Point Cloud Video Backbone for Online and Offline Perception in Robotic Applications**|Jiayang Ao Team|[2512.01383](http://arxiv.org/abs/2512.01383)|null|
|**2025-12-01**|**Stabilizing Reinforcement Learning with LLMs: Formulation and Practices**|Junyang Lin Team|[2512.01374](http://arxiv.org/abs/2512.01374)|null|
|**2025-12-01**|**BlinkBud: Detecting Hazards from Behind via Sampled Monocular 3D Detection on a Single Earbud**|Minyi Guo Team|[2512.01366](http://arxiv.org/abs/2512.01366)|**[link](https://doi.org/10.1145/3770707)**|
|**2025-12-01**|**Directed evolution algorithm drives neural prediction**|Patrick C M Wong Team|[2512.01362](http://arxiv.org/abs/2512.01362)|null|
|**2025-12-01**|**Discovering Self-Protective Falling Policy for Humanoid Robot via Deep Reinforcement Learning**|Donglin Wang Team|[2512.01336](http://arxiv.org/abs/2512.01336)|null|
|**2025-12-01**|**Extending NGU to Multi-Agent RL: A Preliminary Study**|Rodrigo Toro Icarte Team|[2512.01321](http://arxiv.org/abs/2512.01321)|null|
|**2025-12-01**|**CuES: A Curiosity-driven and Environment-grounded Synthesis Framework for Agentic RL**|Bolin Ding Team|[2512.01311](http://arxiv.org/abs/2512.01311)|null|
|**2025-12-01**|**Kardia-R1: Unleashing LLMs to Reason toward Understanding and Empathy for Emotional Support via Rubric-as-Judge Reinforcement Learning**|Usman Naseem Team|[2512.01282](http://arxiv.org/abs/2512.01282)|null|
|**2025-12-01**|**PSR: Scaling Multi-Subject Personalized Image Generation with Pairwise Subject-Consistency Rewards**|Qi Tian Team|[2512.01236](http://arxiv.org/abs/2512.01236)|null|
|**2025-12-01**|**On the Tension Between Optimality and Adversarial Robustness in Policy Optimization**|Nan Jiang Team|[2512.01228](http://arxiv.org/abs/2512.01228)|null|
|**2025-12-01**|**CoSineVerifier: Tool-Augmented Answer Verification for Computation-Oriented Scientific Questions**|Tao Zhang Team|[2512.01224](http://arxiv.org/abs/2512.01224)|null|
|**2025-12-01**|**How do trout regulate patterns of muscle contraction to optimize propulsive efficiency during steady swimming**|Lu Zhang Team|[2512.01218](http://arxiv.org/abs/2512.01218)|null|
|**2025-12-01**|**Sum Rate Maximization in STAR-RIS-UAV-Assisted Networks: A CA-DDPG Approach for Joint Optimization**|Wen Chen Team|[2512.01202](http://arxiv.org/abs/2512.01202)|null|
|**2025-12-01**|**Real-World Reinforcement Learning of Active Perception Behaviors**|Dinesh Jayaraman Team|[2512.01188](http://arxiv.org/abs/2512.01188)|null|
|**2025-12-01**|**A TinyML Reinforcement Learning Approach for Energy-Efficient Light Control in Low-Cost Greenhouse Systems**|Ahmed Harb Rabia Team|[2512.01167](http://arxiv.org/abs/2512.01167)|**[link](https://doi.org/10.1109/INTCEC65580.2025.11256135)**|
|**2025-11-30**|**Mode-Conditioning Unlocks Superior Test-Time Scaling**|Aditi Raghunathan Team|[2512.01127](http://arxiv.org/abs/2512.01127)|null|
|**2025-11-30**|**World Model Robustness via Surprise Recognition**|Mark Riedl Team|[2512.01119](http://arxiv.org/abs/2512.01119)|null|
|**2025-11-30**|**Accelerating Inference of Masked Image Generators via Reinforcement Learning**|Aditya Grover Team|[2512.01094](http://arxiv.org/abs/2512.01094)|null|
|**2025-11-30**|**Reinforcement Learning for Gliding Projectile Guidance and Control**|Philippe Pastor Team|[2512.01066](http://arxiv.org/abs/2512.01066)|null|

<p align=right>(<a href=#updated-on-20251217>back to top</a>)</p>

## Locomotion

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-12-12**|**Bench-Push: Benchmarking Pushing-based Navigation and Manipulation Tasks for Mobile Robots**|Stephen L. Smith Team|[2512.11736](http://arxiv.org/abs/2512.11736)|null|
|**2025-12-11**|**Design of a six wheel suspension and a three-axis linear actuation mechanism for a laser weeding robot**|Asad Nisar Awan Team|[2512.10319](http://arxiv.org/abs/2512.10319)|null|
|**2025-12-11**|**Lies We Can Trust: Quantifying Action Uncertainty with Inaccurate Stochastic Dynamics through Conformalized Nonholonomic Lie Groups**|Dmitry Berenson Team|[2512.10294](http://arxiv.org/abs/2512.10294)|null|
|**2025-12-10**|**LISN: Language-Instructed Social Navigation with VLM-based Controller Modulating**|Lin Shao Team|[2512.09920](http://arxiv.org/abs/2512.09920)|null|
|**2025-12-10**|**REASAN: Learning Reactive Safe Navigation for Legged Robots**|Kailai Li Team|[2512.09537](http://arxiv.org/abs/2512.09537)|null|
|**2025-12-09**|**ShelfAware: Real-Time Visual-Inertial Semantic Localization in Quasi-Static Environments with Low-Cost Sensors**|Bradley Hayes Team|[2512.09065](http://arxiv.org/abs/2512.09065)|null|
|**2025-12-09**|**Learning Spatiotemporal Tubes for Temporal Reach-Avoid-Stay Tasks using Physics-Informed Neural Networks**|Pushpak Jagtap Team|[2512.08248](http://arxiv.org/abs/2512.08248)|null|
|**2025-12-08**|**Multi-Domain Motion Embedding: Expressive Real-Time Mimicry for Legged Robots**|Marco Hutter Team|[2512.07673](http://arxiv.org/abs/2512.07673)|null|
|**2025-12-08**|**Efficient Computation of a Continuous Topological Model of the Configuration Space of Tethered Mobile Robots**|Bart De Schutter Team|[2512.07303](http://arxiv.org/abs/2512.07303)|null|
|**2025-12-08**|**SINRL: Socially Integrated Navigation with Reinforcement Learning using Spiking Neural Networks**|Sören Hohmann Team|[2512.07266](http://arxiv.org/abs/2512.07266)|null|
|**2025-12-08**|**Time-Varying Formation Tracking Control of Wheeled Mobile Robots With Region Constraint: A Generalized Udwadia-Kalaba Framework**|Chen Guanrong Team|[2512.07137](http://arxiv.org/abs/2512.07137)|null|
|**2025-12-06**|**Entropy-Controlled Intrinsic Motivation Reinforcement Learning for Quadruped Robot Locomotion in Complex Terrains**|Xiaoqing Zhu Team|[2512.06486](http://arxiv.org/abs/2512.06486)|null|
|**2025-12-06**|**Fault Tolerant Control of Mecanum Wheeled Mobile Robots**|Zhiyong Sun Team|[2512.06444](http://arxiv.org/abs/2512.06444)|null|
|**2025-12-05**|**REWW-ARM -- Remote Wire-Driven Mobile Robot: Design, Control, and Experimental Validation**|Kei Okada Team|[2512.06192](http://arxiv.org/abs/2512.06192)|null|
|**2025-12-05**|**Real-Time Spatiotemporal Tubes for Dynamic Unsafe Sets**|Pushpak Jagtap Team|[2512.06151](http://arxiv.org/abs/2512.06151)|null|
|**2025-12-05**|**Spatiotemporal Tubes for Differential Drive Robots with Model Uncertainty**|Pushpak Jagtap Team|[2512.05495](http://arxiv.org/abs/2512.05495)|null|
|**2025-12-05**|**CLIO: A Tour Guide Robot with Co-speech Actions for Visual Attention Guidance and Enhanced User Engagement**|Lei Yang Team|[2512.05389](http://arxiv.org/abs/2512.05389)|null|
|**2025-12-04**|**XR-DT: Extended Reality-Enhanced Digital Twin for Agentic Mobile Robots**|Christian Claudel Team|[2512.05270](http://arxiv.org/abs/2512.05270)|null|
|**2025-12-04**|**Wake Vectoring for Efficient Morphing Flight**|Morteza Gharib Team|[2512.05211](http://arxiv.org/abs/2512.05211)|null|
|**2025-12-04**|**Contact-Implicit Modeling and Simulation of a Snake Robot on Compliant and Granular Terrain**|Haroon Hublikar Team|[2512.05008](http://arxiv.org/abs/2512.05008)|null|
|**2025-12-03**|**Adaptive Parameter Control Using AAN for Lower Limb Rehabilitation Exoskeletons**|Xin Ma Team|[2512.03871](http://arxiv.org/abs/2512.03871)|null|
|**2025-12-02**|**SAT-MapIt: A SAT-based Modulo Scheduling Mapper for Coarse Grain Reconfigurable Architectures**|Laura Pozzi Team|[2512.02875](http://arxiv.org/abs/2512.02875)|null|
|**2025-12-02**|**Wi-Fi Rate Adaptation for Moving Equipment in Industrial Environments**|Gianluca Cena Team|[2512.02455](http://arxiv.org/abs/2512.02455)|null|
|**2025-12-02**|**GUI Exploration Lab: Enhancing Screen Navigation in Agents via Multi-Turn Reinforcement Learning**|Daxin Jiang Team|[2512.02423](http://arxiv.org/abs/2512.02423)|null|
|**2025-12-01**|**Learning Sim-to-Real Humanoid Locomotion in 15 Minutes**|Pieter Abbeel Team|[2512.01996](http://arxiv.org/abs/2512.01996)|**[link](https://younggyo.me/fastsac-humanoid)**|
|**2025-12-01**|**Integrated YOLOP Perception and Lyapunov-based Control for Autonomous Mobile Robot Navigation on Track**|Mo Chen Team|[2512.01608](http://arxiv.org/abs/2512.01608)|null|
|**2025-12-01**|**A Cross-Embodiment Gripper Benchmark for Rigid-Object Manipulation in Aerial and Industrial Robotics**|Ivan Virgala Team|[2512.01598](http://arxiv.org/abs/2512.01598)|null|
|**2025-11-30**|**Autonomous Grasping On Quadruped Robot With Task Level Interaction**|Chastine Fatichah Team|[2512.01052](http://arxiv.org/abs/2512.01052)|null|
|**2025-11-30**|**Integration of UWB Radar on Mobile Robots for Continuous Obstacle and Environment Mapping**|Eli De Poorter Team|[2512.01018](http://arxiv.org/abs/2512.01018)|null|
|**2025-11-30**|**H-Zero: Cross-Humanoid Locomotion Pretraining Enables Few-shot Novel Embodiment Transfer**|Weinan Zhang Team|[2512.00971](http://arxiv.org/abs/2512.00971)|null|
|**2025-11-30**|**SAGAS: Semantic-Aware Graph-Assisted Stitching for Offline Temporal Logic Planning**|Xiang Yin Team|[2512.00775](http://arxiv.org/abs/2512.00775)|null|
|**2025-11-30**|**MS-PPO: Morphological-Symmetry-Equivariant Policy for Legged Robot Locomotion**|Lu Gan Team|[2512.00727](http://arxiv.org/abs/2512.00727)|null|
|**2025-11-25**|**A Hierarchical Framework for Humanoid Locomotion with Supernumerary Limbs**|Bowen Zhi Team|[2512.00077](http://arxiv.org/abs/2512.00077)|null|
|**2025-11-18**|**Socially aware navigation for mobile robots: a survey on deep reinforcement learning approaches**|Muhammad Faizan Mysorewala Team|[2512.00049](http://arxiv.org/abs/2512.00049)|null|
|**2025-11-28**|**Commanding Humanoid by Free-form Language: A Large Language Action Model with Unified Motion Vocabulary**|Jingya Wang Team|[2511.22963](http://arxiv.org/abs/2511.22963)|**[link](https://humanoidlla.github.io/)**|
|**2025-11-27**|**Beyond Egocentric Limits: Multi-View Depth-Based Learning for Robust Quadrupedal Locomotion**|Wael Suleiman Team|[2511.22744](http://arxiv.org/abs/2511.22744)|**[link](https://anonymous.4open.science/r/multiview-parkour-6FB8)**|
|**2025-11-27**|**BINDER: Instantly Adaptive Mobile Manipulation with Open-Vocabulary Commands**|Jonghyun Choi Team|[2511.22364](http://arxiv.org/abs/2511.22364)|null|
|**2025-11-27**|**MLATC: Fast Hierarchical Topological Mapping from 3D LiDAR Point Clouds Based on Adaptive Resonance Theory**|Takayuki Matsuno Team|[2511.22238](http://arxiv.org/abs/2511.22238)|null|
|**2025-11-26**|**UniArt: Unified 3D Representation for Generating 3D Articulated Objects with Open-Set Articulation**|Yao Yao Team|[2511.21887](http://arxiv.org/abs/2511.21887)|null|
|**2025-11-26**|**MarketGen: A Scalable Simulation Platform with Auto-Generated Embodied Supermarket Environments**|Zhaoxiang Zhang Team|[2511.21161](http://arxiv.org/abs/2511.21161)|**[link](https://xuhu0529.github.io/MarketGen)**|
|**2025-11-25**|**OVAL-Grasp: Open-Vocabulary Affordance Localization for Task Oriented Grasping**|Odest Chadwicke Jenkins Team|[2511.20841](http://arxiv.org/abs/2511.20841)|null|
|**2025-11-25**|**Power-Efficient Autonomous Mobile Robots**|Kang G. Shin Team|[2511.20467](http://arxiv.org/abs/2511.20467)|null|
|**2025-12-04**|**HAFO: A Force-Adaptive Control Framework for Humanoid Robots in Intense Interaction Environments**|Bin He Team|[2511.20275](http://arxiv.org/abs/2511.20275)|null|
|**2025-11-24**|**Robot-Powered Data Flywheels: Deploying Robots in the Wild for Continual Data Collection and Foundation Model Adaptation**|Dorsa Sadigh Team|[2511.19647](http://arxiv.org/abs/2511.19647)|null|
|**2025-11-19**|**Strong Duality and Dual Ascent Approach to Continuous-Time Chance-Constrained Stochastic Optimal Control**|Takashi Tanaka Team|[2511.19451](http://arxiv.org/abs/2511.19451)|null|
|**2025-11-24**|**Reference-Free Sampling-Based Model Predictive Control**|Justin Carpentier Team|[2511.19204](http://arxiv.org/abs/2511.19204)|null|
|**2025-11-24**|**Accelerating Reinforcement Learning via Error-Related Human Brain Signals**|Hyo-Jeong Jang Team|[2511.18878](http://arxiv.org/abs/2511.18878)|null|
|**2025-11-24**|**AutoOdom: Learning Auto-regressive Proprioceptive Odometry for Legged Locomotion**|Mingguo Zhao Team|[2511.18857](http://arxiv.org/abs/2511.18857)|null|
|**2025-11-24**|**SP-VINS: A Hybrid Stereo Visual Inertial Navigation System based on Implicit Environmental Map**|JunMao Team|[2511.18756](http://arxiv.org/abs/2511.18756)|null|
|**2025-11-23**|**Splatblox: Traversability-Aware Gaussian Splatting for Outdoor Robot Navigation**|Dinesh Manocha Team|[2511.18525](http://arxiv.org/abs/2511.18525)|null|
|**2025-11-22**|**Switch-JustDance: Benchmarking Whole Body Motion Tracking Policies Using a Commercial Console Game**|Tianyu Li Team|[2511.17925](http://arxiv.org/abs/2511.17925)|null|
|**2025-11-22**|**MobileVLA-R1: Reinforcing Vision-Language-Action for Mobile Robots**|Hao Tang Team|[2511.17889](http://arxiv.org/abs/2511.17889)|null|
|**2025-11-21**|**SAFE-SMART: Safety Analysis and Formal Evaluation using STL Metrics for Autonomous RoboTs**|Huan Xu Team|[2511.17781](http://arxiv.org/abs/2511.17781)|null|
|**2025-11-21**|**Feasibility of Embodied Dynamics Based Bayesian Learning for Continuous Pursuit Motion Control of Assistive Mobile Robots in the Built Environment**|Vineet R. Kamat Team|[2511.17401](http://arxiv.org/abs/2511.17401)|null|
|**2025-11-21**|**MonoSpheres: Large-Scale Monocular SLAM-Based UAV Exploration through Perception-Coupled Mapping and Planning**|Martin Saska Team|[2511.17299](http://arxiv.org/abs/2511.17299)|null|
|**2025-11-21**|**MobileOcc: A Human-Aware Semantic Occupancy Dataset for Mobile Robots**|Javier Alonso-Mora Team|[2511.16949](http://arxiv.org/abs/2511.16949)|null|
|**2025-11-20**|**Homogeneous Proportional-Integral-Derivative Controller in Mobile Robotic Manipulators**|Andrey Polyakov Team|[2511.16406](http://arxiv.org/abs/2511.16406)|null|
|**2025-11-20**|**How Robot Dogs See the Unseeable**|Jeremy E. Niven Team|[2511.16262](http://arxiv.org/abs/2511.16262)|null|
|**2025-11-19**|**Discovering Optimal Natural Gaits of Dissipative Systems via Virtual Energy Injection**|Alin Albu-Schäffer Team|[2511.15513](http://arxiv.org/abs/2511.15513)|null|
|**2025-11-18**|**iGaussian: Real-Time Camera Pose Estimation via Feed-Forward 3D Gaussian Splatting Inversion**|Haibin Yan Team|[2511.14149](http://arxiv.org/abs/2511.14149)|null|
|**2025-11-17**|**GaRLILEO: Gravity-aligned Radar-Leg-Inertial Enhanced Odometry**|Ayoung Kim Team|[2511.13216](http://arxiv.org/abs/2511.13216)|null|
|**2025-11-17**|**Collision-Free Navigation of Mobile Robots via Quadtree-Based Model Predictive Control**|Emmanuel Dean Team|[2511.13188](http://arxiv.org/abs/2511.13188)|null|
|**2025-11-17**|**SplatSearch: Instance Image Goal Navigation for Mobile Robots using 3D Gaussian Splatting and Diffusion Models**|Goldie Nejat Team|[2511.12972](http://arxiv.org/abs/2511.12972)|**[link](https://splat-search.github.io/)**|
|**2025-11-17**|**TOPP-DWR: Time-Optimal Path Parameterization of Differential-Driven Wheeled Robots Considering Piecewise-Constant Angular Velocity Constraints**|Hui Cheng Team|[2511.12910](http://arxiv.org/abs/2511.12910)|null|
|**2025-11-16**|**Botany Meets Robotics in Alpine Scree Monitoring**|Manolo Garabini Team|[2511.12526](http://arxiv.org/abs/2511.12526)|null|
|**2025-11-15**|**SAC-MoE: Reinforcement Learning with Mixture-of-Experts for Control of Hybrid Dynamical Systems with Uncertainty**|Sebastian Fischmeister Team|[2511.12361](http://arxiv.org/abs/2511.12361)|null|
|**2025-11-15**|**SocialNav-Map: Dynamic Mapping with Human Trajectory Prediction for Zero-Shot Social Navigation**|Wenbo Ding Team|[2511.12232](http://arxiv.org/abs/2511.12232)|null|
|**2025-11-15**|**ARCSnake V2: An Amphibious Multi-Domain Screw-Propelled Snake-Like Robot**|Michael C. Yip Team|[2511.11970](http://arxiv.org/abs/2511.11970)|null|
|**2025-11-14**|**WetExplorer: Automating Wetland Greenhouse-Gas Surveys with an Autonomous Mobile Robot**|Xuping Zhang Team|[2511.10864](http://arxiv.org/abs/2511.10864)|null|
|**2025-11-13**|**Dynamically Extensible and Retractable Robotic Leg Linkages for Multi-task Execution in Search and Rescue Scenarios**|Micheal C. Yip Team|[2511.10816](http://arxiv.org/abs/2511.10816)|null|
|**2025-11-12**|**APEX: Action Priors Enable Efficient Exploration for Robust Motion Tracking on Legged Robots**|Guillaume Sartoretti Team|[2511.09091](http://arxiv.org/abs/2511.09091)|null|
|**2025-11-12**|**SMF-VO: Direct Ego-Motion Estimation via Sparse Motion Fields**|Jongwoo Lim Team|[2511.09072](http://arxiv.org/abs/2511.09072)|null|
|**2025-11-12**|**A Shared Control Framework for Mobile Robots with Planning-Level Intention Prediction**|Hesheng Wang Team|[2511.08912](http://arxiv.org/abs/2511.08912)|null|
|**2025-11-11**|**ATOM-CBF: Adaptive Safe Perception-Based Control under Out-of-Distribution Measurements**|Navid Azizan Team|[2511.08741](http://arxiv.org/abs/2511.08741)|null|
|**2025-11-11**|**A CODECO Case Study and Initial Validation for Edge Orchestration of Autonomous Mobile Robots**|R. C. Sofia Team|[2511.08354](http://arxiv.org/abs/2511.08354)|null|
|**2025-11-11**|**Learning Omnidirectional Locomotion for a Salamander-Like Quadruped Robot**|Xian Guo Team|[2511.08299](http://arxiv.org/abs/2511.08299)|null|
|**2025-11-11**|**X-IONet: Cross-Platform Inertial Odometry Network with Dual-Stage Attention**|Changhao Chen Team|[2511.08277](http://arxiv.org/abs/2511.08277)|null|
|**2025-11-11**|**Dual-MPC Footstep Planning for Robust Quadruped Locomotion**|Kyung-Soo Kim Team|[2511.07921](http://arxiv.org/abs/2511.07921)|null|
|**2025-11-11**|**Virtual Traffic Lights for Multi-Robot Navigation: Decentralized Planning with Centralized Conflict Resolution**|Akansel Cosgun Team|[2511.07811](http://arxiv.org/abs/2511.07811)|null|
|**2025-11-10**|**Automated Generation of Continuous-Space Roadmaps for Routing Mobile Robot Fleets**|Kai Furmans Team|[2511.07175](http://arxiv.org/abs/2511.07175)|null|
|**2025-11-10**|**Multi-Agent Reinforcement Learning for Deadlock Handling among Autonomous Mobile Robots**|Marcel Müller Team|[2511.07071](http://arxiv.org/abs/2511.07071)|**[link](https://github.com/Nerozud/dl_reference_models)**|
|**2025-11-09**|**Koopman global linearization of contact dynamics for robot locomotion and manipulation enables elaborate control**|H. Harry Asada Team|[2511.06515](http://arxiv.org/abs/2511.06515)|null|
|**2025-11-09**|**Adaptive PID Control for Robotic Systems via Hierarchical Meta-Learning and Reinforcement Learning with Physics-Based Data Augmentation**|ShengWen Yu Team|[2511.06500](http://arxiv.org/abs/2511.06500)|null|
|**2025-11-07**|**Lite VLA: Efficient Vision-Language-Action Control on CPU-Bound Edge Robots**|Mrinmoy Sarkar Team|[2511.05642](http://arxiv.org/abs/2511.05642)|null|
|**2025-11-07**|**Stable and Robust SLIP Model Control via Energy Conservation-Based Feedback Cancellation for Quadrupedal Applications**|Christian Hubicki Team|[2511.05402](http://arxiv.org/abs/2511.05402)|null|
|**2025-11-05**|**OneOcc: Semantic Occupancy Prediction for Legged Robots with a Single Panoramic Camera**|Kaiwei Wang Team|[2511.03571](http://arxiv.org/abs/2511.03571)|**[link](https://github.com/MasterHow/OneOcc)**|
|**2025-11-05**|**ROSBag MCP Server: Analyzing Robot Data with LLMs for Agentic Embodied AI Applications**|Giovanni Toffetti Team|[2511.03497](http://arxiv.org/abs/2511.03497)|null|
|**2025-11-05**|**Learning Natural and Robust Hexapod Locomotion over Complex Terrains via Motion Priors based on Deep Reinforcement Learning**|Feng Gao Team|[2511.03167](http://arxiv.org/abs/2511.03167)|null|
|**2025-11-04**|**Keeping it Local, Tiny and Real: Automated Report Generation on Edge Computing Devices for Mechatronic-Based Cognitive Systems**|Jürgen Graf Team|[2511.02507](http://arxiv.org/abs/2511.02507)|null|
|**2025-11-04**|**From the Laboratory to Real-World Application: Evaluating Zero-Shot Scene Interpretation on Edge Devices for Mobile Robotics**|Jürgen Graf Team|[2511.02427](http://arxiv.org/abs/2511.02427)|null|
|**2025-11-04**|**SuckTac: Camera-based Tactile Sucker for Unstructured Surface Perception and Interaction**|Guoying Gu Team|[2511.02294](http://arxiv.org/abs/2511.02294)|null|
|**2025-11-03**|**Hybrid Neural Network-Based Indoor Localisation System for Mobile Robots Using CSI Data in a Robotics Simulator**|Manuel Castillo-Cara Team|[2511.01797](http://arxiv.org/abs/2511.01797)|null|
|**2025-11-03**|**Design and development of an electronics-free earthworm robot**|Falk J. Tauber Team|[2511.01347](http://arxiv.org/abs/2511.01347)|null|
|**2025-11-03**|**Tackling the Kidnapped Robot Problem via Sparse Feasible Hypothesis Sampling and Reliable Batched Multi-Stage Inference**|Henry Leung Team|[2511.01219](http://arxiv.org/abs/2511.01219)|null|
|**2025-11-02**|**Occlusion-Aware Diffusion Model for Pedestrian Intention Prediction**|He Kong Team|[2511.00858](http://arxiv.org/abs/2511.00858)|null|
|**2025-11-01**|**OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback**|Kailun Yang Team|[2511.00510](http://arxiv.org/abs/2511.00510)|**[link](https://github.com/xifen523/OmniTrack)**|
|**2025-10-30**|**Real-DRL: Teach and Learn in Reality**|Lui Sha Team|[2511.00112](http://arxiv.org/abs/2511.00112)|null|
|**2025-10-31**|**Confined Space Underwater Positioning Using Collaborative Robots**|Keir Groves Team|[2510.27151](http://arxiv.org/abs/2510.27151)|null|
|**2025-10-30**|**NaviTrace: Evaluating Embodied Navigation of Vision-Language Models**|Jonas Frey Team|[2510.26909](http://arxiv.org/abs/2510.26909)|null|
|**2025-10-30**|**Adaptive Trajectory Refinement for Optimization-based Local Planning in Narrow Passages**|Young J. Kim Team|[2510.26142](http://arxiv.org/abs/2510.26142)|null|
|**2025-10-30**|**Morphology-Aware Graph Reinforcement Learning for Tensegrity Robot Locomotion**|Xiaonan Huang Team|[2510.26067](http://arxiv.org/abs/2510.26067)|null|
|**2025-10-29**|**Development of Implicit-Explicit Control Based Amphibious Centipede-Type Robot and Evaluation of its Mobile Performance**|Koichi Osuka Team|[2510.25280](http://arxiv.org/abs/2510.25280)|null|
|**2025-10-29**|**NanoVLA: Routing Decoupled Vision-Language Understanding for Nano-sized Generalist Robotic Policies**|Jinghui Lu Team|[2510.25122](http://arxiv.org/abs/2510.25122)|null|
|**2025-10-28**|**Smooth path planning with safety margins using Piece-Wise Bezier curves**|Catalin Dosoftei Team|[2510.24972](http://arxiv.org/abs/2510.24972)|null|
|**2025-10-28**|**GroundLoc: Efficient Large-Scale Outdoor LiDAR-Only Localization**|Daniel Goehring Team|[2510.24623](http://arxiv.org/abs/2510.24623)|null|
|**2025-10-28**|**Dynamically-Consistent Trajectory Optimization for Legged Robots via Contact Point Decomposition**|Hae-Won Park Team|[2510.24069](http://arxiv.org/abs/2510.24069)|null|
|**2025-10-28**|**Balanced Collaborative Exploration via Distributed Topological Graph Voronoi Partition**|Meiqin Liu Team|[2510.24067](http://arxiv.org/abs/2510.24067)|null|
|**2025-10-28**|**VOCALoco: Viability-Optimized Cost-aware Adaptive Locomotion**|Hsiu-Chin Lin Team|[2510.23997](http://arxiv.org/abs/2510.23997)|null|
|**2025-10-27**|**Stand, Walk, Navigate: Recovery-Aware Visual Navigation on a Low-Cost Wheeled Quadruped**|Diego Quiroz Team|[2510.23902](http://arxiv.org/abs/2510.23902)|null|
|**2025-10-27**|**Combining High Level Scheduling and Low Level Control to Manage Fleets of Mobile Robots**|Knut Åkesson Team|[2510.23129](http://arxiv.org/abs/2510.23129)|null|
|**2025-10-27**|**Seq-DeepIPC: Sequential Sensing for End-to-End Control in Legged Robot Navigation**|Jun Miura Team|[2510.23057](http://arxiv.org/abs/2510.23057)|null|
|**2025-10-26**|**Learning Neural Observer-Predictor Models for Limb-level Sampling-based Locomotion Planning**|Guoquan Huang Team|[2510.22789](http://arxiv.org/abs/2510.22789)|null|
|**2025-10-25**|**Separation of Unconscious Robots with Obstructed Visibility**|Partha Sarathi Mandal Team|[2510.22434](http://arxiv.org/abs/2510.22434)|null|
|**2025-10-17**|**Real-Time QP Solvers: A Concise Review and Practical Guide Towards Legged Robots**|Van Nam Dinh Team|[2510.21773](http://arxiv.org/abs/2510.21773)|null|
|**2025-09-15**|**When Robots Say No: Temporal Trust Recovery Through Explanation**|Edmund R. Hunt Team|[2510.21716](http://arxiv.org/abs/2510.21716)|null|
|**2025-10-24**|**AURASeg: Attention Guided Upsampling with Residual Boundary-Assistive Refinement for Drivable-Area Segmentation**|Sridevi. M Team|[2510.21536](http://arxiv.org/abs/2510.21536)|null|
|**2025-10-24**|**PREVENT: Proactive Risk Evaluation and Vigilant Execution of Tasks for Mobile Robotic Chemists using Multi-Modal Behavior Trees**|Andrew Ian Cooper Team|[2510.21438](http://arxiv.org/abs/2510.21438)|null|
|**2025-10-24**|**Load-bearing Assessment for Safe Locomotion of Quadruped Robots on Collapsing Terrain**|Victor Barasuol Team|[2510.21369](http://arxiv.org/abs/2510.21369)|null|
|**2025-10-23**|**VAMOS: A Hierarchical Vision-Language-Action Model for Capability-Modulated and Steerable Navigation**|Abhishek Gupta Team|[2510.20818](http://arxiv.org/abs/2510.20818)|null|
|**2025-10-22**|**Control Barrier Functions for the Full Class of Signal Temporal Logic Tasks using Spatiotemporal Tubes**|Pushpak Jagtap Team|[2510.19595](http://arxiv.org/abs/2510.19595)|null|
|**2025-10-21**|**Safe Active Navigation and Exploration for Planetary Environments Using Proprioceptive Measurements**|Feifei Qian Team|[2510.19101](http://arxiv.org/abs/2510.19101)|null|
|**2025-10-21**|**Towards Proprioceptive Terrain Mapping with Quadruped Robots for Exploration in Planetary Permanently Shadowed Regions**|Claudio Semini Team|[2510.18986](http://arxiv.org/abs/2510.18986)|null|
|**2025-10-21**|**Online Object-Level Semantic Mapping for Quadrupeds in Real-World Environments**|Claudio Semini Team|[2510.18776](http://arxiv.org/abs/2510.18776)|null|
|**2025-10-21**|**Sharing the Load: Distributed Model-Predictive Control for Precise Multi-Rover Cargo Transport**|Timothy D. Barfoot Team|[2510.18766](http://arxiv.org/abs/2510.18766)|null|
|**2025-10-21**|**Towards An Adaptive Locomotion Strategy For Quadruped Rovers: Quantifying When To Slide Or Walk On Planetary Slopes**|Claudio Semini Team|[2510.18678](http://arxiv.org/abs/2510.18678)|null|
|**2025-10-21**|**Quadrupeds for Planetary Exploration: Field Testing Control Algorithms on an Active Volcano**|Frank Kirchner Team|[2510.18600](http://arxiv.org/abs/2510.18600)|null|
|**2025-10-21**|**MPC-based motion planning for non-holonomic systems in non-convex domains**|Fabrizio Dabbene Team|[2510.18402](http://arxiv.org/abs/2510.18402)|null|
|**2025-10-21**|**PGTT: Phase-Guided Terrain Traversal for Perceptive Legged Locomotion**|Konstantinos Chatzilygeroudis Team|[2510.18348](http://arxiv.org/abs/2510.18348)|null|
|**2025-10-20**|**An adaptive hierarchical control framework for quadrupedal robots in planetary exploration**|Frank Kirchner Team|[2510.17249](http://arxiv.org/abs/2510.17249)|null|
|**2025-10-20**|**Pole-Image: A Self-Supervised Pole-Anchored Descriptor for Long-Term LiDAR Localization and Map Maintenance**|Kanji Tanaka Team|[2510.17237](http://arxiv.org/abs/2510.17237)|null|
|**2025-10-20**|**A Data-Driven Framework for Online Mitigation of False Data Injection Signals in Networked Control Systems**|Mohammadamin Lari Team|[2510.17155](http://arxiv.org/abs/2510.17155)|null|
|**2025-10-19**|**Adaptive Invariant Extended Kalman Filter for Legged Robot State Estimation**|Dong Jin Hyun Team|[2510.16755](http://arxiv.org/abs/2510.16755)|null|
|**2025-10-17**|**LVI-Q: Robust LiDAR-Visual-Inertial-Kinematic Odometry for Quadruped Robots Using Tightly-Coupled and Efficient Alternating Optimization**|Hyun Myung Team|[2510.15220](http://arxiv.org/abs/2510.15220)|null|
|**2025-10-16**|**Further Results on Safety-Critical Stabilization of Force-Controlled Nonholonomic Mobile Robots**|Guangwei Wang Team|[2510.14931](http://arxiv.org/abs/2510.14931)|null|
|**2025-10-16**|**Generative Models From and For Sampling-Based MPC: A Bootstrapped Approach For Adaptive Contact-Rich Manipulation**|Simon Le Cleac'h Team|[2510.14643](http://arxiv.org/abs/2510.14643)|null|
|**2025-10-16**|**Proprioceptive Image: An Image Representation of Proprioceptive Data from Quadruped Robots for Contact Estimation Learning**|Claudio Semini Team|[2510.14612](http://arxiv.org/abs/2510.14612)|null|
|**2025-09-01**|**Choreographing Trash Cans: On Speculative Futures of Weak Robots in Public Spaces**|Lea Luka Sikau Team|[2510.13810](http://arxiv.org/abs/2510.13810)|null|
|**2025-10-15**|**Bridge the Gap: Enhancing Quadruped Locomotion with Vertical Ground Perturbations**|André Seyfarth Team|[2510.13488](http://arxiv.org/abs/2510.13488)|null|
|**2025-10-14**|**The Omega Turn: A General Turning Template for Elongate Robots**|Daniel I. Goldman Team|[2510.12970](http://arxiv.org/abs/2510.12970)|null|
|**2025-10-14**|**Autonomous Legged Mobile Manipulation for Lunar Surface Operations via Constrained Reinforcement Learning**|Jorge Pomares Team|[2510.12684](http://arxiv.org/abs/2510.12684)|null|
|**2025-10-14**|**Pretraining in Actor-Critic Reinforcement Learning for Robot Locomotion**|Marco Hutter Team|[2510.12363](http://arxiv.org/abs/2510.12363)|null|
|**2025-10-14**|**PolygMap: A Perceptive Locomotion Framework for Humanoid Robot Stair Climbing**|Yucong Wu Team|[2510.12346](http://arxiv.org/abs/2510.12346)|null|
|**2025-10-14**|**Learning Social Navigation from Positive and Negative Demonstrations and Rule-Based Specifications**|Sungjoon Choi Team|[2510.12215](http://arxiv.org/abs/2510.12215)|**[link](https://chanwookim971024.github.io/PioneeR/)**|
|**2025-10-13**|**Simultaneous Calibration of Noise Covariance and Kinematics for State Estimation of Legged Robots via Bi-level Optimization**|Xiaobin Xiong Team|[2510.11539](http://arxiv.org/abs/2510.11539)|null|
|**2025-10-13**|**Adap-RPF: Adaptive Trajectory Sampling for Robot Person Following in Dynamic Crowded Environments**|Hong Zhang Team|[2510.11308](http://arxiv.org/abs/2510.11308)|**[link](https://adap-rpf.github.io/)**|
|**2025-10-12**|**Contact Sensing via Joint Torque Sensors and a Force/Torque Sensor for Legged Robots**|Yanran Ding Team|[2510.10843](http://arxiv.org/abs/2510.10843)|null|
|**2025-10-12**|**Real2USD: Scene Representations in Universal Scene Description Language**|Pratik Chaudhari Team|[2510.10778](http://arxiv.org/abs/2510.10778)|null|
|**2025-10-12**|**Gain Tuning Is Not What You Need: Reward Gain Adaptation for Constrained Locomotion Learning**|Poramate Manoonpong Team|[2510.10759](http://arxiv.org/abs/2510.10759)|null|
|**2025-10-11**|**Towards Safe Maneuvering of Double-Ackermann-Steering Robots with a Soft Actor-Critic Framework**|Olivier Ly Team|[2510.10332](http://arxiv.org/abs/2510.10332)|null|
|**2025-10-11**|**ATRos: Learning Energy-Efficient Agile Locomotion for Wheeled-legged Robots**|Mingyu Zhang Team|[2510.09980](http://arxiv.org/abs/2510.09980)|null|
|**2025-10-11**|**LLM-HBT: Dynamic Behavior Tree Construction for Adaptive Coordination in Heterogeneous Robots**|Changju Wu Team|[2510.09963](http://arxiv.org/abs/2510.09963)|null|
|**2025-10-10**|**HANDO: Hierarchical Autonomous Navigation and Dexterous Omni-loco-manipulation**|Qingyi Si Team|[2510.09221](http://arxiv.org/abs/2510.09221)|null|
|**2025-10-10**|**Robust Visual Teach-and-Repeat Navigation with Flexible Topo-metric Graph Map Representation**|Zonghai Chen Team|[2510.09089](http://arxiv.org/abs/2510.09089)|null|
|**2025-10-09**|**Whole Body Model Predictive Control for Spin-Aware Quadrupedal Table Tennis**|Zhaoming Xie Team|[2510.08754](http://arxiv.org/abs/2510.08754)|null|
|**2025-10-09**|**NovaFlow: Zero-Shot Manipulation via Actionable Flow from Generated Videos**|Jiahui Fu Team|[2510.08568](http://arxiv.org/abs/2510.08568)|null|
|**2025-10-09**|**GraphEnet: Event-driven Human Pose Estimation with a Graph Neural Network**|Chiara Bartolozzi Team|[2510.07990](http://arxiv.org/abs/2510.07990)|null|
|**2025-10-08**|**FLEET: Formal Language-Grounded Scheduling for Heterogeneous Robot Teams**|David Handelman Team|[2510.07417](http://arxiv.org/abs/2510.07417)|null|
|**2025-10-08**|**DPL: Depth-only Perceptive Humanoid Locomotion via Realistic Depth Synthesis and Cross-Attention Terrain Reconstruction**|Qiang Zhang Team|[2510.07152](http://arxiv.org/abs/2510.07152)|null|
|**2025-10-08**|**Sampling Strategies for Robust Universal Quadrupedal Locomotion Policies**|Ioannis Havoutis Team|[2510.07094](http://arxiv.org/abs/2510.07094)|null|
|**2025-10-08**|**HARP-NeXt: High-Speed and Accurate Range-Point Fusion Network for 3D LiDAR Semantic Segmentation**|Jean-Emmanuel Deschaud Team|[2510.06876](http://arxiv.org/abs/2510.06876)|null|
|**2025-10-07**|**Constrained Natural Language Action Planning for Resilient Embodied Systems**|Mathias Unberath Team|[2510.06357](http://arxiv.org/abs/2510.06357)|null|
|**2025-10-07**|**EmbodiedCoder: Parameterized Embodied Mobile Manipulation via Modern Coding Model**|Zhaoxiang Zhang Team|[2510.06207](http://arxiv.org/abs/2510.06207)|**[link](https://embodiedcoder.github.io/EmbodiedCoder/)**|
|**2025-10-07**|**Toward Model Matching for Remotely Controlled Differential Drive Robotic Vehicles**|Anastasios Dimakakos Team|[2510.06081](http://arxiv.org/abs/2510.06081)|null|
|**2025-10-07**|**Learning to Crawl: Latent Model-Based Reinforcement Learning for Soft Robotic Adaptive Locomotion**|Robin Chhabra Team|[2510.05957](http://arxiv.org/abs/2510.05957)|null|
|**2025-10-06**|**AD-NODE: Adaptive Dynamics Learning with Neural ODEs for Mobile Robots Control**|Tarek Zohdi Team|[2510.05443](http://arxiv.org/abs/2510.05443)|null|
|**2025-10-06**|**Walking, Rolling, and Beyond: First-Principles and RL Locomotion on a TARS-Inspired Robot**|Abhishek Warrier Team|[2510.05001](http://arxiv.org/abs/2510.05001)|null|
|**2025-10-06**|**A Comparative Study of Vision Transformers and CNNs for Few-Shot Rigid Transformation and Fundamental Matrix Estimation**|Inna Stainvas Team|[2510.04794](http://arxiv.org/abs/2510.04794)|null|
|**2025-10-06**|**OKVIS2-X: Open Keyframe-based Visual-Inertial SLAM Configurable with Dense Depth or LiDAR, and GNSS**|Stefan Leutenegger Team|[2510.04612](http://arxiv.org/abs/2510.04612)|null|
|**2025-10-05**|**HEHA: Hierarchical Planning for Heterogeneous Multi-Robot Exploration of Unknown Environments**|Zhongqiang Ren Team|[2510.04161](http://arxiv.org/abs/2510.04161)|null|
|**2025-10-04**|**Trajectory prediction for heterogeneous agents: A performance analysis on small and imbalanced datasets**|Achim J. Lilienthal Team|[2510.03776](http://arxiv.org/abs/2510.03776)|null|
|**2025-10-03**|**Metrics vs Surveys: Can Quantitative Measures Replace Human Surveys in Social Robot Navigation? A Correlation Analysis**|Marcello Chiaberge Team|[2510.02941](http://arxiv.org/abs/2510.02941)|null|
|**2025-10-03**|**Point Cloud-Based Control Barrier Functions for Model Predictive Control in Safety-Critical Navigation of Autonomous Mobile Robots**|Shi-Lu Dai Team|[2510.02885](http://arxiv.org/abs/2510.02885)|null|
|**2025-10-03**|**Novel UWB Synthetic Aperture Radar Imaging for Mobile Robot Mapping**|U-Xuan Tan Team|[2510.02874](http://arxiv.org/abs/2510.02874)|**[link](https://ipin-conference.org/2025/)**|
|**2025-10-03**|**A Control-Barrier-Function-Based Algorithm for Policy Adaptation in Reinforcement Learning**|Shaoshuai Mou Team|[2510.02720](http://arxiv.org/abs/2510.02720)|null|
|**2025-10-02**|**Efficient Optimal Path Planning in Dynamic Environments Using Koopman MPC**|Shima Nazari Team|[2510.02584](http://arxiv.org/abs/2510.02584)|null|
|**2025-10-02**|**SPARC: Spine with Prismatic and Revolute Compliance for Quadruped Robot**|Yue Wang Team|[2510.01984](http://arxiv.org/abs/2510.01984)|null|
|**2025-10-02**|**GreenhouseSplat: A Dataset of Photorealistic Greenhouse Simulations for Mobile Robotics**|Gianni Di Caro Team|[2510.01848](http://arxiv.org/abs/2510.01848)|null|
|**2025-10-02**|**Like Playing a Video Game: Spatial-Temporal Optimization of Foot Trajectories for Controlled Football Kicking in Bipedal Robots**|Peng Lu Team|[2510.01843](http://arxiv.org/abs/2510.01843)|null|
|**2025-10-02**|**What Matters in RL-Based Methods for Object-Goal Navigation? An Empirical Study and A Unified Framework**|Marc Pollefeys Team|[2510.01830](http://arxiv.org/abs/2510.01830)|null|
|**2025-10-02**|**Real-time Multi-Plane Segmentation Based on GPU Accelerated High-Resolution 3D Voxel Mapping for Legged Robot Locomotion**|Masaya Kinoshita Team|[2510.01592](http://arxiv.org/abs/2510.01592)|null|
|**2025-10-01**|**Probabilistic Control Barrier Functions: Safety in Probability for Discrete-Time Stochastic Systems**|Aaron D. Ames Team|[2510.01501](http://arxiv.org/abs/2510.01501)|null|
|**2025-10-01**|**OTFS for Joint Radar and Communication: Algorithms, Prototypes, and Experiments**|Francois Chin Po Shin Team|[2510.00668](http://arxiv.org/abs/2510.00668)|null|
|**2025-09-30**|**Unwinding Rotations Reduces VR Sickness in Nonsimulated Immersive Telepresence**|Timo Ojala Team|[2509.26439](http://arxiv.org/abs/2509.26439)|null|
|**2025-09-30**|**Kinodynamic Motion Planning for Mobile Robot Navigation across Inconsistent World Models**|Thomas M. Howard Team|[2509.26339](http://arxiv.org/abs/2509.26339)|null|
|**2025-09-30**|**Conflict-Based Search and Prioritized Planning for Multi-Agent Path Finding Among Movable Obstacles**|Zhongqiang Ren Team|[2509.26050](http://arxiv.org/abs/2509.26050)|null|
|**2025-09-30**|**Field Calibration of Hyperspectral Cameras for Terrain Inference**|Taşkın Padır Team|[2509.25663](http://arxiv.org/abs/2509.25663)|null|
|**2025-09-29**|**Fast Feature Field ( $\text{F}^3$ ): A Predictive Representation of Events**|Pratik Chaudhari Team|[2509.25146](http://arxiv.org/abs/2509.25146)|null|
|**2025-09-29**|**DRCP: Diffusion on Reinforced Cooperative Perception for Perceiving Beyond Limits**|Chen Sun Team|[2509.24903](http://arxiv.org/abs/2509.24903)|null|
|**2025-09-29**|**APREBot: Active Perception System for Reflexive Evasion Robot**|Jin Song Dong Team|[2509.24733](http://arxiv.org/abs/2509.24733)|null|
|**2025-09-28**|**KiVi: Kinesthetic-Visuospatial Integration for Dynamic and Safe Egocentric Legged Locomotion**|Guillaume Sartoretti Team|[2509.23650](http://arxiv.org/abs/2509.23650)|null|
|**2025-09-27**|**A Novel Narrow Region Detector for Sampling-Based Planners' Efficiency: Match Based Passage Identifier**|Volkan Sezer Team|[2509.23288](http://arxiv.org/abs/2509.23288)|null|
|**2025-09-27**|**SAC-Loco: Safe and Adjustable Compliant Quadrupedal Locomotion**|Cheng Xiang Team|[2509.23223](http://arxiv.org/abs/2509.23223)|null|
|**2025-09-26**|**Good Weights: Proactive, Adaptive Dead Reckoning Fusion for Continuous and Robust Visual SLAM**|Patricio A. Vela Team|[2509.22910](http://arxiv.org/abs/2509.22910)|null|
|**2025-09-26**|**Teleoperator-Aware and Safety-Critical Adaptive Nonlinear MPC for Shared Autonomy in Obstacle Avoidance of Legged Robots**|Kaveh Akbari Hamed Team|[2509.22815](http://arxiv.org/abs/2509.22815)|null|
|**2025-09-20**|**Mobile Robot Localization via Indoor Positioning System and Odometry Fusion**|Oka Mahendra Team|[2509.22693](http://arxiv.org/abs/2509.22693)|null|
|**2025-09-26**|**Effect of Gait Design on Proprioceptive Sensing of Terrain Properties in a Quadrupedal Robot**|Feifei Qian Team|[2509.22065](http://arxiv.org/abs/2509.22065)|null|
|**2025-09-26**|**An Adaptive ICP LiDAR Odometry Based on Reliable Initial Pose**|Zhe Xu Team|[2509.22058](http://arxiv.org/abs/2509.22058)|null|
|**2025-09-26**|**Learning Multi-Skill Legged Locomotion Using Conditional Adversarial Motion Priors**|Qinchuan Li Team|[2509.21810](http://arxiv.org/abs/2509.21810)|null|
|**2025-09-26**|**On Suboptimal Safety-Critical Tracking Controller Design**|Saber Omidi Team|[2509.21726](http://arxiv.org/abs/2509.21726)|null|
|**2025-09-25**|**Autonomous UAV-Quadruped Docking in Complex Terrains via Active Posture Alignment and Constraint-Aware Control**|Bin He Team|[2509.21571](http://arxiv.org/abs/2509.21571)|null|
|**2025-09-25**|**SLAM-Free Visual Navigation with Hierarchical Vision-Language Perception and Coarse-to-Fine Semantic Topological Planning**|Jun Ma Team|[2509.20739](http://arxiv.org/abs/2509.20739)|null|
|**2025-09-25**|**Learning Terrain-Specialized Policies for Adaptive Locomotion in Challenging Environments**|Marcelo Becker Team|[2509.20635](http://arxiv.org/abs/2509.20635)|null|
|**2025-09-24**|**A Biomimetic Vertebraic Soft Robotic Tail for High-Speed, High-Force Dynamic Maneuvering**|Chaoyang Song Team|[2509.20219](http://arxiv.org/abs/2509.20219)|null|
|**2025-09-24**|**MARG: MAstering Risky Gap Terrains for Legged Robots with Elevation Mapping**|Peng Lu Team|[2509.20036](http://arxiv.org/abs/2509.20036)|null|
|**2025-09-24**|**DynaFlow: Dynamics-embedded Flow Matching for Physically Consistent Motion Generation from State-only Demonstrations**|Hae-Won Park Team|[2509.19804](http://arxiv.org/abs/2509.19804)|null|
|**2025-09-23**|**Spectral Signature Mapping from RGB Imagery for Terrain-Aware Navigation**|Taskin Padir Team|[2509.19105](http://arxiv.org/abs/2509.19105)|null|
|**2025-09-22**|**Semantic-Aware Particle Filter for Reliable Vineyard Robot Localisation**|Riccardo Polvara Team|[2509.18342](http://arxiv.org/abs/2509.18342)|null|
|**2025-09-22**|**The Surprising Effectiveness of Linear Models for Whole-Body Model-Predictive Control**|Zachary Manchester Team|[2509.17884](http://arxiv.org/abs/2509.17884)|**[link](https://linearwalking.github.io/)**|
|**2025-09-22**|**GeCCo -- a Generalist Contact-Conditioned Policy for Loco-Manipulation Skills on Legged Robots**|Ioannis Havoutis Team|[2509.17582](http://arxiv.org/abs/2509.17582)|**[link](https://youtu.be/o8Dd44MkG2E)**|
|**2025-09-22**|**GroundGazer: Camera-based indoor localization of mobile robots with millimeter accuracy at low cost**|Bin Yang Team|[2509.17346](http://arxiv.org/abs/2509.17346)|null|
|**2025-09-22**|**Investigation of ArUco Marker Placement for Planar Indoor Localization**|Bin Yang Team|[2509.17345](http://arxiv.org/abs/2509.17345)|null|
|**2025-09-21**|**Task-Oriented Communications for 3D Scene Representation: Balancing Timeliness and Fidelity**|David Flynn Team|[2509.17282](http://arxiv.org/abs/2509.17282)|null|
|**2025-09-21**|**Delay compensation of multi-input distinct delay nonlinear systems via neural operators**|Yuanyuan Shi Team|[2509.17131](http://arxiv.org/abs/2509.17131)|null|
|**2025-09-19**|**Subteaming and Adaptive Formation Control for Coordinated Multi-Robot Navigation**|Hao Zhang Team|[2509.16412](http://arxiv.org/abs/2509.16412)|null|
|**2025-09-19**|**Latent Conditioned Loco-Manipulation Using Motion Priors**|Olivier Stasse Team|[2509.16061](http://arxiv.org/abs/2509.16061)|**[link](https://gepetto.github.io/LaCoLoco/)**|
|**2025-09-19**|**A Matter of Height: The Impact of a Robotic Object on Human Compliance**|Hadas Erel Team|[2509.16032](http://arxiv.org/abs/2509.16032)|null|
|**2025-09-19**|**An MPC framework for efficient navigation of mobile robots in cluttered environments**|Melanie Zeilinger Team|[2509.15917](http://arxiv.org/abs/2509.15917)|**[link](https://github.com/IntelligentControlSystems/ClutteredEnvironment)**|
|**2025-09-19**|**Indoor Positioning Based on Active Radar Sensing and Passive Reflectors: Reflector Placement Optimization**|Bin Yang Team|[2509.15613](http://arxiv.org/abs/2509.15613)|null|
|**2025-09-19**|**STARC: See-Through-Wall Augmented Reality Framework for Human-Robot Collaboration in Emergency Response**|Lihua Xie Team|[2509.15507](http://arxiv.org/abs/2509.15507)|null|
|**2025-09-18**|**DIPP: Discriminative Impact Point Predictor for Catching Diverse In-Flight Objects**|Takamitsu Matsubara Team|[2509.15254](http://arxiv.org/abs/2509.15254)|null|
|**2025-09-18**|**PERAL: Perception-Aware Motion Control for Passive LiDAR Excitation in Spherical Robots**|Lihua Xie Team|[2509.14915](http://arxiv.org/abs/2509.14915)|null|
|**2025-09-18**|**Scalable Multi-Objective Robot Reinforcement Learning through Gradient Conflict Resolution**|David Howard Team|[2509.14816](http://arxiv.org/abs/2509.14816)|null|
|**2025-09-17**|**Multi-Quadruped Cooperative Object Transport: Learning Decentralized Pinch-Lift-Move**|Alan Fern Team|[2509.14342](http://arxiv.org/abs/2509.14342)|null|
|**2025-09-17**|**Whole-body Motion Control of an Omnidirectional Wheel-Legged Mobile Manipulator via Contact-Aware Dynamic Optimization**|Yiqun Li Team|[2509.14010](http://arxiv.org/abs/2509.14010)|null|
|**2025-09-17**|**How Fly Neural Perception Mechanisms Enhance Visuomotor Control of Micro Robots**|Qinbing Fu Team|[2509.13827](http://arxiv.org/abs/2509.13827)|null|
|**2025-09-17**|**EZREAL: Enhancing Zero-Shot Outdoor Robot Navigation toward Distant Targets under Varying Visibility**|Hong Zhang Team|[2509.13720](http://arxiv.org/abs/2509.13720)|**[link](https://tianlezeng.github.io/EzReal/)**|
|**2025-09-16**|**Collaborative Loco-Manipulation for Pick-and-Place Tasks with Dynamic Reward Curriculum**|Stelian Coros Team|[2509.13239](http://arxiv.org/abs/2509.13239)|null|
|**2025-09-16**|**Empowering Multi-Robot Cooperation via Sequential World Models**|Dongbin Zhao Team|[2509.13095](http://arxiv.org/abs/2509.13095)|null|
|**2025-09-16**|**DVDP: An End-to-End Policy for Mobile Robot Visual Docking with RGB-D Perception**|Shenghai Yuan Team|[2509.13024](http://arxiv.org/abs/2509.13024)|null|
|**2025-09-16**|**Integrating Trajectory Optimization and Reinforcement Learning for Quadrupedal Jumping with Terrain-Adaptive Landing**|Donglin Wang Team|[2509.12776](http://arxiv.org/abs/2509.12776)|null|
|**2025-09-15**|**Bio-inspired tail oscillation enables robot fast crawling on deformable granular terrains**|Feifei Qian Team|[2509.12468](http://arxiv.org/abs/2509.12468)|null|
|**2025-09-15**|**Synthetic vs. Real Training Data for Visual Navigation**|Joni-Kristian Kämäräinen Team|[2509.11791](http://arxiv.org/abs/2509.11791)|null|
|**2025-09-15**|**Time to Play: Simulating Early-Life Animal Dynamics Enhances Robotics Locomotion Discovery**|Antoine Cully Team|[2509.11755](http://arxiv.org/abs/2509.11755)|null|
|**2025-09-15**|**Design and Development of a Remotely Wire-Driven Walking Robot**|Kei Okada Team|[2509.11506](http://arxiv.org/abs/2509.11506)|**[link](https://hatofly.github.io/remote-wire-driven-quadruped/)**|
|**2025-09-15**|**FR-Net: Learning Robust Quadrupedal Fall Recovery on Challenging Terrains through Mass-Contact Prediction**|Peng Lu Team|[2509.11504](http://arxiv.org/abs/2509.11504)|null|
|**2025-09-13**|**Nav-R1: Reasoning and Navigation in Embodied Scenes**|Hao Tang Team|[2509.10884](http://arxiv.org/abs/2509.10884)|null|
|**2025-09-13**|**Follow-Bench: A Unified Motion Planning Benchmark for Socially-Aware Robot Person Following**|Hong Zhang Team|[2509.10796](http://arxiv.org/abs/2509.10796)|**[link](https://follow-bench.github.io/)**|
|**2025-09-12**|**Efficient Learning-Based Control of a Legged Robot in Lunar Gravity**|Marco Hutter Team|[2509.10128](http://arxiv.org/abs/2509.10128)|null|
|**2025-09-11**|**MOFU: Development of a MOrphing Fluffy Unit with Expansion and Contraction Capabilities and Evaluation of the Animacy of Its Movements**|Yoshihiro Nakata Team|[2509.09613](http://arxiv.org/abs/2509.09613)|null|
|**2025-09-11**|**RENet: Fault-Tolerant Motion Control for Quadruped Robots via Redundant Estimator Networks under Visual Collapse**|Lihua Zhang Team|[2509.09283](http://arxiv.org/abs/2509.09283)|null|
|**2025-09-10**|**Calib3R: A 3D Foundation Model for Multi-Camera to Robot Calibration and 3D Metric-Scaled Scene Reconstruction**|Stefano Ghidoni Team|[2509.08813](http://arxiv.org/abs/2509.08813)|null|
|**2025-09-09**|**Real-Time Obstacle Avoidance for a Mobile Robot Using CNN-Based Sensor Fusion**|Lamiaa H. Zain Team|[2509.08095](http://arxiv.org/abs/2509.08095)|null|
|**2025-09-08**|**Embodied Hazard Mitigation using Vision-Language Models for Autonomous Mobile Robots**|Aliasghar Arab Team|[2509.06768](http://arxiv.org/abs/2509.06768)|null|
|**2025-09-08**|**Towards bridging the gap: Systematic sim-to-real transfer for diverse legged robots**|Marco Hutter Team|[2509.06342](http://arxiv.org/abs/2509.06342)|null|
|**2025-09-07**|**Hybrid A* Path Planning with Multi-Modal Motion Extension for Four-Wheel Steering Mobile Robots**|Shoukun Wang Team|[2509.06115](http://arxiv.org/abs/2509.06115)|null|
|**2025-09-07**|**Energy-Efficient Path Planning with Multi-Location Object Pickup for Mobile Robots on Uneven Terrain**|Isma Farah Siddiqui Team|[2509.06061](http://arxiv.org/abs/2509.06061)|null|
|**2025-09-01**|**Plantbot: Integrating Plant and Robot through LLM Modular Agent Networks**|Takashi Ikegami Team|[2509.05338](http://arxiv.org/abs/2509.05338)|null|
|**2025-09-05**|**Robust Model Predictive Control Design for Autonomous Vehicles with Perception-based Observers**|Hamidreza Modares Team|[2509.05201](http://arxiv.org/abs/2509.05201)|null|
|**2025-09-05**|**Ground-Aware Octree-A* Hybrid Path Planning for Memory-Efficient 3D Navigation of Ground Vehicles**|Kyung-Soo Kim Team|[2509.04950](http://arxiv.org/abs/2509.04950)|null|
|**2025-09-05**|**Towards an Accurate and Effective Robot Vision (The Problem of Topological Localization for Mobile Robots)**|Emanuela Boros Team|[2509.04948](http://arxiv.org/abs/2509.04948)|null|
|**2025-09-05**|**Hierarchical Reduced-Order Model Predictive Control for Robust Locomotion on Humanoid Robots**|Aaron D. Ames Team|[2509.04722](http://arxiv.org/abs/2509.04722)|null|
|**2025-09-04**|**EMMA: Scaling Mobile Manipulation via Egocentric Human Data**|Danfei Xu Team|[2509.04443](http://arxiv.org/abs/2509.04443)|null|
|**2025-09-04**|**On the impact of unlimited computational power in OBLOT: consequences for synchronous robots on graphs**|Alfredo Navarra Team|[2509.04383](http://arxiv.org/abs/2509.04383)|null|
|**2025-09-04**|**Odometry Calibration and Pose Estimation of a 4WIS4WID Mobile Wall Climbing Robot**|Bojan Jerbić Team|[2509.04016](http://arxiv.org/abs/2509.04016)|null|
|**2025-09-03**|**CTBC: Contact-Triggered Blind Climbing for Wheeled Bipedal Robots with Instruction Learning and Reinforcement Learning**|Wenlong Liao Team|[2509.02986](http://arxiv.org/abs/2509.02986)|null|
|**2025-09-02**|**Multi-Embodiment Locomotion at Scale with extreme Embodiment Randomization**|Jan Peters Team|[2509.02815](http://arxiv.org/abs/2509.02815)|null|
|**2025-09-02**|**Acrobotics: A Generalist Approach to Quadrupedal Robots' Parkour**|Ioannis Havoutis Team|[2509.02727](http://arxiv.org/abs/2509.02727)|**[link](https://drive.google.com/drive/folders/18h25azbCFfPF4fhSsRfxKrnZo3dPKs_j?usp=sharing)**|
|**2025-09-02**|**OpenGuide: Assistive Object Retrieval in Indoor Spaces for Individuals with Visual Impairments**|Carol Menassa Team|[2509.02425](http://arxiv.org/abs/2509.02425)|null|
|**2025-09-02**|**Enhancing Reliability in LLM-Integrated Robotic Systems: A Unified Approach to Security and Safety**|Jin B. Hong Team|[2509.02163](http://arxiv.org/abs/2509.02163)|null|
|**2025-09-02**|**Geometric Control of Mechanical Systems with Symmetries Based on Sliding Modes**|Yu Tang Team|[2509.01985](http://arxiv.org/abs/2509.01985)|null|
|**2025-09-01**|**Disentangled Multi-Context Meta-Learning: Unlocking robust and Generalized Task Learning**|Seongil Hong Team|[2509.01297](http://arxiv.org/abs/2509.01297)|null|
|**2025-09-01**|**Metamorphic Testing of Multimodal Human Trajectory Prediction**|Nassim Belmecheri Team|[2509.01294](http://arxiv.org/abs/2509.01294)|null|
|**2025-08-30**|**Gray-Box Computed Torque Control for Differential-Drive Mobile Robot Tracking**|Arman Javan Sekhavat Pishkhani Team|[2509.00571](http://arxiv.org/abs/2509.00571)|null|
|**2025-08-30**|**A Layered Control Perspective on Legged Locomotion: Embedding Reduced Order Models via Hybrid Zero Dynamics**|Aaron D. Ames Team|[2509.00294](http://arxiv.org/abs/2509.00294)|null|
|**2025-08-29**|**First Order Model-Based RL through Decoupled Backpropagation**|Ludovic Righetti Team|[2509.00215](http://arxiv.org/abs/2509.00215)|**[link](https://machines-in-motion.github.io/DMO/)**|
|**2025-08-29**|**Can a mobile robot learn from a pedestrian model to prevent the sidewalk salsa?**|David Abbink Team|[2508.21690](http://arxiv.org/abs/2508.21690)|null|
|**2025-08-27**|**A Standing Support Mobility Robot for Enhancing Independence in Elderly Daily Living**|Yasuhisa Hirata Team|[2508.19816](http://arxiv.org/abs/2508.19816)|null|
|**2025-08-27**|**Beyond Pairwise Comparisons: Unveiling Structural Landscape of Mobile Robot Models**|Koichi Wada Team|[2508.19805](http://arxiv.org/abs/2508.19805)|null|
|**2025-08-26**|**FlipWalker: Jacob's Ladder toy-inspired robot for locomotion across diverse, complex terrain**|Matthew A. Robertson Team|[2508.19380](http://arxiv.org/abs/2508.19380)|null|
|**2025-08-25**|**The Effects of Communication Delay on Human Performance and Neurocognitive Responses in Mobile Robot Teleoperation**|Junqiang Xi Team|[2508.18074](http://arxiv.org/abs/2508.18074)|null|
|**2025-08-25**|**SEBVS: Synthetic Event-based Visual Servoing for Robot Navigation and Manipulation**|Bharatesh Chakravarthi Team|[2508.17643](http://arxiv.org/abs/2508.17643)|null|
|**2025-08-24**|**Optimizing Grasping in Legged Robots: A Deep Learning Approach to Loco-Manipulation**|Marcelo Becker Team|[2508.17466](http://arxiv.org/abs/2508.17466)|null|
|**2025-08-23**|**Fiducial Marker Splatting for High-Fidelity Robotics Simulations**|Gianni Di Caro Team|[2508.17012](http://arxiv.org/abs/2508.17012)|null|
|**2025-08-22**|**Hierarchical Decision-Making for Autonomous Navigation: Integrating Deep Reinforcement Learning and Fuzzy Logic in Four-Wheel Independent Steering and Driving Systems**|Peng Chen Team|[2508.16574](http://arxiv.org/abs/2508.16574)|null|
|**2025-08-22**|**Terrain Classification for the Spot Quadrupedal Mobile Robot Using Only Proprioceptive Sensing**|Joshua A. Marshall Team|[2508.16504](http://arxiv.org/abs/2508.16504)|null|
|**2025-08-21**|**Universal Dancing by Luminous Robots under Sequential Schedulers**|Nicola Santoro Team|[2508.15484](http://arxiv.org/abs/2508.15484)|null|
|**2025-08-21**|**Hardware Implementation of a Zero-Prior-Knowledge Approach to Lifelong Learning in Kinematic Control of Tendon-Driven Quadrupeds**|Francisco J. Valero-Cuevas Team|[2508.15160](http://arxiv.org/abs/2508.15160)|null|
|**2025-08-20**|**A Vision-Based Shared-Control Teleoperation Scheme for Controlling the Robotic Arm of a Four-Legged Robot**|Marcelo Becker Team|[2508.14994](http://arxiv.org/abs/2508.14994)|null|
|**2025-08-20**|**An Informative Planning Framework for Target Tracking and Active Mapping in Dynamic Environments with ASVs**|Erlend M. Coates Team|[2508.14636](http://arxiv.org/abs/2508.14636)|null|
|**2025-08-19**|**Lightweight Tracking Control for Computationally Constrained Aerial Systems with the Newton-Raphson Method**|Samuel Coogan Team|[2508.14185](http://arxiv.org/abs/2508.14185)|null|
|**2025-08-19**|**MR6D: Benchmarking 6D Pose Estimation for Mobile Robots**|Alice Kirchheim Team|[2508.13775](http://arxiv.org/abs/2508.13775)|null|
|**2025-08-19**|**The 9th AI City Challenge**|Rama Chellappa Team|[2508.13564](http://arxiv.org/abs/2508.13564)|null|
|**2025-08-19**|**A Three-Level Whole-Body Disturbance Rejection Control Framework for Dynamic Motions in Legged Robots**|Han Ding Team|[2508.13531](http://arxiv.org/abs/2508.13531)|null|
|**2025-08-19**|**Switch4EAI: Leveraging Console Game Platform for Benchmarking Robotic Athletics**|Sehoon Ha Team|[2508.13444](http://arxiv.org/abs/2508.13444)|null|
|**2025-08-18**|**Simultaneous Contact Sequence and Patch Planning for Dynamic Locomotion**|Majid Khadiv Team|[2508.12928](http://arxiv.org/abs/2508.12928)|null|
|**2025-08-18**|**Deformation of the panoramic sphere into an ellipsoid to induce self-motion in telepresence users**|Matti Pouke Team|[2508.12925](http://arxiv.org/abs/2508.12925)|null|
|**2025-08-16**|**Control of Legged Robots using Model Predictive Optimized Path Integral**|Majid Khadiv Team|[2508.11917](http://arxiv.org/abs/2508.11917)|null|
|**2025-08-15**|**Geometry-Aware Predictive Safety Filters on Humanoids: From Poisson Safety Functions to CBF Constrained MPC**|Aaron D. Ames Team|[2508.11129](http://arxiv.org/abs/2508.11129)|null|
|**2025-08-14**|**Synthesis of Deep Neural Networks with Safe Robust Adaptive Control for Reliable Operation of Wheeled Mobile Robots**|Jouni Mattila Team|[2508.10634](http://arxiv.org/abs/2508.10634)|null|
|**2025-08-14**|**MLM: Learning Multi-task Loco-Manipulation Whole-Body Control for Quadruped Robot with Arm**|Xuelong Li Team|[2508.10538](http://arxiv.org/abs/2508.10538)|null|
|**2025-08-14**|**MASH: Cooperative-Heterogeneous Multi-Agent Reinforcement Learning for Single Humanoid Robot Locomotion**|Yanjie Li Team|[2508.10423](http://arxiv.org/abs/2508.10423)|null|
|**2025-08-14**|**BEASST: Behavioral Entropic Gradient based Adaptive Source Seeking for Mobile Robots**|Solmaz S. Kia Team|[2508.10363](http://arxiv.org/abs/2508.10363)|null|
|**2025-08-13**|**PPL: Point Cloud Supervised Proprioceptive Locomotion Reinforcement Learning for Legged Robots in Crawl Spaces**|Chunpeng Lu Team|[2508.09950](http://arxiv.org/abs/2508.09950)|null|
|**2025-08-12**|**Unsupervised Skill Discovery as Exploration for Learning Agile Locomotion**|Sehoon Ha Team|[2508.08982](http://arxiv.org/abs/2508.08982)|null|
|**2025-08-12**|**Communication Efficient Robotic Mixed Reality with Gaussian Splatting Cross-Layer Optimization**|Chengzhong Xu Team|[2508.08624](http://arxiv.org/abs/2508.08624)|null|
|**2025-08-12**|**DeepFleet: Multi-Agent Foundation Models for Mobile Robots**|Joseph W. Durham Team|[2508.08574](http://arxiv.org/abs/2508.08574)|null|
|**2025-08-11**|**ODYSSEY: Open-World Quadrupeds Exploration and Manipulation for Long-Horizon Tasks**|Chunhua Shen Team|[2508.08240](http://arxiv.org/abs/2508.08240)|null|
|**2025-08-11**|**Verti-Arena: A Controllable and Standardized Indoor Testbed for Multi-Terrain Off-Road Autonomy**|Xuesu Xiao Team|[2508.08226](http://arxiv.org/abs/2508.08226)|null|
|**2025-08-11**|**COMponent-Aware Pruning for Accelerated Control Tasks in Latent Space Models**|Daniel Görges Team|[2508.08144](http://arxiv.org/abs/2508.08144)|null|
|**2025-08-11**|**Deep Reinforcement Learning with anticipatory reward in LSTM for Collision Avoidance of Mobile Robots**|François Guérin Team|[2508.07941](http://arxiv.org/abs/2508.07941)|null|
|**2025-08-11**|**SwarmVLM: VLM-Guided Impedance Control for Autonomous Navigation of Heterogeneous Robots in Dynamic Warehousing**|Dzmitry Tsetserukou Team|[2508.07814](http://arxiv.org/abs/2508.07814)|null|
|**2025-08-11**|**AgentWorld: An Interactive Simulation Platform for Scene Construction and Mobile Robotic Manipulation**|Lei Han Team|[2508.07770](http://arxiv.org/abs/2508.07770)|null|
|**2025-08-11**|**LAURON VI: A Six-Legged Robot for Dynamic Walking**|Ruediger Dillmann Team|[2508.07689](http://arxiv.org/abs/2508.07689)|null|
|**2025-08-10**|**AgriVLN: Vision-and-Language Navigation for Agricultural Robots**|Xiang Li Team|[2508.07406](http://arxiv.org/abs/2508.07406)|null|
|**2025-08-09**|**From Data to Safe Mobile Robot Navigation: An Efficient and Modular Robust MPC Design Pipeline**|Laura Ferranti Team|[2508.07045](http://arxiv.org/abs/2508.07045)|null|
|**2025-08-08**|**Learning Causal Structure Distributions for Robust Planning**|Lantao Liu Team|[2508.06742](http://arxiv.org/abs/2508.06742)|null|
|**2025-08-04**|**Symbolic Learning of Interpretable Reduced-Order Models for Jumping Quadruped Robots**|Jiatao Ding Team|[2508.06538](http://arxiv.org/abs/2508.06538)|null|
|**2025-08-08**|**Real-Time 3D Vision-Language Embedding Mapping**|Elmar Rueckert Team|[2508.06291](http://arxiv.org/abs/2508.06291)|null|
|**2025-08-07**|**Towards Generalizable Safety in Crowd Navigation via Conformal Uncertainty Handling**|Jiachen Li Team|[2508.05634](http://arxiv.org/abs/2508.05634)|**[link](https://gen-safe-nav.github.io/.)**|
|**2025-08-07**|**Chemist Eye: A Visual Language Model-Powered System for Safety Monitoring and Robot Decision-Making in Self-Driving Laboratories**|Andrew I. Cooper Team|[2508.05148](http://arxiv.org/abs/2508.05148)|null|
|**2025-08-07**|**MAG-Nav: Language-Driven Object Navigation Leveraging Memory-Reserved Active Grounding**|Yuzhen Liu Team|[2508.05021](http://arxiv.org/abs/2508.05021)|null|
|**2025-08-07**|**Hierarchical Deep Deterministic Policy Gradient for Autonomous Maze Navigation of Mobile Robots**|Hann Woei Ho Team|[2508.04994](http://arxiv.org/abs/2508.04994)|null|
|**2025-08-06**|**Incorporating Stochastic Models of Controller Behavior into Kinodynamic Efficiently Adaptive State Lattices for Mobile Robot Motion Planning in Off-Road Environments**|Thomas M. Howard Team|[2508.04384](http://arxiv.org/abs/2508.04384)|null|
|**2025-08-05**|**CogniPlan: Uncertainty-Guided Path Planning with Conditional Generative Layout Prediction**|Guillaume Sartoretti Team|[2508.03027](http://arxiv.org/abs/2508.03027)|null|
|**2025-08-04**|**Optimal Trajectory Planning in a Vertically Undulating Snake Locomotion using Contact-implicit Optimization**|Alireza Ramezani Team|[2508.02953](http://arxiv.org/abs/2508.02953)|null|
|**2025-08-04**|**QuaDreamer: Controllable Panoramic Video Generation for Quadruped Robots**|Kailun Yang Team|[2508.02512](http://arxiv.org/abs/2508.02512)|**[link](https://github.com/losehu/QuaDreamer)**|
|**2025-08-04**|**Quantum Machine Learning-based Test Oracle for Autonomous Mobile Robots**|Thomas Peyrucain Team|[2508.02407](http://arxiv.org/abs/2508.02407)|null|
|**2025-08-04**|**Vision Language Model-based Testing of Industrial Autonomous Mobile Robots**|Thomas Peyrucain Team|[2508.02338](http://arxiv.org/abs/2508.02338)|null|
|**2025-08-03**|**HALO: Human Preference Aligned Offline Reward Learning for Robot Navigation**|Dinesh Manocha Team|[2508.01539](http://arxiv.org/abs/2508.01539)|null|
|**2025-08-02**|**Coordinated Humanoid Robot Locomotion with Symmetry Equivariant Reinforcement Learning Policy**|Yue Gao Team|[2508.01247](http://arxiv.org/abs/2508.01247)|null|
|**2025-08-02**|**NarraGuide: an LLM-based Narrative Mobile Robot for Remote Place Exploration**|Bilge Mutlu Team|[2508.01235](http://arxiv.org/abs/2508.01235)|null|
|**2025-07-31**|**BarlowWalk: Self-supervised Representation Learning for Legged Robot Terrain-adaptive Locomotion**|Wenfu Xu Team|[2508.00939](http://arxiv.org/abs/2508.00939)|null|
|**2025-08-01**|**OpenScout v1.1 mobile robot: a case study on open hardware continuation**|Charles Fox Team|[2508.00625](http://arxiv.org/abs/2508.00625)|null|
|**2025-08-01**|**A control scheme for collaborative object transportation between a human and a quadruped robot using the MIGHTY suction cup**|Dimitrios Papageorgiou Team|[2508.00584](http://arxiv.org/abs/2508.00584)|null|
|**2025-07-31**|**XRoboToolkit: A Cross-Platform Framework for Robot Teleoperation**|Ning Yang Team|[2508.00097](http://arxiv.org/abs/2508.00097)|**[link](http://xr-robotics.github.io/)**|
|**2025-07-31**|**Multi-Waypoint Path Planning and Motion Control for Non-holonomic Mobile Robots in Agricultural Applications**|Matthias Lorenzen Team|[2507.23350](http://arxiv.org/abs/2507.23350)|null|
|**2025-07-31**|**Quadratic Programming-Based Posture Manipulation and Thrust-vectoring for Agile Dynamic Walking on Narrow Pathways**|Morteza Gharib Team|[2507.23203](http://arxiv.org/abs/2507.23203)|null|

<p align=right>(<a href=#updated-on-20251217>back to top</a>)</p>

## Uncategorized

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2025-12-16**|**MemFlow: Flowing Adaptive Memory for Consistent and Efficient Long Video Narratives**|Hengshuang Zhao Team|[2512.14699](http://arxiv.org/abs/2512.14699)|**[link](https://sihuiji.github.io/MemFlow.github.io/)**|
|**2025-12-16**|**TimeLens: Rethinking Video Temporal Grounding with Multimodal LLMs**|Limin Wang Team|[2512.14698](http://arxiv.org/abs/2512.14698)|**[link](https://timelens-arc-lab.github.io/)**|
|**2025-12-16**|**Spherical Leech Quantization for Visual Tokenization and Generation**|Philipp Krähenbühl Team|[2512.14697](http://arxiv.org/abs/2512.14697)|**[link](https://zhaoyue-zephyrus.github.io/npq/)**|
|**2025-12-16**|**CRISP: Contact-Guided Real2Sim from Monocular Video with Planar Scene Primitives**|Deva Ramanan Team|[2512.14696](http://arxiv.org/abs/2512.14696)|**[link](https://crisp-real2sim.github.io/CRISP-Real2Sim/)**|
|**2025-12-16**|**Native and Compact Structured Latents for 3D Generation**|Jiaolong Yang Team|[2512.14692](http://arxiv.org/abs/2512.14692)|**[link](https://microsoft.github.io/TRELLIS.2/)**|
|**2025-12-16**|**MMGR: Multi-Modal Generative Reasoning**|Junjie Hu Team|[2512.14691](http://arxiv.org/abs/2512.14691)|null|
|**2025-12-16**|**CHIP: Adaptive Compliance for Humanoid Control through Hindsight Perturbation**|Yuke Zhu Team|[2512.14689](http://arxiv.org/abs/2512.14689)|**[link](https://nvlabs.github.io/CHIP/)**|
|**2025-12-16**|**VASA-3D: Lifelike Audio-Driven Gaussian Head Avatars from a Single Image**|Baining Guo Team|[2512.14677](http://arxiv.org/abs/2512.14677)|**[link](https://www.microsoft.com/en-us/research/project/vasa-3d/)**|
|**2025-12-16**|**ART: Articulated Reconstruction Transformer**|Zhao Dong Team|[2512.14671](http://arxiv.org/abs/2512.14671)|**[link](https://kyleleey.github.io/ART/)**|
|**2025-12-16**|**EVOLVE-VLA: Test-Time Training from Environment Feedback for Vision-Language-Action Models**|Mike Zheng Shou Team|[2512.14666](http://arxiv.org/abs/2512.14666)|null|
|**2025-12-16**|**Enhancing Visual Sentiment Analysis via Semiotic Isotopy-Guided Dataset Construction**|Mauro Barni Team|[2512.14665](http://arxiv.org/abs/2512.14665)|null|
|**2025-12-16**|**Focus: A Streaming Concentration Architecture for Efficient Vision-Language Models**|Yiran Chen Team|[2512.14661](http://arxiv.org/abs/2512.14661)|null|
|**2025-12-16**|**WaveSim: A Wavelet-based Multi-scale Similarity Metric for Weather and Climate Fields**|David Lawrence Team|[2512.14656](http://arxiv.org/abs/2512.14656)|null|
|**2025-12-16**|**ViRC: Enhancing Visual Interleaved Mathematical CoT with Reason Chunking**|Zhe Li Team|[2512.14654](http://arxiv.org/abs/2512.14654)|**[link](https://github.com/Leon-LihongWang/ViRC)**|
|**2025-12-16**|**Segmental Attention Decoding With Long Form Acoustic Encodings**|Xiaodan Zhuang Team|[2512.14652](http://arxiv.org/abs/2512.14652)|null|
|**2025-12-16**|**Adaptable Segmentation Pipeline for Diverse Brain Tumors with Radiomic-guided Subtyping and Lesion-Wise Model Ensemble**|Marius George Linguraru Team|[2512.14648](http://arxiv.org/abs/2512.14648)|null|
|**2025-12-16**|**A Multicenter Benchmark of Multiple Instance Learning Models for Lymphoma Subtyping from HE-stained Whole Slide Images**|Carsten Marr Team|[2512.14640](http://arxiv.org/abs/2512.14640)|null|
|**2025-12-16**|**AMD-HookNet++: Evolution of AMD-HookNet with Hybrid CNN-Transformer Feature Enhancement for Glacier Calving Front Segmentation**|Vincent Christlein Team|[2512.14639](http://arxiv.org/abs/2512.14639)|null|
|**2025-12-16**|**Distill Video Datasets into Images**|Yan Yan Team|[2512.14621](http://arxiv.org/abs/2512.14621)|null|
|**2025-12-16**|**JMMMU-Pro: Image-based Japanese Multi-discipline Multimodal Understanding Benchmark via Vibe Benchmark Construction**|Kiyoharu Aizawa Team|[2512.14620](http://arxiv.org/abs/2512.14620)|**[link](https://mmmu-japanese-benchmark.github.io/JMMMU_Pro/)**|
|**2025-12-16**|**Model-Based Reinforcement Learning in Discrete-Action Non-Markovian Reward Decision Processes**|Fabio Patrizi Team|[2512.14617](http://arxiv.org/abs/2512.14617)|null|
|**2025-12-16**|**WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling**|Chunchao Guo Team|[2512.14614](http://arxiv.org/abs/2512.14614)|**[link](https://3d-models.hunyuan.tencent.com/world/)**|
|**2025-12-16**|**FakeRadar: Probing Forgery Outliers to Detect Unknown Deepfake Videos**|Rushi Lan Team|[2512.14601](http://arxiv.org/abs/2512.14601)|null|
|**2025-12-16**|**TUMTraf EMOT: Event-Based Multi-Object Tracking Dataset and Baseline for Traffic Scenarios**|Hu Cao Team|[2512.14595](http://arxiv.org/abs/2512.14595)|null|
|**2025-12-16**|**LLM-driven Knowledge Enhancement for Multimodal Cancer Survival Prediction**|Hao Chen Team|[2512.14594](http://arxiv.org/abs/2512.14594)|null|
|**2025-12-16**|**FoodLogAthl-218: Constructing a Real-World Food Image Dataset Using Dietary Management Applications**|Yoko Yamakata Team|[2512.14574](http://arxiv.org/abs/2512.14574)|null|
|**2025-12-16**|**CLNet: Cross-View Correspondence Makes a Stronger Geo-Localizationer**|Licheng Jiao Team|[2512.14560](http://arxiv.org/abs/2512.14560)|null|
|**2025-12-16**|**Test Time Optimized Generalized AI-based Medical Image Registration Method**|Sudhanya Chatterjee Team|[2512.14556](http://arxiv.org/abs/2512.14556)|null|
|**2025-12-16**|**TAT: Task-Adaptive Transformer for All-in-One Medical Image Restoration**|Yan Xu Team|[2512.14550](http://arxiv.org/abs/2512.14550)|null|
|**2025-12-16**|**HiFi-Portrait: Zero-shot Identity-preserved Portrait Generation with High-fidelity Multi-face Fusion**|Sidan Du Team|[2512.14542](http://arxiv.org/abs/2512.14542)|null|
|**2025-12-16**|**A Graph-Based Forensic Framework for Inferring Hardware Noise of Cloud Quantum Backend**|Swaroop Ghosh Team|[2512.14541](http://arxiv.org/abs/2512.14541)|null|
|**2025-12-16**|**CAPRMIL: Context-Aware Patch Representations for Multiple Instance Learning**|Maria Vakalopoulou Team|[2512.14540](http://arxiv.org/abs/2512.14540)|null|
|**2025-12-16**|**DASP: Self-supervised Nighttime Monocular Depth Estimation with Domain Adaptation of Spatiotemporal Priors**|Wenyin Liu Team|[2512.14536](http://arxiv.org/abs/2512.14536)|null|
|**2025-12-16**|**RecGPT-V2 Technical Report**|Zile Zhou Team|[2512.14503](http://arxiv.org/abs/2512.14503)|null|
|**2025-12-16**|**Native Intelligence Emerges from Large-Scale Clinical Practice: A Retinal Foundation Model with Deployment Efficiency**|Huiqi Li Team|[2512.14499](http://arxiv.org/abs/2512.14499)|null|
|**2025-12-16**|**SignIT: A Comprehensive Dataset and Multimodal Analysis for Italian Sign Language Recognition**|Francesco Ragusa Team|[2512.14489](http://arxiv.org/abs/2512.14489)|null|
|**2025-12-16**|**Hybrid Cognitive IoT with Cooperative Caching and SWIPT-EH: A Hierarchical Reinforcement Learning Framework**|Walaa Hamouda Team|[2512.14488](http://arxiv.org/abs/2512.14488)|null|
|**2025-12-16**|**SuperCLIP: CLIP with Simple Classification Supervision**|Xinggang Wang Team|[2512.14480](http://arxiv.org/abs/2512.14480)|**[link](https://github.com/hustvl/SuperCLIP)**|
|**2025-12-16**|**TACK Tunnel Data (TTD): A Benchmark Dataset for Deep Learning-Based Defect Detection in Tunnels**|Andrea Nascetti Team|[2512.14477](http://arxiv.org/abs/2512.14477)|null|
|**2025-12-16**|**Context-Picker: Dynamic context selection using multi-stage reinforcement learning**|Chao Yu Team|[2512.14465](http://arxiv.org/abs/2512.14465)|null|
|**2025-12-16**|**A4-Agent: An Agentic Framework for Zero-Shot Affordance Reasoning**|Ying-Cong Chen Team|[2512.14442](http://arxiv.org/abs/2512.14442)|null|
|**2025-12-16**|**S2D: Sparse-To-Dense Keymask Distillation for Unsupervised Video Instance Segmentation**|Timo Ropinski Team|[2512.14440](http://arxiv.org/abs/2512.14440)|**[link](https://leonsick.github.io/s2d/)**|
|**2025-12-16**|**VICTOR: Dataset Copyright Auditing in Video Recognition Systems**|Jiming Chen Team|[2512.14439](http://arxiv.org/abs/2512.14439)|null|
|**2025-12-16**|**Score-Based Turbo Message Passing for Plug-and-Play Compressive Imaging**|Ying-Jun Angela Zhang Team|[2512.14435](http://arxiv.org/abs/2512.14435)|null|
|**2025-12-16**|**The Devil is in Attention Sharing: Improving Complex Non-rigid Image Editing Faithfulness via Attention Synergy**|Wen Li Team|[2512.14423](http://arxiv.org/abs/2512.14423)|**[link](https://synps26.github.io/)**|
|**2025-12-16**|**LCMem: A Universal Model for Robust Image Memorization Detection**|Bernhard Kainz Team|[2512.14421](http://arxiv.org/abs/2512.14421)|null|
|**2025-12-16**|**DISCODE: Distribution-Aware Score Decoder for Robust Automatic Evaluation of Image Captioning**|Yusuke Sekikawa Team|[2512.14420](http://arxiv.org/abs/2512.14420)|null|
|**2025-12-16**|**Dual-Axis RCCL: Representation-Complete Convergent Learning for Organic Chemical Space**|Junliang Zhang Team|[2512.14418](http://arxiv.org/abs/2512.14418)|null|
|**2025-12-16**|**Broadening View Synthesis of Dynamic Scenes from Constrained Monocular Videos**|Sarah Ostadabbas Team|[2512.14406](http://arxiv.org/abs/2512.14406)|null|
|**2025-12-16**|**EcoScapes: LLM-Powered Advice for Crafting Sustainable Cities**|Vincent Christlein Team|[2512.14373](http://arxiv.org/abs/2512.14373)|null|
|**2025-12-16**|**A Comprehensive Safety Metric to Evaluate Perception in Autonomous Systems**|Oliver Bringmann Team|[2512.14367](http://arxiv.org/abs/2512.14367)|null|
|**2025-12-16**|**Optimizing Rank for High-Fidelity Implicit Neural Representations**|Benedikt Wiestler Team|[2512.14366](http://arxiv.org/abs/2512.14366)|null|
|**2025-12-16**|**Unified Semantic Transformer for 3D Scene Understanding**|Federico Tombari Team|[2512.14364](http://arxiv.org/abs/2512.14364)|**[link](https://unite-page.github.io/)**|
|**2025-12-16**|**Mimicking Human Visual Development for Learning Robust Image Representations**|Chetan Arora Team|[2512.14360](http://arxiv.org/abs/2512.14360)|null|
|**2025-12-16**|**CoLD Fusion: A Real-time Capable Spline-based Fusion Algorithm for Collective Lane Detection**|Oliver Bringmann Team|[2512.14355](http://arxiv.org/abs/2512.14355)|null|
|**2025-12-16**|**Enhancing Interpretability for Vision Models via Shapley Value Optimization**|Chen Ma Team|[2512.14354](http://arxiv.org/abs/2512.14354)|null|
|**2025-12-16**|**HGS: Hybrid Gaussian Splatting with Static-Dynamic Decomposition for Compact Dynamic View Synthesis**|Yong-Jin Liu Team|[2512.14352](http://arxiv.org/abs/2512.14352)|null|
|**2025-12-16**|**Towards Transferable Defense Against Malicious Image Edits**|Xilin Chen Team|[2512.14341](http://arxiv.org/abs/2512.14341)|null|
|**2025-12-16**|**Vector Prism: Animating Vector Graphics by Stratifying Semantic Structure**|Jaegul Choo Team|[2512.14336](http://arxiv.org/abs/2512.14336)|null|
|**2025-12-16**|**Dual Attention Guided Defense Against Malicious Edits**|Xilin Chen Team|[2512.14333](http://arxiv.org/abs/2512.14333)|null|
|**2025-12-16**|**A data-physics hybrid generative model for patient-specific post-stroke motor rehabilitation using wearable sensor data**|Shuo Gao Team|[2512.14329](http://arxiv.org/abs/2512.14329)|null|
|**2025-12-16**|**Multi-Agent Medical Decision Consensus Matrix System: An Intelligent Collaborative Framework for Oncology MDT Consultations**|Zhenyu Yu Team|[2512.14321](http://arxiv.org/abs/2512.14321)|null|
|**2025-12-16**|**Semantic Mismatch and Perceptual Degradation: A New Perspective on Image Editing Immunity**|Xilin Chen Team|[2512.14320](http://arxiv.org/abs/2512.14320)|null|
|**2025-12-16**|**From YOLO to VLMs: Advancing Zero-Shot and Few-Shot Detection of Wastewater Treatment Plants Using Satellite Imagery in MENA Region**|Garcia Andarcia Mariangel Team|[2512.14312](http://arxiv.org/abs/2512.14312)|null|
|**2025-12-16**|**PSMamba: Progressive Self-supervised Vision Mamba for Plant Disease Recognition**|Mohammad Awrangjeb Team|[2512.14309](http://arxiv.org/abs/2512.14309)|null|
|**2025-12-16**|**A Threshold-Triggered Deep Q-Network-Based Framework for Self-Healing in Autonomic Software-Defined IIoT-Edge Networks**|Madeleine Gibescu Team|[2512.14297](http://arxiv.org/abs/2512.14297)|null|
|**2025-12-16**|**GLM-TTS Technical Report**|Jie Tang Team|[2512.14291](http://arxiv.org/abs/2512.14291)|null|
|**2025-12-16**|**SS4D: Native 4D Generative Model via Structured Spacetime Latents**|Dahua Lin Team|[2512.14284](http://arxiv.org/abs/2512.14284)|null|
|**2025-12-16**|**SPARQL-LLM: Real-Time SPARQL Query Generation from Natural Language Questions**|Tarcisio Mendes de Farias Team|[2512.14277](http://arxiv.org/abs/2512.14277)|null|
|**2025-12-16**|**TUN: Detecting Significant Points in Persistence Diagrams with Deep Learning**|Hongwei Lin Team|[2512.14274](http://arxiv.org/abs/2512.14274)|null|
|**2025-12-16**|**Zoom-Zero: Reinforced Coarse-to-Fine Video Understanding via Temporal Zoom-in**|Ryo Hachiuma Team|[2512.14273](http://arxiv.org/abs/2512.14273)|**[link](https://xiaoqian-shen.github.io/Zoom-Zero/)**|
|**2025-12-16**|**DriverGaze360: OmniDirectional Driver Attention with Object-Level Guidance**|Jason Rambach Team|[2512.14266](http://arxiv.org/abs/2512.14266)|null|
|**2025-12-16**|**Enhancing Visual Programming for Visual Reasoning via Probabilistic Graphs**|Keze Wang Team|[2512.14257](http://arxiv.org/abs/2512.14257)|null|
|**2025-12-16**|**On fractal minimizers and potentials of occupation measures**|Lauri Viitasaari Team|[2512.14248](http://arxiv.org/abs/2512.14248)|null|
|**2025-12-16**|**From Context to EDUs: Faithful and Structured Context Compression via Elementary Discourse Unit Decomposition**|Maosong Sun Team|[2512.14244](http://arxiv.org/abs/2512.14244)|null|
|**2025-12-16**|**Elastic3D: Controllable Stereo Video Conversion with Guided Latent Decoding**|Federico Tombari Team|[2512.14236](http://arxiv.org/abs/2512.14236)|null|
|**2025-12-16**|**4D-RaDiff: Latent Diffusion for 4D Radar Point Cloud Generation**|Andras Palffy Team|[2512.14235](http://arxiv.org/abs/2512.14235)|null|
|**2025-12-16**|**ViBES: A Conversational Agent with Behaviorally-Intelligent 3D Virtual Body**|Ehsan Adeli Team|[2512.14234](http://arxiv.org/abs/2512.14234)|**[link](https://ai.stanford.edu/~juze/ViBES/)**|
|**2025-12-16**|**PentestEval: Benchmarking LLM-based Penetration Testing with Modular and Stage-Level Design**|Xiaofei Xie Team|[2512.14233](http://arxiv.org/abs/2512.14233)|null|
|**2025-12-16**|**Multi-View MRI Approach for Classification of MGMT Methylation in Glioblastoma Patients**|Mona Alshahrani Team|[2512.14232](http://arxiv.org/abs/2512.14232)|null|
|**2025-12-16**|**OmniGen: Unified Multimodal Sensor Generation for Autonomous Driving**|Xiaodan Liang Team|[2512.14225](http://arxiv.org/abs/2512.14225)|null|
|**2025-12-16**|**History-Enhanced Two-Stage Transformer for Aerial Vision-and-Language Navigation**|Jie Qin Team|[2512.14222](http://arxiv.org/abs/2512.14222)|null|
|**2025-12-16**|**DRAW2ACT: Turning Depth-Encoded Trajectories into Robotic Demonstration Videos**|Gitta Kutyniok Team|[2512.14217](http://arxiv.org/abs/2512.14217)|null|
|**2025-12-16**|**Graph Signal Denoising Using Regularization by Denoising and Its Parameter Estimation**|Yuichi Tanaka Team|[2512.14213](http://arxiv.org/abs/2512.14213)|null|
|**2025-12-16**|**Trajectory Tracking for Multi-Manipulator Systems in Constrained Environments**|Dimos V. Dimarogonas Team|[2512.14206](http://arxiv.org/abs/2512.14206)|null|
|**2025-12-16**|**Understanding and Improving Hyperbolic Deep Reinforcement Learning**|Sebastian Tschiatschek Team|[2512.14202](http://arxiv.org/abs/2512.14202)|null|
|**2025-12-16**|**Beyond a Single Light: A Large-Scale Aerial Dataset for Urban Scene Reconstruction Under Varying Illumination**|Wufan Zhao Team|[2512.14200](http://arxiv.org/abs/2512.14200)|null|
|**2025-12-16**|**Fracture Morphology Classification: Local Multiclass Modeling for Multilabel Complexity**|Ron Keuth Team|[2512.14196](http://arxiv.org/abs/2512.14196)|null|
|**2025-12-16**|**Establishing Stochastic Object Models from Noisy Data via Ambient Measurement-Integrated Diffusion**|Hu Gao Team|[2512.14187](http://arxiv.org/abs/2512.14187)|null|
|**2025-12-16**|**Spherical Voronoi: Directional Appearance as a Differentiable Partition of the Sphere**|Andrea Tagliasacchi Team|[2512.14180](http://arxiv.org/abs/2512.14180)|null|
|**2025-12-16**|**Improving Semantic Uncertainty Quantification in LVLMs with Semantic Gaussian Processes**|Gianni Franchi Team|[2512.14177](http://arxiv.org/abs/2512.14177)|null|
|**2025-12-16**|**IntentMiner: Intent Inversion Attack via Tool Call Analysis in the Model Context Protocol**|Xiang-Yang Li Team|[2512.14166](http://arxiv.org/abs/2512.14166)|null|
|**2025-12-16**|**FastDDHPose: Towards Unified, Efficient, and Disentangled 3D Human Pose Estimation**|Yongzhen Huang Team|[2512.14162](http://arxiv.org/abs/2512.14162)|null|
|**2025-12-16**|**CIS-BA: Continuous Interaction Space Based Backdoor Attack for Object Detection in the Real-World**|Yilang Zhang Team|[2512.14158](http://arxiv.org/abs/2512.14158)|null|
|**2025-12-16**|**Incentivizing Tool-augmented Thinking with Images for Medical Image Analysis**|Shihui Zhen Team|[2512.14157](http://arxiv.org/abs/2512.14157)|null|
|**2025-12-16**|**TorchTraceAP: A New Benchmark Dataset for Detecting Performance Anti-Patterns in Computer Vision Models**|Partha Kanuparthy Team|[2512.14141](http://arxiv.org/abs/2512.14141)|null|
|**2025-12-16**|**SketchAssist: A Practical Assistant for Semantic Edits and Precise Local Redrawing**|Zhenpeng Zhan Team|[2512.14140](http://arxiv.org/abs/2512.14140)|null|
|**2025-12-16**|**Erasing CLIP Memories: Non-Destructive, Data-Free Zero-Shot class Unlearning in CLIP Models**|Martin Foltin Team|[2512.14137](http://arxiv.org/abs/2512.14137)|null|
|**2025-12-16**|**AnimaMimic: Imitating 3D Animation from Video Priors**|Chenfanfu Jiang Team|[2512.14133](http://arxiv.org/abs/2512.14133)|null|
|**2025-12-16**|**UIXPOSE: Mobile Malware Detection via Intention-Behaviour Discrepancy Analysis**|Van-Thuan Pham Team|[2512.14130](http://arxiv.org/abs/2512.14130)|null|
|**2025-12-16**|**Consistent Instance Field for Dynamic Scene Understanding**|Ziyan Wu Team|[2512.14126](http://arxiv.org/abs/2512.14126)|null|
|**2025-12-16**|**SportsGPT: An LLM-driven Framework for Interpretable Sports Motion Assessment and Training Guidance**|Zhang Zhang Team|[2512.14121](http://arxiv.org/abs/2512.14121)|null|
|**2025-12-16**|**MFE-GAN: Efficient GAN-based Framework for Document Image Enhancement and Binarization with Multi-scale Feature Extraction**|Jen-Shiun Chiang Team|[2512.14114](http://arxiv.org/abs/2512.14114)|null|
|**2025-12-16**|**Selective, Controlled and Domain-Agnostic Unlearning in Pretrained CLIP: A Training- and Data-Free Approach**|Martin Foltin Team|[2512.14113](http://arxiv.org/abs/2512.14113)|null|
|**2025-12-16**|**Interactive Motion Planning for Human-Robot Collaboration Based on Human-Centric Configuration Space Ergonomic Field**|Fei Chen Team|[2512.14111](http://arxiv.org/abs/2512.14111)|null|
|**2025-12-16**|**Neurosymbolic Inference On Foundation Models For Remote Sensing Text-to-image Retrieval With Complex Queries**|Maarten Kruithof Team|[2512.14102](http://arxiv.org/abs/2512.14102)|null|
|**2025-12-16**|**A First-Order Logic-Based Alternative to Reward Models in RLHF**|Xinhua Zhu Team|[2512.14100](http://arxiv.org/abs/2512.14100)|null|
|**2025-12-16**|**ViewMask-1-to-3: Multi-View Consistent Image Generation via Multimodal Diffusion Models**|Xuelong Li Team|[2512.14099](http://arxiv.org/abs/2512.14099)|null|
|**2025-12-16**|**OUSAC: Optimized Guidance Scheduling with Adaptive Caching for DiT Acceleration**|Jin Sun Team|[2512.14096](http://arxiv.org/abs/2512.14096)|null|
|**2025-12-16**|**AnchorHOI: Zero-shot Generation of 4D Human-Object Interaction via Anchor-based Prior Distillation**|Kai Xu Team|[2512.14095](http://arxiv.org/abs/2512.14095)|null|
|**2025-12-16**|**Quality-Aware Framework for Video-Derived Respiratory Signals**|Miguel Bordallo López Team|[2512.14093](http://arxiv.org/abs/2512.14093)|null|
|**2025-12-16**|**ProtoFlow: Interpretable and Robust Surgical Workflow Modeling with Learned Dynamic Scene Graph Prototypes**|Nassir Navab Team|[2512.14092](http://arxiv.org/abs/2512.14092)|null|
|**2025-12-16**|**GaussianPlant: Structure-aligned Gaussian Splatting for 3D Reconstruction of Plants**|Fumio Okura Team|[2512.14087](http://arxiv.org/abs/2512.14087)|null|
|**2025-12-16**|**RADAR: Accelerating Large Language Model Inference With RL-Based Dynamic Draft Trees**|Jinlong Li Team|[2512.14069](http://arxiv.org/abs/2512.14069)|null|
|**2025-12-16**|**SDAR-VL: Stable and Efficient Block-wise Diffusion for Vision-Language Understanding**|Bowen Zhou Team|[2512.14068](http://arxiv.org/abs/2512.14068)|null|
|**2025-12-16**|**Bridging Fidelity-Reality with Controllable One-Step Diffusion for Image Super-Resolution**|Jiangxin Dong Team|[2512.14061](http://arxiv.org/abs/2512.14061)|**[link](https://github.com/Chanson94/CODSR)**|
|**2025-12-16**|**Real-time prediction of workplane illuminance distribution for daylight-linked controls using non-intrusive multimodal deep learning**|Yu Bian Team|[2512.14058](http://arxiv.org/abs/2512.14058)|null|
|**2025-12-16**|**Context Representation via Action-Free Transformer encoder-decoder for Meta Reinforcement Learning**|Homayoun Najjaran Team|[2512.14057](http://arxiv.org/abs/2512.14057)|null|
|**2025-12-16**|**FacEDiT: Unified Talking Face Editing and Generation via Facial Motion Infilling**|Tae-Hyun Oh Team|[2512.14056](http://arxiv.org/abs/2512.14056)|**[link](https://facedit.github.io/)**|
|**2025-12-16**|**Expert Switching for Robust AAV Landing: A Dual-Detector Framework in Simulation**|Hyung-Jin Yoon Team|[2512.14054](http://arxiv.org/abs/2512.14054)|null|
|**2025-12-16**|**HyperVL: An Efficient and Dynamic Multimodal Large Language Model for Edge Devices**|Ying Huang Team|[2512.14052](http://arxiv.org/abs/2512.14052)|null|
|**2025-12-16**|**SELECT: Detecting Label Errors in Real-world Scene Text Data**|Yuke Li Team|[2512.14050](http://arxiv.org/abs/2512.14050)|null|
|**2025-12-16**|**OmniDrive-R1: Reinforcement-driven Interleaved Multi-modal Chain-of-Thought for Trustworthy Vision-Language Autonomous Driving**|Wuxiong Huang Team|[2512.14044](http://arxiv.org/abs/2512.14044)|null|
|**2025-12-16**|**ChartAgent: A Chart Understanding Framework with Tool Integrated Reasoning**|Chenglin Liu Team|[2512.14040](http://arxiv.org/abs/2512.14040)|null|
|**2025-12-16**|**ASAP-Textured Gaussians: Enhancing Textured Gaussians with Adaptive Sampling and Anisotropic Parameterization**|Jianfei Cai Team|[2512.14039](http://arxiv.org/abs/2512.14039)|null|
|**2025-12-16**|**ACE-SLAM: Scene Coordinate Regression for Neural Implicit Real-Time SLAM**|Andrew J. Davison Team|[2512.14032](http://arxiv.org/abs/2512.14032)|**[link](https://github.com/ialzugaray/ace-slam)**|
|**2025-12-16**|**Sample-Efficient Robot Skill Learning for Construction Tasks: Benchmarking Hierarchical Reinforcement Learning and Vision-Language-Action VLA Model**|Ci-Jyun Liang Team|[2512.14031](http://arxiv.org/abs/2512.14031)|null|
|**2025-12-16**|**Cooperative Caching Towards Efficient Spectrum Utilization in Cognitive-IoT Networks**|Walaa Hamouda Team|[2512.14029](http://arxiv.org/abs/2512.14029)|null|
|**2025-12-16**|**Robust Single-shot Structured Light 3D Imaging via Neural Feature Decoding**|Wenzheng Chen Team|[2512.14028](http://arxiv.org/abs/2512.14028)|null|
|**2025-12-16**|**Unleashing the Power of Image-Tabular Self-Supervised Learning via Breaking Cross-Tabular Barriers**|Yueming Jin Team|[2512.14026](http://arxiv.org/abs/2512.14026)|null|
|**2025-12-16**|**Multivariate Time Series Forecasting with Hybrid Euclidean-SPD Manifold Graph Neural Networks**|Er-Ping Li Team|[2512.14023](http://arxiv.org/abs/2512.14023)|null|
|**2025-12-16**|**Deep Learning Perspective of Scene Understanding in Autonomous Robots**|Dur E Nayab Tashfa Team|[2512.14020](http://arxiv.org/abs/2512.14020)|null|
|**2025-12-16**|**KFS-Bench: Comprehensive Evaluation of Key Frame Sampling in Long Video Understanding**|Jianquan Liu Team|[2512.14017](http://arxiv.org/abs/2512.14017)|null|
|**2025-12-16**|**MobileWorldBench: Towards Semantic World Modeling For Mobile Agents**|Aditya Grover Team|[2512.14014](http://arxiv.org/abs/2512.14014)|null|
|**2025-12-16**|**Hierarchical Deep Reinforcement Learning for Robust Access in Cognitive IoT Networks under Smart Jamming Attacks**|Walaa Hamouda Team|[2512.14013](http://arxiv.org/abs/2512.14013)|null|
|**2025-12-16**|**Sparse-LaViDa: Sparse Multimodal Discrete Diffusion Language Models**|Jason Kuen Team|[2512.14008](http://arxiv.org/abs/2512.14008)|null|
|**2025-12-16**|**Real-Time Service Subscription and Adaptive Offloading Control in Vehicular Edge Computing**|Arvind Easwaran Team|[2512.14002](http://arxiv.org/abs/2512.14002)|null|
|**2025-12-16**|**CLAIM: Camera-LiDAR Alignment with Intensity and Monodepth**|Yikang Ding Team|[2512.14001](http://arxiv.org/abs/2512.14001)|null|
|**2025-12-16**|**Repurposing 2D Diffusion Models for 3D Shape Completion**|Ehsan Adeli Team|[2512.13991](http://arxiv.org/abs/2512.13991)|null|
|**2025-12-16**|**FocalComm: Hard Instance-Aware Multi-Agent Perception**|Vijayakumar Bhagavatula Team|[2512.13982](http://arxiv.org/abs/2512.13982)|null|
|**2025-12-16**|**XAI-Driven Diagnosis of Generalization Failure in State-Space Cerebrovascular Segmentation Models: A Case Study on Domain Shift Between RSNA and TopCoW Datasets**|Ahmad Al-Kabbany Team|[2512.13977](http://arxiv.org/abs/2512.13977)|null|
|**2025-12-16**|**Autonomous Construction-Site Safety Inspection Using Mobile Robots: A Multilayer VLM-LLM Pipeline**|Abiola Akanmu Team|[2512.13974](http://arxiv.org/abs/2512.13974)|null|
|**2025-12-16**|**Quality-Driven and Diversity-Aware Sample Expansion for Robust Marine Obstacle Segmentation**|Zeeshan Hayder Team|[2512.13970](http://arxiv.org/abs/2512.13970)|null|
|**2025-12-15**|**From Unlearning to UNBRANDING: A Benchmark for Trademark-Safe Text-to-Image Generation**|Przemysław Spurek Team|[2512.13953](http://arxiv.org/abs/2512.13953)|null|
|**2025-12-15**|**An evaluation of SVBRDF Prediction from Generative Image Models for Appearance Modeling of 3D Scenes**|George Drettakis Team|[2512.13950](http://arxiv.org/abs/2512.13950)|**[link](http://repo-sam.inria.fr/nerphys/svbrdf-evaluation)**|
|**2025-12-15**|**A Complete Guide to Spherical Equivariant Graph Transformers**|Sophia Tang Team|[2512.13927](http://arxiv.org/abs/2512.13927)|null|
|**2025-12-15**|**Adaptive digital twins for predictive decision-making: Online Bayesian learning of transition dynamics**|Andrea Manzoni Team|[2512.13919](http://arxiv.org/abs/2512.13919)|null|
|**2025-12-15**|**Generative AI for Video Translation: A Scalable Architecture for Multilingual Video Conferencing**|Mehmet S. Aktas Team|[2512.13904](http://arxiv.org/abs/2512.13904)|null|
|**2025-12-15**|**KLO-Net: A Dynamic K-NN Attention U-Net with CSP Encoder for Efficient Prostate Gland Segmentation from MRI**|Jeongkyu Lee Team|[2512.13902](http://arxiv.org/abs/2512.13902)|null|
|**2025-12-15**|**Group-Theoretic Reinforcement Learning of Dynamical Decoupling Sequences**|Murray J. Holland Team|[2512.13890](http://arxiv.org/abs/2512.13890)|null|
|**2025-12-15**|**Route-DETR: Pairwise Query Routing in Transformers for Object Detection**|Zhengjian Kang Team|[2512.13876](http://arxiv.org/abs/2512.13876)|null|
|**2025-12-15**|**SAGE: Training Smart Any-Horizon Agents for Long Video Reasoning with Reinforcement Learning**|Humphrey Shi Team|[2512.13874](http://arxiv.org/abs/2512.13874)|**[link](https://praeclarumjj3.github.io/sage/)**|
|**2025-12-15**|**Coarse-to-Fine Hierarchical Alignment for UAV-based Human Detection using Diffusion Models**|Qing Qu Team|[2512.13869](http://arxiv.org/abs/2512.13869)|null|
|**2025-12-15**|**Improvise, Adapt, Overcome -- Telescopic Adapters for Efficient Fine-tuning of Vision Language Models in Medical Imaging**|Amit Shukla Team|[2512.13855](http://arxiv.org/abs/2512.13855)|null|
|**2025-12-15**|**Topologically-Stabilized Graph Neural Networks: Empirical Robustness Across Domains**|Jelena Losic Team|[2512.13852](http://arxiv.org/abs/2512.13852)|null|
|**2025-12-15**|**MoLingo: Motion-Language Alignment for Text-to-Motion Generation**|Gerard Pons-Moll Team|[2512.13840](http://arxiv.org/abs/2512.13840)|**[link](https://hynann.github.io/molingo/MoLingo.html)**|
|**2025-12-15**|**Explainable reinforcement learning from human feedback to improve alignment**|Minghui Zhu Team|[2512.13837](http://arxiv.org/abs/2512.13837)|null|
|**2025-12-15**|**VajraV1 -- The most accurate Real Time Object Detector of the YOLO family**|Naman Balbir Singh Makkar Team|[2512.13834](http://arxiv.org/abs/2512.13834)|null|
|**2025-12-15**|**EEG-D3: A Solution to the Hidden Overfitting Problem of Deep Learning Models**|Stefanos Zafeiriou Team|[2512.13806](http://arxiv.org/abs/2512.13806)|null|
|**2025-12-15**|**Nexels: Neurally-Textured Surfels for Real-Time Novel View Synthesis with Sparse Geometries**|David B. Lindell Team|[2512.13796](http://arxiv.org/abs/2512.13796)|**[link](https://lessvrong.com/cs/nexels)**|
|**2025-12-15**|**Enhancing Semi-Supervised Multi-View Graph Convolutional Networks via Supervised Contrastive Learning and Self-Training**|Jingjun Bi Team|[2512.13770](http://arxiv.org/abs/2512.13770)|null|
|**2025-12-15**|**Network-Wide Traffic Volume Estimation from Speed Profiles using a Spatio-Temporal Graph Neural Network with Directed Spatial Attention**|Laurent Najman Team|[2512.13758](http://arxiv.org/abs/2512.13758)|null|
|**2025-12-15**|**Improving the Plausibility of Pressure Distributions Synthesized from Depth through Generative Modeling**|Axel Schneider Team|[2512.13757](http://arxiv.org/abs/2512.13757)|null|
|**2025-12-15**|**Time-aware UNet and super-resolution deep residual networks for spatial downscaling**|Sara Taskinen Team|[2512.13753](http://arxiv.org/abs/2512.13753)|null|
|**2025-12-15**|**STAR: STacked AutoRegressive Scheme for Unified Multimodal Learning**|Lin Ma Team|[2512.13752](http://arxiv.org/abs/2512.13752)|null|
|**2025-12-15**|**Comparative Evaluation of Embedding Representations for Financial News Sentiment Analysis**|Samaresh Kumar Singh Team|[2512.13749](http://arxiv.org/abs/2512.13749)|null|
|**2025-12-15**|**Why Text Prevails: Vision May Undermine Multimodal Medical Decision Making**|Liang Zhan Team|[2512.13747](http://arxiv.org/abs/2512.13747)|null|
|**2025-12-14**|**DL $^3$ M: A Vision-to-Language Framework for Expert-Level Medical Reasoning through Deep Learning and Large Language Models**|Hui Wang Team|[2512.13742](http://arxiv.org/abs/2512.13742)|null|
|**2025-12-14**|**Human-AI Collaboration Mechanism Study on AIGC Assisted Image Production for Special Coverage**|Yinan Zhu Team|[2512.13739](http://arxiv.org/abs/2512.13739)|null|
|**2025-12-14**|**Complex Mathematical Expression Recognition: Benchmark, Large-Scale Dataset and Strong Baseline**|Zhineng Chen Team|[2512.13731](http://arxiv.org/abs/2512.13731)|null|
|**2025-12-15**|**DiffusionBrowser: Interactive Diffusion Previews via Multi-Branch Decoders**|Jui-Hsien Wang Team|[2512.13690](http://arxiv.org/abs/2512.13690)|**[link](https://susunghong.github.io/DiffusionBrowser)**|
|**2025-12-15**|**LitePT: Lighter Yet Stronger Point Transformer**|Konrad Schindler Team|[2512.13689](http://arxiv.org/abs/2512.13689)|**[link](https://litept.github.io/)**|
|**2025-12-15**|**Towards Scalable Pre-training of Visual Tokenizers for Generation**|Xinggang Wang Team|[2512.13687](http://arxiv.org/abs/2512.13687)|**[link](https://github.com/MiniMax-AI/VTP)**|
|**2025-12-15**|**Recurrent Video Masked Autoencoders**|Andrew Zisserman Team|[2512.13684](http://arxiv.org/abs/2512.13684)|null|
|**2025-12-15**|**I-Scene: 3D Instance Models are Implicit Generalizable Spatial Learners**|Aniket Bera Team|[2512.13683](http://arxiv.org/abs/2512.13683)|null|
|**2025-12-15**|**LASER: Layer-wise Scale Alignment for Training-Free Streaming 4D Reconstruction**|Huaizu Jiang Team|[2512.13680](http://arxiv.org/abs/2512.13680)|null|
|**2025-12-15**|**Feedforward 3D Editing via Text-Steerable Image-to-3D**|Georgia Gkioxari Team|[2512.13678](http://arxiv.org/abs/2512.13678)|**[link](https://glab-caltech.github.io/steer3d/)**|
|**2025-12-15**|**JoVA: Unified Multimodal Learning for Joint Video-Audio Generation**|Kai Han Team|[2512.13677](http://arxiv.org/abs/2512.13677)|**[link](https://visual-ai.github.io/jova})**|
|**2025-12-15**|**Towards Interactive Intelligence for Digital Humans**|You Zhou Team|[2512.13674](http://arxiv.org/abs/2512.13674)|null|
|**2025-12-15**|**Directional Textual Inversion for Personalized Text-to-Image Generation**|Hyunjung Shim Team|[2512.13672](http://arxiv.org/abs/2512.13672)|**[link](https://kunheek.github.io/dti)**|
|**2025-12-15**|**AgentIAD: Tool-Augmented Single-Agent for Industrial Anomaly Detection**|Yan Wang Team|[2512.13671](http://arxiv.org/abs/2512.13671)|null|
|**2025-12-15**|**A Scientific Reasoning Model for Organic Synthesis Procedure Generation**|Marwin Segler Team|[2512.13668](http://arxiv.org/abs/2512.13668)|null|
|**2025-12-15**|**Grab-3D: Detecting AI-Generated Videos from 3D Geometric Temporal Consistency**|Theo Gevers Team|[2512.13665](http://arxiv.org/abs/2512.13665)|null|
|**2025-12-15**|**RoboTracer: Mastering Spatial Trace with Reasoning in Vision-Language Models for Robotics**|Shanghang Zhang Team|[2512.13660](http://arxiv.org/abs/2512.13660)|**[link](https://zhoues.github.io/RoboTracer)**|
|**2025-12-15**|**Advancing Machine Learning Optimization of Chiral Photonic Metasurface: Comparative Study of Neural Network and Genetic Algorithm Approaches**|Arash Rahimi-Iman Team|[2512.13656](http://arxiv.org/abs/2512.13656)|null|
|**2025-12-15**|**World Models Can Leverage Human Videos for Dexterous Manipulation**|Yann LeCun Team|[2512.13644](http://arxiv.org/abs/2512.13644)|null|
|**2025-12-15**|**From Code to Field: Evaluating the Robustness of Convolutional Neural Networks for Disease Diagnosis in Mango Leaves**|Erick de Andrade Barboza Team|[2512.13641](http://arxiv.org/abs/2512.13641)|null|
|**2025-12-15**|**Charge: A Comprehensive Novel View Synthesis Benchmark and Dataset to Bind Them All**|Eduardo Pérez-Pellitero Team|[2512.13639](http://arxiv.org/abs/2512.13639)|**[link](https://charge-benchmark.github.io/)**|
|**2025-12-15**|**MindDrive: A Vision-Language-Action Model for Autonomous Driving via Online Reinforcement Learning**|Xiang Bai Team|[2512.13636](http://arxiv.org/abs/2512.13636)|**[link](https://xiaomi-mlab.github.io/MindDrive/)**|
|**2025-12-15**|**SCR2-ST: Combine Single Cell with Spatial Transcriptomics for Efficient Active Sampling via Reinforcement Learning**|Yuankai Huo Team|[2512.13635](http://arxiv.org/abs/2512.13635)|null|
|**2025-12-15**|**LightTopoGAT: Enhancing Graph Attention Networks with Topological Features for Efficient Graph Classification**|Sayan Roy Gupta Team|[2512.13617](http://arxiv.org/abs/2512.13617)|null|
|**2025-12-15**|**Do-Undo: Generating and Reversing Physical Actions in Vision-Language Models**|Fatih Porikli Team|[2512.13609](http://arxiv.org/abs/2512.13609)|null|
|**2025-12-15**|**DBT-DINO: Towards Foundation model based analysis of Digital Breast Tomosynthesis**|Christopher P. Bridge Team|[2512.13608](http://arxiv.org/abs/2512.13608)|null|
|**2025-12-15**|**Nemotron-Cascade: Scaling Cascaded Reinforcement Learning for General-Purpose Reasoning Models**|Wei Ping Team|[2512.13607](http://arxiv.org/abs/2512.13607)|**[link](https://huggingface.co/collections/nvidia/nemotron-cascade)**|
|**2025-12-15**|**LongVie 2: Multimodal Controllable Ultra-Long Video World Model**|Ziwei Liu Team|[2512.13604](http://arxiv.org/abs/2512.13604)|**[link](https://vchitect.github.io/LongVie2-project/)**|
|**2025-12-15**|**DA-SSL: self-supervised domain adaptor to leverage foundational models in turbt histopathology slides**|Michael Haffner Team|[2512.13600](http://arxiv.org/abs/2512.13600)|null|
|**2025-12-15**|**Lighting in Motion: Spatiotemporal HDR Lighting Estimation**|Jean-François Lalonde Team|[2512.13597](http://arxiv.org/abs/2512.13597)|null|
|**2025-12-15**|**Image Diffusion Preview with Consistency Solver**|Long Zhao Team|[2512.13592](http://arxiv.org/abs/2512.13592)|null|
|**2025-12-15**|**MMhops-R1: Multimodal Multi-hop Reasoning**|Weiming Hu Team|[2512.13573](http://arxiv.org/abs/2512.13573)|null|
|**2025-12-15**|**Memory in the Age of AI Agents**|Shuicheng Yan Team|[2512.13564](http://arxiv.org/abs/2512.13564)|null|
|**2025-12-15**|**Near-Field Perception for Safety Enhancement of Autonomous Mobile Robots in Manufacturing Environments**|Chenhui Shao Team|[2512.13561](http://arxiv.org/abs/2512.13561)|null|
|**2025-12-15**|**3D Human-Human Interaction Anomaly Detection**|Chao Zhang Team|[2512.13560](http://arxiv.org/abs/2512.13560)|null|
|**2025-12-15**|**On the Ability of Deep Learning to Detect Signals with Unknown Parameters**|R. Michael Buehrer Team|[2512.13542](http://arxiv.org/abs/2512.13542)|null|
|**2025-12-15**|**Pancakes: Consistent Multi-Protocol Image Segmentation Across Biomedical Domains**|Adrian V. Dalca Team|[2512.13534](http://arxiv.org/abs/2512.13534)|**[link](https://github.com/mariannerakic/Pancakes)**|
|**2025-12-15**|**How Low Can You Go? The Data-Light SE Challenge**|Tim Menzies Team|[2512.13524](http://arxiv.org/abs/2512.13524)|null|
|**2025-12-15**|**Reinforcement Learning based 6-DoF Maneuvers for Microgravity Intravehicular Docking: A Simulation Study with Int-Ball2 in ISS-JEM**|Miguel Olivares-Mendez Team|[2512.13514](http://arxiv.org/abs/2512.13514)|null|
|**2025-12-15**|**TARA: Simple and Efficient Time Aware Retrieval Adaptation of MLLMs for Video Understanding**|Andrew Zisserman Team|[2512.13511](http://arxiv.org/abs/2512.13511)|**[link](http://bpiyush.github.io/tara-website)**|
|**2025-12-15**|**MedCEG: Reinforcing Verifiable Medical Reasoning with Critical Evidence Graph**|Xiaofan Zhang Team|[2512.13510](http://arxiv.org/abs/2512.13510)|null|
|**2025-12-15**|**Seedance 1.5 pro: A Native Audio-Visual Joint Generation Foundation Model**|Feilong Zuo Team|[2512.13507](http://arxiv.org/abs/2512.13507)|null|
|**2025-12-15**|**On-Device Continual Learning for Unsupervised Visual Anomaly Detection in Dynamic Manufacturing**|Darko Anicic Team|[2512.13497](http://arxiv.org/abs/2512.13497)|null|
|**2025-12-15**|**Soul: Breathe Life into Digital Human for High-fidelity Long-term Multimodal Animation**|Chengjie Wang Team|[2512.13495](http://arxiv.org/abs/2512.13495)|**[link](https://zhangzjn.github.io/projects/Soul/)**|
|**2025-12-15**|**Transform Trained Transformer: Accelerating Naive 4K Video Generation Over 10 $\times$**|Chengjie Wang Team|[2512.13492](http://arxiv.org/abs/2512.13492)|**[link](https://zhangzjn.github.io/projects/T3-Video)**|
|**2025-12-15**|**PoseAnything: Universal Pose-guided Video Generation with Part-aware Temporal Coherence**|Lizhuang Ma Team|[2512.13465](http://arxiv.org/abs/2512.13465)|null|
|**2025-12-15**|**Test-Time Modification: Inverse Domain Transformation for Robust Perception**|Yuki M. Asano Team|[2512.13454](http://arxiv.org/abs/2512.13454)|null|
|**2025-12-15**|**IMILIA: interpretable multiple instance learning for inflammation prediction in IBD from H&E whole slide images**|Hector Roux de Bezieux Team|[2512.13440](http://arxiv.org/abs/2512.13440)|null|
|**2025-12-15**|**Self-Supervised Ultrasound Representation Learning for Renal Anomaly Prediction in Prenatal Imaging**|Mark C. Walker Team|[2512.13434](http://arxiv.org/abs/2512.13434)|null|
|**2025-12-15**|**A Domain-Adapted Lightweight Ensemble for Resource-Efficient Few-Shot Plant Disease Classification**|Md. Hasanul Kabir Team|[2512.13428](http://arxiv.org/abs/2512.13428)|null|
|**2025-12-15**|**MineTheGap: Automatic Mining of Biases in Text-to-Image Models**|Tomer Michaeli Team|[2512.13427](http://arxiv.org/abs/2512.13427)|**[link](https://noa-cohen.github.io/MineTheGap/)**|
|**2025-12-15**|**RecTok: Reconstruction Distillation along Rectified Flow**|Xuelong Li Team|[2512.13421](http://arxiv.org/abs/2512.13421)|null|
|**2025-12-15**|**Learning to Generate Cross-Task Unexploitable Examples**|Jun Liu Team|[2512.13416](http://arxiv.org/abs/2512.13416)|null|
|**2025-12-15**|**USTM: Unified Spatial and Temporal Modeling for Continuous Sign Language Recognition**|Hamzah Luqman Team|[2512.13415](http://arxiv.org/abs/2512.13415)|null|
|**2025-12-15**|**Computer vision training dataset generation for robotic environments using Gaussian splatting**|Marcin Iwanowski Team|[2512.13411](http://arxiv.org/abs/2512.13411)|**[link](https://patrykni.github.io/UnitySplat2Data/)**|
|**2025-12-15**|**End2Reg: Learning Task-Specific Segmentation for Markerless Registration in Spine Surgery**|Maria Licci Team|[2512.13402](http://arxiv.org/abs/2512.13402)|**[link](https://lorenzopettinari.github.io/end-2-reg/)**|
|**2025-12-15**|**Differentiable Evolutionary Reinforcement Learning**|Difan Zou Team|[2512.13399](http://arxiv.org/abs/2512.13399)|**[link](https://github.com/sitaocheng/DERL)**|
|**2025-12-15**|**rNCA: Self-Repairing Segmentation Masks**|Madeleine K. Wyburd Team|[2512.13397](http://arxiv.org/abs/2512.13397)|null|
|**2025-12-15**|**QoS-Aware State-Augmented Learnable Framework for 5G NR-U/Wi-Fi Coexistence: Impact of Parameter Selection and Enhanced Collision Resolution**|Brian L. Mark Team|[2512.13393](http://arxiv.org/abs/2512.13393)|null|
|**2025-12-15**|**Beyond the Visible: Disocclusion-Aware Editing via Proxy Dynamic Graphs**|Niloy J. Mitra Team|[2512.13392](http://arxiv.org/abs/2512.13392)|null|
|**2025-12-15**|**Universal Dexterous Functional Grasping via Demonstration-Editing Reinforcement Learning**|Zongqing Lu Team|[2512.13380](http://arxiv.org/abs/2512.13380)|null|
|**2025-12-15**|**Unlocking Generalization in Polyp Segmentation with DINO Self-Attention "keys"**|Wilson Silva Team|[2512.13376](http://arxiv.org/abs/2512.13376)|null|
|**2025-12-15**|**Automated User Identification from Facial Thermograms with Siamese Networks**|Vladimir Faerman Team|[2512.13361](http://arxiv.org/abs/2512.13361)|null|
|**2025-12-15**|**Fast Policy Learning for 6-DOF Position Control of Underwater Vehicles**|Ignacio Carlucho Team|[2512.13359](http://arxiv.org/abs/2512.13359)|null|
|**2025-12-15**|**Control of a Twin Rotor using Twin Delayed Deep Deterministic Policy Gradient (TD3)**|Ayman El-Badawy Team|[2512.13356](http://arxiv.org/abs/2512.13356)|null|
|**2025-12-15**|**Face Identity Unlearning for Retrieval via Embedding Dispersion**|Mikhail Zakharov Team|[2512.13317](http://arxiv.org/abs/2512.13317)|null|
|**2025-12-15**|**KlingAvatar 2.0 Technical Report**|Yan Zhou Team|[2512.13313](http://arxiv.org/abs/2512.13313)|null|
|**2025-12-15**|**Humanoid Robot Running Through Random Stepping Stones and Jumping Over Obstacles: Step Adaptation Using Spring-Mass Trajectories**|Christian Ott Team|[2512.13304](http://arxiv.org/abs/2512.13304)|**[link](https://youtu.be/HlAg2nbNct4)**|
|**2025-12-15**|**ShowTable: Unlocking Creative Table Visualization with Collaborative Reflection and Refinement**|Hongtao Xie Team|[2512.13303](http://arxiv.org/abs/2512.13303)|**[link](https://lntzm.github.io/showtable-page/)**|
|**2025-12-15**|**Intrinsic-Motivation Multi-Robot Social Formation Navigation with Coordinated Exploration**|Shuai Zhou Team|[2512.13293](http://arxiv.org/abs/2512.13293)|null|
|**2025-12-15**|**LINA: Learning INterventions Adaptively for Physical Alignment and Generalization in Diffusion Models**|Chaochao Lu Team|[2512.13290](http://arxiv.org/abs/2512.13290)|null|
|**2025-12-15**|**CausalCLIP: Causally-Informed Feature Disentanglement and Filtering for Generalizable Detection of Generated Images**|Qinghui He Team|[2512.13285](http://arxiv.org/abs/2512.13285)|null|
|**2025-12-15**|**Video Reality Test: Can AI-Generated ASMR Videos fool VLMs and Humans?**|Kevin Qinghong Lin Team|[2512.13281](http://arxiv.org/abs/2512.13281)|**[link](https://github.com/video-reality-test/video-reality-test)**|
|**2025-12-15**|**AutoTool: Dynamic Tool Selection and Integration for Agentic Reasoning**|Mengdi Wang Team|[2512.13278](http://arxiv.org/abs/2512.13278)|null|
|**2025-12-15**|**CogniEdit: Dense Gradient Flow Optimization for Fine-Grained Image Editing**|Qi Tian Team|[2512.13276](http://arxiv.org/abs/2512.13276)|null|
|**2025-12-15**|**SPARS: A Reinforcement Learning-Enabled Simulator for Power Management in HPC Job Scheduling**|Hiroyuki Takizawa Team|[2512.13268](http://arxiv.org/abs/2512.13268)|null|
|**2025-12-15**|**Post-Training and Test-Time Scaling of Generative Agent Behavior Models for Interactive Autonomous Driving**|Monu Surana Team|[2512.13262](http://arxiv.org/abs/2512.13262)|null|
|**2025-12-15**|**Toward Ambulatory Vision: Learning Visually-Grounded Active View Selection**|Minhyuk Sung Team|[2512.13250](http://arxiv.org/abs/2512.13250)|**[link](https://active-view-selection.github.io/)**|
|**2025-12-15**|**STARCaster: Spatio-Temporal AutoRegressive Video Diffusion for Identity- and View-Aware Talking Portraits**|Stefanos Zafeiriou Team|[2512.13247](http://arxiv.org/abs/2512.13247)|**[link](https://foivospar.github.io/STARCaster/)**|
|**2025-12-15**|**Reflective Preference Optimization (RPO): Enhancing On-Policy Alignment via Hint-Guided Reflection**|Zechang Li Team|[2512.13240](http://arxiv.org/abs/2512.13240)|null|
|**2025-12-15**|**Ego-EXTRA: video-language Egocentric Dataset for EXpert-TRAinee assistance**|Giovanni Maria Farinella Team|[2512.13238](http://arxiv.org/abs/2512.13238)|null|
|**2025-12-15**|**POLAR: A Portrait OLAT Dataset and Generative Framework for Illumination-Aware Face Modeling**|Yichao Yan Team|[2512.13192](http://arxiv.org/abs/2512.13192)|null|
|**2025-12-15**|**CoRA: A Collaborative Robust Architecture with Hybrid Fusion for Efficient Perception**|Xiaohui Xie Team|[2512.13191](http://arxiv.org/abs/2512.13191)|null|
|**2025-12-15**|**MMDrive: Interactive Scene Understanding Beyond Vision with Multi-representational Fusion**|Weiping Ding Team|[2512.13177](http://arxiv.org/abs/2512.13177)|null|
|**2025-12-15**|**Seeing the Whole Picture: Distribution-Guided Data-Free Distillation for Semantic Segmentation**|Tao Wu Team|[2512.13175](http://arxiv.org/abs/2512.13175)|null|
|**2025-12-15**|**SACn: Soft Actor-Critic with n-step Returns**|Paweł Wawrzyński Team|[2512.13165](http://arxiv.org/abs/2512.13165)|null|
|**2025-12-15**|**A Semantically Enhanced Generative Foundation Model Improves Pathological Image Synthesis**|Yongbing Zhang Team|[2512.13164](http://arxiv.org/abs/2512.13164)|null|
|**2025-12-15**|**SpeakRL: Synergizing Reasoning, Speaking, and Acting in Language Models with Reinforcement Learning**|Xing Fan Team|[2512.13159](http://arxiv.org/abs/2512.13159)|null|
|**2025-12-15**|**Intrinsic Image Fusion for Multi-View 3D Material Reconstruction**|Matthias Nießner Team|[2512.13157](http://arxiv.org/abs/2512.13157)|**[link](https://peter-kocsis.github.io/IntrinsicImageFusion/)**|
|**2025-12-15**|**StarryGazer: Leveraging Monocular Depth Estimation Models for Domain-Agnostic Single Depth Image Completion**|Kyoung Mu Lee Team|[2512.13147](http://arxiv.org/abs/2512.13147)|null|
|**2025-12-15**|**Weight Space Correlation Analysis: Quantifying Feature Utilization in Deep Learning Models**|Aasa Feragen Team|[2512.13144](http://arxiv.org/abs/2512.13144)|null|
|**2025-12-15**|**Towards Unified Co-Speech Gesture Generation via Hierarchical Implicit Periodicity Learning**|Jia Li Team|[2512.13131](http://arxiv.org/abs/2512.13131)|null|
|**2025-12-15**|**LeafTrackNet: A Deep Learning Framework for Robust Leaf Tracking in Top-Down Plant Phenotyping**|Marina M. -C. Höhne Team|[2512.13130](http://arxiv.org/abs/2512.13130)|null|
|**2025-12-15**|**DePT3R: Joint Dense Point Tracking and 3D Reconstruction of Dynamic Scenes in a Single Forward Pass**|M. Khalid Jawed Team|[2512.13122](http://arxiv.org/abs/2512.13122)|null|
|**2025-12-15**|**Less Is More: Sparse and Cooperative Perturbation for Point Cloud Attacks**|Zhihong Tian Team|[2512.13119](http://arxiv.org/abs/2512.13119)|null|
|**2025-12-15**|**Diffusion-Based Restoration for Multi-Modal 3D Object Detection in Adverse Weather**|Xiaoyu Tang Team|[2512.13107](http://arxiv.org/abs/2512.13107)|null|
|**2025-12-15**|**TraPO: A Semi-Supervised Reinforcement Learning Framework for Boosting LLM Reasoning**|Haobo Wang Team|[2512.13106](http://arxiv.org/abs/2512.13106)|null|
|**2025-12-15**|**FID-Net: A Feature-Enhanced Deep Learning Network for Forest Infestation Detection**|Pei Wang Team|[2512.13104](http://arxiv.org/abs/2512.13104)|null|
|**2025-12-15**|**Harmonizing Generalization and Specialization: Uncertainty-Informed Collaborative Learning for Semi-supervised Medical Image Segmentation**|Yang Yang Team|[2512.13101](http://arxiv.org/abs/2512.13101)|null|
|**2025-12-15**|**OXE-AugE: A Large-Scale Robot Augmentation of OXE for Scaling Cross-Embodiment Policy Learning**|Ken Goldberg Team|[2512.13100](http://arxiv.org/abs/2512.13100)|null|
|**2025-12-15**|**Toward Self-Healing Networks-on-Chip: RL-Driven Routing in 2D Torus Architectures**|Zaid Hussain Team|[2512.13096](http://arxiv.org/abs/2512.13096)|null|
|**2025-12-15**|**ADHint: Adaptive Hints with Difficulty Priors for Reinforcement Learning**|Yang Yang Team|[2512.13095](http://arxiv.org/abs/2512.13095)|null|
|**2025-12-15**|**Sequence of Expert: Boosting Imitation Planners for Autonomous Driving through Temporal Alternation**|Zhong Cao Team|[2512.13094](http://arxiv.org/abs/2512.13094)|null|
|**2025-12-15**|**PvP: Data-Efficient Humanoid Robot Learning with Proprioceptive-Privileged Contrastive Representations**|Wenjun Zeng Team|[2512.13093](http://arxiv.org/abs/2512.13093)|null|
|**2025-12-15**|**Multi-Robot Motion Planning from Vision and Language using Heat-Inspired Diffusion**|Jongeun Choi Team|[2512.13090](http://arxiv.org/abs/2512.13090)|null|
|**2025-12-15**|**UniVCD: A New Method for Unsupervised Change Detection in the Open-Vocabulary Era**|Bowei Yang Team|[2512.13089](http://arxiv.org/abs/2512.13089)|null|
|**2025-12-15**|**DiRe: Diversity-promoting Regularization for Dataset Condensation**|Konda Reddy Mopuri Team|[2512.13083](http://arxiv.org/abs/2512.13083)|null|
|**2025-12-15**|**Spatial-Aware VLA Pretraining through Visual-Physical Alignment from Human Videos**|Zongqing Lu Team|[2512.13080](http://arxiv.org/abs/2512.13080)|null|
|**2025-12-15**|**Heart Disease Prediction using Case Based Reasoning (CBR)**|Ahmad Fakhri Ab Nasir Team|[2512.13078](http://arxiv.org/abs/2512.13078)|null|
|**2025-12-15**|**Forging a Dynamic Memory: Retrieval-Guided Continual Learning for Generalist Medical Foundation Models**|Lihua Zhang Team|[2512.13072](http://arxiv.org/abs/2512.13072)|null|
|**2025-12-15**|**M-GRPO: Stabilizing Self-Supervised Reinforcement Learning for Large Language Models with Momentum-Anchored Policy Optimization**|Tao Chen Team|[2512.13070](http://arxiv.org/abs/2512.13070)|null|
|**2025-12-15**|**Deep Q-Learning-Based Intelligent Scheduling for ETL Optimization in Heterogeneous Data Environments**|Wei Li Team|[2512.13060](http://arxiv.org/abs/2512.13060)|null|
|**2025-12-15**|**Towards Test-time Efficient Visual Place Recognition via Asymmetric Query Processing**|Sung-Eui Yoon Team|[2512.13055](http://arxiv.org/abs/2512.13055)|null|
|**2025-12-15**|**GTR-Turbo: Merged Checkpoint is Secretly a Free Teacher for Agentic VLM Training**|Deheng Ye Team|[2512.13043](http://arxiv.org/abs/2512.13043)|null|
|**2025-12-15**|**Bi-Erasing: A Bidirectional Framework for Concept Removal in Diffusion Models**|Songze Li Team|[2512.13039](http://arxiv.org/abs/2512.13039)|null|
|**2025-12-15**|**Comprehensive Evaluation of Rule-Based, Machine Learning, and Deep Learning in Human Estimation Using Radio Wave Sensing: Accuracy, Spatial Generalization, and Output Granularity Trade-offs**|Ryo Yonemoto Team|[2512.13031](http://arxiv.org/abs/2512.13031)|null|
|**2025-12-15**|**Motus: A Unified Latent Action World Model**|Jun Zhu Team|[2512.13030](http://arxiv.org/abs/2512.13030)|null|
|**2025-12-15**|**SneakPeek: Future-Guided Instructional Streaming Video Generation**|Albert Pumarola Team|[2512.13019](http://arxiv.org/abs/2512.13019)|null|
|**2025-12-15**|**Comprehensive Deployment-Oriented Assessment for Cross-Environment Generalization in Deep Learning-Based mmWave Radar Sensing**|Ryo Yonemoto Team|[2512.13018](http://arxiv.org/abs/2512.13018)|null|
|**2025-12-15**|**What Happens Next? Next Scene Prediction with a Unified Video Model**|Vimal Bhat Team|[2512.13015](http://arxiv.org/abs/2512.13015)|null|
|**2025-12-15**|**JoDiffusion: Jointly Diffusing Image with Pixel-Level Annotations for Semantic Segmentation Promotion**|Chen Ding Team|[2512.13014](http://arxiv.org/abs/2512.13014)|null|
|**2025-12-15**|**TWLR: Text-Guided Weakly-Supervised Lesion Localization and Severity Regression for Explainable Diabetic Retinopathy Grading**|Huaxiong Huang Team|[2512.13008](http://arxiv.org/abs/2512.13008)|null|
|**2025-12-15**|**Light Field Based 6DoF Tracking of Previously Unobserved Objects**|Donald G. Dansereau Team|[2512.13007](http://arxiv.org/abs/2512.13007)|null|
|**2025-12-15**|**Few-Step Distillation for Text-to-Image Generation: A Practical Guide**|Gao Huang Team|[2512.13006](http://arxiv.org/abs/2512.13006)|null|
|**2025-12-15**|**Calibrating Uncertainty for Zero-Shot Adversarial CLIP**|Qibin Zhao Team|[2512.12997](http://arxiv.org/abs/2512.12997)|null|
|**2025-12-15**|**Learning Terrain Aware Bipedal Locomotion via Reduced Dimensional Perceptual Representations**|Ayonga Hereid Team|[2512.12993](http://arxiv.org/abs/2512.12993)|null|
|**2025-12-15**|**Tackling Snow-Induced Challenges: Safe Autonomous Lane-Keeping with Robust Reinforcement Learning**|Ali Kamali Iglie Team|[2512.12987](http://arxiv.org/abs/2512.12987)|null|
|**2025-12-15**|**VoroLight: Learning Quality Volumetric Voronoi Meshes from General Inputs**|Chenfanfu Jiang Team|[2512.12984](http://arxiv.org/abs/2512.12984)|null|
|**2025-12-15**|**Scaling Up AI-Generated Image Detection via Generator-Aware Prototypes**|Xiaolong Zheng Team|[2512.12982](http://arxiv.org/abs/2512.12982)|null|
|**2025-12-15**|**CoDeQ: End-to-End Joint Model Compression with Dead-Zone Quantizer for High-Sparsity and Low-Precision Networks**|Raghavendra Selvan Team|[2512.12981](http://arxiv.org/abs/2512.12981)|**[link](https://github.com/saintslab/CoDeQ)**|
|**2025-12-15**|**VLCache: Computing 2% Vision Tokens and Reusing 98% for Vision-Language Inference**|Junyang Lin Team|[2512.12977](http://arxiv.org/abs/2512.12977)|null|
|**2025-12-15**|**QwenLong-L1.5: Post-Training Recipe for Long-Context Reasoning and Memory Management**|Ming Yan Team|[2512.12967](http://arxiv.org/abs/2512.12967)|null|
|**2025-12-15**|**SCAdapter: Content-Style Disentanglement for Diffusion Style Transfer**|Atsuki Osanai Team|[2512.12963](http://arxiv.org/abs/2512.12963)|null|
|**2025-12-15**|**Leveraging Compression to Construct Transferable Bitrate Ladders**|Alan C. Bovik Team|[2512.12952](http://arxiv.org/abs/2512.12952)|null|
|**2025-12-15**|**SLIM-VDB: A Real-Time 3D Probabilistic Semantic Mapping Framework**|Katherine A. Skinner Team|[2512.12945](http://arxiv.org/abs/2512.12945)|null|
|**2025-12-15**|**UAGLNet: Uncertainty-Aggregated Global-Local Fusion Network with Cooperative CNN-Transformer for Building Extraction**|Xiaochun Cao Team|[2512.12941](http://arxiv.org/abs/2512.12941)|null|
|**2025-12-15**|**Continuous Edit Distance, Geodesics and Barycenters of Time-varying Persistence Diagrams**|Julien Tierny Team|[2512.12939](http://arxiv.org/abs/2512.12939)|null|
|**2025-12-15**|**Content Adaptive based Motion Alignment Framework for Learned Video Compression**|Siwei Ma Team|[2512.12936](http://arxiv.org/abs/2512.12936)|null|
|**2025-12-15**|**Unified Interactive Multimodal Moment Retrieval via Cascaded Embedding-Reranking and Temporal-Aware Score Fusion**|Anh Nguyen Nhu Tinh Team|[2512.12935](http://arxiv.org/abs/2512.12935)|null|
|**2025-12-15**|**MADTempo: An Interactive System for Multi-Event Temporal Video Retrieval with Query Augmentation**|Thanh-Huong Le Team|[2512.12929](http://arxiv.org/abs/2512.12929)|null|
|**2025-12-15**|**Sharpness-aware Dynamic Anchor Selection for Generalized Category Discovery**|Ming-Ming Cheng Team|[2512.12925](http://arxiv.org/abs/2512.12925)|null|
|**2025-12-15**|**Interpretable Hypothesis-Driven Trading:A Rigorous Walk-Forward Validation Framework for Market Microstructure Signals**|William Lamptey Team|[2512.12924](http://arxiv.org/abs/2512.12924)|null|
|**2025-12-15**|**LLM-based Personalized Portfolio Recommender: Integrating Large Language Models and Reinforcement Learning for Intelligent Investment Strategy Optimization**|Ziyang Ding Team|[2512.12922](http://arxiv.org/abs/2512.12922)|null|
|**2025-12-15**|**Predictive Sample Assignment for Semantically Coherent Out-of-Distribution Detection**|Ming-Ming Cheng Team|[2512.12906](http://arxiv.org/abs/2512.12906)|null|
|**2025-12-15**|**Qonvolution: Towards Learning High-Frequency Signals with Queried Convolution**|Suren Kumar Team|[2512.12898](http://arxiv.org/abs/2512.12898)|**[link](https://abhi1kumar.github.io/qonvolution/)**|
|**2025-12-15**|**Meta-GPT: Decoding the Metasurface Genome with Generative Artificial Intelligence**|Wilton J. M. Kort-Kamp Team|[2512.12888](http://arxiv.org/abs/2512.12888)|null|
|**2025-12-15**|**Revisiting 2D Foundation Models for Scalable 3D Medical Image Classification**|Sasa Grbic Team|[2512.12887](http://arxiv.org/abs/2512.12887)|null|
|**2025-12-14**|**SignRAG: A Retrieval-Augmented System for Scalable Zero-Shot Road Sign Recognition**|Keith Redmill Team|[2512.12885](http://arxiv.org/abs/2512.12885)|null|
|**2025-12-14**|**Cross-Level Sensor Fusion with Object Lists via Transformer for 3D Object Detection**|Hao Shen Team|[2512.12884](http://arxiv.org/abs/2512.12884)|null|
|**2025-12-14**|**Schrodinger Audio-Visual Editor: Object-Level Audiovisual Removal**|Paul Pu Liang Team|[2512.12875](http://arxiv.org/abs/2512.12875)|null|
|**2025-12-14**|**Information-Consistent Language Model Recommendations through Group Relative Policy Optimization**|Kaushik Dutta Team|[2512.12858](http://arxiv.org/abs/2512.12858)|null|
|**2025-12-14**|**MPC-Guided Safe Reinforcement Learning and Lipschitz-Based Filtering for Structured Nonlinear Systems**|Anahita Jamshidnejad Team|[2512.12855](http://arxiv.org/abs/2512.12855)|null|
|**2025-12-14**|**SAGA: Open-World Mobile Manipulation via Structured Affordance Grounding**|Jiuguang Wang Team|[2512.12842](http://arxiv.org/abs/2512.12842)|null|
|**2025-12-14**|**GradID: Adversarial Detection via Intrinsic Dimensionality of Gradients**|Saeed Bagheri Shouraki Team|[2512.12827](http://arxiv.org/abs/2512.12827)|null|
|**2025-12-14**|**Adapting Multimodal Foundation Models for Few-Shot Learning: A Comprehensive Study on Contrastive Captioners**|Uthayasanker Thayasivam Team|[2512.12824](http://arxiv.org/abs/2512.12824)|null|
|**2025-12-14**|**Lemon: A Unified and Scalable 3D Multimodal Model for Universal Spatial Understanding**|Furong Huang Team|[2512.12822](http://arxiv.org/abs/2512.12822)|null|
|**2025-12-14**|**OPAL: Operator-Programmed Algorithms for Landscape-Aware Black-Box Optimization**|Huiling Chen Team|[2512.12809](http://arxiv.org/abs/2512.12809)|**[link](https://github.com/junbolian/OPAL.)**|
|**2025-12-14**|**Fault-Tolerant Sandboxing for AI Coding Agents: A Transactional Approach to Safe Autonomous Execution**|Boyang Yan Team|[2512.12806](http://arxiv.org/abs/2512.12806)|null|
|**2025-12-14**|**From Small to Large: Generalization Bounds for Transformers on Variable-Size Inputs**|Pan Li Team|[2512.12805](http://arxiv.org/abs/2512.12805)|null|
|**2025-12-14**|**Distributed Reinforcement Learning using Local Smart Meter Data for Voltage Regulation in Distribution Networks**|Pedro P. Vergara Team|[2512.12803](http://arxiv.org/abs/2512.12803)|null|
|**2025-12-14**|**Learning Common and Salient Generative Factors Between Two Image Datasets**|Pietro Gori Team|[2512.12800](http://arxiv.org/abs/2512.12800)|null|
|**2025-12-14**|**DrivePI: Spatial-aware 4D MLLM for Unified Autonomous Driving Understanding, Perception, Prediction and Planning**|Hengshuang Zhao Team|[2512.12799](http://arxiv.org/abs/2512.12799)|null|
|**2025-12-14**|**VLG-Loc: Vision-Language Global Localization from Labeled Footprint Maps**|Ryo Yonetani Team|[2512.12793](http://arxiv.org/abs/2512.12793)|null|
|**2025-12-14**|**L-STEC: Learned Video Compression with Long-term Spatio-Temporal Enhanced Context**|Siwei Ma Team|[2512.12790](http://arxiv.org/abs/2512.12790)|null|
|**2025-12-14**|**Fast 2DGS: Efficient Image Representation with Deep Gaussian Prior**|Abolfazl Razi Team|[2512.12774](http://arxiv.org/abs/2512.12774)|null|
|**2025-12-14**|**JointAVBench: A Benchmark for Joint Audio-Visual Reasoning Evaluation**|Liyun Ru Team|[2512.12772](http://arxiv.org/abs/2512.12772)|null|
|**2025-12-14**|**CoRe3D: Collaborative Reasoning as a Foundation for 3D Intelligence**|Ismini Lourentzou Team|[2512.12768](http://arxiv.org/abs/2512.12768)|null|
|**2025-12-14**|**Federated Learning with Feedback Alignment**|Yon Dohn Chung Team|[2512.12762](http://arxiv.org/abs/2512.12762)|null|
|**2025-12-14**|**Intelligent Scientific Literature Explorer using Machine Learning (ISLE)**|Zahra Rahimi Team|[2512.12760](http://arxiv.org/abs/2512.12760)|null|
|**2025-12-14**|**FysicsWorld: A Unified Full-Modality Benchmark for Any-to-Any Understanding, Generation, and Reasoning**|Lihua Zhang Team|[2512.12756](http://arxiv.org/abs/2512.12756)|null|
|**2025-12-14**|**GenieDrive: Towards Physics-Aware Driving World Model with 4D Occupancy Guided Video Generation**|Hengshuang Zhao Team|[2512.12751](http://arxiv.org/abs/2512.12751)|**[link](https://huster-yzy.github.io/geniedrive_project_page/)**|
|**2025-12-14**|**Spinal Line Detection for Posture Evaluation through Train-ing-free 3D Human Body Reconstruction with 2D Depth Images**|Taemin Lee Team|[2512.12718](http://arxiv.org/abs/2512.12718)|null|
|**2025-12-14**|**CoDA: A Context-Decoupled Hierarchical Agent with Reinforcement Learning**|Pan Li Team|[2512.12716](http://arxiv.org/abs/2512.12716)|null|
|**2025-12-14**|**Self-Motivated Growing Neural Network for Adaptive Architecture via Local Structural Plasticity**|Chengxu Zhou Team|[2512.12713](http://arxiv.org/abs/2512.12713)|null|
|**2025-12-14**|**Synergizing Code Coverage and Gameplay Intent: Coverage-Aware Game Playtesting with LLM-Guided Reinforcement Learning**|Jialong Li Team|[2512.12706](http://arxiv.org/abs/2512.12706)|null|
|**2025-12-14**|**Robust Motion Generation using Part-level Reliable Data from Videos**|Zongqing Lu Team|[2512.12703](http://arxiv.org/abs/2512.12703)|null|
|**2025-12-14**|**Efficient Vision-Language Reasoning via Adaptive Token Pruning**|Henry Hu Team|[2512.12701](http://arxiv.org/abs/2512.12701)|null|
|**2025-12-14**|**Hybrid Retrieval-Augmented Generation for Robust Multilingual Document Question Answering**|Souhail Bakkali Team|[2512.12694](http://arxiv.org/abs/2512.12694)|null|
|**2025-12-14**|**WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment**|Md Rizwan Parvez Team|[2512.12692](http://arxiv.org/abs/2512.12692)|**[link](https://kagnlp.github.io/WebOperator/)**|
|**2025-12-14**|**Reassessing the Role of Supervised Fine-Tuning: An Empirical Study in VLM Reasoning**|Jian Liang Team|[2512.12690](http://arxiv.org/abs/2512.12690)|null|
|**2025-12-14**|**Memoria: A Scalable Agentic Memory Framework for Personalized Conversational AI**|Dhagash Mehta Team|[2512.12686](http://arxiv.org/abs/2512.12686)|null|
|**2025-12-14**|**Quantum Implicit Neural Representations for 3D Scene Reconstruction and Novel View Synthesis**|Fernando Vilariño Team|[2512.12683](http://arxiv.org/abs/2512.12683)|null|
|**2025-12-14**|**$β$ -CLIP: Text-Conditioned Contrastive Learning for Multi-Granular Vision-Language Alignment**|Bernard Ghanem Team|[2512.12678](http://arxiv.org/abs/2512.12678)|null|
|**2025-12-14**|**Scone: Bridging Composition and Distinction in Subject-Driven Image Generation via Unified Understanding-Generation Modeling**|Wentao Zhang Team|[2512.12675](http://arxiv.org/abs/2512.12675)|**[link](https://github.com/Ryann-Ran/Scone)**|
|**2025-12-14**|**Progressive Conditioned Scale-Shift Recalibration of Self-Attention for Online Test-time Adaptation**|Zhihai He Team|[2512.12673](http://arxiv.org/abs/2512.12673)|null|
|**2025-12-14**|**DynaGen: Unifying Temporal Knowledge Graph Reasoning with Dynamic Subgraphs and Generative Regularization**|Shimin Di Team|[2512.12669](http://arxiv.org/abs/2512.12669)|null|
|**2025-12-14**|**Open-World Deepfake Attribution via Confidence-Aware Asymmetric Learning**|Zhun Zhong Team|[2512.12667](http://arxiv.org/abs/2512.12667)|null|
|**2025-12-14**|**InteracTalker: Prompt-Based Human-Object Interaction with Co-Speech Gesture Generation**|Charu Sharma Team|[2512.12664](http://arxiv.org/abs/2512.12664)|null|
|**2025-12-14**|**PerNodeDrop: A Method Balancing Specialized Subnets and Regularization in Deep Neural Networks**|Sreeja CS Team|[2512.12663](http://arxiv.org/abs/2512.12663)|null|
|**2025-12-14**|**Anatomy-Guided Representation Learning Using a Transformer-Based Network for Thyroid Nodule Segmentation in Ultrasound Images**|Junaid Qadir Team|[2512.12662](http://arxiv.org/abs/2512.12662)|null|
|**2025-12-14**|**CogDoc: Towards Unified thinking in Documents**|Wenhu Chen Team|[2512.12658](http://arxiv.org/abs/2512.12658)|null|
|**2025-12-14**|**Cross-modal Fundus Image Registration under Large FoV Disparity**|Xirong Li Team|[2512.12657](http://arxiv.org/abs/2512.12657)|null|
|**2025-12-14**|**Modeling Authorial Style in Urdu Novels Using Character Interaction Graphs and Graph Neural Networks**|Hanzlah Munir Team|[2512.12654](http://arxiv.org/abs/2512.12654)|null|
|**2025-12-14**|**Torch Geometric Pool: the Pytorch library for pooling in Graph Neural Networks**|Ivan Marisca Team|[2512.12642](http://arxiv.org/abs/2512.12642)|null|
|**2025-12-14**|**DiG: Differential Grounding for Enhancing Fine-Grained Perception in Multimodal Large Language Model**|Linli Xu Team|[2512.12633](http://arxiv.org/abs/2512.12633)|null|
|**2025-12-14**|**Reasoning Within the Mind: Dynamic Multimodal Interleaving in Latent Space**|Xin Eric Wang Team|[2512.12623](http://arxiv.org/abs/2512.12623)|null|
|**2025-12-14**|**D3D-VLP: Dynamic 3D Vision-Language-Planning Model for Embodied Grounding and Navigation**|Gim Hee Lee Team|[2512.12622](http://arxiv.org/abs/2512.12622)|null|
|**2025-12-14**|**StruProKGR: A Structural and Probabilistic Framework for Sparse Knowledge Graph Reasoning**|Xueqi Cheng Team|[2512.12613](http://arxiv.org/abs/2512.12613)|null|
|**2025-12-14**|**Patch-wise Retrieval: A Bag of Practical Techniques for Instance-level Matching**|Tae-Hyun Oh Team|[2512.12610](http://arxiv.org/abs/2512.12610)|null|
|**2025-12-14**|**No Cache Left Idle: Accelerating diffusion model via Extreme-slimming Caching**|Xueqian Wang Team|[2512.12604](http://arxiv.org/abs/2512.12604)|**[link](https://thu-accdiff.github.io/xslim-page/)**|
|**2025-12-14**|**Geometry-Aware Scene-Consistent Image Generation**|Zhenpeng Zhan Team|[2512.12598](http://arxiv.org/abs/2512.12598)|null|
|**2025-12-14**|**Content-Aware Ad Banner Layout Generation with Two-Stage Chain-of-Thought in Vision Language Models**|Kazuhide Nakata Team|[2512.12596](http://arxiv.org/abs/2512.12596)|null|
|**2025-12-14**|**Vision-Enhanced Large Language Models for High-Resolution Image Synthesis and Multimodal Data Interpretation**|Karthikeya KV Team|[2512.12595](http://arxiv.org/abs/2512.12595)|null|
|**2025-12-14**|**ceLLMate: Sandboxing Browser AI Agents**|Earlence Fernandes Team|[2512.12594](http://arxiv.org/abs/2512.12594)|**[link](https://cellmate-sandbox.github.io)**|
|**2025-12-14**|**Automatic Wire-Harness Color Sequence Detector**|Mervyn Parakrama B. Ekanayake Team|[2512.12590](http://arxiv.org/abs/2512.12590)|null|
|**2025-12-14**|**StegaVAR: Privacy-Preserving Video Action Recognition via Steganographic Domain Analysis**|Xun Lin Team|[2512.12586](http://arxiv.org/abs/2512.12586)|null|
|**2025-12-14**|**Coupled Variational Reinforcement Learning for Language Model General Reasoning**|Debing Zhang Team|[2512.12576](http://arxiv.org/abs/2512.12576)|null|
|**2025-12-14**|**From Tokens to Photons: Test-Time Physical Prompting for Vison-Language Models**|Hyung-Sin Kim Team|[2512.12571](http://arxiv.org/abs/2512.12571)|null|
|**2025-12-14**|**StreamingAssistant: Efficient Visual Token Pruning for Accelerating Online Video Understanding**|Weiqiang Wang Team|[2512.12560](http://arxiv.org/abs/2512.12560)|null|
|**2025-12-14**|**Supervised Contrastive Frame Aggregation for Video Representation Learning**|Greg Hamerly Team|[2512.12549](http://arxiv.org/abs/2512.12549)|null|
|**2025-12-14**|**World Models Unlock Optimal Foraging Strategies in Reinforcement Learning Agents**|Luis F. Giraldo Team|[2512.12548](http://arxiv.org/abs/2512.12548)|null|
|**2025-12-14**|**Anatomy Guided Coronary Artery Segmentation from CCTA Using Spatial Frequency Joint Modeling**|Chen Zhao Team|[2512.12539](http://arxiv.org/abs/2512.12539)|null|
|**2025-12-14**|**Animus3D: Text-driven 3D Animation via Motion Score Distillation**|Jing Liao Team|[2512.12534](http://arxiv.org/abs/2512.12534)|null|
|**2025-12-14**|**Empirical Mode Decomposition and Graph Transformation of the MSCI World Index: A Multiscale Topological Analysis for Graph Neural Network Modeling**|León Beleña Team|[2512.12526](http://arxiv.org/abs/2512.12526)|null|
|**2025-12-14**|**Generative Spatiotemporal Data Augmentation**|Jeong Joon Park Team|[2512.12508](http://arxiv.org/abs/2512.12508)|null|
|**2025-12-14**|**KidsArtBench: Multi-Dimensional Children's Art Evaluation with Attribute-Aware MLLMs**|Helen Yannakoudakis Team|[2512.12503](http://arxiv.org/abs/2512.12503)|null|
|**2025-12-14**|**SafeGen: Embedding Ethical Safeguards in Text-to-Image Generation**|Pham Thanh Hieu Team|[2512.12501](http://arxiv.org/abs/2512.12501)|null|
|**2025-12-13**|**Advancing Cache-Based Few-Shot Classification via Patch-Driven Relational Gated Graph Attention**|Ardhendu Behera Team|[2512.12498](http://arxiv.org/abs/2512.12498)|null|
|**2025-12-13**|**Adaptive Detector-Verifier Framework for Zero-Shot Polyp Detection in Open-World Settings**|Yuqi Ouyang Team|[2512.12492](http://arxiv.org/abs/2512.12492)|null|
|**2025-12-13**|**GoMS: Graph of Molecule Substructure Network for Molecule Property Prediction**|Cheolwoo Park Team|[2512.12489](http://arxiv.org/abs/2512.12489)|null|
|**2025-12-13**|**More Than the Final Answer: Improving Visual Extraction and Logical Consistency in Vision-Language Models**|Jing Shi Team|[2512.12487](http://arxiv.org/abs/2512.12487)|null|
|**2025-12-13**|**MetaHGNIE: Meta-Path Induced Hypergraph Contrastive Learning in Heterogeneous Knowledge Graphs**|Yanlong Zhao Team|[2512.12477](http://arxiv.org/abs/2512.12477)|null|
|**2025-12-13**|**HetRL: Efficient Reinforcement Learning for LLMs in Heterogeneous Environments**|George Karypis Team|[2512.12476](http://arxiv.org/abs/2512.12476)|null|
|**2025-12-13**|**Autonomously Unweaving Multiple Cables Using Visual Feedback**|Howie Choset Team|[2512.12468](http://arxiv.org/abs/2512.12468)|null|
|**2025-12-13**|**Exploring the Design Space of Transition Matching**|Yaron Lipman Team|[2512.12465](http://arxiv.org/abs/2512.12465)|null|
|**2025-12-13**|**From Particles to Fields: Reframing Photon Mapping with Continuous Gaussian Photon Fields**|Ziyan Wu Team|[2512.12459](http://arxiv.org/abs/2512.12459)|null|
|**2025-12-13**|**Can GPT replace human raters? Validity and reliability of machine-generated norms for metaphors**|Valentina Bambini Team|[2512.12444](http://arxiv.org/abs/2512.12444)|null|
|**2025-12-13**|**Sim2Real Reinforcement Learning for Soccer skills**|Jonathan Spraggett Team|[2512.12437](http://arxiv.org/abs/2512.12437)|null|
|**2025-12-13**|**Endless World: Real-Time 3D-Aware Long Video Generation**|Vishal M. Patel Team|[2512.12430](http://arxiv.org/abs/2512.12430)|null|
|**2025-12-13**|**Unifying Quadrotor Motion Planning and Control by Chaining Different Fidelity Models**|Davide Scaramuzza Team|[2512.12427](http://arxiv.org/abs/2512.12427)|null|
|**2025-12-13**|**BokehDepth: Enhancing Monocular Depth Estimation through Bokeh Generation**|Xingang Pan Team|[2512.12425](http://arxiv.org/abs/2512.12425)|null|
|**2025-12-13**|**ViInfographicVQA: A Benchmark for Single and Multi-image Visual Question Answering on Vietnamese Infographics**|Quoc-Thai Nguyen Team|[2512.12424](http://arxiv.org/abs/2512.12424)|null|
|**2025-12-13**|**Deep Hedging with Reinforcement Learning: A Practical Framework for Option Risk Management**|Carrie Hu Team|[2512.12420](http://arxiv.org/abs/2512.12420)|**[link](https://github.com/tlucius16/deep-hedging-rl)**|
|**2025-12-13**|**A Graph Attention Network-Based Framework for Reconstructing Missing LiDAR Beams**|Mohammad El-Yabroudi Team|[2512.12410](http://arxiv.org/abs/2512.12410)|null|
|**2025-12-13**|**Generalised De-Preferential Random Graphs**|Kunal Joshi Team|[2512.12408](http://arxiv.org/abs/2512.12408)|null|
|**2025-12-13**|**ArtGen: Conditional Generative Modeling of Articulated Objects in Arbitrary Part-Level States**|Yakun Huang Team|[2512.12395](http://arxiv.org/abs/2512.12395)|null|
|**2025-12-13**|**Anchoring Values in Temporal and Group Dimensions for Flow Matching Model Alignment**|Zheng-Jun Zha Team|[2512.12387](http://arxiv.org/abs/2512.12387)|null|
|**2025-12-13**|**Speedrunning ImageNet Diffusion**|Swayam Bhanded Team|[2512.12386](http://arxiv.org/abs/2512.12386)|null|
|**2025-12-13**|**M4Human: A Large-Scale Multimodal mmWave Radar Benchmark for Human Mesh Reconstruction**|Fangqiang Ding Team|[2512.12378](http://arxiv.org/abs/2512.12378)|null|
|**2025-12-13**|**INDOOR-LiDAR: Bridging Simulation and Reality for Robot-Centric 360 degree Indoor LiDAR Perception -- A Robot-Centric Hybrid Dataset**|Tomi Westerlund Team|[2512.12377](http://arxiv.org/abs/2512.12377)|null|
|**2025-12-13**|**V-Warper: Appearance-Consistent Video Diffusion Personalization via Value Warping**|Seungryong Kim Team|[2512.12375](http://arxiv.org/abs/2512.12375)|**[link](https://cvlab-kaist.github.io/V-Warper)**|
|**2025-12-13**|**STAGE: Storyboard-Anchored Generation for Cinematic Multi-shot Narrative**|Boxin Shi Team|[2512.12372](http://arxiv.org/abs/2512.12372)|null|
|**2025-12-13**|**JPEG-Inspired Cloud-Edge Holography**|Renjing Xu Team|[2512.12367](http://arxiv.org/abs/2512.12367)|null|
|**2025-12-13**|**ElasticVR: Elastic Task Computing in Multi-User Multi-Connectivity Wireless Virtual Reality (VR) Systems**|Morteza Hashemi Team|[2512.12366](http://arxiv.org/abs/2512.12366)|null|
|**2025-12-13**|**VideoARM: Agentic Reasoning over Hierarchical Memory for Long-Form Video Understanding**|Zhou Yu Team|[2512.12360](http://arxiv.org/abs/2512.12360)|null|
|**2025-12-13**|**TCLeaf-Net: a transformer-convolution framework with global-local attention for robust in-field lesion-level plant leaf disease detection**|Jiarui Li Team|[2512.12357](http://arxiv.org/abs/2512.12357)|null|
|**2025-12-13**|**Unified Control for Inference-Time Guidance of Denoising Diffusion Models**|Hadi Jamali-Rad Team|[2512.12339](http://arxiv.org/abs/2512.12339)|null|
|**2025-12-13**|**The Role of AI in Modern Penetration Testing**|Nasir U. Eisty Team|[2512.12326](http://arxiv.org/abs/2512.12326)|null|
|**2025-12-13**|**WeDetect: Fast Open-Vocabulary Object Detection as Retrieval**|Wei-Shi Zheng Team|[2512.12309](http://arxiv.org/abs/2512.12309)|null|
|**2025-12-13**|**MRD: Using Physically Based Differentiable Rendering to Probe Vision Models for 3D Scene Understanding**|Thomas S. A. Wallis Team|[2512.12307](http://arxiv.org/abs/2512.12307)|null|
|**2025-12-13**|**OMUDA: Omni-level Masking for Unsupervised Domain Adaptation in Semantic Segmentation**|Xu Zhu Team|[2512.12303](http://arxiv.org/abs/2512.12303)|null|
|**2025-12-13**|**From Human Intention to Action Prediction: A Comprehensive Benchmark for Intention-driven End-to-End Autonomous Driving**|Jianbing Shen Team|[2512.12302](http://arxiv.org/abs/2512.12302)|null|
|**2025-12-13**|**A Conflict-Aware Resource Management Framework for the Computing Continuum**|Schahram Dustdar Team|[2512.12299](http://arxiv.org/abs/2512.12299)|null|
|**2025-12-13**|**GrowTAS: Progressive Expansion from Small to Large Subnets for Efficient ViT Architecture Search**|Bumsub Ham Team|[2512.12296](http://arxiv.org/abs/2512.12296)|null|
|**2025-12-13**|**RealDrag: The First Dragging Benchmark with Real Target Image**|Hamid R. Rabiee Team|[2512.12287](http://arxiv.org/abs/2512.12287)|null|
|**2025-12-13**|**V-Rex: Real-Time Streaming Video LLM Acceleration via Dynamic KV Cache Retrieval**|Joo-Young Kim Team|[2512.12284](http://arxiv.org/abs/2512.12284)|null|
|**2025-12-13**|**Cognitive-YOLO: LLM-Driven Architecture Synthesis from First Principles of Data for Object Detection**|Jiahao Zhao Team|[2512.12281](http://arxiv.org/abs/2512.12281)|null|
|**2025-12-13**|**Feature Aggregation for Efficient Continual Learning of Complex Facial Expressions**|Lionel Prevost Team|[2512.12277](http://arxiv.org/abs/2512.12277)|null|
|**2025-12-13**|**MetaTPT: Meta Test-time Prompt Tuning for Vision-Language Models**|Ling Shao Team|[2512.12268](http://arxiv.org/abs/2512.12268)|null|
|**2025-12-13**|**A Multi-Axial Mindset for Ontology Design Lessons from Wikidata's Polyhierarchical Structure**|Peter F. Patel-Schneider Team|[2512.12260](http://arxiv.org/abs/2512.12260)|null|
|**2025-12-13**|**Moment and Highlight Detection via MLLM Frame Segmentation**|Ayu Purwarianti Team|[2512.12246](http://arxiv.org/abs/2512.12246)|null|
|**2025-12-13**|**Resolution-Independent Neural Operators for Multi-Rate Sparse-View CT**|Anima Anandkumar Team|[2512.12236](http://arxiv.org/abs/2512.12236)|null|
|**2025-12-13**|**Learning to Get Up Across Morphologies: Zero-Shot Recovery with a Unified Humanoid Policy**|Jonathan Spraggett Team|[2512.12230](http://arxiv.org/abs/2512.12230)|null|
|**2025-12-13**|**Ultra-Low Bitrate Perceptual Image Compression with Shallow Encoder**|Chang Wen Chen Team|[2512.12229](http://arxiv.org/abs/2512.12229)|null|
|**2025-12-13**|**Comparison of different segmentation algorithms on brain volume and fractal dimension in infant brain MRIs**|Umberto Michelucci Team|[2512.12222](http://arxiv.org/abs/2512.12222)|null|
|**2025-12-13**|**ProImage-Bench: Rubric-Based Evaluation for Professional Image Generation**|Lijuan Wang Team|[2512.12220](http://arxiv.org/abs/2512.12220)|null|
|**2025-12-13**|**Fine-Grained Zero-Shot Learning with Attribute-Centric Representations**|Yuxiang Cai Team|[2512.12219](http://arxiv.org/abs/2512.12219)|null|
|**2025-12-13**|**Journey Before Destination: On the importance of Visual Faithfulness in Slow Thinking**|Zheng Qi Team|[2512.12218](http://arxiv.org/abs/2512.12218)|null|
|**2025-12-13**|**CineLOG: A Training Free Approach for Cinematic Long Video Generation**|Hamid R. Rabiee Team|[2512.12209](http://arxiv.org/abs/2512.12209)|null|
|**2025-12-13**|**A Hybrid Deep Learning Framework for Emotion Recognition in Children with Autism During NAO Robot-Mediated Interaction**|Bishakh Bhattacharya Team|[2512.12208](http://arxiv.org/abs/2512.12208)|null|
|**2025-12-13**|**ALERT Open Dataset and Input-Size-Agnostic Vision Transformer for Driver Activity Recognition using IR-UWB**|Saewoong Bahk Team|[2512.12206](http://arxiv.org/abs/2512.12206)|null|
|**2025-12-13**|**A Multi-Year Urban Streetlight Imagery Dataset for Visual Monitoring and Spatio-Temporal Drift Detection**|Aftab Khan Team|[2512.12205](http://arxiv.org/abs/2512.12205)|null|
|**2025-12-13**|**Navigation Around Unknown Space Objects Using Visible-Thermal Image Fusion**|David W. Miller Team|[2512.12203](http://arxiv.org/abs/2512.12203)|null|
|**2025-12-13**|**Thermal RGB Fusion for Micro-UAV Wildfire Perimeter Tracking with Minimal Comms**|Ayça Ak Team|[2512.12199](http://arxiv.org/abs/2512.12199)|null|
|**2025-12-13**|**MolGuidance: Advanced Guidance Strategies for Conditional Molecular Generation with Flow Matching**|Mingjie Liu Team|[2512.12198](http://arxiv.org/abs/2512.12198)|**[link](https://github.com/Liu-Group-UF/MolGuidance)**|
|**2025-12-13**|**AutoMV: An Automatic Multi-Agent System for Music Video Generation**|Yinghao Ma Team|[2512.12196](http://arxiv.org/abs/2512.12196)|null|
|**2025-12-13**|**SMRABooth: Subject and Motion Representation Alignment for Customized Video Generation**|Bing-Kun Bao Team|[2512.12193](http://arxiv.org/abs/2512.12193)|null|
|**2025-12-13**|**TA-KAND: Two-stage Attention Triple Enhancement and U-KAN based Diffusion For Few-shot Knowledge Graph Completion**|Xinyu Gao Team|[2512.12182](http://arxiv.org/abs/2512.12182)|null|
|**2025-12-13**|**Floorplan2Guide: LLM-Guided Floorplan Parsing for BLV Indoor Navigation**|Tim Oates Team|[2512.12177](http://arxiv.org/abs/2512.12177)|null|
|**2025-12-13**|**Audio-Visual Camera Pose Estimationn with Passive Scene Sounds and In-the-Wild Video**|Kristen Grauman Team|[2512.12165](http://arxiv.org/abs/2512.12165)|null|
|**2025-12-13**|**A Framework for Scalable Digital Twin Deployment in Smart Campus Building Facility Management**|Thyda Siv Team|[2512.12149](http://arxiv.org/abs/2512.12149)|null|
|**2025-12-13**|**Open Horizons: Evaluating Deep Models in the Wild**|Yuito Sugimoto Team|[2512.12146](http://arxiv.org/abs/2512.12146)|null|
|**2025-12-13**|**MeltwaterBench: Deep learning for spatiotemporal downscaling of surface meltwater**|Marco Tedesco Team|[2512.12142](http://arxiv.org/abs/2512.12142)|null|
|**2025-12-13**|**A Benchmark Dataset for Spatially Aligned Road Damage Assessment in Small Uncrewed Aerial Systems Disaster Imagery**|Robin R. Murphy Team|[2512.12128](http://arxiv.org/abs/2512.12128)|null|
|**2025-12-13**|**High-Dimensional Tensor Discriminant Analysis: Low-Rank Discriminant Structure, Representation Synergy, and Theoretical Guarantees**|Jiayu Li Team|[2512.12122](http://arxiv.org/abs/2512.12122)|null|
|**2025-12-13**|**BRIDG-ICS: AI-Grounded Knowledge Graphs for Intelligent Threat Analytics in Industry~5.0 Cyber-Physical Systems**|Helge Janicke Team|[2512.12112](http://arxiv.org/abs/2512.12112)|null|
|**2025-12-13**|**A Novel Patch-Based TDA Approach for Computed Tomography**|Amber L. Simpson Team|[2512.12108](http://arxiv.org/abs/2512.12108)|null|
|**2025-12-13**|**EchoVLM: Measurement-Grounded Multimodal Learning for Echocardiography**|Puneet Sharma Team|[2512.12107](http://arxiv.org/abs/2512.12107)|null|
|**2025-12-13**|**AI-Augmented Pollen Recognition in Optical and Holographic Microscopy for Veterinary Imaging**|Roberts Kadiķis Team|[2512.12101](http://arxiv.org/abs/2512.12101)|null|
|**2025-12-12**|**SPDMark: Selective Parameter Displacement for Robust Video Watermarking**|Karthik Nandakumar Team|[2512.12090](http://arxiv.org/abs/2512.12090)|null|
|**2025-12-12**|**VEGAS: Mitigating Hallucinations in Large Vision-Language Models via Vision-Encoder Attention Guided Adaptive Steering**|Peng Li Team|[2512.12089](http://arxiv.org/abs/2512.12089)|null|
|**2025-12-12**|**RePack: Representation Packing of Vision Foundation Model Features Enhances Diffusion Transformer**|Chao Gao Team|[2512.12083](http://arxiv.org/abs/2512.12083)|null|
|**2025-12-12**|**BAgger: Backwards Aggregation for Mitigating Drift in Autoregressive Video Diffusion Models**|Gordon Wetzstein Team|[2512.12080](http://arxiv.org/abs/2512.12080)|**[link](https://ryanpo.com/bagger)**|
|**2025-12-12**|**Rethinking Jailbreak Detection of Large Vision Language Models with Representational Contrastive Scoring**|Ning Zhang Team|[2512.12069](http://arxiv.org/abs/2512.12069)|null|
|**2025-12-12**|**CreativeVR: Diffusion-Prior-Guided Approach for Structure and Motion Restoration in Generative and Real Videos**|Xue Bai Team|[2512.12060](http://arxiv.org/abs/2512.12060)|null|
|**2025-12-12**|**Enhancing deep learning performance on burned area delineation from SPOT-6/7 imagery for emergency management**|Oscar Narvaez Team|[2512.12056](http://arxiv.org/abs/2512.12056)|null|
|**2025-12-12**|**Adaptive federated learning for ship detection across diverse satellite imagery sources**|Marco Chini Team|[2512.12053](http://arxiv.org/abs/2512.12053)|null|
|**2025-12-12**|**An algorithm to align a chain of sequences to paths in a pangenome graph**|Ugur Dogrusoz Team|[2512.12052](http://arxiv.org/abs/2512.12052)|null|
|**2025-12-12**|**Context-Aware Agentic Power Resources Optimisation in EV using Smart2ChargeApp**|Huseyin Seker Team|[2512.12048](http://arxiv.org/abs/2512.12048)|null|
|**2025-12-12**|**Goal Reaching with Eikonal-Constrained Hierarchical Quasimetric Reinforcement Learning**|Ahmed H. Qureshi Team|[2512.12046](http://arxiv.org/abs/2512.12046)|null|
|**2025-12-12**|**Accelerating Sparse Matrix-Matrix Multiplication on GPUs with Processing Near HBMs**|Jongryool Kim Team|[2512.12036](http://arxiv.org/abs/2512.12036)|null|
|**2025-12-12**|**DT-MPC: Synthesizing Derivation-Free Model Predictive Control from Power Converter Netlists via Physics-Informed Neural Digital Twins**|Leopoldo G. Franquelo Team|[2512.12026](http://arxiv.org/abs/2512.12026)|null|
|**2025-12-12**|**Modified Hybrid A* Collision-Free Path-Planning for Automated Reverse Parking**|Levent Guvenc Team|[2512.12021](http://arxiv.org/abs/2512.12021)|null|
|**2025-12-12**|**Exploring Spatial-Temporal Representation via Star Graph for mmWave Radar-based Human Activity Recognition**|Xuyu Wang Team|[2512.12013](http://arxiv.org/abs/2512.12013)|null|
|**2025-12-12**|**Semantic-Drive: Democratizing Long-Tail Data Curation via Open-Vocabulary Grounding and Neuro-Symbolic VLM Consensus**|Antonio Guillen-Perez Team|[2512.12012](http://arxiv.org/abs/2512.12012)|null|
|**2025-12-12**|**V-REX: Benchmarking Exploratory Visual Reasoning via Chain-of-Questions**|Tianyi Zhou Team|[2512.11995](http://arxiv.org/abs/2512.11995)|null|
|**2025-12-12**|**Policy Gradient Algorithms for Age-of-Information Cost Minimization**|Israel Leyva-Mayorga Team|[2512.11990](http://arxiv.org/abs/2512.11990)|null|
|**2025-12-12**|**CARI4D: Category Agnostic 4D Reconstruction of Human-Object Interaction**|Stan Birchfield Team|[2512.11988](http://arxiv.org/abs/2512.11988)|**[link](https://nvlabs.github.io/CARI4D/)**|
|**2025-12-12**|**Learning to Extract Context for Context-Aware LLM Inference**|Alessandro Sordoni Team|[2512.11986](http://arxiv.org/abs/2512.11986)|null|
|**2025-12-12**|**Evidence-Driven Decision Support for AI Model Selection in Research Software Engineering**|Siamak Farshidi Team|[2512.11984](http://arxiv.org/abs/2512.11984)|null|
|**2025-12-12**|**Semantic search for 100M+ galaxy images using AI-generated captions**|Shirley Ho Team|[2512.11982](http://arxiv.org/abs/2512.11982)|null|
|**2025-12-12**|**Designing The Internet of Agents: A Framework for Trustworthy, Transparent, and Collaborative Human-Agent Interaction (HAX)**|Srishti Kush Team|[2512.11979](http://arxiv.org/abs/2512.11979)|null|
|**2025-12-12**|**A Comparative Analysis of Semiconductor Wafer Map Defect Detection with Image Transformer**|Sushmita Nath Team|[2512.11977](http://arxiv.org/abs/2512.11977)|null|
|**2025-12-12**|**Pre-training vision models for the classification of alerts from wide-field time-domain surveys**|Mansi M. Kasliwal Team|[2512.11957](http://arxiv.org/abs/2512.11957)|null|
|**2025-12-12**|**A Review of Learning-Based Motion Planning: Toward a Data-Driven Optimal Control Approach**|Haoran Wang Team|[2512.11944](http://arxiv.org/abs/2512.11944)|null|
|**2025-12-12**|**DynaPURLS: Dynamic Refinement of Part-aware Representations for Skeleton-based Zero-Shot Action Recognition**|Qiuhong Ke Team|[2512.11941](http://arxiv.org/abs/2512.11941)|null|
|**2025-12-12**|**Contextual Peano Scan and Fast Image Segmentation Using Hidden and Evidential Markov Chains**|Wojciech Pieczynski Team|[2512.11939](http://arxiv.org/abs/2512.11939)|null|
|**2025-12-12**|**AGAPI-Agents: An Open-Access Agentic AI Platform for Accelerated Materials Design on AtomGPT.org**|Kamal Choudhary Team|[2512.11935](http://arxiv.org/abs/2512.11935)|null|
|**2025-12-12**|**Evolutionary Reinforcement Learning based AI tutor for Socratic Interdisciplinary Instruction**|Aimin Zhou Team|[2512.11930](http://arxiv.org/abs/2512.11930)|null|
|**2025-12-12**|**TransBridge: Boost 3D Object Detection by Scene-Level Completion with Transformer Decoder**|Jianbing Shen Team|[2512.11926](http://arxiv.org/abs/2512.11926)|null|
|**2025-12-11**|**FloraForge: LLM-Assisted Procedural Generation of Editable and Analysis-Ready 3D Plant Geometric Models For Agricultural Applications**|Baskar Ganapathysubramanian Team|[2512.11925](http://arxiv.org/abs/2512.11925)|null|
|**2025-12-11**|**Towards Accessible Physical AI: LoRA-Based Fine-Tuning of VLA Models for Real-World Robot Control**|Ibrahim Sheikh Mohamed Team|[2512.11921](http://arxiv.org/abs/2512.11921)|null|
|**2025-12-10**|**Safe Learning for Contact-Rich Robot Tasks: A Survey from Classical Learning-Based Methods to Safe Foundation Models**|Arash Ajoudani Team|[2512.11908](http://arxiv.org/abs/2512.11908)|null|
|**2025-12-10**|**Structured Personalization: Modeling Constraints as Matroids for Data-Minimal LLM Agents**|Hossein Rahnama Team|[2512.11907](http://arxiv.org/abs/2512.11907)|null|
|**2025-12-10**|**Aion: Towards Hierarchical 4D Scene Graphs with Temporal Flow Dynamics**|Jorge Pena-Queralta Team|[2512.11903](http://arxiv.org/abs/2512.11903)|null|
|**2025-12-10**|**Mirror Mode in Fire Emblem: Beating Players at their own Game with Imitation and Reinforcement Learning**|Aske Plaat Team|[2512.11902](http://arxiv.org/abs/2512.11902)|null|
|**2025-12-10**|**Read or Ignore? A Unified Benchmark for Typographic-Attack Robustness and Text Recognition in Vision-Language Models**|Tsubasa Takahashi Team|[2512.11899](http://arxiv.org/abs/2512.11899)|null|
|**2025-12-10**|**mmWEAVER: Environment-Specific mmWave Signal Synthesis from a Photo and Activity Description**|Shahriar Nirjon Team|[2512.11894](http://arxiv.org/abs/2512.11894)|null|
|**2025-12-09**|**VLSA: Vision-Language-Action Models with Plug-and-Play Safety Constraint Layer**|Xiao He Team|[2512.11891](http://arxiv.org/abs/2512.11891)|null|
|**2025-12-09**|**Generalization vs. Specialization: Evaluating Segment Anything Model (SAM3) Zero-Shot Segmentation Against Fine-Tuned YOLO Detectors**|Nikolaos D. Tselikas Team|[2512.11884](http://arxiv.org/abs/2512.11884)|null|
|**2025-12-09**|**Aesthetic Alignment Risks Assimilation: How Image Generation and Reward Models Reinforce Beauty Bias and Ideological "Censorship"**|Shan Du Team|[2512.11883](http://arxiv.org/abs/2512.11883)|null|
|**2025-12-07**|**Traversability Aware Autonomous Navigation for Multi-Modal Mobility Morphobot (M4)**|Hrigved Mahesh Suryawanshi Team|[2512.11876](http://arxiv.org/abs/2512.11876)|null|
|**2025-12-07**|**Pseudo-Label Refinement for Robust Wheat Head Segmentation via Two-Stage Hybrid Training**|Jingkuan Song Team|[2512.11874](http://arxiv.org/abs/2512.11874)|null|
|**2025-12-06**|**WAM-Diff: A Masked Diffusion VLA Framework with MoE and Online Reinforcement Learning for Autonomous Driving**|Siyu Zhu Team|[2512.11872](http://arxiv.org/abs/2512.11872)|null|
|**2025-12-05**|**Explainable Adversarial-Robust Vision-Language-Action Model for Robotic Manipulation**|Gun-Woo Kim Team|[2512.11865](http://arxiv.org/abs/2512.11865)|null|
|**2025-12-05**|**Hierarchical Task Offloading and Trajectory Optimization in Low-Altitude Intelligent Networks Via Auction and Diffusion-based MARL**|Zhu Han Team|[2512.11862](http://arxiv.org/abs/2512.11862)|null|
|**2025-12-05**|**An Operator-Consistent Graph Neural Network for Learning Diffusion Dynamics on Irregular Meshes**|Andrew Rushing Hands Team|[2512.11860](http://arxiv.org/abs/2512.11860)|null|
|**2025-12-05**|**GCoDE: Efficient Device-Edge Co-Inference for GNNs via Architecture-Mapping Co-Search**|Chunming Hu Team|[2512.11856](http://arxiv.org/abs/2512.11856)|null|
|**2025-12-04**|**Exploring Topological Bias in Heterogeneous Graph Neural Networks**|Yihan Zhang Team|[2512.11846](http://arxiv.org/abs/2512.11846)|null|
|**2025-12-03**|**Large Language Models as Generalist Policies for Network Optimization**|Zhi Wang Team|[2512.11839](http://arxiv.org/abs/2512.11839)|**[link](https://duowuyms.github.io/trailblazer)**|
|**2025-12-12**|**Moment-Based 3D Gaussian Splatting: Resolving Volumetric Occlusion with Order-Independent Transmittance**|Reinhard Klein Team|[2512.11800](http://arxiv.org/abs/2512.11800)|null|
|**2025-12-12**|**V-RGBX: Video Editing with Accurate Controls over Intrinsic Properties**|Tuanfeng Yang Wang Team|[2512.11799](http://arxiv.org/abs/2512.11799)|**[link](https://aleafy.github.io/vrgbx)**|
|**2025-12-12**|**Particulate: Feed-Forward 3D Object Articulation**|Andrea Vedaldi Team|[2512.11798](http://arxiv.org/abs/2512.11798)|**[link](https://ruiningli.com/particulate)**|
|**2025-12-12**|**AnchorDream: Repurposing Video Diffusion for Embodiment-Aware Robot Data Synthesis**|Vitor Guizilini Team|[2512.11797](http://arxiv.org/abs/2512.11797)|**[link](https://jay-ye.github.io/AnchorDream/)**|
|**2025-12-12**|**A General Algorithm for Detecting Higher-Order Interactions via Random Sequential Additions**|Claire McWhite Team|[2512.11793](http://arxiv.org/abs/2512.11793)|null|
|**2025-12-12**|**Structure From Tracking: Distilling Structure-Preserving Motion for Video Generation**|Benlin Liu Team|[2512.11792](http://arxiv.org/abs/2512.11792)|**[link](https://sam2videox.github.io/)**|
|**2025-12-12**|**Uncertainty-Aware Domain Adaptation for Vitiligo Segmentation in Clinical Photographs**|Nicole Nyamongo Team|[2512.11791](http://arxiv.org/abs/2512.11791)|null|
|**2025-12-12**|**MatAnyone 2: Scaling Video Matting via a Learned Quality Evaluator**|Qingyi Tao Team|[2512.11782](http://arxiv.org/abs/2512.11782)|**[link](https://pq-yang.github.io/projects/MatAnyone2/)**|
|**2025-12-12**|**Agile Flight Emerges from Multi-Agent Competitive Racing**|Antonio Loquercio Team|[2512.11781](http://arxiv.org/abs/2512.11781)|null|
|**2025-12-12**|**Smudged Fingerprints: A Systematic Evaluation of the Robustness of AI Image Fingerprints**|Marc Juarez Team|[2512.11771](http://arxiv.org/abs/2512.11771)|null|
|**2025-12-12**|**BLURR: A Boosted Low-Resource Inference for Vision-Language-Action Models**|Yanfang Ye Team|[2512.11769](http://arxiv.org/abs/2512.11769)|**[link](https://github.com/JijiKing-Sam/BLURR-A-Boosted-Low-Resource-Inference-for-Vision-Language-Action-Model)**|
|**2025-12-12**|**Reducing Domain Gap with Diffusion-Based Domain Adaptation for Cell Counting**|Wallapak Tavanapong Team|[2512.11763](http://arxiv.org/abs/2512.11763)|null|
|**2025-12-12**|**SUMFORU: An LLM-Based Review Summarization Framework for Personalized Purchase Decision Support**|Xinrui Jiang Team|[2512.11755](http://arxiv.org/abs/2512.11755)|**[link](https://github.com/Harry20030331/SumForU)**|
|**2025-12-12**|**SVG-T2I: Scaling Up Text-to-Image Latent Diffusion Model Without Variational Autoencoder**|Jiwen Lu Team|[2512.11749](http://arxiv.org/abs/2512.11749)|**[link](https://github.com/KlingTeam/SVG-T2I)**|
|**2025-12-12**|**mViSE: A Visual Search Engine for Analyzing Multiplex IHC Brain Tissue Images**|Badrinath Roysam Team|[2512.11745](http://arxiv.org/abs/2512.11745)|null|
|**2025-12-12**|**Weak-to-Strong Generalization Enables Fully Automated De Novo Training of Multi-head Mask-RCNN Model for Segmenting Densely Overlapping Cell Nuclei in Multiplex Whole-slice Brain Images**|Badrinath Roysam Team|[2512.11722](http://arxiv.org/abs/2512.11722)|null|
|**2025-12-12**|**Reframing Music-Driven 2D Dance Pose Generation as Multi-Channel Image Generation**|Zhenpeng Zhan Team|[2512.11720](http://arxiv.org/abs/2512.11720)|null|
|**2025-12-12**|**Referring Change Detection in Remote Sensing Imagery**|Vishal M. Patel Team|[2512.11719](http://arxiv.org/abs/2512.11719)|null|
|**2025-12-12**|**EditMGT: Unleashing Potentials of Masked Generative Transformers in Image Editing**|Songhua Liu Team|[2512.11715](http://arxiv.org/abs/2512.11715)|null|
|**2025-12-12**|**Particle Image Velocimetry Refinement via Consensus ADMM**|Antonio Terpin Team|[2512.11695](http://arxiv.org/abs/2512.11695)|**[link](https://github.com/antonioterpin/flowgym)**|
|**2025-12-12**|**Text images processing system using artificial intelligence models**|Aya Kaysan Bahjat Team|[2512.11691](http://arxiv.org/abs/2512.11691)|null|
|**2025-12-12**|**Depth-Copy-Paste: Multimodal and Depth-Aware Compositing for Robust Face Detection**|Qiushi Guo Team|[2512.11683](http://arxiv.org/abs/2512.11683)|null|
|**2025-12-12**|**Cross-modal Context-aware Learning for Visual Prompt Guided Multimodal Image Understanding in Remote Sensing**|Zhiyong Li Team|[2512.11680](http://arxiv.org/abs/2512.11680)|null|
|**2025-12-12**|**Stochastics of shapes and Kunita flows**|Elizabeth Louise Baker Team|[2512.11676](http://arxiv.org/abs/2512.11676)|null|
|**2025-12-12**|**Natural Language Interaction for Editing Visual Knowledge Graphs**|Jaime Ruiz Team|[2512.11674](http://arxiv.org/abs/2512.11674)|null|
|**2025-12-12**|**Kinetic Mining in Context: Few-Shot Action Synthesis via Text-to-Motion Distillation**|Ahed Alboody Team|[2512.11654](http://arxiv.org/abs/2512.11654)|null|
|**2025-12-12**|**FactorPortrait: Controllable Portrait Animation via Disentangled Expression, Pose, and Viewpoint**|Peihong Guo Team|[2512.11645](http://arxiv.org/abs/2512.11645)|**[link](https://tangjiapeng.github.io/FactorPortrait/)**|
|**2025-12-12**|**Fast and Explicit: Slice-to-Volume Reconstruction via 3D Gaussian Primitives with Analytic Point Spread Function Modeling**|Daniel Rueckert Team|[2512.11624](http://arxiv.org/abs/2512.11624)|null|
|**2025-12-12**|**Embodied Image Compression**|Guangtao Zhai Team|[2512.11612](http://arxiv.org/abs/2512.11612)|null|
|**2025-12-12**|**Using GUI Agent for Electronic Design Automation**|Guangtao Zhai Team|[2512.11611](http://arxiv.org/abs/2512.11611)|null|
|**2025-12-12**|**UniBYD: A Unified Framework for Learning Robotic Manipulation Across Embodiments Beyond Imitation of Human Demonstrations**|Jinqiao Wang Team|[2512.11609](http://arxiv.org/abs/2512.11609)|null|
|**2025-12-12**|**Transfer learning of GW-Bethe-Salpeter Equation excitation energies**|Lucas Visscher Team|[2512.11596](http://arxiv.org/abs/2512.11596)|null|
|**2025-12-12**|**Atomic Action Slicing: Planner-Aligned Options for Generalist VLA Agents**|Boris Kraychev Team|[2512.11584](http://arxiv.org/abs/2512.11584)|null|
|**2025-12-12**|**Brain-Semantoks: Learning Semantic Tokens of Brain Dynamics with a Self-Distilled Foundation Model**|Kerstin Ritter Team|[2512.11582](http://arxiv.org/abs/2512.11582)|**[link](https://github.com/SamGijsen/Brain-Semantoks)**|
|**2025-12-12**|**Safe Bayesian optimization across noise models via scenario programming**|Dominik Baumann Team|[2512.11580](http://arxiv.org/abs/2512.11580)|null|
|**2025-12-12**|**In-Context Learning for Seismic Data Processing**|Janis Keuper Team|[2512.11575](http://arxiv.org/abs/2512.11575)|**[link](https://codeberg.org/fuchsfa/in-context-learning-seismic)**|
|**2025-12-12**|**Evaluating Foundation Models' 3D Understanding Through Multi-View Correspondence Analysis**|Mohammadreza Salehi Team|[2512.11574](http://arxiv.org/abs/2512.11574)|null|
|**2025-12-12**|**Cross-Entropy Optimization of Physically Grounded Task and Motion Plans**|Javier Alonso-Mora Team|[2512.11571](http://arxiv.org/abs/2512.11571)|null|
|**2025-12-12**|**Extending a Parliamentary Corpus with MPs' Tweets: Automatic Annotation and Evaluation Using MultiParTweet**|Alexander Mehler Team|[2512.11567](http://arxiv.org/abs/2512.11567)|null|
|**2025-12-12**|**Fully Inductive Node Representation Learning via Graph View Transformation**|Jaemin Yoo Team|[2512.11561](http://arxiv.org/abs/2512.11561)|null|
|**2025-12-12**|**Multi-temporal Calving Front Segmentation**|Vincent Christlein Team|[2512.11560](http://arxiv.org/abs/2512.11560)|null|
|**2025-12-12**|**DentalGPT: Incentivizing Multimodal Complex Reasoning in Dentistry**|Benyou Wang Team|[2512.11558](http://arxiv.org/abs/2512.11558)|null|
|**2025-12-12**|**3DTeethSAM: Taming SAM2 for 3D Teeth Segmentation**|Kun Zhou Team|[2512.11557](http://arxiv.org/abs/2512.11557)|null|
|**2025-12-12**|**SSL-MedSAM2: A Semi-supervised Medical Image Segmentation Framework Powered by Few-shot Learning of SAM2**|Xin Chen Team|[2512.11548](http://arxiv.org/abs/2512.11548)|null|
|**2025-12-12**|**Graph Embedding with Mel-spectrograms for Underwater Acoustic Target Recognition**|Xiaoqian Zhu Team|[2512.11545](http://arxiv.org/abs/2512.11545)|null|
|**2025-12-12**|**Infinity and Beyond: Compositional Alignment in VAR and Diffusion T2I Models**|Mahdieh Soleymani Baghshah Team|[2512.11542](http://arxiv.org/abs/2512.11542)|null|
|**2025-12-12**|**HFS: Holistic Query-Aware Frame Selection for Efficient Video Reasoning**|Kin-Man Lam Team|[2512.11534](http://arxiv.org/abs/2512.11534)|null|
|**2025-12-12**|**Parallax: Runtime Parallelization for Operator Fallbacks in Heterogeneous Edge Systems**|Jagmohan Chauhan Team|[2512.11532](http://arxiv.org/abs/2512.11532)|null|
|**2025-12-12**|**Super-Resolved Canopy Height Mapping from Sentinel-2 Time Series Using LiDAR HD Reference Data across Metropolitan France**|Milena Planells Team|[2512.11524](http://arxiv.org/abs/2512.11524)|null|
|**2025-12-12**|**Reconstruction as a Bridge for Event-Based Visual Question Answering**|Boxin Shi Team|[2512.11510](http://arxiv.org/abs/2512.11510)|null|
|**2025-12-12**|**On Geometric Understanding and Learned Data Priors in VGGT**|Christian Rupprecht Team|[2512.11508](http://arxiv.org/abs/2512.11508)|null|
|**2025-12-12**|**SSA3D: Text-Conditioned Assisted Self-Supervised Framework for Automatic Dental Abutment Design**|Linlin Shen Team|[2512.11507](http://arxiv.org/abs/2512.11507)|null|
|**2025-12-12**|**EmeraldMind: A Knowledge Graph-Augmented Framework for Greenwashing Detection**|Panayiotis Tsaparas Team|[2512.11506](http://arxiv.org/abs/2512.11506)|null|
|**2025-12-12**|**TSkel-Mamba: Temporal Dynamic Modeling via State Space Model for Human Skeleton-based Action Recognition**|Qiuhong Ke Team|[2512.11503](http://arxiv.org/abs/2512.11503)|null|
|**2025-12-12**|**VLM2GeoVec: Toward Universal Multimodal Embeddings for Remote Sensing**|Michael Felsberg Team|[2512.11490](http://arxiv.org/abs/2512.11490)|null|
|**2025-12-12**|**CADMorph: Geometry-Driven Parametric CAD Editing via a Plan-Generate-Verify Loop**|Jiang Bian Team|[2512.11480](http://arxiv.org/abs/2512.11480)|null|
|**2025-12-12**|**Rethinking Expert Trajectory Utilization in LLM Post-training**|Tao Lin Team|[2512.11470](http://arxiv.org/abs/2512.11470)|null|
|**2025-12-12**|**Three methods, one problem: Classical and AI approaches to no-three-in-line**|Sreedath Panat Team|[2512.11469](http://arxiv.org/abs/2512.11469)|null|
|**2025-12-12**|**DOS: Distilling Observable Softmaps of Zipfian Prototypes for Self-Supervised Point Representation**|Abhinav Valada Team|[2512.11465](http://arxiv.org/abs/2512.11465)|null|
|**2025-12-12**|**Exploring MLLM-Diffusion Information Transfer with MetaCanvas**|Chu Wang Team|[2512.11464](http://arxiv.org/abs/2512.11464)|**[link](https://metacanvas.github.io)**|
|**2025-12-11**|**Motif-2-12.7B-Reasoning: A Practitioner's Guide to RL Training Recipes**|Dongjoo Weon Team|[2512.11463](http://arxiv.org/abs/2512.11463)|null|
|**2025-12-12**|**Boosting Skeleton-based Zero-Shot Action Recognition with Training-Free Test-Time Adaptation**|Qiuhong Ke Team|[2512.11458](http://arxiv.org/abs/2512.11458)|null|
|**2025-12-12**|**YawDD+: Frame-level Annotations for Accurate Yawn Prediction**|Radu Prodan Team|[2512.11446](http://arxiv.org/abs/2512.11446)|null|
|**2025-12-12**|**Flowception: Temporally Expansive Flow Matching for Video Generation**|Ricky T. Q. Chen Team|[2512.11438](http://arxiv.org/abs/2512.11438)|null|
|**2025-12-12**|**Back to the Baseline: Examining Baseline Effects on Explainability Metrics**|Thomas Fel Team|[2512.11433](http://arxiv.org/abs/2512.11433)|null|
|**2025-12-12**|**JoyAvatar: Real-time and Infinite Audio-Driven Avatar Generation with Autoregressive Diffusion**|Xiaodong He Team|[2512.11423](http://arxiv.org/abs/2512.11423)|null|
|**2025-12-12**|**Towards Trustworthy Multi-Turn LLM Agents via Behavioral Guidance**|Gonca Gürsun Team|[2512.11421](http://arxiv.org/abs/2512.11421)|null|
|**2025-12-12**|**Collaborative Reconstruction and Repair for Multi-class Industrial Anomaly Detection**|Wenqiang Zhang Team|[2512.11401](http://arxiv.org/abs/2512.11401)|null|
|**2025-12-12**|**Minimal Clips, Maximum Salience: Long Video Summarization via Key Moment Extraction**|Nancy F. Chen Team|[2512.11399](http://arxiv.org/abs/2512.11399)|null|
|**2025-12-12**|**FlowDC: Flow-Based Decoupling-Decay for Complex Image Editing**|Long Chen Team|[2512.11395](http://arxiv.org/abs/2512.11395)|null|
|**2025-12-12**|**The N-Body Problem: Parallel Execution from Single-Person Egocentric Video**|Dima Damen Team|[2512.11393](http://arxiv.org/abs/2512.11393)|**[link](https://zhifanzhu.github.io/ego-nbody)**|
|**2025-12-12**|**Mitigating the Safety Alignment Tax with Null-Space Constrained Policy Optimization**|Jia Li Team|[2512.11391](http://arxiv.org/abs/2512.11391)|null|
|**2025-12-12**|**Out-of-Distribution Segmentation via Wasserstein-Based Evidential Uncertainty**|Kira Maag Team|[2512.11373](http://arxiv.org/abs/2512.11373)|null|
|**2025-12-12**|**Assisted Refinement Network Based on Channel Information Interaction for Camouflaged and Salient Object Detection**|Xiaoming Tao Team|[2512.11369](http://arxiv.org/abs/2512.11369)|null|
|**2025-12-12**|**An Anatomy of Vision-Language-Action Models: From Modules to Milestones and Challenges**|Jiankang Deng Team|[2512.11362](http://arxiv.org/abs/2512.11362)|null|
|**2025-12-12**|**Reliable Detection of Minute Targets in High-Resolution Aerial Imagery across Temporal Shifts**|Ehsan Pazouki Team|[2512.11360](http://arxiv.org/abs/2512.11360)|null|
|**2025-12-12**|**Attacking and Securing Community Detection: A Game-Theoretic Framework**|Jia Li Team|[2512.11359](http://arxiv.org/abs/2512.11359)|null|
|**2025-12-12**|**Prior-Enhanced Gaussian Splatting for Dynamic Scene Reconstruction from Casual Video**|Brian Curless Team|[2512.11356](http://arxiv.org/abs/2512.11356)|null|
|**2025-12-12**|**A Multi-Mode Structured Light 3D Imaging System with Multi-Source Information Fusion for Underwater Pipeline Detection**|Zhiqing Li Team|[2512.11354](http://arxiv.org/abs/2512.11354)|null|
|**2025-12-12**|**CAT: Can Trust be Predicted with Context-Awareness in Dynamic Heterogeneous Networks?**|Elisa Bertino Team|[2512.11352](http://arxiv.org/abs/2512.11352)|null|
|**2025-12-12**|**Surveillance Video-Based Traffic Accident Detection Using Transformer Architecture**|Long T. Truong Team|[2512.11350](http://arxiv.org/abs/2512.11350)|null|
|**2025-12-12**|**Symmetry-Aware Steering of Equivariant Diffusion Policies: Benefits and Limits**|Roberto Horowitz Team|[2512.11345](http://arxiv.org/abs/2512.11345)|null|
|**2025-12-12**|**DAPO: Design Structure-Aware Pass Ordering in High-Level Synthesis with Graph Contrastive and Reinforcement Learning**|Wei Zhang Team|[2512.11342](http://arxiv.org/abs/2512.11342)|null|
|**2025-12-12**|**Task-Specific Distance Correlation Matching for Few-Shot Action Recognition**|Peihua Li Team|[2512.11340](http://arxiv.org/abs/2512.11340)|null|
|**2025-12-12**|**UFVideo: Towards Unified Fine-Grained Video Cooperative Understanding with Large Language Models**|Shengshan Hu Team|[2512.11336](http://arxiv.org/abs/2512.11336)|null|
|**2025-12-12**|**FreqDINO: Frequency-Guided Adaptation for Generalized Boundary-Aware Ultrasound Image Segmentation**|Zhen Chen Team|[2512.11335](http://arxiv.org/abs/2512.11335)|null|
|**2025-12-12**|**Physics-Informed Video Flare Synthesis and Removal Leveraging Motion Independence between Flare and Scene**|Hua Huang Team|[2512.11327](http://arxiv.org/abs/2512.11327)|null|
|**2025-12-12**|**MLLM Machine Unlearning via Visual Knowledge Distillation**|Gang Hua Team|[2512.11325](http://arxiv.org/abs/2512.11325)|null|
|**2025-12-12**|**CAPTURE: A Benchmark and Evaluation for LVLMs in CAPTCHA Resolving**|Zhangchi Zhao Team|[2512.11323](http://arxiv.org/abs/2512.11323)|null|
|**2025-12-12**|**KeyframeFace: From Text to Expressive Facial Keyframes**|Xiangru Huang Team|[2512.11321](http://arxiv.org/abs/2512.11321)|null|
|**2025-12-12**|**SATMapTR: Satellite Image Enhanced Online HD Map Construction**|Jianping Wang Team|[2512.11319](http://arxiv.org/abs/2512.11319)|null|
|**2025-12-12**|**Condensation-Concatenation Framework for Dynamic Graph Continual Learning**|Ye Yuan Team|[2512.11317](http://arxiv.org/abs/2512.11317)|null|
|**2025-12-12**|**Benchmarking the Generality of Vision-Language-Action Models**|Yangyue Wang Team|[2512.11315](http://arxiv.org/abs/2512.11315)|null|
|**2025-12-12**|**RollMux: Phase-Level Multiplexing for Disaggregated RL Post-Training**|Wei Wang Team|[2512.11306](http://arxiv.org/abs/2512.11306)|null|
|**2025-12-12**|**MultiEgo: A Multi-View Egocentric Video Dataset for 4D Scene Reconstruction**|Wenjun Zhang Team|[2512.11301](http://arxiv.org/abs/2512.11301)|null|
|**2025-12-12**|**Few-Shot VLM-Based G-Code and HMI Verification in CNC Machining**|Vinh Nguyen Team|[2512.11296](http://arxiv.org/abs/2512.11296)|null|
|**2025-12-12**|**Autoregressive Video Autoencoder with Decoupled Temporal and Spatial Context**|Gengdai Liu Team|[2512.11293](http://arxiv.org/abs/2512.11293)|null|
|**2025-12-12**|**RcAE: Recursive Reconstruction Framework for Unsupervised Industrial Anomaly Detection**|Ye Lin Team|[2512.11284](http://arxiv.org/abs/2512.11284)|null|
|**2025-12-12**|**When Actions Teach You to Think: Reasoning-Action Synergy via Reinforcement Learning in Conversational Agents**|Roberto Pieraccini Team|[2512.11277](http://arxiv.org/abs/2512.11277)|null|
|**2025-12-12**|**Towards Logic-Aware Manipulation: A Knowledge Primitive for VLM-Based Assistants in Smart Manufacturing**|Daqiang Guo Team|[2512.11275](http://arxiv.org/abs/2512.11275)|null|
|**2025-12-12**|**FilmWeaver: Weaving Consistent Multi-Shot Videos with Cache-Guided Autoregressive Diffusion**|Shao-Lun Huang Team|[2512.11274](http://arxiv.org/abs/2512.11274)|null|
|**2025-12-12**|**Vision-Based Learning for Cyberattack Detection in Blockchain Smart Contracts and Transactions**|Nguyen Linh Trung Team|[2512.11272](http://arxiv.org/abs/2512.11272)|null|
|**2025-12-12**|**A-LAMP: Agentic LLM-Based Framework for Automated MDP Modeling and Policy Generation**|Hyun-Suk Lee Team|[2512.11270](http://arxiv.org/abs/2512.11270)|null|
|**2025-12-12**|**Evaluating the Efficacy of Sentinel-2 versus Aerial Imagery in Serrated Tussock Classification**|Shyh Wei Teng Team|[2512.11267](http://arxiv.org/abs/2512.11267)|null|
|**2025-12-12**|**Do We Need Reformer for Vision? An Experimental Comparison with Vision Transformers**|Rhassan Berber Team|[2512.11260](http://arxiv.org/abs/2512.11260)|null|
|**2025-12-12**|**PersonaLive! Expressive Portrait Image Animation for Live Streaming**|Xiaodong Cun Team|[2512.11253](http://arxiv.org/abs/2512.11253)|null|
|**2025-12-12**|**Personalized Pricing in Social Networks with Individual and Group Fairness Considerations**|Jing Huang Team|[2512.11252](http://arxiv.org/abs/2512.11252)|null|
|**2025-12-12**|**Elevation Aware 2D/3D Co-simulation Framework for Large-scale Traffic Flow and High-fidelity Vehicle Dynamics**|Weizi Li Team|[2512.11249](http://arxiv.org/abs/2512.11249)|null|
|**2025-12-12**|**Multi-Objective Reinforcement Learning for Large-Scale Mixed Traffic Control**|Weizi Li Team|[2512.11247](http://arxiv.org/abs/2512.11247)|null|
|**2025-12-12**|**Task-Aware Multi-Expert Architecture For Lifelong Deep Learning**|Hoda Bidkhori Team|[2512.11243](http://arxiv.org/abs/2512.11243)|null|
|**2025-12-12**|**Cross-modal Prompting for Balanced Incomplete Multi-modal Emotion Recognition**|Zheng Zhang Team|[2512.11239](http://arxiv.org/abs/2512.11239)|null|
|**2025-12-12**|**WildCap: Facial Appearance Capture in the Wild via Hybrid Inverse Rendering**|Feng Xu Team|[2512.11237](http://arxiv.org/abs/2512.11237)|**[link](https://yxuhan.github.io/WildCap/index.html)**|
|**2025-12-12**|**RoomPilot: Controllable Synthesis of Interactive Indoor Environments via Multimodal Semantic Parsing**|Ruihui Li Team|[2512.11234](http://arxiv.org/abs/2512.11234)|null|
|**2025-12-12**|**REST: Diffusion-based Real-time End-to-end Streaming Talking Head Generation via ID-Context Caching and Asynchronous Streaming Distillation**|Qingfeng Liu Team|[2512.11229](http://arxiv.org/abs/2512.11229)|null|
|**2025-12-12**|**FutureX: Enhance End-to-End Autonomous Driving via Latent Chain-of-Thought World Model**|Zhen Li Team|[2512.11226](http://arxiv.org/abs/2512.11226)|null|
|**2025-12-12**|**VFMF: World Modeling by Forecasting Vision Foundation Model Features**|Andrea Vedaldi Team|[2512.11225](http://arxiv.org/abs/2512.11225)|null|
|**2025-12-12**|**Seeing to Act, Prompting to Specify: A Bayesian Factorization of Vision Language Action Policy**|Yue Wang Team|[2512.11218](http://arxiv.org/abs/2512.11218)|null|
|**2025-12-12**|**AutoRefiner: Improving Autoregressive Video Diffusion Models via Reflective Refinement Over the Stochastic Sampling Path**|Yuki Mitsufuji Team|[2512.11203](http://arxiv.org/abs/2512.11203)|null|
|**2025-12-12**|**Beyond Memorization: Gradient Projection Enables Selective Learning in Diffusion Models**|Jaclyn Pytlarz Team|[2512.11194](http://arxiv.org/abs/2512.11194)|null|
|**2025-12-12**|**Lightweight 3D Gaussian Splatting Compression via Video Codec**|Zhu Li Team|[2512.11186](http://arxiv.org/abs/2512.11186)|null|
|**2025-12-11**|**Bandwidth-constrained Variational Message Encoding for Cooperative Multi-agent Reinforcement Learning**|Junyu Xuan Team|[2512.11179](http://arxiv.org/abs/2512.11179)|null|
|**2025-12-11**|**Learning Category-level Last-meter Navigation from RGB Demonstrations of a Single-instance**|Karthik Desingh Team|[2512.11173](http://arxiv.org/abs/2512.11173)|null|
|**2025-12-11**|**CORL: Reinforcement Learning of MILP Policies Solved via Branch and Bound**|Sebastien Gros Team|[2512.11169](http://arxiv.org/abs/2512.11169)|null|
|**2025-12-11**|**Image Tiling for High-Resolution Reasoning: Balancing Local Detail with Global Context**|Irina Rish Team|[2512.11167](http://arxiv.org/abs/2512.11167)|null|
|**2025-12-11**|**Benchmarking RL-Enhanced Spatial Indices Against Traditional, Advanced, and Learned Counterparts**|Zhifeng Bao Team|[2512.11161](http://arxiv.org/abs/2512.11161)|null|
|**2025-12-11**|**Refining Graphical Neural Network Predictions Using Flow Matching for Optimal Power Flow with Constraint-Satisfaction Guarantee**|Kshitiz Khanal Team|[2512.11127](http://arxiv.org/abs/2512.11127)|null|
|**2025-12-11**|**In-Context Multi-Objective Optimization**|Samuel Kaski Team|[2512.11114](http://arxiv.org/abs/2512.11114)|null|
|**2025-12-11**|**Limits and Gains of Test-Time Scaling in Vision-Language Reasoning**|Mahdieh Soleymani Baghshah Team|[2512.11109](http://arxiv.org/abs/2512.11109)|null|
|**2025-12-11**|**VGent: Visual Grounding via Modular Design for Disentangling Reasoning and Prediction**|Kangning Liu Team|[2512.11099](http://arxiv.org/abs/2512.11099)|null|
|**2025-12-11**|**Vision-Language Models for Infrared Industrial Sensing in Additive Manufacturing Scene Description**|Vinh Nguyen Team|[2512.11098](http://arxiv.org/abs/2512.11098)|null|
|**2025-12-11**|**Your plan may succeed, but what about failure? Investigating how people use ChatGPT for long-term life task planning**|Jiqun Liu Team|[2512.11096](http://arxiv.org/abs/2512.11096)|null|
|**2025-12-11**|**VDAWorld: World Modelling via VLM-Directed Abstraction and Simulation**|Ayush Tewari Team|[2512.11061](http://arxiv.org/abs/2512.11061)|**[link](https://felixomahony.github.io/vdaworld/)**|
|**2025-12-11**|**Synthetic Vasculature and Pathology Enhance Vision-Language Model Reasoning**|Johannes C. Paetzold Team|[2512.11060](http://arxiv.org/abs/2512.11060)|null|
|**2025-12-11**|**WholeBodyVLA: Towards Unified Latent VLA for Whole-Body Loco-Manipulation Control**|Hongyang Li Team|[2512.11047](http://arxiv.org/abs/2512.11047)|null|
|**2025-12-10**|**Query Optimization Beyond Data Systems: The Case for Multi-Agent Systems**|Ioana Giurgiu Team|[2512.11001](http://arxiv.org/abs/2512.11001)|null|
|**2025-12-10**|**KBQA-R1: Reinforcing Large Language Models for Knowledge Base Question Answering**|Liang Wang Team|[2512.10999](http://arxiv.org/abs/2512.10999)|null|
|**2025-12-05**|**Marti-5: A Mathematical Model of "Self in the World" as a First Step Toward Self-Awareness**|Sergey Shumsky Team|[2512.10985](http://arxiv.org/abs/2512.10985)|null|
|**2025-12-02**|**Agent-Based Modular Learning for Multimodal Emotion Recognition in Human-Agent Systems**|Ilya Afanasyev Team|[2512.10975](http://arxiv.org/abs/2512.10975)|null|
|**2025-12-11**|**WorldLens: Full-Spectrum Evaluations of Driving World Models in Real World**|Ziwei Liu Team|[2512.10958](http://arxiv.org/abs/2512.10958)|**[link](https://worldbench.github.io/worldlens)**|
|**2025-12-11**|**SceneMaker: Open-set 3D Scene Generation with Decoupled De-occlusion and Pose Estimation Model**|Lei Zhang Team|[2512.10957](http://arxiv.org/abs/2512.10957)|**[link](https://idea-research.github.io/SceneMaker/)**|
|**2025-12-11**|**Group Diffusion: Enhancing Image Generation by Unlocking Cross-Sample Collaboration**|Yuheng Li Team|[2512.10954](http://arxiv.org/abs/2512.10954)|**[link](https://sichengmo.github.io/GroupDiff/)**|
|**2025-12-11**|**E-RayZer: Self-supervised 3D Reconstruction as Spatial Visual Pre-training**|Hanwen Jiang Team|[2512.10950](http://arxiv.org/abs/2512.10950)|**[link](https://qitaozhao.github.io/E-RayZer)**|
|**2025-12-11**|**Are We Ready for RL in Text-to-3D Generation? A Progressive Investigation**|Bin Zhao Team|[2512.10949](http://arxiv.org/abs/2512.10949)|**[link](https://github.com/Ivan-Tang-3D/3DGen-R1)**|
|**2025-12-11**|**MeViS: A Multi-Modal Dataset for Referring Motion Expression Video Segmentation**|Yu-Gang Jiang Team|[2512.10945](http://arxiv.org/abs/2512.10945)|**[link](https://henghuiding.com/MeViS/)**|
|**2025-12-11**|**AlcheMinT: Fine-grained Temporal Control for Multi-Reference Consistent Video Generation**|Sergey Tulyakov Team|[2512.10943](http://arxiv.org/abs/2512.10943)|**[link](https://snap-research.github.io/Video-AlcheMinT/snap-research.github.io/Video-AlcheMinT)**|
|**2025-12-11**|**VL-JEPA: Joint Embedding Predictive Architecture for Vision-language**|Pascale Fung Team|[2512.10942](http://arxiv.org/abs/2512.10942)|null|
|**2025-12-11**|**Mull-Tokens: Modality-Agnostic Latent Thinking**|Wen-Sheng Chu Team|[2512.10941](http://arxiv.org/abs/2512.10941)|**[link](https://arijitray.com/multimodal_thinking/)**|
|**2025-12-11**|**OmniView: An All-Seeing Diffusion Model for 3D and 4D View Synthesis**|Ranjay Krishna Team|[2512.10940](http://arxiv.org/abs/2512.10940)|**[link](https://snap-research.github.io/OmniView/)**|
|**2025-12-11**|**GaussianHeadTalk: Wobble-Free 3D Talking Heads with Audio Driven Gaussian Splatting**|Steven McDonagh Team|[2512.10939](http://arxiv.org/abs/2512.10939)|null|
|**2025-12-11**|**Any4D: Unified Feed-Forward Metric 4D Reconstruction**|Deva Ramanan Team|[2512.10935](http://arxiv.org/abs/2512.10935)|**[link](https://any-4d.github.io/)**|
|**2025-12-11**|**Curriculum-Based Reinforcement Learning for Autonomous UAV Navigation in Unknown Curved Tubular Conduit**|Julien Seinturier Team|[2512.10934](http://arxiv.org/abs/2512.10934)|null|
|**2025-12-11**|**BabyVLM-V2: Toward Developmentally Grounded Pretraining and Benchmarking of Vision Foundation Models**|Boqing Gong Team|[2512.10932](http://arxiv.org/abs/2512.10932)|null|
|**2025-12-11**|**Digital Twin Supervised Reinforcement Learning Framework for Autonomous Underwater Navigation**|Pierre Drap Team|[2512.10925](http://arxiv.org/abs/2512.10925)|null|
|**2025-12-11**|**Reinforcement Learning in Financial Decision Making: A Systematic Review of Performance, Challenges, and Implementation Strategies**|M. Kabir Hassan Team|[2512.10913](http://arxiv.org/abs/2512.10913)|null|
|**2025-12-11**|**Distributionally Robust Regret Optimal Control Under Moment-Based Ambiguity Sets**|Eilyan Bitar Team|[2512.10906](http://arxiv.org/abs/2512.10906)|null|
|**2025-12-11**|**DuetSVG: Unified Multimodal SVG Generation with Internal Visual Guidance**|Difan Liu Team|[2512.10894](http://arxiv.org/abs/2512.10894)|**[link](https://intchous.github.io/DuetSVG-site)**|
|**2025-12-11**|**Iterative Compositional Data Generation for Robot Control**|Eric Eaton Team|[2512.10891](http://arxiv.org/abs/2512.10891)|null|
|**2025-12-11**|**PubTables-v2: A new large-scale dataset for full-page and multi-page table extraction**|Maury Courtland Team|[2512.10888](http://arxiv.org/abs/2512.10888)|null|
|**2025-12-11**|**From Macro to Micro: Benchmarking Microscopic Spatial Intelligence on Molecules via Vision-Language Models**|Wenbing Huang Team|[2512.10867](http://arxiv.org/abs/2512.10867)|null|
|**2025-12-11**|**Learning Controllable and Diverse Player Behaviors in Multi-Agent Environments**|Atay Özgövde Team|[2512.10835](http://arxiv.org/abs/2512.10835)|null|
|**2025-12-11**|**Interpretable and Steerable Concept Bottleneck Sparse Autoencoders**|Kowshik Thopalli Team|[2512.10805](http://arxiv.org/abs/2512.10805)|null|
|**2025-12-11**|**Physics-Informed Learning of Microvascular Flow Models using Graph Neural Networks**|Paolo Zunino Team|[2512.10792](http://arxiv.org/abs/2512.10792)|null|
|**2025-12-11**|**Natural Language Interface for Firewall Configuration**|A. Aslanbayli Team|[2512.10789](http://arxiv.org/abs/2512.10789)|null|
|**2025-12-06**|**Metaphor-based Jailbreaking Attacks on Text-to-Image Models**|An-An Liu Team|[2512.10766](http://arxiv.org/abs/2512.10766)|null|
|**2025-12-11**|**OPV: Outcome-based Process Verifier for Efficient Long Chain-of-Thought Verification**|Kai Chen Team|[2512.10756](http://arxiv.org/abs/2512.10756)|null|
|**2025-12-11**|**Learning to Split: A Reinforcement-Learning-Guided Splitting Heuristic for Neural Network Verification**|Guy Katz Team|[2512.10747](http://arxiv.org/abs/2512.10747)|null|
|**2025-12-11**|**Long-horizon Reasoning Agent for Olympiad-Level Mathematical Problem Solving**|Kai Chen Team|[2512.10739](http://arxiv.org/abs/2512.10739)|null|
|**2025-12-11**|**LGAN: An Efficient High-Order Graph Neural Network via the Line Graph Aggregation**|Zhao Li Team|[2512.10735](http://arxiv.org/abs/2512.10735)|null|
|**2025-12-11**|**SpaceDrive: Infusing Spatial Awareness into VLM-based Autonomous Driving**|Andreas Zell Team|[2512.10719](http://arxiv.org/abs/2512.10719)|null|
|**2025-12-11**|**How to Brake? Ethical Emergency Braking with Deep Reinforcement Learning**|Johan Thunberg Team|[2512.10698](http://arxiv.org/abs/2512.10698)|null|
|**2025-12-11**|**Enhancing Radiology Report Generation and Visual Grounding using Reinforcement Learning**|Michael Krauthammer Team|[2512.10691](http://arxiv.org/abs/2512.10691)|null|
|**2025-12-11**|**Evaluating Gemini Robotics Policies in a Veo World Simulator**|Allan Zhou Team|[2512.10675](http://arxiv.org/abs/2512.10675)|null|
|**2025-12-11**|**XDen-1K: A Density Field Dataset of Real-World Objects**|Jingyi Yu Team|[2512.10668](http://arxiv.org/abs/2512.10668)|null|
|**2025-12-11**|**CAPTAIN: Semantic Feature Injection for Memorization Mitigation in Text-to-Image Diffusion Models**|Bernard Ghanem Team|[2512.10655](http://arxiv.org/abs/2512.10655)|null|
|**2025-12-11**|**AgriGPT-Omni: A Unified Speech-Vision-Text Framework for Multilingual Agricultural Intelligence**|Shijian Li Team|[2512.10624](http://arxiv.org/abs/2512.10624)|null|
|**2025-12-11**|**DOCR-Inspector: Fine-Grained and Automated Evaluation of Document Parsing with VLM**|Wentao Zhang Team|[2512.10619](http://arxiv.org/abs/2512.10619)|null|
|**2025-12-11**|**Lang2Motion: Bridging Language and Motion through Joint Embedding Spaces**|Sarah Ostadabbas Team|[2512.10617](http://arxiv.org/abs/2512.10617)|null|
|**2025-12-11**|**LEO-RobotAgent: A General-purpose Robotic Agent for Language-driven Embodied Operator**|Jun Meng Team|[2512.10605](http://arxiv.org/abs/2512.10605)|null|
|**2025-12-11**|**Multi-Objective Reward and Preference Optimization: Theory and Algorithms**|Akhil Agnihotri Team|[2512.10601](http://arxiv.org/abs/2512.10601)|null|
|**2025-12-11**|**Beyond Pixels: A Training-Free, Text-to-Text Framework for Remote Sensing Image Retrieval**|M. Prasad Team|[2512.10596](http://arxiv.org/abs/2512.10596)|null|
|**2025-12-11**|**Motion Planning for Safe Landing of a Human-Piloted Parafoil**|Anna Clarke Team|[2512.10595](http://arxiv.org/abs/2512.10595)|null|
|**2025-12-11**|**Salient Object Detection in Complex Weather Conditions via Noise Indicators**|Chenggang Yan Team|[2512.10592](http://arxiv.org/abs/2512.10592)|null|
|**2025-12-11**|**THeGAU: Type-Aware Heterogeneous Graph Autoencoder and Augmentation**|Che Lin Team|[2512.10589](http://arxiv.org/abs/2512.10589)|null|
|**2025-12-11**|**DeMapGS: Simultaneous Mesh Deformation and Surface Attribute Mapping via Gaussian Splatting**|Takeshi Oishi Team|[2512.10572](http://arxiv.org/abs/2512.10572)|**[link](https://shuyizhou495.github.io/DeMapGS-project-page/)**|
|**2025-12-11**|**Audio-sync Video Instance Editing with Granularity-Aware Mask Refiner**|Xinlong Wang Team|[2512.10571](http://arxiv.org/abs/2512.10571)|null|
|**2025-12-11**|**Grounding Everything in Tokens for Multimodal Large Language Models**|Chao Ma Team|[2512.10554](http://arxiv.org/abs/2512.10554)|null|
|**2025-12-11**|**Mr. Virgil: Learning Multi-robot Visual-range Relative Localization**|Yue Wang Team|[2512.10540](http://arxiv.org/abs/2512.10540)|null|
|**2025-12-11**|**Achieving Olympia-Level Geometry Large Language Model Agent via Complexity Boosting Reinforcement Learning**|Kai Chen Team|[2512.10534](http://arxiv.org/abs/2512.10534)|null|
|**2025-12-11**|**Disentangled and Distilled Encoder for Out-of-Distribution Reasoning with Rademacher Guarantees**|Arvind Easwaran Team|[2512.10522](http://arxiv.org/abs/2512.10522)|null|
|**2025-12-11**|**Take a Peek: Efficient Encoder Adaptation for Few-Shot Semantic Segmentation via LoRA**|Giovanna Castellano Team|[2512.10521](http://arxiv.org/abs/2512.10521)|null|
|**2025-12-11**|**Adaptive Replay Buffer for Offline-to-Online Reinforcement Learning**|Jinkyoo Park Team|[2512.10510](http://arxiv.org/abs/2512.10510)|null|
|**2025-12-11**|**UACER: An Uncertainty-Aware Critic Ensemble Framework for Robust Adversarial Reinforcement Learning**|Xueqian Wang Team|[2512.10492](http://arxiv.org/abs/2512.10492)|null|
|**2025-12-11**|**From Lab to Reality: A Practical Evaluation of Deep Learning Models and LLMs for Vulnerability Detection**|Bert Lagaisse Team|[2512.10485](http://arxiv.org/abs/2512.10485)|null|
|**2025-12-11**|**Symphony: A Heuristic Normalized Calibrated Advantage Actor and Critic Algorithm in application for Humanoid Robots**|József Dombi Team|[2512.10477](http://arxiv.org/abs/2512.10477)|**[link](https://github.com/SuspensionRailway/symphony)**|
|**2025-12-11**|**T-SKM-Net: Trainable Neural Network Framework for Linear Constraint Satisfaction via Sampling Kaczmarz-Motzkin Method**|Qingchun Hou Team|[2512.10461](http://arxiv.org/abs/2512.10461)|null|
|**2025-12-11**|**Shot and Architecture Adaptive Subspace Variational Quantum Eigensolver for Microwave Simulation**|Zaichen Zhang Team|[2512.10458](http://arxiv.org/abs/2512.10458)|null|
|**2025-12-11**|**Outdoor Crowd Flow Estimation Using RSRP from Commercial LTE Base Station: A Field Study**|Shinya Otsuki Team|[2512.10447](http://arxiv.org/abs/2512.10447)|null|
|**2025-12-11**|**Decoding Student Minds: Leveraging Conversational Agents for Psychological and Learning Analysis**|Laid Kahloul Team|[2512.10441](http://arxiv.org/abs/2512.10441)|null|
|**2025-12-11**|**Enhancing Next-Generation Language Models with Knowledge Graphs: Extending Claude, Mistral IA, and GPT-4 via KG-BERT**|Hamza Hammami Team|[2512.10440](http://arxiv.org/abs/2512.10440)|null|
|**2025-12-11**|**HypeR Adaptivity: Joint $hr$ -Adaptive Meshing via Hypergraph Multi-Agent Deep Reinforcement Learning**|Stefania Fresca Team|[2512.10439](http://arxiv.org/abs/2512.10439)|null|
|**2025-12-11**|**Targeted Data Protection for Diffusion Model by Matching Training Trajectory**|Nojun Kwak Team|[2512.10433](http://arxiv.org/abs/2512.10433)|null|
|**2025-12-11**|**Neural Hamiltonian Deformation Fields for Dynamic Scene Rendering**|Jincheng Dai Team|[2512.10424](http://arxiv.org/abs/2512.10424)|**[link](https://qin-jingyun.github.io/NeHaD)**|
|**2025-12-11**|**Boosting RL-Based Visual Reasoning with Selective Adversarial Entropy Intervention**|Xiaomeng Li Team|[2512.10414](http://arxiv.org/abs/2512.10414)|null|
|**2025-12-11**|**RoboNeuron: A Modular Framework Linking Foundation Models and ROS for Embodied AI**|Jian Cheng Team|[2512.10394](http://arxiv.org/abs/2512.10394)|null|
|**2025-12-11**|**Adaptive Dual-Weighted Gravitational Point Cloud Denoising Method**|Bin Liu Team|[2512.10386](http://arxiv.org/abs/2512.10386)|null|
|**2025-12-11**|**Towards Fine-Grained Recognition with Large Visual Language Models: Benchmark and Optimization Strategies**|Xin Lou Team|[2512.10384](http://arxiv.org/abs/2512.10384)|null|
|**2025-12-11**|**RaLiFlow: Scene Flow Estimation with 4D Radar and LiDAR Point Clouds**|Na Zhao Team|[2512.10376](http://arxiv.org/abs/2512.10376)|null|
|**2025-12-11**|**Breaking the Vicious Cycle: Coherent 3D Gaussian Splatting from Sparse and Motion-Blurred Views**|Yonghong Tian Team|[2512.10369](http://arxiv.org/abs/2512.10369)|null|
|**2025-12-11**|**Better Prevent than Tackle: Valuing Defense in Soccer Based on Graph Neural Networks**|Chanyoung Park Team|[2512.10355](http://arxiv.org/abs/2512.10355)|null|
|**2025-12-11**|**Hybrid Transformer-Mamba Architecture for Weakly Supervised Volumetric Medical Segmentation**|Girish Dwivedi Team|[2512.10353](http://arxiv.org/abs/2512.10353)|null|
|**2025-12-11**|**Design and Validation of an Under-actuated Robotic Finger with Synchronous Tendon Routing**|Weibang Bai Team|[2512.10349](http://arxiv.org/abs/2512.10349)|null|
|**2025-12-11**|**CoSPlan: Corrective Sequential Planning via Scene Graph Incremental Updates**|Yogesh S Rawat Team|[2512.10342](http://arxiv.org/abs/2512.10342)|null|
|**2025-12-11**|**A Privacy-Preserving Cloud Architecture for Distributed Machine Learning at Scale**|Kabilan Kannan Team|[2512.10341](http://arxiv.org/abs/2512.10341)|null|
|**2025-12-11**|**Multilingual VLM Training: Adapting an English-Trained VLM to French**|Alexis Roger Team|[2512.10336](http://arxiv.org/abs/2512.10336)|null|
|**2025-12-11**|**Point2Pose: A Generative Framework for 3D Human Pose Estimation with Multi-View Point Cloud Dataset**|Hyeokjae Oh Team|[2512.10321](http://arxiv.org/abs/2512.10321)|null|
|**2025-12-11**|**ConStruct: Structural Distillation of Foundation Models for Prototype-Based Weakly Supervised Histopathology Segmentation**|Hien Van Nguyen Team|[2512.10316](http://arxiv.org/abs/2512.10316)|null|
|**2025-12-11**|**DualProtoSeg: Simple and Efficient Design with Text- and Image-Guided Prototype Learning for Weakly Supervised Histopathology Image Segmentation**|Hien Van Nguyen Team|[2512.10314](http://arxiv.org/abs/2512.10314)|null|
|**2025-12-11**|**Investigating The Functional Roles of Attention Heads in Vision Language Models: Evidence for Reasoning Modules**|Krista A. Ehinger Team|[2512.10300](http://arxiv.org/abs/2512.10300)|null|
|**2025-12-11**|**Physically Aware 360 $^\circ$ View Generation from a Single Image using Disentangled Scene Embeddings**|Narendra Bandaru Team|[2512.10293](http://arxiv.org/abs/2512.10293)|null|
|**2025-12-11**|**A Kernel-based Resource-efficient Neural Surrogate for Multi-fidelity Prediction of Aerodynamic Field**|Sourav Saha Team|[2512.10287](http://arxiv.org/abs/2512.10287)|null|
|**2025-12-11**|**ShotDirector: Directorially Controllable Multi-Shot Video Generation with Cinematographic Transitions**|Yu Qiao Team|[2512.10286](http://arxiv.org/abs/2512.10286)|**[link](https://uknowsth.github.io/ShotDirector/)**|
|**2025-12-11**|**Graph Neural Network Based Adaptive Threat Detection for Cloud Identity and Access Management Logs**|Venkata Tanuja Madireddy Team|[2512.10280](http://arxiv.org/abs/2512.10280)|null|
|**2025-12-11**|**Hybrid Learning and Optimization-Based Dynamic Scheduling for DL Workloads on Heterogeneous GPU Clusters**|Ali R. Butt Team|[2512.10271](http://arxiv.org/abs/2512.10271)|null|
|**2025-12-11**|**Long-LRM++: Preserving Fine Details in Feed-Forward Wide-Coverage Reconstruction**|Li Fuxin Team|[2512.10267](http://arxiv.org/abs/2512.10267)|null|
|**2025-12-11**|**THE-Pose: Topological Prior with Hybrid Graph Fusion for Estimating Category-Level 6D Object Pose**|Ayoung Kim Team|[2512.10251](http://arxiv.org/abs/2512.10251)|null|
|**2025-12-11**|**Solving Semi-Supervised Few-Shot Learning from an Auto-Annotation Perspective**|Shu Kong Team|[2512.10244](http://arxiv.org/abs/2512.10244)|**[link](https://tian1327.github.io/SWIFT)**|
|**2025-12-11**|**Multi-dimensional Preference Alignment by Conditioning Reward Itself**|Nojun Kwak Team|[2512.10237](http://arxiv.org/abs/2512.10237)|null|
|**2025-12-11**|**Task-Oriented Grasping Using Reinforcement Learning with a Contextual Reward Machine**|Hongsheng He Team|[2512.10235](http://arxiv.org/abs/2512.10235)|null|
|**2025-12-11**|**Latent Chain-of-Thought World Modeling for End-to-End Driving**|Boris Ivanovic Team|[2512.10226](http://arxiv.org/abs/2512.10226)|null|
|**2025-12-11**|**Galaxy Phase-Space and Field-Level Cosmology: The Strength of Semi-Analytic Models**|Tiago Castro Team|[2512.10222](http://arxiv.org/abs/2512.10222)|null|
|**2025-12-11**|**An exploration for higher efficiency in multi objective optimisation with reinforcement learning**|Mehmet Emin Aydin Team|[2512.10208](http://arxiv.org/abs/2512.10208)|null|
|**2025-12-10**|**Explicit Control Barrier Function-based Safety Filters and their Resource-Aware Computation**|Aaron D. Ames Team|[2512.10118](http://arxiv.org/abs/2512.10118)|null|
|**2025-12-10**|**Fast Functionally Redundant Inverse Kinematics for Robotic Toolpath Optimisation in Manufacturing Tasks**|Tirthankar Bandyopadhyay Team|[2512.10116](http://arxiv.org/abs/2512.10116)|**[link](https://ssl.linklings.net/conferences/acra/acra2025_proceedings/views/includes/files/pap149s2.pdf)**|
|**2025-12-10**|**Modeling Narrative Archetypes in Conspiratorial Narratives: Insights from Singapore-Based Telegram Groups**|Navin Kumar Team|[2512.10105](http://arxiv.org/abs/2512.10105)|null|
|**2025-12-10**|**Push Smarter, Not Harder: Hierarchical RL-Diffusion Policy for Efficient Nonprehensile Manipulation**|Stephen L. Smith Team|[2512.10099](http://arxiv.org/abs/2512.10099)|null|
|**2025-12-10**|**TraceFlow: Dynamic 3D Reconstruction of Specular Scenes Driven by Ray Tracing**|Yan Yan Team|[2512.10095](http://arxiv.org/abs/2512.10095)|null|
|**2025-12-10**|**Openpi Comet: Competition Solution For 2025 BEHAVIOR Challenge**|Xiaohui Zeng Team|[2512.10071](http://arxiv.org/abs/2512.10071)|null|
|**2025-12-10**|**Independent Density Estimation**|Jiahao Liu Team|[2512.10067](http://arxiv.org/abs/2512.10067)|null|
|**2025-12-10**|**Text2Graph: Combining Lightweight LLMs and GNNs for Efficient Text Classification in Label-Scarce Scenarios**|Ricardo Marcondes Marcacini Team|[2512.10061](http://arxiv.org/abs/2512.10061)|null|
|**2025-12-10**|**SimWorld-Robotics: Synthesizing Photorealistic and Dynamic Urban Environments for Multimodal Robot Navigation and Collaboration**|Tianmin Shu Team|[2512.10046](http://arxiv.org/abs/2512.10046)|null|
|**2025-12-10**|**SEMDICE: Off-policy State Entropy Maximization via Stationary Distribution Correction Estimation**|Pieter Abbeel Team|[2512.10042](http://arxiv.org/abs/2512.10042)|null|
|**2025-12-10**|**MetaVoxel: Joint Diffusion Modeling of Imaging and Clinical Metadata**|Bennett A. Landman Team|[2512.10041](http://arxiv.org/abs/2512.10041)|null|
|**2025-12-10**|**Diffusion Is Your Friend in Show, Suggest and Tell**|Alessandro Capotondi Team|[2512.10038](http://arxiv.org/abs/2512.10038)|null|
|**2025-12-10**|**DynaMate: An Autonomous Agent for Protein-Ligand Molecular Dynamics Simulations**|Philippe Schwaller Team|[2512.10034](http://arxiv.org/abs/2512.10034)|null|
|**2025-12-10**|**ABBSPO: Adaptive Bounding Box Scaling and Symmetric Prior based Orientation Prediction for Detecting Aerial Image Objects**|Munchurl Kim Team|[2512.10031](http://arxiv.org/abs/2512.10031)|**[link](https://kaist-viclab.github.io/ABBSPO_site/)**|
|**2025-12-10**|**Latent Action World Models for Control with Unlabeled Trajectories**|Philip Becker-Ehmck Team|[2512.10016](http://arxiv.org/abs/2512.10016)|null|
|**2025-12-10**|**TDC-Cache: A Trustworthy Decentralized Cooperative Caching Framework for Web3.0**|Wei Zhang Team|[2512.09961](http://arxiv.org/abs/2512.09961)|null|
|**2025-12-09**|**CloudFix: Automated Policy Repair for Cloud Access Control Policies Using Large Language Models**|William Eiers Team|[2512.09957](http://arxiv.org/abs/2512.09957)|null|
|**2025-12-08**|**HGC-Herd: Efficient Heterogeneous Graph Condensation via Representative Node Herding**|Yulin Hu Team|[2512.09947](http://arxiv.org/abs/2512.09947)|null|
|**2025-12-06**|**Echo-CoPilot: A Multi-View, Multi-Task Agent for Echocardiography Interpretation and Reporting**|Ilker Hacihaliloglu Team|[2512.09944](http://arxiv.org/abs/2512.09944)|null|
|**2025-12-10**|**Closing the Train-Test Gap in World Models for Gradient-Based Planning**|Micah Goldblum Team|[2512.09929](http://arxiv.org/abs/2512.09929)|null|
|**2025-12-10**|**HiF-VLA: Hindsight, Insight and Foresight through Motion Representation for Vision-Language-Action Models**|Donglin Wang Team|[2512.09928](http://arxiv.org/abs/2512.09928)|**[link](https://hifvla.github.io)**|
|**2025-12-10**|**Token Expand-Merge: Training-Free Token Compression for Vision-Language-Action Models**|Zhihe Lu Team|[2512.09927](http://arxiv.org/abs/2512.09927)|null|
|**2025-12-10**|**GAINS: Gaussian-based Inverse Rendering from Sparse Multi-View Captures**|Roni Sengupta Team|[2512.09925](http://arxiv.org/abs/2512.09925)|null|
|**2025-12-10**|**ReViSE: Towards Reason-Informed Video Editing in Unified Models with Self-Reflective Learning**|Yike Guo Team|[2512.09924](http://arxiv.org/abs/2512.09924)|**[link](https://github.com/Liuxinyv/ReViSE))**|
|**2025-12-10**|**Splatent: Splatting Diffusion Latents for Novel View Synthesis**|Lior Fritz Team|[2512.09923](http://arxiv.org/abs/2512.09923)|null|
|**2025-12-10**|**LISN: Language-Instructed Social Navigation with VLM-based Controller Modulating**|Lin Shao Team|[2512.09920](http://arxiv.org/abs/2512.09920)|null|
|**2025-12-10**|**NordFKB: a fine-grained benchmark dataset for geospatial AI in Norway**|Alexander Salveson Nossum Team|[2512.09913](http://arxiv.org/abs/2512.09913)|null|
|**2025-12-10**|**STACHE: Local Black-Box Explanations for Reinforcement Learning Policies**|Orna Grumberg Team|[2512.09909](http://arxiv.org/abs/2512.09909)|null|
|**2025-12-10**|**VisualActBench: Can VLMs See and Act like a Human?**|Jiebo Luo Team|[2512.09907](http://arxiv.org/abs/2512.09907)|null|
|**2025-12-10**|**YOPO-Nav: Visual Navigation using 3DGS Graphs from One-Pass Videos**|Kristin Dana Team|[2512.09903](http://arxiv.org/abs/2512.09903)|null|
|**2025-12-10**|**HPM-KD: Hierarchical Progressive Multi-Teacher Framework for Knowledge Distillation and Efficient Model Compression**|Paulo Henrique Dourado da Silva Team|[2512.09886](http://arxiv.org/abs/2512.09886)|null|
|**2025-12-10**|**Benchmarking Document Parsers on Mathematical Formula Extraction from PDFs**|Janis Keuper Team|[2512.09874](http://arxiv.org/abs/2512.09874)|null|
|**2025-12-10**|**FlipLLM: Efficient Bit-Flip Attacks on Multimodal LLMs using Reinforcement Learning**|Khaza Anuarul Hoque Team|[2512.09872](http://arxiv.org/abs/2512.09872)|null|
|**2025-12-10**|**UniUGP: Unifying Understanding, Generation, and Planing For End-to-end Autonomous Driving**|Ying-Cong Chen Team|[2512.09864](http://arxiv.org/abs/2512.09864)|**[link](https://seed-uniugp.github.io/)**|
|**2025-12-10**|**Simultaneous Tactile-Visual Perception for Learning Multimodal Robot Manipulation**|Yixin Zhu Team|[2512.09851](http://arxiv.org/abs/2512.09851)|null|
|**2025-12-10**|**ChronusOmni: Improving Time Awareness of Omni Large Language Models**|Liyun Ru Team|[2512.09841](http://arxiv.org/abs/2512.09841)|**[link](https://github.com/YJCX330/Chronus/)**|
|**2025-12-10**|**RIFT: A Scalable Methodology for LLM Accelerator Fault Assessment using Reinforcement Learning**|Khaza Anuarul Hoque Team|[2512.09829](http://arxiv.org/abs/2512.09829)|null|
|**2025-12-10**|**Quantum Algorithm for Estimating Ollivier-Ricci Curvature**|Trung V. Phan Team|[2512.09822](http://arxiv.org/abs/2512.09822)|null|
|**2025-12-10**|**DynaIP: Dynamic Image Prompt Adapter for Scalable Zero-shot Personalized Text-to-Image Generation**|Kehan Li Team|[2512.09814](http://arxiv.org/abs/2512.09814)|null|
|**2025-12-10**|**M3Net: A Multi-Metric Mixture of Experts Network Digital Twin with Graph Neural Networks**|Carlee Joe-Wong Team|[2512.09797](http://arxiv.org/abs/2512.09797)|null|
|**2025-12-10**|**Prefrontal scaling of reward prediction error readout gates reinforcement-derived adaptive behavior in primates**|Zheng Wang Team|[2512.09761](http://arxiv.org/abs/2512.09761)|null|
|**2025-12-10**|**MOA: Multi-Objective Alignment for Role-Playing Agents**|Yongbin Li Team|[2512.09756](http://arxiv.org/abs/2512.09756)|null|
|**2025-12-10**|**Flexible Reconfigurable Intelligent Surface-Aided Covert Communications in UAV Networks**|Wei Huang Team|[2512.09714](http://arxiv.org/abs/2512.09714)|null|
|**2025-12-10**|**Knowledge Graph Enrichment and Reasoning for Nobel Laureates**|Mai-Vu Tran Team|[2512.09707](http://arxiv.org/abs/2512.09707)|null|
|**2025-12-10**|**Training One Model to Master Cross-Level Agentic Actions via Reinforcement Learning**|Yitao Liang Team|[2512.09706](http://arxiv.org/abs/2512.09706)|null|
|**2025-12-10**|**Dynamic one-time delivery of critical data by small and sparse UAV swarms: a model problem for MARL scaling studies**|Adam Andersson Team|[2512.09682](http://arxiv.org/abs/2512.09682)|null|
|**2025-12-10**|**d-TreeRPO: Towards More Reliable Policy Optimization for Diffusion Language Models**|Lijie Wen Team|[2512.09675](http://arxiv.org/abs/2512.09675)|null|
|**2025-12-10**|**An Automated Tip-and-Cue Framework for Optimized Satellite Tasking and Visual Intelligence**|Israel Cohen Team|[2512.09670](http://arxiv.org/abs/2512.09670)|null|
|**2025-12-10**|**Persistent Cycle Representatives and Generalized Landscapes for Codimension 1 Persistent Homology**|Leon Renkin Team|[2512.09668](http://arxiv.org/abs/2512.09668)|null|
|**2025-12-10**|**SynthPix: A lightspeed PIV images generator**|Raffaello D'Andrea Team|[2512.09664](http://arxiv.org/abs/2512.09664)|**[link](https://github.com/antonioterpin/synthpix)**|
|**2025-12-10**|**ReMoSPLAT: Reactive Mobile Manipulation Control on a Gaussian Splat**|Niko Suenderhauf Team|[2512.09656](http://arxiv.org/abs/2512.09656)|null|
|**2025-12-10**|**VHOI: Controllable Video Generation of Human-Object Interactions from Sparse Trajectories via Motion Densification**|Christian Theobalt Team|[2512.09646](http://arxiv.org/abs/2512.09646)|null|
|**2025-12-10**|**GLaD: Geometric Latent Distillation for Vision-Language-Action Models**|Xiaojun Chang Team|[2512.09619](http://arxiv.org/abs/2512.09619)|null|
|**2025-12-10**|**Super4DR: 4D Radar-centric Self-supervised Odometry and Gaussian-based Map Optimization**|Zheng Fang Team|[2512.09608](http://arxiv.org/abs/2512.09608)|null|
|**2025-12-10**|**UrbanNav: Learning Language-Guided Urban Navigation from Web-Scale Human Trajectories**|Jing Liu Team|[2512.09607](http://arxiv.org/abs/2512.09607)|null|
|**2025-12-10**|**Model management to support systems engineering workflows using ontology-based knowledge graphs**|Hans Vangheluwe Team|[2512.09596](http://arxiv.org/abs/2512.09596)|null|
|**2025-12-10**|**Graph-Based Bayesian Optimization for Quantum Circuit Architecture Search with Uncertainty Calibrated Surrogates**|Rajeev Singh Team|[2512.09586](http://arxiv.org/abs/2512.09586)|null|
|**2025-12-10**|**Hands-on Evaluation of Visual Transformers for Object Recognition and Detection**|Dimitrios A. Koutsomitropoulos Team|[2512.09579](http://arxiv.org/abs/2512.09579)|null|
|**2025-12-10**|**Mastering Diverse, Unknown, and Cluttered Tracks for Robust Vision-Based Drone Racing**|Danping Zou Team|[2512.09571](http://arxiv.org/abs/2512.09571)|null|
|**2025-12-10**|**Toward Closed-loop Molecular Discovery via Language Model, Property Alignment and Strategic Search**|Zexuan Zhu Team|[2512.09566](http://arxiv.org/abs/2512.09566)|null|
|**2025-12-10**|**Building Reasonable Inference for Vision-Language Models in Blind Image Quality Assessment**|Shin'ya Nishida Team|[2512.09555](http://arxiv.org/abs/2512.09555)|null|
|**2025-12-10**|**SWEnergy: An Empirical Study on Energy Efficiency in Agentic Issue Resolution Frameworks with SLMs**|Karthik Vaidhyanathan Team|[2512.09543](http://arxiv.org/abs/2512.09543)|null|
|**2025-12-10**|**REASAN: Learning Reactive Safe Navigation for Legged Robots**|Kailai Li Team|[2512.09537](http://arxiv.org/abs/2512.09537)|null|
|**2025-12-10**|**Transport Novelty Distance: A Distributional Metric for Evaluating Material Generative Models**|Philipp Benner Team|[2512.09514](http://arxiv.org/abs/2512.09514)|null|
|**2025-12-10**|**MODA: The First Challenging Benchmark for Multispectral Object Detection in Aerial Images**|Jianan Li Team|[2512.09489](http://arxiv.org/abs/2512.09489)|null|
|**2025-12-10**|**RouteRAG: Efficient Retrieval-Augmented Generation from Text and Graph via Reinforcement Learning**|Xueqi Cheng Team|[2512.09487](http://arxiv.org/abs/2512.09487)|null|
|**2025-12-10**|**Defect-aware Hybrid Prompt Optimization via Progressive Tuning for Zero-Shot Multi-type Anomaly Detection and Segmentation**|Steffen Staab Team|[2512.09446](http://arxiv.org/abs/2512.09446)|null|
|**2025-12-10**|**Advancing Text Classification with Large Language Models and Neural Attention Mechanisms**|Qingyuan Zhang Team|[2512.09444](http://arxiv.org/abs/2512.09444)|null|
|**2025-12-10**|**Representation Calibration and Uncertainty Guidance for Class-Incremental Learning based on Vision Language Model**|Ruixuan Wang Team|[2512.09441](http://arxiv.org/abs/2512.09441)|null|
|**2025-12-10**|**A Hierarchical, Model-Based System for High-Performance Humanoid Soccer**|Dennis W. Hong Team|[2512.09431](http://arxiv.org/abs/2512.09431)|null|
|**2025-12-10**|**Label-free Motion-Conditioned Diffusion Model for Cardiac Ultrasound Synthesis**|Bernhard Kainz Team|[2512.09418](http://arxiv.org/abs/2512.09418)|null|
|**2025-12-10**|**D $^2$ GSLAM: 4D Dynamic Gaussian Splatting SLAM**|Hesheng Wang Team|[2512.09411](http://arxiv.org/abs/2512.09411)|null|
|**2025-12-10**|**Generalizable Collaborative Search-and-Capture in Cluttered Environments via Path-Guided MAPPO and Directional Frontier Allocation**|Yihuan Liao Team|[2512.09410](http://arxiv.org/abs/2512.09410)|null|
|**2025-12-10**|**Generative Point Cloud Registration**|Jianmin Zheng Team|[2512.09407](http://arxiv.org/abs/2512.09407)|null|
|**2025-12-10**|**H2R-Grounder: A Paired-Data-Free Paradigm for Translating Human Interaction Videos into Physically Grounded Robot Videos**|Mike Zheng Shou Team|[2512.09406](http://arxiv.org/abs/2512.09406)|null|
|**2025-12-10**|**BugSweeper: Function-Level Detection of Smart Contract Vulnerabilities Using Graph Neural Networks**|Soo-Mook Moon Team|[2512.09385](http://arxiv.org/abs/2512.09385)|null|
|**2025-12-10**|**FUSER: Feed-Forward MUltiview 3D Registration Transformer and SE(3) $^N$ Diffusion Refinement**|Jianmin Zheng Team|[2512.09373](http://arxiv.org/abs/2512.09373)|null|
|**2025-12-10**|**Are Hypervectors Enough? Single-Call LLM Reasoning over Knowledge Graphs**|Mohsen Imani Team|[2512.09369](http://arxiv.org/abs/2512.09369)|null|
|**2025-12-10**|**CFLight: Enhancing Safety with Traffic Signal Control through Counterfactual Learning**|Qiang Wu Team|[2512.09368](http://arxiv.org/abs/2512.09368)|null|
|**2025-12-10**|**KGOT: Unified Knowledge Graph and Optimal Transport Pseudo-Labeling for Molecule-Protein Interaction Prediction**|Zhiqiang Xu Team|[2512.09365](http://arxiv.org/abs/2512.09365)|null|
|**2025-12-10**|**ASSIST-3D: Adapted Scene Synthesis for Class-Agnostic 3D Instance Segmentation**|Xiaojuan Qi Team|[2512.09364](http://arxiv.org/abs/2512.09364)|null|
|**2025-12-10**|**StereoWorld: Geometry-Aware Monocular-to-Stereo Video Generation**|Yunchao Wei Team|[2512.09363](http://arxiv.org/abs/2512.09363)|null|
|**2025-12-10**|**Branching Strategies Based on Subgraph GNNs: A Study on Theoretical Promise versus Practical Reality**|Pan Li Team|[2512.09355](http://arxiv.org/abs/2512.09355)|null|
|**2025-12-10**|**Video-QTR: Query-Driven Temporal Reasoning Framework for Lightweight Video Understanding**|Jianwei Yin Team|[2512.09354](http://arxiv.org/abs/2512.09354)|null|
|**2025-12-10**|**The Third Visual Pathway for Social Perception**|David Pitcher Team|[2512.09351](http://arxiv.org/abs/2512.09351)|null|
|**2025-12-10**|**TextGuider: Training-Free Guidance for Text Rendering via Attention Alignment**|Sungroh Yoon Team|[2512.09350](http://arxiv.org/abs/2512.09350)|null|
|**2025-12-10**|**COVLM-RL: Critical Object-Oriented Reasoning for Autonomous Driving Using VLM-Guided Reinforcement Learning**|Chen Lv Team|[2512.09349](http://arxiv.org/abs/2512.09349)|null|
|**2025-12-10**|**Relightable and Dynamic Gaussian Avatar Reconstruction from Monocular Video**|Sanghoon Lee Team|[2512.09335](http://arxiv.org/abs/2512.09335)|null|
|**2025-12-10**|**Passing the Baton: High Throughput Distributed Disk-Based Vector Search with BatANN**|Ken Birman Team|[2512.09331](http://arxiv.org/abs/2512.09331)|null|
|**2025-12-10**|**Tyche: A Hybrid Computation Framework of Illumination Pattern for Satellite Beam Hopping**|Yue Gao Team|[2512.09312](http://arxiv.org/abs/2512.09312)|null|
|**2025-12-10**|**Scene-agnostic Hierarchical Bimanual Task Planning via Visual Affordance Reasoning**|Sung-Hee Lee Team|[2512.09310](http://arxiv.org/abs/2512.09310)|null|
|**2025-12-10**|**VABench: A Comprehensive Benchmark for Audio-Video Generation**|Wentao Zhang Team|[2512.09299](http://arxiv.org/abs/2512.09299)|null|
|**2025-12-10**|**One-Shot Real-World Demonstration Synthesis for Scalable Bimanual Manipulation**|Kui Jia Team|[2512.09297](http://arxiv.org/abs/2512.09297)|null|
|**2025-12-10**|**Electric Arc Furnaces Scheduling under Electricity Price Volatility with Reinforcement Learning**|Bolun Xu Team|[2512.09293](http://arxiv.org/abs/2512.09293)|null|
|**2025-12-10**|**LongT2IBench: A Benchmark for Evaluating Long Text-to-Image Generation with Graph-structured Annotations**|Leida Li Team|[2512.09271](http://arxiv.org/abs/2512.09271)|null|
|**2025-12-10**|**MoRel: Long-Range Flicker-Free 4D Motion Modeling via Anchor Relay-based Bidirectional Blending with Hierarchical Densification**|Jihyong Oh Team|[2512.09270](http://arxiv.org/abs/2512.09270)|**[link](https://cmlab-korea.github.io/MoRel/)**|
|**2025-12-10**|**ROI-Packing: Efficient Region-Based Compression for Machine Vision**|Borko Furht Team|[2512.09258](http://arxiv.org/abs/2512.09258)|null|
|**2025-12-10**|**The Illusion of Rationality: Tacit Bias and Strategic Dominance in Frontier LLM Negotiation Games**|Luis F. Giraldo Team|[2512.09254](http://arxiv.org/abs/2512.09254)|null|
|**2025-12-10**|**OmniPSD: Layered PSD Generation with Diffusion Transformer**|Mike Zheng Shou Team|[2512.09247](http://arxiv.org/abs/2512.09247)|null|
|**2025-12-10**|**Exploratory Mean-Variance with Jumps: An Equilibrium Approach**|David Saunders Team|[2512.09224](http://arxiv.org/abs/2512.09224)|null|
|**2025-12-10**|**View-on-Graph: Zero-shot 3D Visual Grounding via Vision-Language Reasoning on Scene Graphs**|Xin Yang Team|[2512.09215](http://arxiv.org/abs/2512.09215)|null|
|**2025-12-09**|**Learning Patient-Specific Disease Dynamics with Latent Flow Matching for Longitudinal Imaging Generation**|Chao Li Team|[2512.09185](http://arxiv.org/abs/2512.09185)|null|
|**2025-12-09**|**Understanding the Failure Modes of Transformers through the Lens of Graph Neural Networks**|Hunjae Lee Team|[2512.09182](http://arxiv.org/abs/2512.09182)|null|
|**2025-12-09**|**Prompt-Based Continual Compositional Zero-Shot Learning**|Mohsen Ali Team|[2512.09172](http://arxiv.org/abs/2512.09172)|null|
|**2025-12-09**|**Magic Gems: A Polyhedral Framework for Magic Squares**|Kyle Elliott Mathewson Team|[2512.09170](http://arxiv.org/abs/2512.09170)|**[link](https://kylemath.github.io/MagicGemWebpage/)**|
|**2025-12-09**|**AI-Driven Expansion and Application of the Alexandria Database**|Miguel A. L. Marques Team|[2512.09169](http://arxiv.org/abs/2512.09169)|null|
|**2025-12-09**|**WonderZoom: Multi-Scale 3D World Generation**|Jiajun Wu Team|[2512.09164](http://arxiv.org/abs/2512.09164)|**[link](https://wonderzoom.github.io/)**|
|**2025-12-09**|**GTAvatar: Bridging Gaussian Splatting and Texture Mapping for Relightable and Editable Gaussian Avatars**|Adnane Boukhayma Team|[2512.09162](http://arxiv.org/abs/2512.09162)|null|
|**2025-12-09**|**Detecting Hallucinations in Graph Retrieval-Augmented Generation via Attention Patterns and Semantic Alignment**|Philip S. Yu Team|[2512.09148](http://arxiv.org/abs/2512.09148)|null|
|**2025-12-09**|**Knowledge-Guided Large Language Model for Automatic Pediatric Dental Record Understanding and Safe Antibiotic Recommendation**|Caifeng Li Team|[2512.09127](http://arxiv.org/abs/2512.09127)|null|
|**2025-12-09**|**GimbalDiffusion: Gravity-Aware Camera Control for Video Generation**|Jean-François Lalonde Team|[2512.09112](http://arxiv.org/abs/2512.09112)|**[link](https://lvsn.github.io/GimbalDiffusion/)**|
|**2025-12-09**|**Learning Unmasking Policies for Diffusion Language Models**|Marco Cuturi Team|[2512.09106](http://arxiv.org/abs/2512.09106)|null|
|**2025-12-09**|**Masked Generative Policy for Robotic Control**|Paul Henderson Team|[2512.09101](http://arxiv.org/abs/2512.09101)|null|
|**2025-12-09**|**Food Image Generation on Multi-Noun Categories**|Fengqing Zhu Team|[2512.09095](http://arxiv.org/abs/2512.09095)|null|
|**2025-12-09**|**AgentComp: From Agentic Reasoning to Compositional Mastery in Text-to-Image Models**|Zhenheng Yang Team|[2512.09081](http://arxiv.org/abs/2512.09081)|null|
|**2025-12-09**|**SIP: Site in Pieces- A Dataset of Disaggregated Construction-Phase 3D Scans for Semantic Segmentation and Scene Understanding**|Yong Kwon Cho Team|[2512.09062](http://arxiv.org/abs/2512.09062)|null|
|**2025-12-09**|**ConceptPose: Training-Free Zero-Shot Object Pose Estimation using Concept Vectors**|Benjamin Busam Team|[2512.09056](http://arxiv.org/abs/2512.09056)|null|
|**2025-12-09**|**Improving Multi-Class Calibration through Normalization-Aware Isotonic Techniques**|Saharon Rosset Team|[2512.09054](http://arxiv.org/abs/2512.09054)|null|
|**2025-12-09**|**Graph Deep Learning for Intracranial Aneurysm Blood Flow Simulation and Risk Assessment**|Elie Hachem Team|[2512.09013](http://arxiv.org/abs/2512.09013)|null|
|**2025-12-09**|**Towards Lossless Ultimate Vision Token Compression for VLMs**|Xinghao Chen Team|[2512.09010](http://arxiv.org/abs/2512.09010)|null|
|**2025-12-08**|**PoultryTalk: A Multi-modal Retrieval-Augmented Generation (RAG) System for Intelligent Poultry Management and Decision Support**|Ramesh Bahadur Bist Team|[2512.08995](http://arxiv.org/abs/2512.08995)|null|
|**2025-12-06**|**An Efficient Test-Time Scaling Approach for Image Generation**|Lav R. Varshney Team|[2512.08985](http://arxiv.org/abs/2512.08985)|null|
|**2025-12-05**|**Mitigating Bias with Words: Inducing Demographic Ambiguity in Face Recognition Templates by Text Encoding**|Fadi Boutros Team|[2512.08981](http://arxiv.org/abs/2512.08981)|null|
|**2025-12-05**|**Training Multi-Image Vision Agents via End2End Reinforcement Learning**|Guojun Yin Team|[2512.08980](http://arxiv.org/abs/2512.08980)|null|
|**2025-12-09**|**Astra: General Interactive World Model with Autoregressive Denoising**|Jiwen Lu Team|[2512.08931](http://arxiv.org/abs/2512.08931)|**[link](https://github.com/EternalEvan/Astra)**|
|**2025-12-09**|**Same Content, Different Answers: Cross-Modal Inconsistency in MLLMs**|Yuki M. Asano Team|[2512.08923](http://arxiv.org/abs/2512.08923)|null|
|**2025-12-09**|**Unified Diffusion Transformer for High-fidelity Text-Aware Image Restoration**|Seungryong Kim Team|[2512.08922](http://arxiv.org/abs/2512.08922)|null|
|**2025-12-09**|**OSMO: Open-Source Tactile Glove for Human-to-Robot Skill Transfer**|Tess Hellebrekers Team|[2512.08920](http://arxiv.org/abs/2512.08920)|**[link](https://jessicayin.github.io/osmo_tactile_glove/)**|
|**2025-12-09**|**Self-Evolving 3D Scene Generation from a Single Image**|Xin Eric Wang Team|[2512.08905](http://arxiv.org/abs/2512.08905)|null|
|**2025-12-09**|**No Labels, No Problem: Training Visual Reasoners with Multimodal Verifiers**|Georgia Gkioxari Team|[2512.08889](http://arxiv.org/abs/2512.08889)|**[link](https://glab-caltech.github.io/valor/)**|
|**2025-12-09**|**SATGround: A Spatially-Aware Approach for Visual Grounding in Remote Sensing**|Jiankang Deng Team|[2512.08881](http://arxiv.org/abs/2512.08881)|null|
|**2025-12-09**|**IPPO Learns the Game, Not the Team: A Study on Generalization in Heterogeneous Agent Teams**|Jack Kolb Team|[2512.08877](http://arxiv.org/abs/2512.08877)|null|
|**2025-12-09**|**Tri-Bench: Stress-Testing VLM Reliability on Spatial Reasoning under Camera Tilt and Object Interference**|Amit Bendkhale Team|[2512.08860](http://arxiv.org/abs/2512.08860)|**[link](https://github.com/Amiton7/Tri-Bench.)**|
|**2025-12-09**|**Reinforcement Learning From State and Temporal Differences**|Jonathan Baxter Team|[2512.08855](http://arxiv.org/abs/2512.08855)|null|
|**2025-12-09**|**InfiniteVL: Synergizing Linear and Sparse Attention for Highly-Efficient, Unlimited-Input Vision-Language Models**|Xinggang Wang Team|[2512.08829](http://arxiv.org/abs/2512.08829)|null|
|**2025-12-09**|**CARLoS: Retrieval via Concise Assessment Representation of LoRAs at Scale**|Amit H. Bermano Team|[2512.08826](http://arxiv.org/abs/2512.08826)|**[link](https://shahar-sarfaty.github.io/CARLoS/)**|
|**2025-12-09**|**Training-Free Dual Hyperbolic Adapters for Better Cross-Modal Reasoning**|Angelica I. Aviles-Rivero Team|[2512.08820](http://arxiv.org/abs/2512.08820)|null|
|**2025-12-09**|**Multi state neurons**|Robert Worden Team|[2512.08815](http://arxiv.org/abs/2512.08815)|null|
|**2025-12-09**|**Delay-Oriented Distributed Scheduling with TransGNN**|Junyu Luo Team|[2512.08799](http://arxiv.org/abs/2512.08799)|null|
|**2025-12-09**|**Persistent Homology for Labeled Datasets: Gromov-Hausdorff Stability and Generalized Landscapes**|Morgan Weiler Team|[2512.08794](http://arxiv.org/abs/2512.08794)|null|
|**2025-12-09**|**Refining Visual Artifacts in Diffusion Models via Explainable AI-based Flaw Activation Maps**|Jonghyuk Park Team|[2512.08774](http://arxiv.org/abs/2512.08774)|null|
|**2025-12-09**|**Optimal navigation in two-dimensional regular and turbulent flows**|Vladimir Parfenyev Team|[2512.08766](http://arxiv.org/abs/2512.08766)|null|
|**2025-12-09**|**Wan-Move: Motion-controllable Video Generation via Latent Trajectory Guidance**|Yujiu Yang Team|[2512.08765](http://arxiv.org/abs/2512.08765)|**[link](https://github.com/ali-vilab/Wan-Move)**|
|**2025-12-09**|**Learning and Editing Universal Graph Prompt Tuning via Reinforcement Learning**|Edith C. H. Ngai Team|[2512.08763](http://arxiv.org/abs/2512.08763)|null|
|**2025-12-09**|**Skewness-Guided Pruning of Multimodal Swin Transformers for Federated Skin Lesion Classification on Edge Devices**|Yiannis Papadopoulos Team|[2512.08751](http://arxiv.org/abs/2512.08751)|null|
|**2025-12-09**|**A Scalable Pipeline Combining Procedural 3D Graphics and Guided Diffusion for Photorealistic Synthetic Training Data Generation in White Button Mushroom Segmentation**|Péter Galambos Team|[2512.08747](http://arxiv.org/abs/2512.08747)|null|
|**2025-12-09**|**RF sensing with dense IoT network graphs: An EM-informed analysis**|Stefano Savazzi Team|[2512.08746](http://arxiv.org/abs/2512.08746)|null|
|**2025-12-09**|**Insured Agents: A Decentralized Trust Insurance Mechanism for Agentic Economy**|Bangdao Chen Team|[2512.08737](http://arxiv.org/abs/2512.08737)|null|
|**2025-12-09**|**SegEarth-OV3: Exploring SAM 3 for Open-Vocabulary Semantic Segmentation in Remote Sensing Images**|Xiangyong Cao Team|[2512.08730](http://arxiv.org/abs/2512.08730)|null|
|**2025-12-09**|**Exposing Hidden Biases in Text-to-Image Models via Automated Prompt Search**|Yannis Panagakis Team|[2512.08724](http://arxiv.org/abs/2512.08724)|null|
|**2025-12-09**|**Dual-Branch Center-Surrounding Contrast: Rethinking Contrastive Learning for 3D Point Clouds**|Junchi Yan Team|[2512.08673](http://arxiv.org/abs/2512.08673)|null|
|**2025-12-09**|**Direct transfer of optimized controllers to similar systems using dimensionless MPC**|Sébastien Gros Team|[2512.08667](http://arxiv.org/abs/2512.08667)|null|
|**2025-12-09**|**Sim2Swim: Zero-Shot Velocity Control for Agile AUV Maneuvering in 3 Minutes**|Sveinung Johan Ohrem Team|[2512.08656](http://arxiv.org/abs/2512.08656)|null|
|**2025-12-09**|**A Sensor-Aware Phenomenological Framework for Lidar Degradation Simulation and SLAM Robustness Evaluation**|Tomi Westerlund Team|[2512.08653](http://arxiv.org/abs/2512.08653)|null|
|**2025-12-09**|**Chain-of-Image Generation: Toward Monitorable and Controllable Image Generation**|Guillermo Sapiro Team|[2512.08645](http://arxiv.org/abs/2512.08645)|null|
|**2025-12-09**|**Aerial Vision-Language Navigation with a Unified Framework for Spatial, Temporal and Embodied Reasoning**|Feng Xu Team|[2512.08639](http://arxiv.org/abs/2512.08639)|null|
|**2025-12-09**|**See-Control: A Multimodal Agent Framework for Smartphone Interaction with a Robotic Arm**|Jun Wang Team|[2512.08629](http://arxiv.org/abs/2512.08629)|null|
|**2025-12-09**|**Trajectory Densification and Depth from Perspective-based Blur**|Yueting Chen Team|[2512.08627](http://arxiv.org/abs/2512.08627)|null|
|**2025-12-09**|**OpenMonoGS-SLAM: Monocular Gaussian Splatting SLAM with Open-set Semantics**|Eunbyung Park Team|[2512.08625](http://arxiv.org/abs/2512.08625)|null|
|**2025-12-09**|**Heuristics for Combinatorial Optimization via Value-based Reinforcement Learning: A Unified Framework and Analysis**|Nimrod Megiddo Team|[2512.08601](http://arxiv.org/abs/2512.08601)|null|
|**2025-12-09**|**Automated Pollen Recognition in Optical and Holographic Microscopy Images**|Roberts Kadiķis Team|[2512.08589](http://arxiv.org/abs/2512.08589)|**[link](https://ieeexplore.ieee.org/document/11064260)**|
|**2025-12-09**|**Mind to Hand: Purposeful Robotic Control via Embodied Reasoning**|Jianan Wang Team|[2512.08580](http://arxiv.org/abs/2512.08580)|null|
|**2025-12-09**|**Disturbance-Free Surgical Video Generation from Multi-Camera Shadowless Lamps for Open Surgery**|Mariko Isogawa Team|[2512.08577](http://arxiv.org/abs/2512.08577)|null|
|**2025-12-09**|**Instance-Aware Test-Time Segmentation for Continual Domain Shifts**|Sungeun Hong Team|[2512.08569](http://arxiv.org/abs/2512.08569)|null|
|**2025-12-09**|**A Hybrid Model for Stock Market Forecasting: Integrating News Sentiment and Time Series Data with Graph Neural Networks**|Mariam Elzahaby Team|[2512.08567](http://arxiv.org/abs/2512.08567)|**[link](https://papers.academic-conferences.org/index.php/icair/article/view/4294)**|
|**2025-12-09**|**SSCATeR: Sparse Scatter-Based Convolution Algorithm with Temporal Data Recycling for Real-Time 3D Object Detection in LiDAR Point Clouds**|James Riordan Team|[2512.08557](http://arxiv.org/abs/2512.08557)|null|
|**2025-12-09**|**A Novel Wasserstein Quaternion Generative Adversarial Network for Color Image Generation**|Xiaoyu Zhao Team|[2512.08542](http://arxiv.org/abs/2512.08542)|null|
|**2025-12-09**|**Beyond Real Weights: Hypercomplex Representations for Stable Quantization**|Shafin Rahman Team|[2512.08524](http://arxiv.org/abs/2512.08524)|null|
|**2025-12-09**|**SensHRPS: Sensing Comfortable Human-Robot Proxemics and Personal Space With Eye-Tracking**|Karsten Berns Team|[2512.08518](http://arxiv.org/abs/2512.08518)|null|
|**2025-12-09**|**Thinking with Images via Self-Calling Agent**|Qixiang Ye Team|[2512.08511](http://arxiv.org/abs/2512.08511)|**[link](https://github.com/YWenxi/think-with-images-through-self-calling)**|
|**2025-12-09**|**OCCDiff: Occupancy Diffusion Model for High-Fidelity 3D Building Reconstruction from Noisy Point Clouds**|Hongsheng Zhang Team|[2512.08506](http://arxiv.org/abs/2512.08506)|null|
|**2025-12-09**|**Beyond the Noise: Aligning Prompts with Latent Representations in Diffusion Models**|Joao Magalhaes Team|[2512.08505](http://arxiv.org/abs/2512.08505)|null|
|**2025-12-09**|**Learning to Control Physically-simulated 3D Characters via Generating and Mimicking 2D Motions**|Tien-Tsin Wong Team|[2512.08500](http://arxiv.org/abs/2512.08500)|null|
|**2025-12-09**|**On-the-fly Large-scale 3D Reconstruction from Multi-Camera Rigs**|Lei Ma Team|[2512.08498](http://arxiv.org/abs/2512.08498)|null|
|**2025-12-09**|**Temporal Concept Dynamics in Diffusion Models via Prompt-Conditioned Interventions**|Jonas Fischer Team|[2512.08486](http://arxiv.org/abs/2512.08486)|**[link](https://github.com/adagorgun/PCI-Prompt-Controlled-Interventions)**|
|**2025-12-09**|**Optimal Perturbation Budget Allocation for Data Poisoning in Offline Reinforcement Learning**|Jie Li Team|[2512.08485](http://arxiv.org/abs/2512.08485)|null|
|**2025-12-09**|**Visionary: The World Model Carrier Built on WebGPU-Powered Gaussian Splatting Platform**|Zhihang Zhong Team|[2512.08478](http://arxiv.org/abs/2512.08478)|**[link](https://visionary-laboratory.github.io/visionary)**|
|**2025-12-09**|**Using reinforcement learning to probe the role of feedback in skill acquisition**|Raffaello D'Andrea Team|[2512.08463](http://arxiv.org/abs/2512.08463)|**[link](https://antonioterpin.com/fluids-control)**|
|**2025-12-09**|**From Accuracy to Impact: The Impact-Driven AI Framework (IDAIF) for Aligning Engineering Architecture with Theory of Change**|Yong-Woon Kim Team|[2512.08449](http://arxiv.org/abs/2512.08449)|null|
|**2025-12-09**|**LapFM: A Laparoscopic Segmentation Foundation Model via Hierarchical Concept Evolving Pre-training**|Zhen Chen Team|[2512.08439](http://arxiv.org/abs/2512.08439)|null|
|**2025-12-09**|**SDT-6D: Fully Sparse Depth-Transformer for Staged End-to-End 6D Pose Estimation in Industrial Multi-View Bin Picking**|Alfred Schoettl Team|[2512.08430](http://arxiv.org/abs/2512.08430)|null|
|**2025-12-09**|**Learning Robot Manipulation from Audio World Models**|Michael Gienger Team|[2512.08405](http://arxiv.org/abs/2512.08405)|null|
|**2025-12-09**|**Ontology-Based Knowledge Graph Framework for Industrial Standard Documents via Hierarchical and Propositional Structuring**|Misuk Kim Team|[2512.08398](http://arxiv.org/abs/2512.08398)|null|
|**2025-12-09**|**Magneton: Optimizing Energy Efficiency of ML Systems via Differential Energy Debugging**|Baris Kasikci Team|[2512.08365](http://arxiv.org/abs/2512.08365)|null|
|**2025-12-09**|**SCU-CGAN: Enhancing Fire Detection through Synthetic Fire Image Generation and Dataset Augmentation**|Gun-Woo Kim Team|[2512.08362](http://arxiv.org/abs/2512.08362)|null|
|**2025-12-09**|**Turning Threat into Opportunity: DRL-Powered Anti-Jamming via Energy Harvesting in UAV-Disrupted Channels**|Thai-Duong Nguyen Team|[2512.08351](http://arxiv.org/abs/2512.08351)|null|
|**2025-12-09**|**Enhancing Explainability of Graph Neural Networks Through Conceptual and Structural Analyses and Their Extensions**|Tien Cuong Bui Team|[2512.08344](http://arxiv.org/abs/2512.08344)|null|
|**2025-12-09**|**Multi-Agent Deep Reinforcement Learning for Collaborative UAV Relay Networks under Jamming Atatcks**|Symeon Chatzinotas Team|[2512.08341](http://arxiv.org/abs/2512.08341)|null|
|**2025-12-09**|**HybridSplat: Fast Reflection-baked Gaussian Tracing using Hybrid Splatting**|Shi-Sheng Huang Team|[2512.08334](http://arxiv.org/abs/2512.08334)|**[link](https://aetheryne.github.io/HybridSplat/)**|
|**2025-12-09**|**Robust Finetuning of Vision-Language-Action Robot Policies via Parameter Merging**|Sergey Levine Team|[2512.08333](http://arxiv.org/abs/2512.08333)|null|
|**2025-12-09**|**PointDico: Contrastive 3D Representation Learning Guided by Diffusion Models**|Haozhe Cheng Team|[2512.08330](http://arxiv.org/abs/2512.08330)|null|
|**2025-12-09**|**Interpreting Structured Perturbations in Image Protection Methods for Diffusion Models**|Kwan-Liu Ma Team|[2512.08329](http://arxiv.org/abs/2512.08329)|null|
|**2025-12-09**|**Collaborative Intelligence for UAV-Satellite Network Slicing: Towards a Joint QoS-Energy-Fairness MADRL Optimization**|Symeon Chatzinotas Team|[2512.08322](http://arxiv.org/abs/2512.08322)|null|
|**2025-12-09**|**rSIM: Incentivizing Reasoning Capabilities of LLMs via Reinforced Strategy Injection**|Di Niu Team|[2512.08300](http://arxiv.org/abs/2512.08300)|null|
|**2025-12-09**|**OpenSubject: Leveraging Video-Derived Identity and Diversity Priors for Subject-driven Image Generation and Manipulation**|Harry Yang Team|[2512.08294](http://arxiv.org/abs/2512.08294)|null|
|**2025-12-09**|**Systematization of Knowledge: Security and Safety in the Model Context Protocol Ecosystem**|Umesh Yadav Team|[2512.08290](http://arxiv.org/abs/2512.08290)|null|
|**2025-12-09**|**PAVAS: Physics-Aware Video-to-Audio Synthesis**|Yuki Mitsufuji Team|[2512.08282](http://arxiv.org/abs/2512.08282)|null|
|**2025-12-09**|**gHAWK: Local and Global Structure Encoding for Scalable Training of Graph Neural Networks on Knowledge Graphs**|Ashraf Aboulnaga Team|[2512.08274](http://arxiv.org/abs/2512.08274)|null|
|**2025-12-09**|**Zero-Splat TeleAssist: A Zero-Shot Pose Estimation Framework for Semantic Teleoperation**|Dharini Raghavan Team|[2512.08271](http://arxiv.org/abs/2512.08271)|null|
|**2025-12-09**|**EgoX: Egocentric Video Generation from a Single Exocentric Video**|Jaegul Choo Team|[2512.08269](http://arxiv.org/abs/2512.08269)|**[link](https://keh0t0.github.io/EgoX)**|
|**2025-12-09**|**Beyond Traditional Diagnostics: Transforming Patient-Side Information into Predictive Insights with Knowledge Graphs and Prototypes**|Chunyan Miao Team|[2512.08261](http://arxiv.org/abs/2512.08261)|null|
|**2025-12-09**|**Query-aware Hub Prototype Learning for Few-Shot 3D Point Cloud Semantic Segmentation**|Congyan Lang Team|[2512.08253](http://arxiv.org/abs/2512.08253)|null|
|**2025-12-09**|**Distilling Future Temporal Knowledge with Masked Feature Reconstruction for 3D Object Detection**|Yanyan Liang Team|[2512.08247](http://arxiv.org/abs/2512.08247)|null|
|**2025-12-09**|**Persistent Topological Structures and Cohomological Flows as a Mathematical Framework for Brain-Inspired Representation Learning**|Shipra Prashant Team|[2512.08241](http://arxiv.org/abs/2512.08241)|null|
|**2025-12-09**|**HybridToken-VLM: Hybrid Token Compression for Vision-Language Models**|Keze Wang Team|[2512.08240](http://arxiv.org/abs/2512.08240)|null|
|**2025-12-09**|**Semantic-Metric Bayesian Risk Fields: Learning Robot Safety from Human Videos with a VLM Prior**|Mac Schwager Team|[2512.08233](http://arxiv.org/abs/2512.08233)|null|
|**2025-12-09**|**Empowerment Gain and Causal Model Construction: Children and adults are sensitive to controllability and variability in their causal interventions**|Alison Gopnik Team|[2512.08230](http://arxiv.org/abs/2512.08230)|null|
|**2025-12-09**|**Geometry-Aware Sparse Depth Sampling for High-Fidelity RGB-D Depth Completion in Robotic Systems**|Xinhai Sun Team|[2512.08229](http://arxiv.org/abs/2512.08229)|null|
|**2025-12-09**|**MM-CoT:A Benchmark for Probing Visual Chain-of-Thought Reasoning in Multimodal Models**|Keze Wang Team|[2512.08228](http://arxiv.org/abs/2512.08228)|null|
|**2025-12-09**|**SOP^2: Transfer Learning with Scene-Oriented Prompt Pool on 3D Object Detection**|Ching-Chun Huang Team|[2512.08223](http://arxiv.org/abs/2512.08223)|null|
|**2025-12-09**|**VisKnow: Constructing Visual Knowledge Base for Object Understanding**|Xilin Chen Team|[2512.08221](http://arxiv.org/abs/2512.08221)|null|
|**2025-12-09**|**Restoring Network Evolution from Static Structure**|Yanqing Hu Team|[2512.08209](http://arxiv.org/abs/2512.08209)|null|
|**2025-12-09**|**Metasurfaces Enable Active-Like Passive Radar**|Lianlin Li Team|[2512.08208](http://arxiv.org/abs/2512.08208)|null|
|**2025-12-09**|**High-Performance Dual-Arm Task and Motion Planning for Tabletop Rearrangement**|Jingjin Yu Team|[2512.08206](http://arxiv.org/abs/2512.08206)|null|
|**2025-12-09**|**Primal-dual policy learning for mean-field stochastic LQR problem**|Yuanqing Wu Team|[2512.08205](http://arxiv.org/abs/2512.08205)|null|
|**2025-12-09**|**Embodied Tree of Thoughts: Deliberate Manipulation Planning with Embodied World Model**|Rui Chen Team|[2512.08188](http://arxiv.org/abs/2512.08188)|**[link](https://embodied-tree-of-thoughts.github.io)**|
|**2025-12-09**|**Ground Slow, Move Fast: A Dual-System Foundation Model for Generalizable Vision-and-Language Navigation**|Xihui Liu Team|[2512.08186](http://arxiv.org/abs/2512.08186)|null|
|**2025-12-09**|**RAVES-Calib: Robust, Accurate and Versatile Extrinsic Self Calibration Using Optimal Geometric Features**|Wen Yao Team|[2512.08170](http://arxiv.org/abs/2512.08170)|null|
|**2025-12-09**|**Accuracy Does Not Guarantee Human-Likeness in Monocular Depth Estimators**|Taiki Fukiage Team|[2512.08163](http://arxiv.org/abs/2512.08163)|null|
|**2025-12-09**|**TreeGRPO: Tree-Advantage GRPO for Online RL Post-Training of Diffusion Models**|Weirui Ye Team|[2512.08153](http://arxiv.org/abs/2512.08153)|null|
|**2025-12-09**|**Chat with UAV -- Human-UAV Interaction Based on Large Language Models**|Chuanghuang Li Team|[2512.08145](http://arxiv.org/abs/2512.08145)|null|
|**2025-12-09**|**Robust Agents in Open-Ended Worlds**|Mikayel Samvelyan Team|[2512.08139](http://arxiv.org/abs/2512.08139)|null|
|**2025-12-09**|**CVP: Central-Peripheral Vision-Inspired Multimodal Model for Spatial Reasoning**|Zhuowen Tu Team|[2512.08135](http://arxiv.org/abs/2512.08135)|null|
|**2025-12-09**|**Universal Adversarial Suffixes for Language Models Using Reinforcement Learning with Calibrated Reward**|Arijit Sur Team|[2512.08131](http://arxiv.org/abs/2512.08131)|null|
|**2025-12-09**|**FlowSteer: Conditioning Flow Field for Consistent Image Restoration**|Stanley H. Chan Team|[2512.08125](http://arxiv.org/abs/2512.08125)|null|
|**2025-12-08**|**Scalable Offline Model-Based RL with Action Chunks**|Sergey Levine Team|[2512.08108](http://arxiv.org/abs/2512.08108)|null|
|**2025-12-08**|**Training LLMs for Honesty via Confessions**|Amelia Glaese Team|[2512.08093](http://arxiv.org/abs/2512.08093)|null|
|**2025-12-08**|**Bayesian Co-Navigation of a Computational Physical Model and AFM Experiment to Autonomously Survey a Combinatorial Materials Library**|Sergei V. Kalinin Team|[2512.08084](http://arxiv.org/abs/2512.08084)|null|
|**2025-12-08**|**An Introduction to Deep Reinforcement and Imitation Learning**|Pedro Santana Team|[2512.08052](http://arxiv.org/abs/2512.08052)|null|
|**2025-12-08**|**F2: Offline Reinforcement Learning for Hamiltonian Simulation via Free-Fermionic Subroutine Compilation**|Samuel Stein Team|[2512.08023](http://arxiv.org/abs/2512.08023)|null|
|**2025-12-08**|**FRIEDA: Benchmarking Multi-Step Cartographic Reasoning in Vision-Language Models**|Yao-Yi Chiang Team|[2512.08016](http://arxiv.org/abs/2512.08016)|null|
|**2025-12-08**|**Benchmarking Offline Multi-Objective Reinforcement Learning in Critical Care**|Divya Sharma Team|[2512.08012](http://arxiv.org/abs/2512.08012)|null|
|**2025-12-08**|**HOLE: Homological Observation of Latent Embeddings for Neural Network Interpretability**|Paul Rosen Team|[2512.07988](http://arxiv.org/abs/2512.07988)|null|
|**2025-12-08**|**Restrictive Hierarchical Semantic Segmentation for Stratified Tooth Layer Detection**|Yunpeng Li Team|[2512.07984](http://arxiv.org/abs/2512.07984)|null|
|**2025-12-08**|**VLD: Visual Language Goal Distance for Reinforcement Learning Navigation**|Jonas Frey Team|[2512.07976](http://arxiv.org/abs/2512.07976)|null|
|**2025-12-08**|**Agentic Artificial Intelligence for Ethical Cybersecurity in Uganda: A Reinforcement Learning Framework for Threat Detection in Resource-Constrained Environments**|Mutebi Joe Team|[2512.07909](http://arxiv.org/abs/2512.07909)|null|
|**2025-12-08**|**Relational Visual Similarity**|Yuheng Li Team|[2512.07833](http://arxiv.org/abs/2512.07833)|**[link](https://thaoshibe.github.io/relsim)**|
|**2025-12-08**|**UnityVideo: Unified Multi-Modal Multi-Task Learning for Enhancing World-Aware Video Generation**|Jiaya Jia Team|[2512.07831](http://arxiv.org/abs/2512.07831)|**[link](https://jackailab.github.io/Projects/UnityVideo)**|
|**2025-12-08**|**One Layer Is Enough: Adapting Pretrained Visual Encoders for Image Generation**|Jiatao Gu Team|[2512.07829](http://arxiv.org/abs/2512.07829)|null|
|**2025-12-08**|**An Adaptive Multi-Layered Honeynet Architecture for Threat Behavior Analysis via Deep Learning**|Lukas Johannes Möller Team|[2512.07827](http://arxiv.org/abs/2512.07827)|null|
|**2025-12-08**|**WorldReel: 4D Video Generation with Consistent Geometry and Motion Modeling**|Qixing Huang Team|[2512.07821](http://arxiv.org/abs/2512.07821)|null|
|**2025-12-08**|**Efficient and Compliant Control Framework for Versatile Human-Humanoid Collaborative Transportation**|Panagiotis Artemiadis Team|[2512.07819](http://arxiv.org/abs/2512.07819)|null|
|**2025-12-08**|**Multi-view Pyramid Transformer: Look Coarser to See Broader**|Eunbyung Park Team|[2512.07806](http://arxiv.org/abs/2512.07806)|**[link](https://gynjn.github.io/MVP/)**|
|**2025-12-08**|**OneStory: Coherent Multi-Shot Video Generation with Adaptive Memory**|Tian Xie Team|[2512.07802](http://arxiv.org/abs/2512.07802)|**[link](https://zhaochongan.github.io/projects/OneStory)**|
|**2025-12-08**|**On the Interplay of Pre-Training, Mid-Training, and RL on Reasoning Language Models**|Xiang Yue Team|[2512.07783](http://arxiv.org/abs/2512.07783)|null|
|**2025-12-08**|**Distribution Matching Variational AutoEncoder**|Han Hu Team|[2512.07778](http://arxiv.org/abs/2512.07778)|null|
|**2025-12-08**|**GorillaWatch: An Automated System for In-the-Wild Gorilla Re-Identification and Population Monitoring**|Gerard de Melo Team|[2512.07776](http://arxiv.org/abs/2512.07776)|null|
|**2025-12-08**|**RL-MTJail: Reinforcement Learning for Automated Black-Box Multi-Turn Jailbreaking of Large Language Models**|Xiangnan He Team|[2512.07761](http://arxiv.org/abs/2512.07761)|null|
|**2025-12-08**|**DiffusionDriveV2: Reinforcement Learning-Constrained Truncated Diffusion Modeling in End-to-End Autonomous Driving**|Xinggang Wang Team|[2512.07745](http://arxiv.org/abs/2512.07745)|null|
|**2025-12-08**|**SpatialDreamer: Incentivizing Spatial Reasoning via Active Mental Imagery**|Xiaodan Liang Team|[2512.07733](http://arxiv.org/abs/2512.07733)|null|
|**2025-12-08**|**ViSA: 3D-Aware Video Shading for Real-Time Upper-Body Avatar Creation**|Guosheng Lin Team|[2512.07720](http://arxiv.org/abs/2512.07720)|**[link](https://lhyfst.github.io/visa})**|
|**2025-12-08**|**Each Prompt Matters: Scaling Reinforcement Learning Without Wasting Rollouts on Hundred-Billion-Scale MoE**|Ziqin Liew Team|[2512.07710](http://arxiv.org/abs/2512.07710)|null|
|**2025-12-08**|**Guiding What Not to Generate: Automated Negative Prompting for Text-Image Alignment**|Sungroh Yoon Team|[2512.07702](http://arxiv.org/abs/2512.07702)|null|
|**2025-12-08**|**Delay-Aware Diffusion Policy: Bridging the Observation-Execution Gap in Dynamic Tasks**|Shayegan Omidshafiei Team|[2512.07697](http://arxiv.org/abs/2512.07697)|null|
|**2025-12-08**|**When Large Language Models Do Not Work: Online Incivility Prediction through Graph Neural Networks**|Lanyu Yu Team|[2512.07684](http://arxiv.org/abs/2512.07684)|null|
|**2025-12-08**|**Multi-Domain Motion Embedding: Expressive Real-Time Mimicry for Legged Robots**|Marco Hutter Team|[2512.07673](http://arxiv.org/abs/2512.07673)|null|
|**2025-12-08**|**An AI-Powered Autonomous Underwater System for Sea Exploration and Scientific Research**|Maha Alzaabi Team|[2512.07652](http://arxiv.org/abs/2512.07652)|null|
|**2025-12-08**|**The Agent Capability Problem: Predicting Solvability Through Information-Theoretic Bounds**|Shahar Lutati Team|[2512.07631](http://arxiv.org/abs/2512.07631)|null|
|**2025-12-08**|**Comparative Analysis and Parametric Tuning of PPO, GRPO, and DAPO for LLM Reasoning Enhancement**|Yongsheng Lian Team|[2512.07611](http://arxiv.org/abs/2512.07611)|null|
|**2025-12-08**|**Online Segment Any 3D Thing as Instance Tracking**|Zhipeng Zhang Team|[2512.07599](http://arxiv.org/abs/2512.07599)|**[link](https://github.com/AutoLab-SAI-SJTU/AutoSeg3D)**|
|**2025-12-08**|**More than Segmentation: Benchmarking SAM 3 for Segmentation, 3D Perception, and Reconstruction in Robotic Surgery**|Long Bai Team|[2512.07596](http://arxiv.org/abs/2512.07596)|null|
|**2025-12-08**|**Understanding Individual Decision-Making in Multi-Agent Reinforcement Learning: A Dynamical Systems Approach**|Mirco Musolesi Team|[2512.07588](http://arxiv.org/abs/2512.07588)|null|
|**2025-12-08**|**LongCat-Image Technical Report**|Jie Hu Team|[2512.07584](http://arxiv.org/abs/2512.07584)|null|
|**2025-12-08**|**See Once, Then Act: Vision-Language-Action Model with Task Learning from One-Shot Video Demonstrations**|Yufeng Yue Team|[2512.07582](http://arxiv.org/abs/2512.07582)|null|
|**2025-12-08**|**Toward More Reliable Artificial Intelligence: Reducing Hallucinations in Vision-Language Models**|Renzo Ardiccioni Team|[2512.07564](http://arxiv.org/abs/2512.07564)|**[link](https://github.com/kassoumsanogo1/self-correcting-vlm-re-Attention.git)**|
|**2025-12-08**|**ReLaX: Reasoning with Latent Exploration for Large Reasoning Models**|Jibin Wu Team|[2512.07558](http://arxiv.org/abs/2512.07558)|null|
|**2025-12-08**|**Model-Based Reinforcement Learning Under Confounding**|Andreas A. Malikopoulos Team|[2512.07528](http://arxiv.org/abs/2512.07528)|null|
|**2025-12-08**|**Dictionary-Based Contrastive Learning for GNSS Jamming Detection**|Talha Nadeem Team|[2512.07512](http://arxiv.org/abs/2512.07512)|null|
|**2025-12-08**|**ControlVP: Interactive Geometric Refinement of AI-Generated Images with Consistent Vanishing Points**|Toshihiko Yamasaki Team|[2512.07504](http://arxiv.org/abs/2512.07504)|**[link](https://github.com/RyotaOkumura/ControlVP)**|
|**2025-12-08**|**SJD++: Improved Speculative Jacobi Decoding for Training-free Acceleration of Discrete Auto-regressive Text-to-Image Generation**|Xihui Liu Team|[2512.07503](http://arxiv.org/abs/2512.07503)|null|
|**2025-12-08**|**How Do LLMs Fail In Agentic Scenarios? A Qualitative Analysis of Success and Failure Scenarios of Various LLMs in Agentic Simulations**|JV Roig Team|[2512.07497](http://arxiv.org/abs/2512.07497)|null|
|**2025-12-08**|**SemanticTours: A Conceptual Framework for Non-Linear, Knowledge Graph-Driven Data Tours**|Maximilian T. Fischer Team|[2512.07483](http://arxiv.org/abs/2512.07483)|null|
|**2025-12-08**|**Enhancing Agentic RL with Progressive Reward Shaping and Value-based Sampling Policy Optimization**|Xia Zeng Team|[2512.07478](http://arxiv.org/abs/2512.07478)|null|
|**2025-12-08**|**Living the Novel: A System for Generating Self-Training Timeline-Aware Conversational Agents from Novels**|Bo Zheng Team|[2512.07474](http://arxiv.org/abs/2512.07474)|null|
|**2025-12-08**|**Affordance Field Intervention: Enabling VLAs to Escape Memory Traps in Robotic Manipulation**|Chang Xu Team|[2512.07472](http://arxiv.org/abs/2512.07472)|null|
|**2025-12-08**|**Gait-Adaptive Perceptive Humanoid Locomotion with Real-Time Under-Base Terrain Reconstruction**|Houqiang Li Team|[2512.07464](http://arxiv.org/abs/2512.07464)|null|
|**2025-12-08**|**Native Parallel Reasoner: Reasoning in Parallelism via Self-Distilled Reinforcement Learning**|Zilong Zheng Team|[2512.07461](http://arxiv.org/abs/2512.07461)|null|
|**2025-12-08**|**From Show Programmes to Data: Designing a Workflow to Make Performing Arts Ephemera Accessible Through Language Models**|Jeanne Fras Team|[2512.07452](http://arxiv.org/abs/2512.07452)|null|
|**2025-12-08**|**Forget and Explain: Transparent Verification of GNN Unlearning**|Mucheol Kim Team|[2512.07450](http://arxiv.org/abs/2512.07450)|**[link](https://github.com/ImranAhsan23/F-E)**|
|**2025-12-08**|**Scalable Formal Verification of Incremental Stability in Large-Scale Systems Using Graph Neural Networks**|Pushpak Jagtap Team|[2512.07448](http://arxiv.org/abs/2512.07448)|null|
|**2025-12-08**|**KAN-Dreamer: Benchmarking Kolmogorov-Arnold Networks as Function Approximators in World Models**|Xueyu Luan Team|[2512.07437](http://arxiv.org/abs/2512.07437)|null|
|**2025-12-08**|**E-PCN: Jet Tagging with Explainable Particle Chebyshev Networks Using Kinematic Features**|AKM Mahbubur Rahman Team|[2512.07420](http://arxiv.org/abs/2512.07420)|null|
|**2025-12-08**|**Revolutionizing Mixed Precision Quantization: Towards Training-free Automatic Proxy Discovery via Large Language Models**|Lihong Lin Team|[2512.07419](http://arxiv.org/abs/2512.07419)|null|
|**2025-12-08**|**Adaptive Tuning of Parameterized Traffic Controllers via Multi-Agent Reinforcement Learning**|Bart De Schutter Team|[2512.07417](http://arxiv.org/abs/2512.07417)|null|
|**2025-12-08**|**Training Language Models to Use Prolog as a Tool**|Lukas Galke Poech Team|[2512.07407](http://arxiv.org/abs/2512.07407)|null|
|**2025-12-08**|**Recent advancements in the tau reconstruction and identification techniques in CMS**|Andrea Cardini Team|[2512.07387](http://arxiv.org/abs/2512.07387)|null|
|**2025-12-08**|**On the Impact of Graph Neural Networks in Recommender Systems: A Topological Perspective**|Tommaso Di Noia Team|[2512.07384](http://arxiv.org/abs/2512.07384)|null|
|**2025-12-08**|**Tessellation GS: Neural Mesh Gaussians for Robust Monocular Reconstruction of Dynamic Objects**|Yebin Liu Team|[2512.07381](http://arxiv.org/abs/2512.07381)|null|
|**2025-12-08**|**Enhancing Small Object Detection with YOLO: A Novel Framework for Improved Accuracy and Efficiency**|Melika Sabaghian Team|[2512.07379](http://arxiv.org/abs/2512.07379)|null|
|**2025-12-08**|**Control and Reinforcement Learning through the Lens of Optimization: An Algorithmic Perspective**|Peyman Mohajerin Esfahani Team|[2512.07377](http://arxiv.org/abs/2512.07377)|null|
|**2025-12-08**|**ESPADA: Execution Speedup via Semantics Aware Demonstration Data Downsampling for Imitation Learning**|Byoung-Tak Zhang Team|[2512.07371](http://arxiv.org/abs/2512.07371)|**[link](https://project-espada.github.io/espada/)**|
|**2025-12-08**|**The Impact of Spatial Misalignment and Time Delay on Collaborative Presence in Augmented Reality**|Jan-Niklas Voigt-Antons Team|[2512.07363](http://arxiv.org/abs/2512.07363)|null|
|**2025-12-08**|**Structure-Aware Feature Rectification with Region Adjacency Graphs for Training-Free Open-Vocabulary Semantic Segmentation**|Jianbo Jiao Team|[2512.07360](http://arxiv.org/abs/2512.07360)|null|
|**2025-12-08**|**Multi-Rigid-Body Approximation of Human Hands with Application to Digital Twin**|Sheng Yi Team|[2512.07359](http://arxiv.org/abs/2512.07359)|null|
|**2025-12-08**|**Edge-Aware Graph Attention Model for Structural Optimization of High Entropy Carbides**|Abhishek Kumar Singh Team|[2512.07358](http://arxiv.org/abs/2512.07358)|null|
|**2025-12-08**|**Communication-Efficient Serving for Video Diffusion Models with Latent Parallelism**|Yong Wang Team|[2512.07350](http://arxiv.org/abs/2512.07350)|null|
|**2025-12-08**|**MICo-150K: A Comprehensive Dataset Advancing Multi-Image Composition**|Lei Zhang Team|[2512.07348](http://arxiv.org/abs/2512.07348)|**[link](https://MICo-150K.github.io/)**|
|**2025-12-08**|**Debiasing Diffusion Priors via 3D Attention for Consistent Gaussian Splatting**|Yuan Zhou Team|[2512.07345](http://arxiv.org/abs/2512.07345)|null|
|**2025-12-08**|**Venus: An Efficient Edge Memory-and-Retrieval System for VLM-based Online Video Understanding**|Xu Chen Team|[2512.07344](http://arxiv.org/abs/2512.07344)|null|
|**2025-12-08**|**PrivORL: Differentially Private Synthetic Dataset for Offline Reinforcement Learning**|Tianhao Wang Team|[2512.07342](http://arxiv.org/abs/2512.07342)|**[link](https://github.com/2019ChenGong/PrivORL)**|
|**2025-12-08**|**Generalized Referring Expression Segmentation on Aerial Photos**|Bruno Martins Team|[2512.07338](http://arxiv.org/abs/2512.07338)|null|
|**2025-12-08**|**Local-Curvature-Aware Knowledge Graph Embedding: An Extended Ricci Flow Approach**|Zhiqiang Xu Team|[2512.07332](http://arxiv.org/abs/2512.07332)|null|
|**2025-12-08**|**ContextAnyone: Context-Aware Diffusion for Character-Consistent Text-to-Video Generation**|Yu-Wing Tai Team|[2512.07328](http://arxiv.org/abs/2512.07328)|null|
|**2025-12-08**|**Towards a Relationship-Aware Transformer for Tabular Data**|Lev V. Utkin Team|[2512.07310](http://arxiv.org/abs/2512.07310)|null|
|**2025-12-08**|**Efficient Computation of a Continuous Topological Model of the Configuration Space of Tethered Mobile Robots**|Bart De Schutter Team|[2512.07303](http://arxiv.org/abs/2512.07303)|null|
|**2025-12-08**|**Towards Accurate UAV Image Perception: Guiding Vision-Language Models with Stronger Task Prompts**|Chao Tao Team|[2512.07302](http://arxiv.org/abs/2512.07302)|null|
|**2025-12-08**|**Geo3DVQA: Evaluating Vision-Language Models for 3D Geospatial Reasoning from Aerial Imagery**|Naoto Yokoya Team|[2512.07276](http://arxiv.org/abs/2512.07276)|null|
|**2025-12-08**|**RVLF: A Reinforcing Vision-Language Framework for Gloss-Free Sign Language Translation**|Jun Wan Team|[2512.07273](http://arxiv.org/abs/2512.07273)|null|
|**2025-12-08**|**A graph generation pipeline for critical infrastructures based on heuristics, images and depth data**|Yannick Tarant Team|[2512.07269](http://arxiv.org/abs/2512.07269)|null|
|**2025-12-08**|**SINRL: Socially Integrated Navigation with Reinforcement Learning using Spiking Neural Networks**|Sören Hohmann Team|[2512.07266](http://arxiv.org/abs/2512.07266)|null|
|**2025-12-08**|**Benchmarking Humanoid Imitation Learning with Motion Difficulty**|Yipeng Qin Team|[2512.07248](http://arxiv.org/abs/2512.07248)|null|
|**2025-12-08**|**AdLift: Lifting Adversarial Perturbations to Safeguard 3D Gaussian Splatting Assets Against Instruction-Driven Editing**|Tongliang Liu Team|[2512.07247](http://arxiv.org/abs/2512.07247)|null|
|**2025-12-08**|**Ensembling LLM-Induced Decision Trees for Explainable and Robust Error Detection**|Wenjie Zhang Team|[2512.07246](http://arxiv.org/abs/2512.07246)|null|
|**2025-12-08**|**Zero-Shot Textual Explanations via Translating Decision-Critical Features**|Kazuhiko Kawamoto Team|[2512.07245](http://arxiv.org/abs/2512.07245)|null|
|**2025-12-08**|**PINE: Pipeline for Important Node Exploration in Attributed Networks**|Semen Budennyy Team|[2512.07244](http://arxiv.org/abs/2512.07244)|null|
|**2025-12-08**|**Unified Camera Positional Encoding for Controlled Video Generation**|Jianfei Cai Team|[2512.07237](http://arxiv.org/abs/2512.07237)|**[link](https://github.com/chengzhag/UCPE)**|
|**2025-12-08**|**Dropout Prompt Learning: Towards Robust and Adaptive Vision-Language Models**|Yuchen Wang Team|[2512.07234](http://arxiv.org/abs/2512.07234)|null|
|**2025-12-08**|**Cross-platform Product Matching Based on Entity Alignment of Knowledge Graph with RAEA model**|Qingpeng Zhang Team|[2512.07232](http://arxiv.org/abs/2512.07232)|null|
|**2025-12-08**|**STRinGS: Selective Text Refinement in Gaussian Splatting**|Makarand Tapaswi Team|[2512.07230](http://arxiv.org/abs/2512.07230)|**[link](https://STRinGS-official.github.io)**|
|**2025-12-08**|**Towards Robust Protective Perturbation against DeepFake Face Swapping**|Huiping Chen Team|[2512.07228](http://arxiv.org/abs/2512.07228)|null|
|**2025-12-08**|**Pay Less Attention to Function Words for Free Robustness of Vision-Language Models**|Chao Shen Team|[2512.07222](http://arxiv.org/abs/2512.07222)|null|
|**2025-12-08**|**VFM-VLM: Vision Foundation Model and Vision Language Model based Visual Comparison for 3D Pose Estimation**|Sungho Kim Team|[2512.07215](http://arxiv.org/abs/2512.07215)|null|
|**2025-12-08**|**Sample from What You See: Visuomotor Policy Learning via Diffusion Bridge with Observation-Embedded Stochastic Differential Equation**|Ye Shi Team|[2512.07212](http://arxiv.org/abs/2512.07212)|null|
|**2025-12-08**|**Object Pose Distribution Estimation for Determining Revolution and Reflection Uncertainty in Point Clouds**|Thorbjørn Mosekjær Iversen Team|[2512.07211](http://arxiv.org/abs/2512.07211)|null|
|**2025-12-08**|**MMRPT: MultiModal Reinforcement Pre-Training via Masked Vision-Dependent Reasoning**|Yichao Wu Team|[2512.07203](http://arxiv.org/abs/2512.07203)|null|
|**2025-12-08**|**Less is More: Non-uniform Road Segments are Efficient for Bus Arrival Prediction**|Haitao Yu Team|[2512.07200](http://arxiv.org/abs/2512.07200)|null|
|**2025-12-08**|**Generating Storytelling Images with Rich Chains-of-Reasoning**|Kenny Q. Zhu Team|[2512.07198](http://arxiv.org/abs/2512.07198)|null|
|**2025-12-08**|**SUCCESS-GS: Survey of Compactness and Compression for Efficient Static and Dynamic Gaussian Splatting**|Jihyong Oh Team|[2512.07197](http://arxiv.org/abs/2512.07197)|**[link](https://cmlab-korea.github.io/Awesome-Efficient-GS/)**|
|**2025-12-08**|**Using Vision-Language Models as Proxies for Social Intelligence in Human-Robot Interaction**|Wendy Ju Team|[2512.07177](http://arxiv.org/abs/2512.07177)|null|
|**2025-12-08**|**Variational Regularized Bilevel Estimation for Exponential Random Graph Models**|Yoon Choi Team|[2512.07176](http://arxiv.org/abs/2512.07176)|null|
|**2025-12-08**|**MuSASplat: Efficient Sparse-View 3D Gaussian Splats via Lightweight Multi-Scale Adaptation**|Shijian Lu Team|[2512.07165](http://arxiv.org/abs/2512.07165)|null|
|**2025-12-08**|**CHIMERA: Adaptive Cache Injection and Semantic Anchor Prompting for Zero-shot Image Morphing with Morphing-oriented Metrics**|Jihyong Oh Team|[2512.07155](http://arxiv.org/abs/2512.07155)|**[link](https://cmlab-korea.github.io/CHIMERA/)**|
|**2025-12-08**|**Think-Reflect-Revise: A Policy-Guided Reflective Framework for Safety Alignment in Large Vision Language Models**|Wenjie Wang Team|[2512.07141](http://arxiv.org/abs/2512.07141)|null|
|**2025-12-08**|**A Large-Scale Multimodal Dataset and Benchmarks for Human Activity Scene Understanding and Reasoning**|Guoliang Xing Team|[2512.07136](http://arxiv.org/abs/2512.07136)|null|
|**2025-12-08**|**TrajMoE: Scene-Adaptive Trajectory Planning with Mixture of Experts and Reinforcement Learning**|Dongbin Zhao Team|[2512.07135](http://arxiv.org/abs/2512.07135)|null|
|**2025-12-08**|**DART: Leveraging Multi-Agent Disagreement for Tool Recruitment in Multimodal Reasoning**|Mohit Bansal Team|[2512.07132](http://arxiv.org/abs/2512.07132)|**[link](https://github.com/nsivaku/dart)**|
|**2025-12-08**|**MulCLIP: A Multi-level Alignment Framework for Enhancing Fine-grained Long-context CLIP**|Dung D. Le Team|[2512.07128](http://arxiv.org/abs/2512.07128)|null|
|**2025-12-08**|**Surrogate compliance modeling enables reinforcement learned locomotion gaits for soft robots**|Rebecca Kramer-Bottiglio Team|[2512.07114](http://arxiv.org/abs/2512.07114)|null|
|**2025-12-08**|**COREA: Coarse-to-Fine 3D Representation Alignment Between Relightable 3D Gaussians and SDF via Bidirectional 3D-to-3D Supervision**|Jongwon Choi Team|[2512.07107](http://arxiv.org/abs/2512.07107)|**[link](https://cau-vilab.github.io/COREA/)**|
|**2025-12-08**|**DFIR-DETR: Frequency Domain Enhancement and Dynamic Feature Aggregation for Cross-Scene Small Object Detection**|Zichen Li Team|[2512.07078](http://arxiv.org/abs/2512.07078)|null|
|**2025-12-07**|**RAVE: Rate-Adaptive Visual Encoding for 3D Gaussian Splatting**|Enzo Tartaglione Team|[2512.07052](http://arxiv.org/abs/2512.07052)|null|
|**2025-12-07**|**CERNet: Class-Embedding Predictive-Coding RNN for Unified Robot Motion, Recognition, and Confidence Estimation**|Mathias Quoy Team|[2512.07041](http://arxiv.org/abs/2512.07041)|null|
|**2025-12-07**|**Power of Boundary and Reflection: Semantic Transparent Object Segmentation using Pyramid Vision Transformer with Transparent Cues**|Sai-Kit Yeung Team|[2512.07034](http://arxiv.org/abs/2512.07034)|null|
|**2025-12-07**|**A Hetero-Associative Sequential Memory Model Utilizing Neuromorphic Signals: Validated on a Mobile Manipulator**|Gordon Cheng Team|[2512.07032](http://arxiv.org/abs/2512.07032)|null|
|**2025-12-07**|**Utilizing Multi-Agent Reinforcement Learning with Encoder-Decoder Architecture Agents to Identify Optimal Resection Location in Glioblastoma Multiforme Patients**|Paras Goel Team|[2512.06990](http://arxiv.org/abs/2512.06990)|null|
|**2025-12-07**|**LLM-Driven Composite Neural Architecture Search for Multi-Source RL State Encoding**|Li Jin Team|[2512.06982](http://arxiv.org/abs/2512.06982)|null|
|**2025-12-07**|**Selective Masking based Self-Supervised Learning for Image Semantic Segmentation**|Ian Stavness Team|[2512.06981](http://arxiv.org/abs/2512.06981)|null|
|**2025-12-07**|**Neuro-Vesicles: Neuromodulation Should Be a Dynamical System, Not a Tensor Decoration**|Vicki Kane Team|[2512.06966](http://arxiv.org/abs/2512.06966)|null|
|**2025-12-07**|**VideoVLA: Video Generators Can Be Generalizable Robot Manipulators**|Baining Guo Team|[2512.06963](http://arxiv.org/abs/2512.06963)|**[link](https://videovla-nips2025.github.io)**|
|**2025-12-07**|**Statistical analysis of Inverse Entropy-regularized Reinforcement Learning**|Sergey Samsonov Team|[2512.06956](http://arxiv.org/abs/2512.06956)|null|
|**2025-12-07**|**Task adaptation of Vision-Language-Action model: 1st Place Solution for the 2025 BEHAVIOR Challenge**|Akash Karnatak Team|[2512.06951](http://arxiv.org/abs/2512.06951)|null|
|**2025-12-07**|**Can We Go Beyond Visual Features? Neural Tissue Relation Modeling for Relational Graph Analysis in Non-Melanoma Skin Histology**|Jia Wu Team|[2512.06949](http://arxiv.org/abs/2512.06949)|null|
|**2025-12-07**|**ExPUFFIN: Thermodynamic Consistent Viscosity Prediction in an Extended Path-Unifying Feed-Forward Interfaced Network**|Idelfonso B. R. Nogueira Team|[2512.06927](http://arxiv.org/abs/2512.06927)|null|
|**2025-12-07**|**Deep Reinforcement Learning for Phishing Detection with Transformer-Based Semantic Features**|Aseer Al Faisal Team|[2512.06925](http://arxiv.org/abs/2512.06925)|null|
|**2025-12-07**|**Parent-Guided Semantic Reward Model (PGSRM): Embedding-Based Reward Functions for Reinforcement Learning of Transformer Language Models**|Alexandr Plashchinsky Team|[2512.06920](http://arxiv.org/abs/2512.06920)|null|
|**2025-12-07**|**Know your Trajectory -- Trustworthy Reinforcement Learning deployment through Importance-Based Trajectory Analysis**|Balaraman Ravindran Team|[2512.06917](http://arxiv.org/abs/2512.06917)|null|
|**2025-12-07**|**SoK: Trust-Authorization Mismatch in LLM Agent Interactions**|Zhenyu Guan Team|[2512.06914](http://arxiv.org/abs/2512.06914)|null|
|**2025-12-07**|**Khalasi: Energy-Efficient Navigation for Surface Vehicles in Vortical Flow Fields**|Sandeep Manjanna Team|[2512.06912](http://arxiv.org/abs/2512.06912)|null|
|**2025-12-07**|**Scaling Zero-Shot Reference-to-Video Generation**|Sen He Team|[2512.06905](http://arxiv.org/abs/2512.06905)|**[link](https://franciszzj.github.io/Saber/)**|
|**2025-12-07**|**Balanced Learning for Domain Adaptive Semantic Segmentation**|Tianzhu Zhang Team|[2512.06886](http://arxiv.org/abs/2512.06886)|null|
|**2025-12-07**|**Structural and Disentangled Adaptation of Large Vision Language Models for Multimodal Recommendation**|Nan Tang Team|[2512.06883](http://arxiv.org/abs/2512.06883)|null|
|**2025-12-07**|**Hierarchical Image-Guided 3D Point Cloud Segmentation in Industrial Scenes via Multi-View Bayesian Fusion**|Koichi Hashimoto Team|[2512.06882](http://arxiv.org/abs/2512.06882)|null|
|**2025-12-07**|**An Analysis of Large Language Models for Simulating User Responses in Surveys**|Hongyi Wen Team|[2512.06874](http://arxiv.org/abs/2512.06874)|null|
|**2025-12-07**|**Towards Robust Pseudo-Label Learning in Semantic Segmentation: An Encoding Perspective**|Tianzhu Zhang Team|[2512.06870](http://arxiv.org/abs/2512.06870)|null|
|**2025-12-07**|**Spatial Retrieval Augmented Autonomous Driving**|Yu-Gang Jiang Team|[2512.06865](http://arxiv.org/abs/2512.06865)|**[link](https://spatialretrievalad.github.io/)**|
|**2025-12-07**|**Boosting Unsupervised Video Instance Segmentation with Automatic Quality-Guided Self-Training**|Dim P. Papadopoulos Team|[2512.06864](http://arxiv.org/abs/2512.06864)|null|
|**2025-12-07**|**JT-DA: Enhancing Data Analysis with Tool-Integrated Table Reasoning Large Language Models**|Junlan Feng Team|[2512.06859](http://arxiv.org/abs/2512.06859)|null|
|**2025-12-07**|**CKG-LLM: LLM-Assisted Detection of Smart Contract Access Control Vulnerabilities Based on Knowledge Graphs**|Shipeng Ye Team|[2512.06846](http://arxiv.org/abs/2512.06846)|null|
|**2025-12-07**|**Pseudo Anomalies Are All You Need: Diffusion-Based Generation for Weakly-Supervised Video Anomaly Detection**|Mori Kurokawa Team|[2512.06845](http://arxiv.org/abs/2512.06845)|null|
|**2025-12-07**|**Decouple to Generalize: Context-First Self-Evolving Learning for Data-Scarce Vision-Language Reasoning**|Cheng Tan Team|[2512.06835](http://arxiv.org/abs/2512.06835)|null|
|**2025-12-07**|**MeshSplatting: Differentiable Rendering with Opaque Meshes**|Andrea Tagliasacchi Team|[2512.06818](http://arxiv.org/abs/2512.06818)|null|
|**2025-12-07**|**RMAdapter: Reconstruction-based Multi-Modal Adapter for Vision-Language Models**|Di Huang Team|[2512.06811](http://arxiv.org/abs/2512.06811)|null|
|**2025-12-07**|**MMDuet2: Enhancing Proactive Interaction of Video MLLMs with Multi-Turn Reinforcement Learning**|Dongyan Zhao Team|[2512.06810](http://arxiv.org/abs/2512.06810)|null|
|**2025-12-07**|**db-LaCAM: Fast and Scalable Multi-Robot Kinodynamic Motion Planning with Discontinuity-Bounded Search and Lightweight MAPF**|Wolfgang Hönig Team|[2512.06796](http://arxiv.org/abs/2512.06796)|null|
|**2025-12-07**|**Measuring Over-smoothing beyond Dirichlet energy**|Zihao Shi Team|[2512.06782](http://arxiv.org/abs/2512.06782)|null|
|**2025-12-07**|**Crystallographic Texture-Generalizable Orientation-Aware Interaction-Based Deep Material Network for Polycrystal Modeling and Texture Evolution**|Chuin-Shan Chen Team|[2512.06779](http://arxiv.org/abs/2512.06779)|null|
|**2025-12-07**|**RDSplat: Robust Watermarking Against Diffusion Editing for 3D Gaussian Splatting**|Tongliang Liu Team|[2512.06774](http://arxiv.org/abs/2512.06774)|null|
|**2025-12-07**|**Stitch and Tell: A Structured Multimodal Data Augmentation Method for Spatial Understanding**|Kan Li Team|[2512.06769](http://arxiv.org/abs/2512.06769)|null|
|**2025-12-07**|**VisChainBench: A Benchmark for Multi-Turn, Multi-Image Visual Reasoning Beyond Language Priors**|Ling Shao Team|[2512.06759](http://arxiv.org/abs/2512.06759)|null|
|**2025-12-07**|**Multi-Scale Protein Structure Modelling with Geometric Graph U-Nets**|Chaitanya K. Joshi Team|[2512.06752](http://arxiv.org/abs/2512.06752)|**[link](https://github.com/VirtualProteins/GNN_UNet)**|
|**2025-12-07**|**UARE: A Unified Vision-Language Model for Image Quality Assessment, Restoration, and Enhancement**|Shijie Zhao Team|[2512.06750](http://arxiv.org/abs/2512.06750)|null|
|**2025-12-07**|**PrivLLMSwarm: Privacy-Preserving LLM-Driven UAV Swarms for Secure IoT Surveillance**|Huang Qiming Team|[2512.06747](http://arxiv.org/abs/2512.06747)|null|
|**2025-12-07**|**Task-Model Alignment: A Simple Path to Generalizable AI-Generated Image Detection**|Shouhong Ding Team|[2512.06746](http://arxiv.org/abs/2512.06746)|null|
|**2025-12-07**|**The Role of Entropy in Visual Grounding: Analysis and Optimization**|Xuanjing Huang Team|[2512.06726](http://arxiv.org/abs/2512.06726)|null|
|**2025-12-07**|**Learning Thermoelectric Transport from Crystal Structures via Multiscale Graph Neural Network**|Jing Shi Team|[2512.06697](http://arxiv.org/abs/2512.06697)|null|
|**2025-12-07**|**EMGauss: Continuous Slice-to-3D Reconstruction via Dynamic Gaussian Modeling in Volume Electron Microscopy**|Xiaokang Yang Team|[2512.06684](http://arxiv.org/abs/2512.06684)|null|
|**2025-12-07**|**Learning-based Link Prediction Methods Integrating Network Topological Features and Embedding Representations**|Ke-Ke Shang Team|[2512.06677](http://arxiv.org/abs/2512.06677)|null|
|**2025-12-07**|**FedDSR: Federated Deep Supervision and Regularization Towards Autonomous Driving**|Jianping Wang Team|[2512.06676](http://arxiv.org/abs/2512.06676)|null|
|**2025-12-07**|**RunawayEvil: Jailbreaking the Image-to-Video Generative Models**|Caifeng Shan Team|[2512.06674](http://arxiv.org/abs/2512.06674)|null|
|**2025-12-07**|**Statistic-Augmented, Decoupled MoE Routing and Aggregating in Autonomous Driving**|Jianping Wang Team|[2512.06664](http://arxiv.org/abs/2512.06664)|null|
|**2025-12-07**|**CoT4Det: A Chain-of-Thought Framework for Perception-Oriented Vision-Language Tasks**|Jingdong Wang Team|[2512.06663](http://arxiv.org/abs/2512.06663)|null|
|**2025-12-07**|**Personalized Image Descriptions from Attention Sequences**|Dimitris Samaras Team|[2512.06662](http://arxiv.org/abs/2512.06662)|null|
|**2025-12-07**|**LightSearcher: Efficient DeepSearch via Experiential Memory**|Ting Bai Team|[2512.06653](http://arxiv.org/abs/2512.06653)|null|
|**2025-12-07**|**Analyzing Collision Rates in Large-Scale Mixed Traffic Control via Multi-Agent Reinforcement Learning**|Muyang Fan Team|[2512.06645](http://arxiv.org/abs/2512.06645)|null|
|**2025-12-07**|**Learning to Hedge Swaptions**|Frédéric Godin Team|[2512.06639](http://arxiv.org/abs/2512.06639)|null|
|**2025-12-07**|**The Impact of Data Characteristics on GNN Evaluation for Detecting Fake News**|David Jensen Team|[2512.06638](http://arxiv.org/abs/2512.06638)|null|
|**2025-12-07**|**FEALPy v3: A Cross-platform Intelligent Numerical Simulation Engine**|Liang He Team|[2512.06632](http://arxiv.org/abs/2512.06632)|null|
|**2025-12-07**|**MIND-V: Hierarchical Video Generation for Long-Horizon Robotic Manipulation with RL-based Physical Alignment**|Xiu Li Team|[2512.06628](http://arxiv.org/abs/2512.06628)|null|
|**2025-12-07**|**A New Trajectory-Oriented Approach to Enhancing Comprehensive Crowd Navigation Performance**|Liguo Chen Team|[2512.06608](http://arxiv.org/abs/2512.06608)|null|
|**2025-12-06**|**Learning Reachability of Energy Storage Arbitrage**|Yury Dvorkin Team|[2512.06600](http://arxiv.org/abs/2512.06600)|null|
|**2025-12-06**|**MedGRPO: Multi-Task Reinforcement Learning for Heterogeneous Medical Video Understanding**|Ziyan Wu Team|[2512.06581](http://arxiv.org/abs/2512.06581)|null|
|**2025-12-06**|**General Computation using Slidable Tiles with Deterministic Global Forces**|Tim Wylie Team|[2512.06574](http://arxiv.org/abs/2512.06574)|null|
|**2025-12-06**|**Learning Agile Striker Skills for Humanoid Soccer Robots from Noisy Sensory Input**|Peter Stone Team|[2512.06571](http://arxiv.org/abs/2512.06571)|null|
|**2025-12-06**|**Generic visuality of war? How image-generative AI models (mis)represent Russia's war against Ukraine**|Miglė Bareikytė Team|[2512.06570](http://arxiv.org/abs/2512.06570)|null|
|**2025-12-06**|**A-3PO: Accelerating Asynchronous LLM Training with Staleness-aware Proximal Policy Approximation**|Zheng Shen Team|[2512.06547](http://arxiv.org/abs/2512.06547)|null|
|**2025-12-06**|**Beyond Token-level Supervision: Unlocking the Potential of Decoding-based Regression via Reinforcement Learning**|Chao Qian Team|[2512.06533](http://arxiv.org/abs/2512.06533)|null|
|**2025-12-06**|**TacFinRay: Soft Tactile Fin-Ray Finger with Indirect Tactile Sensing for Robust Grasping**|Nathan F. Lepora Team|[2512.06524](http://arxiv.org/abs/2512.06524)|null|
|**2025-12-06**|**Hierarchical geometric deep learning enables scalable analysis of molecular dynamics**|Aaron R. Dinner Team|[2512.06520](http://arxiv.org/abs/2512.06520)|null|
|**2025-12-06**|**Vision-Guided Grasp Planning for Prosthetic Hands in Unstructured Environments**|Simon Bøgh Team|[2512.06517](http://arxiv.org/abs/2512.06517)|null|
|**2025-12-06**|**Entropy-Controlled Intrinsic Motivation Reinforcement Learning for Quadruped Robot Locomotion in Complex Terrains**|Xiaoqing Zhu Team|[2512.06486](http://arxiv.org/abs/2512.06486)|null|
|**2025-12-06**|**Why Goal-Conditioned Reinforcement Learning Works: Relation to Dual Control**|Ali Mesbah Team|[2512.06471](http://arxiv.org/abs/2512.06471)|null|
|**2025-12-06**|**Neural expressiveness for beyond importance model compression**|Sotirios Xydis Team|[2512.06440](http://arxiv.org/abs/2512.06440)|null|
|**2025-12-06**|**AGORA: Adversarial Generation Of Real-time Animatable 3D Gaussian Head Avatars**|Ivan Laptev Team|[2512.06438](http://arxiv.org/abs/2512.06438)|null|
|**2025-12-06**|**Hankel-FNO: Fast Underwater Acoustic Charting Via Physics-Encoded Fourier Neural Operator**|Peter Gerstoft Team|[2512.06417](http://arxiv.org/abs/2512.06417)|null|
|**2025-12-06**|**GENIUS: An Agentic AI Framework for Autonomous Design and Execution of Simulation Protocols**|Celso Ricardo Caldeira Rêgo Team|[2512.06404](http://arxiv.org/abs/2512.06404)|null|
|**2025-12-06**|**Enhancing Information Retrieval in Digital Libraries through Unit Harmonisation in Scholarly Knowledge Graphs**|Sören Auer Team|[2512.06395](http://arxiv.org/abs/2512.06395)|null|
|**2025-12-06**|**RLAX: Large-Scale, Distributed Reinforcement Learning for Large Language Models on TPUs**|Cheng Leong Team|[2512.06392](http://arxiv.org/abs/2512.06392)|null|
|**2025-12-06**|**Beyond Model Jailbreak: Systematic Dissection of the "Ten DeadlySins" in Embodied Intelligence**|Xiuzhen Cheng Team|[2512.06387](http://arxiv.org/abs/2512.06387)|null|
|**2025-12-06**|**Are AI-Generated Driving Videos Ready for Autonomous Driving? A Diagnostic Evaluation Framework**|Jiawei Zhang Team|[2512.06376](http://arxiv.org/abs/2512.06376)|null|
|**2025-12-06**|**VG-Refiner: Towards Tool-Refined Referring Grounded Reasoning via Agentic Reinforcement Learning**|Yansong Tang Team|[2512.06373](http://arxiv.org/abs/2512.06373)|**[link](https://github.com/VoyageWang/VG-Refiner))**|
|**2025-12-06**|**DDFI: Diverse and Distribution-aware Missing Feature Imputation via Two-step Reconstruction**|Jing Tang Team|[2512.06356](http://arxiv.org/abs/2512.06356)|null|
|**2025-12-06**|**TreeQ: Pushing the Quantization Boundary of Diffusion Transformer via Tree-Structured Mixed-Precision Search**|Yulun Zhang Team|[2512.06353](http://arxiv.org/abs/2512.06353)|**[link](https://github.com/racoonykc/TreeQ)**|
|**2025-12-06**|**LLM-Upgraded Graph Reinforcement Learning for Carbon-Aware Job Scheduling in Smart Manufacturing**|Boon Ping Gan Team|[2512.06351](http://arxiv.org/abs/2512.06351)|null|
|**2025-12-06**|**Stabilizing Rate of Stochastic Control Systems**|Guangchen Wang Team|[2512.06349](http://arxiv.org/abs/2512.06349)|null|
|**2025-12-06**|**ReCAD: Reinforcement Learning Enhanced Parametric CAD Model Generation with Vision-Language Models**|Xiangdong Zhou Team|[2512.06328](http://arxiv.org/abs/2512.06328)|null|
|**2025-12-06**|**Exploiting Spatiotemporal Properties for Efficient Event-Driven Human Pose Estimation**|Weidong Cai Team|[2512.06306](http://arxiv.org/abs/2512.06306)|null|
|**2025-12-06**|**Multimodal Graph Neural Networks for Prognostic Modeling of Brain Network Reorganization**|Shrey Kumar Team|[2512.06303](http://arxiv.org/abs/2512.06303)|null|
|**2025-12-06**|**How Sharp and Bias-Robust is a Model? Dual Evaluation Perspectives on Knowledge Graph Completion**|Yunyong Ko Team|[2512.06296](http://arxiv.org/abs/2512.06296)|null|
|**2025-12-06**|**A Hybrid Physics-Based and Reinforcement Learning Framework for Electric Vehicle Charging Time Prediction**|Andreas A. Malikopoulos Team|[2512.06287](http://arxiv.org/abs/2512.06287)|null|
|**2025-12-06**|**Networked Restless Multi-Arm Bandits with Reinforcement Learning**|Kai Wang Team|[2512.06274](http://arxiv.org/abs/2512.06274)|null|
|**2025-12-06**|**TriaGS: Differentiable Triangulation-Guided Geometric Consistency for 3D Gaussian Splatting**|Tuan Dang Team|[2512.06269](http://arxiv.org/abs/2512.06269)|null|
|**2025-12-06**|**Nanbeige4-3B Technical Report: Exploring the Frontier of Small Language Models**|Zongchao Chen Team|[2512.06266](http://arxiv.org/abs/2512.06266)|null|
|**2025-12-06**|**Knowing the Answer Isn't Enough: Fixing Reasoning Path Failures in LVLMs**|Huaxiu Yao Team|[2512.06258](http://arxiv.org/abs/2512.06258)|null|
|**2025-12-06**|**Language-driven Fine-grained Retrieval**|Zi Huang Team|[2512.06255](http://arxiv.org/abs/2512.06255)|null|
|**2025-12-06**|**Learning Without Time-Based Embodiment Resets in Soft-Actor Critic**|A. Rupam Mahmood Team|[2512.06252](http://arxiv.org/abs/2512.06252)|null|
|**2025-12-06**|**NexusFlow: Unifying Disparate Tasks under Partial Supervision via Invertible Flow Networks**|Ziming Zhang Team|[2512.06251](http://arxiv.org/abs/2512.06251)|null|
|**2025-12-06**|**Learning When to Switch: Adaptive Policy Selection via Reinforcement Learning**|Chris Tava Team|[2512.06250](http://arxiv.org/abs/2512.06250)|null|
|**2025-12-06**|**Auto-exploration for online reinforcement learning**|Guanghui Lan Team|[2512.06244](http://arxiv.org/abs/2512.06244)|null|
|**2025-12-06**|**Quantization Blindspots: How Model Compression Breaks Backdoor Defenses**|Eric Ye Team|[2512.06243](http://arxiv.org/abs/2512.06243)|null|
|**2025-12-06**|**AI Application in Anti-Money Laundering for Sustainable and Transparent Financial Systems**|Chao Wang Team|[2512.06240](http://arxiv.org/abs/2512.06240)|null|
|**2025-12-06**|**Empowering GNNs for Domain Adaptation via Denoising Target Graph**|Christos Faloutsos Team|[2512.06236](http://arxiv.org/abs/2512.06236)|null|
|**2025-12-05**|**Average-reward reinforcement learning in semi-Markov decision processes via relative value iteration**|Richard S. Sutton Team|[2512.06218](http://arxiv.org/abs/2512.06218)|null|
|**2025-12-05**|**Quantifying Memory Use in Reinforcement Learning with Temporal Range**|T. Konstantin Rusch Team|[2512.06204](http://arxiv.org/abs/2512.06204)|null|
|**2025-12-05**|**REWW-ARM -- Remote Wire-Driven Mobile Robot: Design, Control, and Experimental Validation**|Kei Okada Team|[2512.06192](http://arxiv.org/abs/2512.06192)|null|
|**2025-12-05**|**Physics-Grounded Attached Shadow Detection Using Approximate 3D Geometry and Light Direction**|Hieu Le Team|[2512.06179](http://arxiv.org/abs/2512.06179)|null|
|**2025-12-05**|**Tracking-Guided 4D Generation: Foundation-Tracker Motion Priors for 3D Model Animation**|Mei Chen Team|[2512.06158](http://arxiv.org/abs/2512.06158)|null|
|**2025-12-05**|**WAM-Flow: Parallel Coarse-to-Fine Motion Planning via Discrete Flow Matching for Autonomous Driving**|Siyu Zhu Team|[2512.06112](http://arxiv.org/abs/2512.06112)|**[link](https://github.com/fudan-generative-vision/WAM-Flow)**|
|**2025-12-05**|**JaxWildfire: A GPU-Accelerated Wildfire Simulator for Reinforcement Learning**|Nick Hawes Team|[2512.06102](http://arxiv.org/abs/2512.06102)|null|
|**2025-12-05**|**Empathy by Design: Aligning Large Language Models for Healthcare Dialogue**|Aritran Piplai Team|[2512.06097](http://arxiv.org/abs/2512.06097)|null|
|**2025-12-05**|**BeLLA: End-to-End Birds Eye View Large Language Assistant for Autonomous Driving**|Amit Arvind Kale Team|[2512.06096](http://arxiv.org/abs/2512.06096)|null|
|**2025-12-05**|**Comparative Analysis of Autonomous and Systematic Control Strategies for Hole-Doped Hubbard Clusters: Reinforcement Learning versus Physics-Guided Design**|Kalum Palandage Team|[2512.06095](http://arxiv.org/abs/2512.06095)|null|
|**2025-12-05**|**Shoot-Bounce-3D: Single-Shot Occlusion-Aware 3D from Lidar by Decomposing Two-Bounce Light**|Rakesh Ranjan Team|[2512.06080](http://arxiv.org/abs/2512.06080)|**[link](https://shoot-bounce-3d.github.io)**|
|**2025-12-05**|**Reinforcement Learning Integrated Agentic RAG for Software Test Cases Authoring**|Mohanakrishnan Hariharan Team|[2512.06060](http://arxiv.org/abs/2512.06060)|null|
|**2025-12-05**|**Representation Learning for Point Cloud Understanding**|Siming Yan Team|[2512.06058](http://arxiv.org/abs/2512.06058)|null|
|**2025-12-05**|**Beyond Prototyping: Autonomous, Enterprise-Grade Frontend Development from Pixel to Production via a Specialized Multi-Agent Framework**|Sajit Vijayakumar Team|[2512.06046](http://arxiv.org/abs/2512.06046)|null|
|**2025-12-04**|**DreamFoley: Scalable VLMs for High-Fidelity Video-to-Audio Generation**|Dongliang He Team|[2512.06022](http://arxiv.org/abs/2512.06022)|null|
|**2025-12-04**|**PrefGen: Multimodal Preference Learning for Preference-Conditioned Image Generation**|Dimitris N. Metaxas Team|[2512.06020](http://arxiv.org/abs/2512.06020)|**[link](https://prefgen.github.io/}{\texttt{https://prefgen.github.io}})**|
|**2025-12-03**|**Training-Free Robot Pose Estimation using Off-the-Shelf Foundational Models**|Laurence Liang Team|[2512.06017](http://arxiv.org/abs/2512.06017)|null|
|**2025-12-03**|**VAT: Vision Action Transformer by Unlocking Full Representation of ViT**|Weixin Mao Team|[2512.06013](http://arxiv.org/abs/2512.06013)|null|
|**2025-12-03**|**Fast and Flexible Robustness Certificates for Semantic Segmentation**|Mathieu Serrurier Team|[2512.06010](http://arxiv.org/abs/2512.06010)|null|
|**2025-12-05**|**EditThinker: Unlocking Iterative Reasoning for Any Image Editor**|Si Liu Team|[2512.05965](http://arxiv.org/abs/2512.05965)|**[link](https://appletea233.github.io/think-while-edit)**|
|**2025-12-05**|**Training-Time Action Conditioning for Efficient Real-Time Chunking**|Sergey Levine Team|[2512.05964](http://arxiv.org/abs/2512.05964)|null|
|**2025-12-05**|**Whatever Remains Must Be True: Filtering Drives Reasoning in LLMs, Shaping Diversity**|Marc Dymetman Team|[2512.05962](http://arxiv.org/abs/2512.05962)|null|
|**2025-12-05**|**M4-RAG: A Massive-Scale Multilingual Multi-Cultural Multimodal RAG**|Genta Indra Winata Team|[2512.05959](http://arxiv.org/abs/2512.05959)|null|
|**2025-12-05**|**SIMPACT: Simulation-Enabled Action Planning using Vision-Language Models**|Yilun Du Team|[2512.05955](http://arxiv.org/abs/2512.05955)|null|
|**2025-12-05**|**Correspondence-Oriented Imitation Learning: Flexible Visuomotor Control with 3D Conditioning**|Kuan Fang Team|[2512.05953](http://arxiv.org/abs/2512.05953)|null|
|**2025-12-05**|**Variational Quantum Rainbow Deep Q-Network for Optimizing Resource Allocation Problem**|Hung Cao Team|[2512.05946](http://arxiv.org/abs/2512.05946)|null|
|**2025-12-05**|**TRACE: A Framework for Analyzing and Enhancing Stepwise Reasoning in Vision-Language Models**|Babak Damavandi Team|[2512.05943](http://arxiv.org/abs/2512.05943)|null|
|**2025-12-05**|**PRiSM: An Agentic Multimodal Benchmark for Scientific Reasoning via Python-Grounded Evaluation**|Babak Damavandi Team|[2512.05930](http://arxiv.org/abs/2512.05930)|null|
|**2025-12-05**|**World Models That Know When They Don't Know: Controllable Video Generation with Calibrated Uncertainty**|Anirudha Majumdar Team|[2512.05927](http://arxiv.org/abs/2512.05927)|null|
|**2025-12-05**|**LPD: Learnable Prototypes with Diversity Regularization for Weakly Supervised Histopathology Segmentation**|Hien Van Nguyen Team|[2512.05922](http://arxiv.org/abs/2512.05922)|null|
|**2025-12-05**|**Learning the Cosmic Web: Graph-based Classification of Simulated Galaxies by their Dark Matter Environments**|Ofer Lahav Team|[2512.05909](http://arxiv.org/abs/2512.05909)|null|
|**2025-12-05**|**Optimal Safety-Aware Scheduling for Multi-Agent Aerial 3D Printing with Utility Maximization under Dependency Constraints**|George Nikolakopoulos Team|[2512.05815](http://arxiv.org/abs/2512.05815)|null|
|**2025-12-05**|**Toward Efficient and Robust Behavior Models for Multi-Agent Driving Simulation**|Christoph Stiller Team|[2512.05812](http://arxiv.org/abs/2512.05812)|null|
|**2025-12-05**|**Probing the effectiveness of World Models for Spatial Reasoning through Test-time Scaling**|Sarath Chandar Team|[2512.05809](http://arxiv.org/abs/2512.05809)|null|
|**2025-12-05**|**Real-time Remote Tracking and Autonomous Planning for Whale Rendezvous using Robots**|Stephanie Gil Team|[2512.05808](http://arxiv.org/abs/2512.05808)|null|
|**2025-12-05**|**3D Path Planning for Robot-assisted Vertebroplasty from Arbitrary Bi-plane X-ray via Differentiable Rendering**|Mathias Unberath Team|[2512.05803](http://arxiv.org/abs/2512.05803)|null|
|**2025-12-05**|**Bring Your Dreams to Life: Continual Text-to-Video Customization**|Fahad Shahbaz Khan Team|[2512.05802](http://arxiv.org/abs/2512.05802)|null|
|**2025-12-05**|**Task-Specific Trust Evaluation for Multi-Hop Collaborator Selection via GNN-Aided Distributed Agentic AI**|Dusit Niyato Team|[2512.05788](http://arxiv.org/abs/2512.05788)|null|
|**2025-12-05**|**Curvature-Regularized Variational Autoencoder for 3D Scene Reconstruction from Sparse Depth**|Soodeh Bakhshandeh Team|[2512.05783](http://arxiv.org/abs/2512.05783)|null|
|**2025-12-05**|**Towards agent-based-model informed neural networks**|Nino Antulov-Fantulin Team|[2512.05764](http://arxiv.org/abs/2512.05764)|null|
|**2025-12-05**|**Label-Efficient Point Cloud Segmentation with Active Learning**|Wolfram Burgard Team|[2512.05759](http://arxiv.org/abs/2512.05759)|null|
|**2025-12-05**|**USV: Unified Sparsification for Accelerating Video Diffusion Models**|Qinglin Lu Team|[2512.05754](http://arxiv.org/abs/2512.05754)|null|
|**2025-12-05**|**A Fast Anti-Jamming Cognitive Radar Deployment Algorithm Based on Reinforcement Learning**|Tiande Guo Team|[2512.05753](http://arxiv.org/abs/2512.05753)|null|
|**2025-12-05**|**HQ-DM: Single Hadamard Transformation-Based Quantization-Aware Training for Low-Bit Diffusion Models**|Yi Kang Team|[2512.05746](http://arxiv.org/abs/2512.05746)|null|
|**2025-12-05**|**Distilling Expert Surgical Knowledge: How to train local surgical VLMs for anatomy explanation in Complete Mesocolic Excision**|Alexander Schlaefer Team|[2512.05740](http://arxiv.org/abs/2512.05740)|null|
|**2025-12-05**|**A High-Order Immersed Boundary Method for Fluid-Structure Interaction Problems**|Esteban Ferrer Team|[2512.05733](http://arxiv.org/abs/2512.05733)|null|
|**2025-12-05**|**Bayesian Active Inference for Intelligent UAV Anti-Jamming and Adaptive Trajectory Planning**|Carlo Regazzoni Team|[2512.05711](http://arxiv.org/abs/2512.05711)|null|
|**2025-12-05**|**Manifold-Aware Point Cloud Completion via Geodesic-Attentive Hierarchical Feature Learning**|Mingyu Fan Team|[2512.05710](http://arxiv.org/abs/2512.05710)|null|
|**2025-12-05**|**Evaluating Concept Filtering Defenses against Child Sexual Abuse Material Generation by Text-to-Image Models**|Carmela Troncoso Team|[2512.05707](http://arxiv.org/abs/2512.05707)|null|
|**2025-12-05**|**OWL: Unsupervised 3D Object Detection by Occupancy Guided Warm-up and Large Model Priors Reasoning**|Chenglu Wen Team|[2512.05698](http://arxiv.org/abs/2512.05698)|null|
|**2025-12-05**|**HiMoE-VLA: Hierarchical Mixture-of-Experts for Generalist Vision-Language-Action Policies**|Yu-Gang Jiang Team|[2512.05693](http://arxiv.org/abs/2512.05693)|null|
|**2025-12-05**|**LA-RL: Language Action-guided Reinforcement Learning with Safety Guarantees for Autonomous Highway Driving**|Chen Sun Team|[2512.05686](http://arxiv.org/abs/2512.05686)|null|
|**2025-12-05**|**Physics-Informed Graph Neural Network with Frequency-Aware Learning for Optical Aberration Correction**|Michael P. Pound Team|[2512.05683](http://arxiv.org/abs/2512.05683)|null|
|**2025-12-05**|**InverseCrafter: Efficient Video ReCapture as a Latent Domain Inverse Problem**|Jong Chul Ye Team|[2512.05672](http://arxiv.org/abs/2512.05672)|null|
|**2025-12-05**|**MedTutor-R1: Socratic Personalized Medical Teaching with Multi-Agent Simulation**|Yi R Fung Team|[2512.05671](http://arxiv.org/abs/2512.05671)|null|
|**2025-12-05**|**LeAD-M3D: Leveraging Asymmetric Distillation for Real-time Monocular 3D Detection**|Daniel Cremers Team|[2512.05663](http://arxiv.org/abs/2512.05663)|null|
|**2025-12-05**|**Bounded Graph Clustering with Graph Neural Networks**|Nicole Ludwig Team|[2512.05623](http://arxiv.org/abs/2512.05623)|null|
|**2025-12-05**|**DistillFSS: Synthesizing Few-Shot Knowledge into a Lightweight Segmentation Model**|Giovanna Castellano Team|[2512.05613](http://arxiv.org/abs/2512.05613)|null|
|**2025-12-05**|**NormalView: sensor-agnostic tree species classification from backpack and aerial lidar data using geometric projections**|Juha Hyyppä Team|[2512.05610](http://arxiv.org/abs/2512.05610)|null|
|**2025-12-05**|**An Integrated System for WEEE Sorting Employing X-ray Imaging, AI-based Object Detection and Segmentation, and Delta Robot Manipulation**|Panagiotis Chatzakos Team|[2512.05599](http://arxiv.org/abs/2512.05599)|null|
|**2025-12-05**|**Fast SceneScript: Accurate and Efficient Structured Language Model via Multi-Token Prediction**|Theo Gevers Team|[2512.05597](http://arxiv.org/abs/2512.05597)|null|
|**2025-12-05**|**Entropy Ratio Clipping as a Soft Global Constraint for Stable Reinforcement Learning**|Guorui Zhou Team|[2512.05591](http://arxiv.org/abs/2512.05591)|null|
|**2025-12-05**|**ProPhy: Progressive Physical Alignment for Dynamic World Simulation**|Xiaodan Liang Team|[2512.05564](http://arxiv.org/abs/2512.05564)|null|
|**2025-12-05**|**Conscious Gaze: Adaptive Attention Mechanisms for Hallucination Mitigation in Vision-Language Models**|Guixian Zhang Team|[2512.05546](http://arxiv.org/abs/2512.05546)|null|
|**2025-12-05**|**VOST-SGG: VLM-Aided One-Stage Spatio-Temporal Scene Graph Generation**|Basura Fernando Team|[2512.05524](http://arxiv.org/abs/2512.05524)|null|
|**2025-12-05**|**GRASP: Graph Reasoning Agents for Systems Pharmacology with Human-in-the-Loop**|Mohammad Jafarnejad Team|[2512.05502](http://arxiv.org/abs/2512.05502)|null|
|**2025-12-05**|**WaterWave: Bridging Underwater Image Enhancement into Video Streams via Wavelet-based Temporal Consistency Field**|Feng Zhao Team|[2512.05492](http://arxiv.org/abs/2512.05492)|null|
|**2025-12-05**|**Concept-based Explainable Data Mining with VLM for 3D Detection**|Mai Tsujimoto Team|[2512.05482](http://arxiv.org/abs/2512.05482)|**[link](https://github.com/mm1129/concept_based_rare_detector_2025)**|
|**2025-12-05**|**Distributed scalable coupled policy algorithm for networked multi-agent reinforcement learning**|Wei Ren Team|[2512.05447](http://arxiv.org/abs/2512.05447)|null|
|**2025-12-05**|**TED-4DGS: Temporally Activated and Embedding-based Deformation for 4DGS Compression**|Wen-Hsiao Peng Team|[2512.05446](http://arxiv.org/abs/2512.05446)|null|
|**2025-12-05**|**ParaUni: Enhance Generation in Unified Multimodal Model with Reinforcement-driven Hierarchical Parallel Information Interaction**|Feng Zhao Team|[2512.05422](http://arxiv.org/abs/2512.05422)|null|
|**2025-12-05**|**Moving object detection from multi-depth images with an attention-enhanced CNN**|Naoya Ozaki Team|[2512.05415](http://arxiv.org/abs/2512.05415)|null|
|**2025-12-05**|**YOLO and SGBM Integration for Autonomous Tree Branch Detection and Depth Estimation in Radiata Pine Pruning Applications**|Richard Green Team|[2512.05412](http://arxiv.org/abs/2512.05412)|null|
|**2025-12-05**|**The Dynamic Prior: Understanding 3D Structures for Casual Dynamic Videos**|Jun Gao Team|[2512.05398](http://arxiv.org/abs/2512.05398)|**[link](https://github.com/wuzy2115/DYNAPO)**|
|**2025-12-05**|**Delving into Latent Spectral Biasing of Video VAEs for Superior Diffusability**|Jie Tang Team|[2512.05394](http://arxiv.org/abs/2512.05394)|null|
|**2025-12-05**|**ChipMind: Retrieval-Augmented Reasoning for Long-Context Circuit Design Specifications**|Jun Yang Team|[2512.05371](http://arxiv.org/abs/2512.05371)|null|
|**2025-12-05**|**SplatPainter: Interactive Authoring of 3D Gaussians from 2D Edits via Test-Time Training**|Wang Yifan Team|[2512.05354](http://arxiv.org/abs/2512.05354)|**[link](https://y-zheng18.github.io/SplatPainter/)**|
|**2025-12-05**|**SpaceControl: Introducing Test-Time Spatial Control to 3D Generative Modeling**|Leonidas Guibas Team|[2512.05343](http://arxiv.org/abs/2512.05343)|**[link](https://spacecontrol3d.github.io/)**|
|**2025-12-05**|**State-Conditional Adversarial Learning: An Off-Policy Visual Domain Transfer Method for End-to-End Imitation Learning**|Shengfan Cao Team|[2512.05335](http://arxiv.org/abs/2512.05335)|null|
|**2025-12-04**|**Enhancing Deep Deterministic Policy Gradients on Continuous Control Tasks with Decoupled Prioritized Experience Replay**|Suleyman Serdar Kozat Team|[2512.05320](http://arxiv.org/abs/2512.05320)|null|
|**2025-12-04**|**WhatsCode: Large-Scale GenAI Deployment for Developer Efficiency at WhatsApp**|Aparup Banerjee Team|[2512.05314](http://arxiv.org/abs/2512.05314)|null|
|**2025-12-04**|**Bridging Interpretability and Optimization: Provably Attribution-Weighted Actor-Critic in Reproducing Kernel Hilbert Spaces**|Xinyu Li Team|[2512.05291](http://arxiv.org/abs/2512.05291)|null|
|**2025-12-04**|**Beyond Detection: A Comprehensive Benchmark and Study on Representation Learning for Fine-Grained Webshell Family Classification**|Feijiang Han Team|[2512.05288](http://arxiv.org/abs/2512.05288)|null|
|**2025-12-04**|**DMAGT: Unveiling miRNA-Drug Associations by Integrating SMILES and RNA Sequence Structures through Graph Transformer Models**|Ziqi Zhang Team|[2512.05287](http://arxiv.org/abs/2512.05287)|null|
|**2025-12-04**|**From Segments to Scenes: Temporal Understanding in Autonomous Driving via Vision-Language Model**|Mohammad Akbari Team|[2512.05277](http://arxiv.org/abs/2512.05277)|null|
|**2025-12-04**|**Enhancing Clinical Note Generation with ICD-10, Clinical Ontology Knowledge Graphs, and Chain-of-Thought Prompting Using GPT-4**|Yaohang Li Team|[2512.05256](http://arxiv.org/abs/2512.05256)|null|
|**2025-12-04**|**IE2Video: Adapting Pretrained Diffusion Models for Event-Based Video Reconstruction**|Yihui Ren Team|[2512.05240](http://arxiv.org/abs/2512.05240)|null|
|**2025-12-04**|**Edged Weisfeiler-Lehman Algorithm**|Guangzhi Qu Team|[2512.05238](http://arxiv.org/abs/2512.05238)|**[link](https://link.springer.com/chapter/10.1007/978-3-031-72344-5_7)**|
|**2025-12-04**|**Invariance Co-training for Robot Visual Generalization**|Dorsa Sadigh Team|[2512.05230](http://arxiv.org/abs/2512.05230)|null|
|**2025-12-04**|**Hierarchical Reinforcement Learning for the Dynamic VNE with Alternatives Problem**|Omran Ayoub Team|[2512.05207](http://arxiv.org/abs/2512.05207)|null|
|**2025-12-04**|**MuMeNet: A Network Simulator for Musical Metaverse Communications**|Omran Ayoub Team|[2512.05201](http://arxiv.org/abs/2512.05201)|null|
|**2025-12-04**|**Semore: VLM-guided Enhanced Semantic Motion Representations for Visual Reinforcement Learning**|Yan Wang Team|[2512.05172](http://arxiv.org/abs/2512.05172)|null|
|**2025-12-04**|**A Mutual Information-based Metric for Temporal Expressivity and Trainability Estimation in Quantum Policy Gradient Pipelines**|Kabgyun Jeong Team|[2512.05157](http://arxiv.org/abs/2512.05157)|null|
|**2025-12-03**|**EFDiT: Efficient Fine-grained Image Generation Using Diffusion Transformer Models**|Lei Fan Team|[2512.05152](http://arxiv.org/abs/2512.05152)|null|
|**2025-12-03**|**TwinFlow: Realizing One-step Generation on Large Models with Self-adversarial Flows**|Tao Lin Team|[2512.05150](http://arxiv.org/abs/2512.05150)|null|
|**2025-12-02**|**Self-Improving VLM Judges Without Human Annotations**|Marjan Ghazvininejad Team|[2512.05145](http://arxiv.org/abs/2512.05145)|null|
|**2025-12-04**|**Value Gradient Guidance for Flow Matching Alignment**|Dinghuai Zhang Team|[2512.05116](http://arxiv.org/abs/2512.05116)|null|
|**2025-12-04**|**Light-X: Generative 4D Video Rendering with Camera and Illumination Control**|Ziwei Liu Team|[2512.05115](http://arxiv.org/abs/2512.05115)|**[link](https://lightx-ai.github.io/)**|
|**2025-12-04**|**Splannequin: Freezing Monocular Mannequin-Challenge Footage with Dual-Detection Splatting**|Yu-Lun Liu Team|[2512.05113](http://arxiv.org/abs/2512.05113)|**[link](https://chien90190.github.io/splannequin/)**|
|**2025-12-04**|**DraCo: Draft as CoT for Text-to-Image Preview and Rare Concept Generation**|Hongsheng Li Team|[2512.05112](http://arxiv.org/abs/2512.05112)|**[link](https://github.com/CaraJ7/DraCo)**|
|**2025-12-04**|**ARM-Thinker: Reinforcing Multimodal Generative Reward Models with Agentic Tool Use and Visual Reasoning**|Jiaqi Wang Team|[2512.05111](http://arxiv.org/abs/2512.05111)|null|
|**2025-12-04**|**STARE-VLA: Progressive Stage-Aware Reinforcement for Fine-Tuning Vision-Language-Action Models**|Benjamin Busam Team|[2512.05107](http://arxiv.org/abs/2512.05107)|null|
|**2025-12-04**|**NeuralRemaster: Phase-Preserving Diffusion for Structure-Aligned Generation**|Rowan McAllister Team|[2512.05106](http://arxiv.org/abs/2512.05106)|null|
|**2025-12-04**|**Semantic Soft Bootstrapping: Long Context Reasoning in LLMs without Reinforcement Learning**|Sennur Ulukus Team|[2512.05105](http://arxiv.org/abs/2512.05105)|null|
|**2025-12-04**|**TV2TV: A Unified Framework for Interleaved Language and Video Generation**|Emily Dinan Team|[2512.05103](http://arxiv.org/abs/2512.05103)|null|
|**2025-12-04**|**Structured Document Translation via Format Reinforcement Learning**|Masao Utiyama Team|[2512.05100](http://arxiv.org/abs/2512.05100)|null|
|**2025-12-04**|**SA-IQA: Redefining Image Quality Assessment for Spatial Aesthetics with Multi-Dimensional Rewards**|Jin Song Team|[2512.05098](http://arxiv.org/abs/2512.05098)|null|
|**2025-12-04**|**From Generated Human Videos to Physically Plausible Robot Trajectories**|Roei Herzig Team|[2512.05094](http://arxiv.org/abs/2512.05094)|**[link](https://genmimic.github.io)**|
|**2025-12-04**|**Visual Reasoning Tracer: Object-Level Grounded Reasoning Benchmark**|Ming-Hsuan Yang Team|[2512.05091](http://arxiv.org/abs/2512.05091)|**[link](https://harboryuan.github.io/visual-reasoning-tracer)**|
|**2025-12-04**|**Deep Forcing: Training-Free Long Video Generation with Deep Sink and Participative Compression**|Seungryong Kim Team|[2512.05081](http://arxiv.org/abs/2512.05081)|**[link](https://cvlab-kaist.github.io/DeepForcing/)**|
|**2025-12-04**|**BulletTime: Decoupled Control of Time and Camera Pose for Video Generation**|Gordon Wetzstein Team|[2512.05076](http://arxiv.org/abs/2512.05076)|**[link](https://19reborn.github.io/Bullet4D/)**|
|**2025-12-04**|**4DLangVGGT: 4D Language-Visual Geometry Grounded Transformer**|Xinggang Wang Team|[2512.05060](http://arxiv.org/abs/2512.05060)|**[link](https://github.com/hustvl/4DLangVGGT)**|
|**2025-12-04**|**CNN on `Top': In Search of Scalable & Lightweight Image-based Jet Taggers**|Satyajit Roy Team|[2512.05031](http://arxiv.org/abs/2512.05031)|null|
|**2025-12-04**|**Generative Neural Video Compression via Video Diffusion Prior**|Siwei Ma Team|[2512.05016](http://arxiv.org/abs/2512.05016)|null|
|**2025-12-04**|**A dynamic memory assignment strategy for dilation-based ICP algorithm on embedded GPUs**|Jun Miyazaki Team|[2512.04996](http://arxiv.org/abs/2512.04996)|null|
|**2025-12-04**|**Nex-N1: Agentic Models Trained via a Unified Ecosystem for Large-Scale Environment Construction**|Xipeng Qiu Team|[2512.04987](http://arxiv.org/abs/2512.04987)|null|
|**2025-12-04**|**Aligned but Stereotypical? The Hidden Influence of System Prompts on Social Bias in LVLM-Based Text-to-Image Models**|Hyunjung Shim Team|[2512.04981](http://arxiv.org/abs/2512.04981)|**[link](https://fairpro-t2i.github.io)**|
|**2025-12-04**|**Preliminary Analysis and Simulation of a Compact Variable Stiffness Wrist**|Giorgio Grioli Team|[2512.04973](http://arxiv.org/abs/2512.04973)|**[link](https://doi.org/10.1007/978-3-031-64057-5_9)**|
|**2025-12-04**|**Environment-Aware Channel Inference via Cross-Modal Flow: From Multimodal Sensing to Wireless Channels**|Lajos Hanzo Team|[2512.04966](http://arxiv.org/abs/2512.04966)|null|
|**2025-12-04**|**GeoPE:A Unified Geometric Positional Embedding for Structured Tensors**|Bowen Yang Team|[2512.04963](http://arxiv.org/abs/2512.04963)|null|
|**2025-12-04**|**Hybrid-Diffusion Models: Combining Open-loop Routines with Visuomotor Diffusion Policies**|Danica Kragic Team|[2512.04960](http://arxiv.org/abs/2512.04960)|null|
|**2025-12-04**|**Realizable Abstractions: Near-Optimal Hierarchical Reinforcement Learning**|Matteo Leonetti Team|[2512.04958](http://arxiv.org/abs/2512.04958)|null|
|**2025-12-04**|**FASTer: Toward Efficient Autoregressive Vision Language Action Modeling via Neural Action Tokenization**|Hang Zhao Team|[2512.04952](http://arxiv.org/abs/2512.04952)|null|
|**2025-12-04**|**CARL: Critical Action Focused Reinforcement Learning for Multi-Step Agent**|Tat-Seng Chua Team|[2512.04949](http://arxiv.org/abs/2512.04949)|null|
|**2025-12-04**|**LiteVGGT: Boosting Vanilla VGGT via Geometry-aware Cached Token Merging**|Xiao-Xiao Long Team|[2512.04939](http://arxiv.org/abs/2512.04939)|null|
|**2025-12-04**|**Multi-Agent Reinforcement Learning for Intraday Operating Rooms Scheduling under Uncertainty**|Thorsten Koch Team|[2512.04918](http://arxiv.org/abs/2512.04918)|null|
|**2025-12-04**|**PVLS: A Learning-based Parameter Prediction Technique for Variational Quantum Linear Solvers**|Youla Yang Team|[2512.04909](http://arxiv.org/abs/2512.04909)|null|
|**2025-12-04**|**Chameleon: Adaptive Adversarial Agents for Scaling-Based Visual Prompt Injection in Multimodal AI Systems**|Saud Satti Team|[2512.04895](http://arxiv.org/abs/2512.04895)|null|
|**2025-12-04**|**You Only Train Once (YOTO): A Retraining-Free Object Detection Framework**|Farhan Muhammad Yasin Team|[2512.04888](http://arxiv.org/abs/2512.04888)|null|
|**2025-12-04**|**SEAL: Self-Evolving Agentic Learning for Conversational Question Answering over Knowledge Graphs**|Xinchi Li Team|[2512.04868](http://arxiv.org/abs/2512.04868)|null|
|**2025-12-04**|**Autoregressive Image Generation Needs Only a Few Lines of Cached Tokens**|Weiyao Lin Team|[2512.04857](http://arxiv.org/abs/2512.04857)|null|
|**2025-12-04**|**Safe model-based Reinforcement Learning via Model Predictive Control and Control Barrier Functions**|Azita Dabiri Team|[2512.04856](http://arxiv.org/abs/2512.04856)|null|
|**2025-12-04**|**Ask Safely: Privacy-Aware LLM Query Generation for Knowledge Graphs**|Jordi Cabot Team|[2512.04852](http://arxiv.org/abs/2512.04852)|null|
|**2025-12-04**|**FreeGen: Feed-Forward Reconstruction-Generation Co-Training for Free-Viewpoint Driving Scene Synthesis**|Peixi Peng Team|[2512.04830](http://arxiv.org/abs/2512.04830)|null|
|**2025-12-04**|**RobustSplat++: Decoupling Densification, Dynamics, and Illumination for In-the-Wild 3DGS**|Xiaochun Cao Team|[2512.04815](http://arxiv.org/abs/2512.04815)|null|
|**2025-12-04**|**MOVE: A Simple Motion-Based Data Collection Paradigm for Spatial Generalization in Robotic Manipulation**|Gao Huang Team|[2512.04813](http://arxiv.org/abs/2512.04813)|null|
|**2025-12-04**|**SIMA 2: A Generalist Embodied Agent for Virtual Worlds**|Zoubin Ghahramani Team|[2512.04797](http://arxiv.org/abs/2512.04797)|null|
|**2025-12-04**|**YingMusic-SVC: Real-World Robust Zero-Shot Singing Voice Conversion with Flow-GRPO and Singing-Specific Inductive Biases**|Zihao Chen Team|[2512.04793](http://arxiv.org/abs/2512.04793)|null|
|**2025-12-04**|**ASTRIDE: A Security Threat Modeling Platform for Agentic-AI Applications**|Nilaan Loganathan Team|[2512.04785](http://arxiv.org/abs/2512.04785)|null|
|**2025-12-02**|**PaCo-RL: Advancing Reinforcement Learning for Consistent Image Generation with Pairwise Reward Modeling**|Hangwei Qian Team|[2512.04784](http://arxiv.org/abs/2512.04784)|null|
|**2025-12-04**|**YingMusic-Singer: Zero-shot Singing Voice Synthesis and Editing with Annotation-free Melody Guidance**|Lei Xie Team|[2512.04779](http://arxiv.org/abs/2512.04779)|null|
|**2025-12-04**|**Using Machine Learning to Take Stay-or-Go Decisions in Data-driven Drone Missions**|Spyros Lalis Team|[2512.04773](http://arxiv.org/abs/2512.04773)|null|
|**2025-12-04**|**MemLoRA: Distilling Expert Adapters for On-Device Memory Systems**|Taha Ceritli Team|[2512.04763](http://arxiv.org/abs/2512.04763)|null|
|**2025-12-04**|**RLHFSpec: Breaking the Efficiency Bottleneck in RLHF Training via Adaptive Drafting**|Depei Qian Team|[2512.04752](http://arxiv.org/abs/2512.04752)|null|
|**2025-12-04**|**Neural Policy Composition from Free Energy Minimization**|Giovanni Russo Team|[2512.04745](http://arxiv.org/abs/2512.04745)|null|
|**2025-12-04**|**MT-Depth: Multi-task Instance feature analysis for the Depth Completion**|Xinhai Sun Team|[2512.04734](http://arxiv.org/abs/2512.04734)|null|
|**2025-12-04**|**E3AD: An Emotion-Aware Vision-Language-Action Model for Human-Centric End-to-End Autonomous Driving**|Chengzhong Xu Team|[2512.04733](http://arxiv.org/abs/2512.04733)|null|
|**2025-12-04**|**Bridging Simulation and Reality: Cross-Domain Transfer with Semantic 2D Gaussian Splatting**|Xuguang Lan Team|[2512.04731](http://arxiv.org/abs/2512.04731)|null|
|**2025-12-04**|**Measuring the Unspoken: A Disentanglement Model and Benchmark for Psychological Analysis in the Wild**|Jie Liu Team|[2512.04728](http://arxiv.org/abs/2512.04728)|null|
|**2025-12-04**|**Multi Task Denoiser Training for Solving Linear Inverse Problems**|François Pitié Team|[2512.04709](http://arxiv.org/abs/2512.04709)|null|
|**2025-12-04**|**Continuous-time reinforcement learning for optimal switching over multiple regimes**|Zhou Zhou Team|[2512.04697](http://arxiv.org/abs/2512.04697)|null|
|**2025-12-04**|**TRINITY: An Evolved LLM Coordinator**|Yujin Tang Team|[2512.04695](http://arxiv.org/abs/2512.04695)|null|
|**2025-12-04**|**Towards Ethical Multi-Agent Systems of Large Language Models: A Mechanistic Interpretability Perspective**|Stefano V. Albrecht Team|[2512.04691](http://arxiv.org/abs/2512.04691)|**[link](https://sites.google.com/view/lamas2026))**|
|**2025-12-04**|**Towards Cross-View Point Correspondence in Vision-Language Models**|Xiaolong Zheng Team|[2512.04686](http://arxiv.org/abs/2512.04686)|null|
|**2025-12-04**|**Reward Forcing: Efficient Streaming Video Generation with Rewarded Distribution Matching Distillation**|Min Zhang Team|[2512.04678](http://arxiv.org/abs/2512.04678)|null|
|**2025-12-04**|**Live Avatar: Streaming Real-time Audio-Driven Avatar Generation with Infinite Length**|Steven Hoi Team|[2512.04677](http://arxiv.org/abs/2512.04677)|null|
|**2025-12-04**|**Semi Centralized Training Decentralized Execution Architecture for Multi Agent Deep Reinforcement Learning in Traffic Signal Control**|Monireh Abdoos Team|[2512.04653](http://arxiv.org/abs/2512.04653)|null|
|**2025-12-04**|**Malicious Image Analysis via Vision-Language Segmentation Fusion: Detection, Element, and Location in One-shot**|Shuo Wang Team|[2512.04599](http://arxiv.org/abs/2512.04599)|null|
|**2025-12-04**|**When Robots Should Say "I Don't Know": Benchmarking Abstention in Embodied Question Answering**|Jianfei Yang Team|[2512.04597](http://arxiv.org/abs/2512.04597)|null|
|**2025-12-04**|**QoSDiff: An Implicit Topological Embedding Learning Framework Leveraging Denoising Diffusion and Adversarial Attention for Robust QoS Prediction**|Wei Wei Team|[2512.04596](http://arxiv.org/abs/2512.04596)|null|
|**2025-12-04**|**CryptoTensors: A Light-Weight Large Language Model File Format for Highly-Secure Model Distribution**|Yier Jin Team|[2512.04580](http://arxiv.org/abs/2512.04580)|null|
|**2025-12-04**|**Gauss-Newton accelerated MPPI Control**|Johannes Reuter Team|[2512.04579](http://arxiv.org/abs/2512.04579)|null|
|**2025-12-04**|**COOPER: A Unified Model for Cooperative Perception and Reasoning in Spatial Intelligence**|Tingwen Liu Team|[2512.04563](http://arxiv.org/abs/2512.04563)|null|
|**2025-12-04**|**Omniscient Attacker in Stochastic Security Games with Interdependent Nodes**|Muhammed O. Sayin Team|[2512.04561](http://arxiv.org/abs/2512.04561)|null|
|**2025-12-04**|**Diffusion Fine-Tuning via Reparameterized Policy Gradient of the Soft Q-Function**|Jinkyoo Park Team|[2512.04559](http://arxiv.org/abs/2512.04559)|null|
|**2025-12-04**|**RRPO: Robust Reward Policy Optimization for LLM-based Emotional TTS**|Ya Li Team|[2512.04552](http://arxiv.org/abs/2512.04552)|null|
|**2025-12-04**|**Gaussian Entropy Fields: Driving Adaptive Sparsity in 3D Gaussian Optimization**|Jianchen Liu Team|[2512.04542](http://arxiv.org/abs/2512.04542)|null|
|**2025-12-04**|**VideoMem: Enhancing Ultra-Long Video Understanding via Adaptive Memory Management**|Sijie Cheng Team|[2512.04540](http://arxiv.org/abs/2512.04540)|null|
|**2025-12-04**|**X-Humanoid: Robotize Human Videos to Generate Humanoid Videos at Scale**|Mike Zheng Shou Team|[2512.04537](http://arxiv.org/abs/2512.04537)|null|
|**2025-12-04**|**GTM: Simulating the World of Tools for AI Agents**|Jiyan He Team|[2512.04535](http://arxiv.org/abs/2512.04535)|null|
|**2025-12-04**|**VideoSSM: Autoregressive Long Video Generation with Hybrid State-Space Memory**|Xiaojuan Qi Team|[2512.04519](http://arxiv.org/abs/2512.04519)|null|
|**2025-12-04**|**EgoLCD: Egocentric Video Generation with Long Context Diffusion**|Hao Tang Team|[2512.04515](http://arxiv.org/abs/2512.04515)|null|
|**2025-12-04**|**BiTAgent: A Task-Aware Modular Framework for Bidirectional Coupling between Multimodal Large Language Models and World Models**|Wenwu Zhu Team|[2512.04513](http://arxiv.org/abs/2512.04513)|null|
|**2025-12-04**|**DuGI-MAE: Improving Infrared Mask Autoencoders via Dual-Domain Guidance**|Di Xu Team|[2512.04511](http://arxiv.org/abs/2512.04511)|null|
|**2025-12-04**|**Not All Birds Look The Same: Identity-Preserving Generation For Birds**|Subhransu Maji Team|[2512.04485](http://arxiv.org/abs/2512.04485)|null|
|**2025-12-04**|**DeRA: Decoupled Representation Alignment for Video Tokenization**|Zuxuan Wu Team|[2512.04483](http://arxiv.org/abs/2512.04483)|null|
|**2025-12-04**|**MARL Warehouse Robots**|Salmon Riaz Team|[2512.04463](http://arxiv.org/abs/2512.04463)|**[link](https://pallman14.github.io/MARL-QMIX-Warehouse-Robots/)**|
|**2025-12-04**|**dVLM-AD: Enhance Diffusion Vision-Language-Model for Driving via Controllable Reasoning**|Chaowei Xiao Team|[2512.04459](http://arxiv.org/abs/2512.04459)|null|
|**2025-12-04**|**Vision-Language-Action Models for Selective Robotic Disassembly: A Case Study on Critical Component Extraction from Desktops**|Minghui Zheng Team|[2512.04446](http://arxiv.org/abs/2512.04446)|null|
|**2025-12-04**|**MindDrive: An All-in-One Framework Bridging World Models and Vision-Language Model for End-to-End Autonomous Driving**|Ziying Song Team|[2512.04441](http://arxiv.org/abs/2512.04441)|null|
|**2025-12-04**|**Quantum-Accelerated Deep Reinforcement Learning for Frequency Regulation Enhancement**|Mert Korkali Team|[2512.04439](http://arxiv.org/abs/2512.04439)|null|
|**2025-12-04**|**UTrice: Unifying Primitives in Differentiable Ray Tracing and Rasterization via Triangles for Particle-Based 3D Scenes**|Manabu Tsukada Team|[2512.04421](http://arxiv.org/abs/2512.04421)|null|
|**2025-12-04**|**Dual-Stream Spectral Decoupling Distillation for Remote Sensing Object Detection**|Wentao Li Team|[2512.04413](http://arxiv.org/abs/2512.04413)|null|
|**2025-12-04**|**Towards 6G Native-AI Edge Networks: A Semantic-Aware and Agentic Intelligence Paradigm**|Xiaohu You Team|[2512.04405](http://arxiv.org/abs/2512.04405)|null|
|**2025-12-04**|**Development of a 15-Degree-of-Freedom Bionic Hand with Cable-Driven Transmission and Distributed Actuation**|Hesheng Wang Team|[2512.04399](http://arxiv.org/abs/2512.04399)|null|
|**2025-12-04**|**Fourier-Attentive Representation Learning: A Fourier-Guided Framework for Few-Shot Generalization in Vision-Language Models**|Cuong Tuan Nguyen Team|[2512.04395](http://arxiv.org/abs/2512.04395)|null|
|**2025-12-04**|**Learning to Orchestrate Agents in Natural Language with the Conductor**|Yujin Tang Team|[2512.04388](http://arxiv.org/abs/2512.04388)|null|
|**2025-12-04**|**FALCON: Actively Decoupled Visuomotor Policies for Loco-Manipulation with Foundation-Model-Based Coordination**|Guillaume Sartoretti Team|[2512.04381](http://arxiv.org/abs/2512.04381)|null|
|**2025-12-04**|**LangSAT: A Novel Framework Combining NLP and Reinforcement Learning for SAT Solving**|Mahfuza Farooque Team|[2512.04374](http://arxiv.org/abs/2512.04374)|null|
|**2025-12-04**|**AutoGuard: A Self-Healing Proactive Security Layer for DevSecOps Pipelines Using Reinforcement Learning**|Piyush Ranjan Team|[2512.04368](http://arxiv.org/abs/2512.04368)|null|
|**2025-12-04**|**Efficient Reinforcement Learning with Semantic and Token Entropy for LLM Reasoning**|Yang Gao Team|[2512.04359](http://arxiv.org/abs/2512.04359)|null|
|**2025-12-04**|**Long-Horizon Model-Based Offline Reinforcement Learning Without Conservatism**|Pierre-Luc Bacon Team|[2512.04341](http://arxiv.org/abs/2512.04341)|null|
|**2025-12-03**|**Data-regularized Reinforcement Learning for Diffusion Models at Scale**|Stefano Ermon Team|[2512.04332](http://arxiv.org/abs/2512.04332)|null|
|**2025-12-03**|**SyncTrack4D: Cross-Video Motion Alignment and Video Synchronization for Multi-Video 4D Gaussian Splatting**|Dinesh Manocha Team|[2512.04315](http://arxiv.org/abs/2512.04315)|null|
|**2025-12-03**|**Mind-to-Face: Neural-Driven Photorealistic Avatar Synthesis via EEG Decoding**|Yajie Zhao Team|[2512.04313](http://arxiv.org/abs/2512.04313)|null|
|**2025-12-03**|**Real-time Cricket Sorting By Sex**|Matthew Smith Team|[2512.04311](http://arxiv.org/abs/2512.04311)|null|
|**2025-12-03**|**ResponsibleRobotBench: Benchmarking Responsible Robot Manipulation using Multi-modal Large Language Models**|Jianwei Zhang Team|[2512.04308](http://arxiv.org/abs/2512.04308)|**[link](https://sites.google.com/view/responsible-robotbench)**|
|**2025-12-03**|**How (Mis)calibrated is Your Federated CLIP and What To Do About It?**|Subhankar Roy Team|[2512.04305](http://arxiv.org/abs/2512.04305)|null|
|**2025-12-03**|**Gamma-from-Mono: Road-Relative, Metric, Self-Supervised Monocular Geometry for Vehicular Applications**|Olaf Hellwich Team|[2512.04303](http://arxiv.org/abs/2512.04303)|null|
|**2025-12-03**|**Towards better dense rewards in Reinforcement Learning Applications**|Shuyuan Zhang Team|[2512.04302](http://arxiv.org/abs/2512.04302)|null|
|**2025-12-03**|**Learning Beamforming for Pinching Antenna System-Enabled ISAC in Low-Altitude Wireless Networks**|Arumugam Nallanathan Team|[2512.04293](http://arxiv.org/abs/2512.04293)|null|
|**2025-12-03**|**Driving Beyond Privilege: Distilling Dense-Reward Knowledge into Sparse-Reward Policies**|Jaerock Kwon Team|[2512.04279](http://arxiv.org/abs/2512.04279)|null|
|**2025-12-03**|**Bootstrapped Mixed Rewards for RL Post-Training: Injecting Canonical Action Order**|Vaibhav Gupta Team|[2512.04277](http://arxiv.org/abs/2512.04277)|null|
|**2025-12-03**|**The Geometry of Benchmarks: A New Path Toward AGI**|Przemyslaw Chojecki Team|[2512.04276](http://arxiv.org/abs/2512.04276)|null|
|**2025-12-03**|**MVRoom: Controllable 3D Indoor Scene Generation with Multi-View Diffusion Models**|Qixing Huang Team|[2512.04248](http://arxiv.org/abs/2512.04248)|null|
|**2025-12-03**|**6 Fingers, 1 Kidney: Natural Adversarial Medical Images Reveal Critical Weaknesses of Vision-Language Models**|Lena Maier-Hein Team|[2512.04238](http://arxiv.org/abs/2512.04238)|null|
|**2025-12-03**|**CRAFT-E: A Neuro-Symbolic Framework for Embodied Affordance Grounding**|Sathyanarayanan N. Aakur Team|[2512.04231](http://arxiv.org/abs/2512.04231)|null|
|**2025-12-03**|**MoReGen: Multi-Agent Motion-Reasoning Engine for Code-based Text-to-Video Synthesis**|Sarah Ostadabbas Team|[2512.04221](http://arxiv.org/abs/2512.04221)|null|
|**2025-12-03**|**Look Around and Pay Attention: Multi-camera Point Tracking Reimagined with Transformers**|Sarah Ostadabbas Team|[2512.04213](http://arxiv.org/abs/2512.04213)|null|
|**2025-12-03**|**Beyond Flicker: Detecting Kinematic Inconsistencies for Generalizable Deepfake Video Detection**|Luis Baumela Team|[2512.04175](http://arxiv.org/abs/2512.04175)|null|
|**2025-12-03**|**SpaceTools: Tool-Augmented Spatial Reasoning via Double Interactive RL**|Jonathan Tremblay Team|[2512.04069](http://arxiv.org/abs/2512.04069)|null|
|**2025-12-03**|**Fast & Efficient Normalizing Flows and Applications of Image Generative Models**|Sandeep Nagar Team|[2512.04039](http://arxiv.org/abs/2512.04039)|null|
|**2025-12-03**|**Jina-VLM: Small Multilingual Vision Language Model**|Han Xiao Team|[2512.04032](http://arxiv.org/abs/2512.04032)|null|
|**2025-12-03**|**C3G: Learning Compact 3D Representations with 2K Gaussians**|Seungryong Kim Team|[2512.04021](http://arxiv.org/abs/2512.04021)|**[link](https://cvlab-kaist.github.io/C3G/)**|
|**2025-12-03**|**Highly Efficient Test-Time Scaling for T2I Diffusion Models with Text Embedding Perturbation**|Feng Zhao Team|[2512.03996](http://arxiv.org/abs/2512.03996)|null|
|**2025-12-03**|**DIQ-H: Evaluating Hallucination Persistence in VLMs Under Temporal Visual Degradation**|Xiaoqiang Team|[2512.03992](http://arxiv.org/abs/2512.03992)|null|
|**2025-12-03**|**Guided Flow Policy: Learning from High-Value Actions in Offline Reinforcement Learning**|Justin Carpentier Team|[2512.03973](http://arxiv.org/abs/2512.03973)|null|
|**2025-12-03**|**MDE-AgriVLN: Agricultural Vision-and-Language Navigation with Monocular Depth Estimation**|Xiang Li Team|[2512.03958](http://arxiv.org/abs/2512.03958)|null|
|**2025-12-03**|**Autonomous Agents and Policy Compliance: A Framework for Reasoning About Penalties**|Daniela Inclezan Team|[2512.03931](http://arxiv.org/abs/2512.03931)|null|
|**2025-12-03**|**Hierarchical Vision Language Action Model Using Success and Failure Demonstrations**|Sungjoon Choi Team|[2512.03913](http://arxiv.org/abs/2512.03913)|**[link](https://vine-vla.github.io/)**|
|**2025-12-03**|**Zero-Shot Video Translation and Editing with Frame Spatial-Temporal Correspondence**|Chen Change Loy Team|[2512.03905](http://arxiv.org/abs/2512.03905)|**[link](https://github.com/Sunnycookies/FRESCO-v2)**|
|**2025-12-03**|**Digital Twin-based Control Co-Design of Full Vehicle Active Suspensions via Deep Reinforcement Learning**|Wei Chen Team|[2512.03891](http://arxiv.org/abs/2512.03891)|null|
|**2025-12-03**|**A Modular Architecture Design for Autonomous Driving Racing in Controlled Environments**|Javier Perez-Robles Team|[2512.03886](http://arxiv.org/abs/2512.03886)|null|
|**2025-12-03**|**OmniDexVLG: Learning Dexterous Grasp Generation from Vision Language Model-Guided Grasp Semantics, Taxonomy and Functional Affordance**|Jianwei Zhang Team|[2512.03874](http://arxiv.org/abs/2512.03874)|**[link](https://sites.google.com/view/omnidexvlg)**|
|**2025-12-03**|**CoDA: From Text-to-Image Diffusion Models to Training-Free Dataset Distillation**|Xinchao Wang Team|[2512.03844](http://arxiv.org/abs/2512.03844)|null|
|**2025-12-03**|**Transmit Weights, Not Features: Orthogonal-Basis Aided Wireless Point-Cloud Transmission**|Rongke Liu Team|[2512.03819](http://arxiv.org/abs/2512.03819)|null|
|**2025-12-03**|**Deep Reinforcement Learning for Dynamic Algorithm Configuration: A Case Study on Optimizing OneMax with the (1+( $λ$,$λ$ ))-GA**|Nguyen Dang Team|[2512.03805](http://arxiv.org/abs/2512.03805)|null|
|**2025-12-03**|**LSRS: Latent Scale Rejection Sampling for Visual Autoregressive Modeling**|Piji Li Team|[2512.03796](http://arxiv.org/abs/2512.03796)|null|
|**2025-12-03**|**AdaptVision: Efficient Vision-Language Models via Adaptive Visual Acquisition**|Deheng Ye Team|[2512.03794](http://arxiv.org/abs/2512.03794)|null|
|**2025-12-03**|**Safety Reinforced Model Predictive Control (SRMPC): Improving MPC with Reinforcement Learning for Motion Planning in Autonomous Driving**|Christoph Stiller Team|[2512.03774](http://arxiv.org/abs/2512.03774)|null|
|**2025-12-03**|**Prediction-Driven Motion Planning: Route Integration Strategies in Attention-Based Prediction Models**|Christoph Stiller Team|[2512.03756](http://arxiv.org/abs/2512.03756)|null|
|**2025-12-03**|**Fully Unsupervised Self-debiasing of Text-to-Image Diffusion Models**|Soma Biswas Team|[2512.03749](http://arxiv.org/abs/2512.03749)|null|
|**2025-12-03**|**Cross-embodied Co-design for Dexterous Hands**|Xiaolong Wang Team|[2512.03743](http://arxiv.org/abs/2512.03743)|null|
|**2025-12-03**|**Autonomous Planning In-space Assembly Reinforcement-learning free-flYer (APIARY) International Space Station Astrobee Testing**|Carl Glen Henshaw Team|[2512.03729](http://arxiv.org/abs/2512.03729)|null|
|**2025-12-03**|**PosA-VLA: Enhancing Action Generation via Pose-Conditioned Anchor Attention**|Mingming Gong Team|[2512.03724](http://arxiv.org/abs/2512.03724)|null|
|**2025-12-03**|**ContactRL: Safe Reinforcement Learning based Motion Planning for Contact based Human Robot Collaboration**|Emma Li Team|[2512.03707](http://arxiv.org/abs/2512.03707)|null|
|**2025-12-03**|**Quantum Topological Graph Neural Networks for Detecting Complex Fraud Patterns**|Mohammad Manthouri Team|[2512.03696](http://arxiv.org/abs/2512.03696)|null|
|**2025-12-03**|**A Novel Approach to Tomato Harvesting Using a Hybrid Gripper with Semantic Segmentation and Keypoint Detection**|Bishakh Bhattacharya Team|[2512.03684](http://arxiv.org/abs/2512.03684)|null|
|**2025-12-03**|**GaussianBlender: Instant Stylization of 3D Gaussians with Disentangled Latent Spaces**|Theo Gevers Team|[2512.03683](http://arxiv.org/abs/2512.03683)|null|
|**2025-12-03**|**ToG-Bench: Task-Oriented Spatio-Temporal Grounding in Egocentric Videos**|Liang He Team|[2512.03666](http://arxiv.org/abs/2512.03666)|null|
|**2025-12-03**|**Dynamically Scaled Activation Steering**|Pau Rodriguez Team|[2512.03661](http://arxiv.org/abs/2512.03661)|null|
|**2025-12-03**|**Evaluation of Foundational Machine Learned Interatomic Potentials for Migration Barrier Predictions**|Gopalakrishnan Sai Gautam Team|[2512.03642](http://arxiv.org/abs/2512.03642)|null|
|**2025-12-03**|**MKSNet: Advanced Small Object Detection in Remote Sensing Imagery with Multi-Kernel and Dual Attention Mechanisms**|Guangyu Gao Team|[2512.03640](http://arxiv.org/abs/2512.03640)|null|
|**2025-12-03**|**Multimodal Control of Manipulators: Coupling Kinematics and Vision for Self-Driving Laboratory Operations**|Naresh Marturi Team|[2512.03630](http://arxiv.org/abs/2512.03630)|null|
|**2025-12-03**|**MemVerse: Multimodal Memory for Lifelong Learning Agents**|Ding Wang Team|[2512.03627](http://arxiv.org/abs/2512.03627)|null|
|**2025-12-03**|**The promising potential of vision language models for the generation of textual weather forecasts**|Charles Ewen Team|[2512.03623](http://arxiv.org/abs/2512.03623)|null|
|**2025-12-03**|**ReCamDriving: LiDAR-Free Camera-Controlled Novel Trajectory Video Generation**|Guang Tan Team|[2512.03621](http://arxiv.org/abs/2512.03621)|**[link](https://recamdriving.github.io/)**|
|**2025-12-03**|**LAMP: Language-Assisted Motion Planning for Controllable Video Generation**|Duygu Ceylan Team|[2512.03619](http://arxiv.org/abs/2512.03619)|**[link](https://cyberiada.github.io/LAMP/)**|
|**2025-12-03**|**Motion4D: Learning 3D-Consistent Motion and Semantics for 4D Scene Understanding**|Gim Hee Lee Team|[2512.03601](http://arxiv.org/abs/2512.03601)|null|
|**2025-12-03**|**Memory-Guided Point Cloud Completion for Dental Reconstruction**|Mingyu Fan Team|[2512.03598](http://arxiv.org/abs/2512.03598)|null|
|**2025-12-03**|**Beyond Boundary Frames: Audio-Visual Semantic Guidance for Context-Aware Video Interpolation**|Yuxing Han Team|[2512.03590](http://arxiv.org/abs/2512.03590)|null|
|**2025-12-03**|**GAOT: Generating Articulated Objects Through Text-Guided Diffusion Models**|Shaohui Liu Team|[2512.03566](http://arxiv.org/abs/2512.03566)|null|
|**2025-12-03**|**Reason-Plan-ReAct: A Reasoner-Planner Supervising a ReAct Executor for Complex Enterprise Tasks**|Fabio Ciravegna Team|[2512.03560](http://arxiv.org/abs/2512.03560)|null|
|**2025-12-03**|**CartoMapQA: A Fundamental Benchmark Dataset Evaluating Vision-Language Models on Cartographic Map Understanding**|Yan Liu Team|[2512.03558](http://arxiv.org/abs/2512.03558)|null|
|**2025-12-03**|**RoboScape-R: Unified Reward-Observation World Models for Generalizable Robotics Training via RL**|Yong Li Team|[2512.03556](http://arxiv.org/abs/2512.03556)|null|
|**2025-12-03**|**PARC: An Autonomous Self-Reflective Coding Agent for Robust Execution of Long-Horizon Tasks**|Daisuke Okanohara Team|[2512.03549](http://arxiv.org/abs/2512.03549)|null|
|**2025-12-03**|**CookAnything: A Framework for Flexible and Consistent Multi-Step Recipe Image Generation**|Wen-Huang Cheng Team|[2512.03540](http://arxiv.org/abs/2512.03540)|null|
|**2025-12-03**|**Real-Time Control and Automation Framework for Acousto-Holographic Microscopy**|Hüseyin Üvet Team|[2512.03539](http://arxiv.org/abs/2512.03539)|null|
|**2025-12-03**|**Rethinking Prompt Design for Inference-time Scaling in Text-to-Visual Generation**|Tobias Hinz Team|[2512.03534](http://arxiv.org/abs/2512.03534)|**[link](https://subin-kim-cv.github.io/PRIS)**|
|**2025-12-03**|**OpenTrack3D: Towards Accurate and Generalizable Open-Vocabulary 3D Instance Segmentation**|Xiao Liu Team|[2512.03532](http://arxiv.org/abs/2512.03532)|null|
|**2025-12-03**|**Exploiting Domain Properties in Language-Driven Domain Generalization for Semantic Segmentation**|Hyeran Byun Team|[2512.03508](http://arxiv.org/abs/2512.03508)|null|
|**2025-12-03**|**Towards Object-centric Understanding for Instructional Videos**|Yu Kong Team|[2512.03479](http://arxiv.org/abs/2512.03479)|null|
|**2025-12-03**|**Fairness-Aware Fine-Tuning of Vision-Language Models for Medical Glaucoma Diagnosis**|Song Wang Team|[2512.03477](http://arxiv.org/abs/2512.03477)|null|
|**2025-12-03**|**Procedural Mistake Detection via Action Effect Modeling**|Yu Kong Team|[2512.03474](http://arxiv.org/abs/2512.03474)|null|
|**2025-12-03**|**Text-Printed Image: Bridging the Image-Text Modality Gap for Text-centric Training of Large Vision-Language Models**|Tsubasa Takahashi Team|[2512.03463](http://arxiv.org/abs/2512.03463)|null|
|**2025-12-03**|**Think Before You Drive: World Model-Inspired Multimodal Grounding for Autonomous Vehicles**|Zhenning Li Team|[2512.03454](http://arxiv.org/abs/2512.03454)|null|
|**2025-12-03**|**GeoVideo: Introducing Geometric Regularization into Video Generation Model**|Qixing Huang Team|[2512.03453](http://arxiv.org/abs/2512.03453)|**[link](https://geovideo.github.io/GeoVideo/)**|
|**2025-12-03**|**GalaxyDiT: Efficient Video Generation with Guidance Alignment and Adaptive Proxy in Diffusion Transformers**|Brucek Khailany Team|[2512.03451](http://arxiv.org/abs/2512.03451)|null|
|**2025-12-03**|**KeyPointDiffuser: Unsupervised 3D Keypoint Learning via Latent Diffusion Models**|Dana Kulić Team|[2512.03450](http://arxiv.org/abs/2512.03450)|null|
|**2025-12-03**|**PerFACT: Motion Policy with LLM-Powered Dataset Synthesis and Fusion Action-Chunking Transformers**|Minghui Zheng Team|[2512.03444](http://arxiv.org/abs/2512.03444)|null|
|**2025-12-03**|**Multimodal Reinforcement Learning with Agentic Verifier for AI Agents**|Jianfeng Gao Team|[2512.03438](http://arxiv.org/abs/2512.03438)|null|
|**2025-12-03**|**DM3D: Deformable Mamba via Offset-Guided Gaussian Sequencing for Point Cloud Understanding**|Xuelian Liu Team|[2512.03424](http://arxiv.org/abs/2512.03424)|null|
|**2025-12-03**|**What Is The Best 3D Scene Representation for Robotics? From Geometric to Foundation Models**|Weidong Chen Team|[2512.03422](http://arxiv.org/abs/2512.03422)|null|
|**2025-12-03**|**Comparative algorithm performance evaluation and prediction for the maximum clique problem using instance space analysis**|Elkafi Hassini Team|[2512.03419](http://arxiv.org/abs/2512.03419)|null|
|**2025-12-03**|**YOLOA: Real-Time Affordance Detection via LLM Adapter**|Xinbo Gao Team|[2512.03418](http://arxiv.org/abs/2512.03418)|null|
|**2025-12-03**|**VS-Graph: Scalable and Efficient Graph Classification Using Hyperdimensional Computing**|Maryam Parsa Team|[2512.03394](http://arxiv.org/abs/2512.03394)|null|
|**2025-12-03**|**ShelfGaussian: Shelf-Supervised Open-Vocabulary Gaussian-based 3D Scene Understanding**|Lu Gan Team|[2512.03370](http://arxiv.org/abs/2512.03370)|null|
|**2025-12-03**|**GOMP: Grasped Object Manifold Projection for Multimodal Imitation Learning of Manipulation**|Nima Fazeli Team|[2512.03347](http://arxiv.org/abs/2512.03347)|null|
|**2025-12-02**|**SpatialReasoner: Active Perception for Large-Scale 3D Scene Understanding**|Hujun Yin Team|[2512.03284](http://arxiv.org/abs/2512.03284)|null|
|**2025-12-02**|**BlendedNet++: A Large-Scale Blended Wing Body Aerodynamics Dataset and Benchmark**|Faez Ahmed Team|[2512.03280](http://arxiv.org/abs/2512.03280)|null|
|**2025-12-02**|**Too Late to Recall: Explaining the Two-Hop Problem in Multimodal Knowledge Retrieval**|Neel Nanda Team|[2512.03276](http://arxiv.org/abs/2512.03276)|null|
|**2025-12-02**|**LLM-Guided Material Inference for 3D Point Clouds**|Teseo Schneider Team|[2512.03237](http://arxiv.org/abs/2512.03237)|null|
|**2025-12-02**|**Flux4D: Flow-based Unsupervised 4D Reconstruction**|Raquel Urtasun Team|[2512.03210](http://arxiv.org/abs/2512.03210)|**[link](https://waabi.ai/flux4d/)**|
|**2025-12-02**|**InvertiTune: High-Quality Data Synthesis for Cost-Effective Single-Shot Text-to-Knowledge Graph Generation**|Yingxue Zhang Team|[2512.03197](http://arxiv.org/abs/2512.03197)|null|
|**2025-12-02**|**GRAND: Guidance, Rebalancing, and Assignment for Networked Dispatch in Multi-Agent Path Finding**|Gioele Zardini Team|[2512.03194](http://arxiv.org/abs/2512.03194)|null|
|**2025-12-02**|**Mitigating Intra- and Inter-modal Forgetting in Continual Learning of Unified Multimodal Models**|Radu Marculescu Team|[2512.03125](http://arxiv.org/abs/2512.03125)|null|
|**2025-12-02**|**Temporal Graph Neural Networks for Early Anomaly Detection and Performance Prediction via PV System Monitoring Data**|Ionnasis Tsanakas Team|[2512.03114](http://arxiv.org/abs/2512.03114)|null|
|**2025-12-02**|**Video2Act: A Dual-System Video Diffusion Policy with Robotic Spatio-Motional Modeling**|Shanghang Zhang Team|[2512.03044](http://arxiv.org/abs/2512.03044)|null|
|**2025-12-02**|**MultiShotMaster: A Controllable Multi-Shot Video Generation Framework**|Xu Jia Team|[2512.03041](http://arxiv.org/abs/2512.03041)|**[link](https://qinghew.github.io/MultiShotMaster)**|
|**2025-12-02**|**Video4Spatial: Towards Visuospatial Intelligence with Context-Guided Video Generation**|Xingang Pan Team|[2512.03040](http://arxiv.org/abs/2512.03040)|**[link](https://xizaoqu.github.io/video4spatial/)**|
|**2025-12-02**|**SMP: Reusable Score-Matching Motion Priors for Physics-Based Character Control**|Xue Bin Peng Team|[2512.03028](http://arxiv.org/abs/2512.03028)|null|
|**2025-12-02**|**Instant Video Models: Universal Adapters for Stabilizing Image-Based Networks**|Mohit Gupta Team|[2512.03014](http://arxiv.org/abs/2512.03014)|null|
|**2025-12-02**|**SurfFill: Completion of LiDAR Point Clouds via Gaussian Surfel Splatting**|Linus Franke Team|[2512.03010](http://arxiv.org/abs/2512.03010)|**[link](https://lfranke.github.io/surffill)**|
|**2025-12-02**|**DGGT: Feedforward 4D Reconstruction of Dynamic Driving Scenes using Unposed Images**|Hao Zhao Team|[2512.03004](http://arxiv.org/abs/2512.03004)|null|
|**2025-12-02**|**DynamicVerse: A Physically-Aware Multimodal Framework for 4D World Modeling**|Zhiwen Fan Team|[2512.03000](http://arxiv.org/abs/2512.03000)|null|
|**2025-12-02**|**GraphFusion3D: Dynamic Graph Attention Convolution with Adaptive Cross-Modal Transformer for 3D Object Detection**|Muhammad Abdullah Adnan Team|[2512.02991](http://arxiv.org/abs/2512.02991)|null|
|**2025-12-02**|**U4D: Uncertainty-Aware 4D World Modeling from LiDAR Sequences**|Qingshan Liu Team|[2512.02982](http://arxiv.org/abs/2512.02982)|null|
|**2025-12-02**|**BEVDilation: LiDAR-Centric Multi-Modal Fusion for 3D Object Detection**|Lei Zhang Team|[2512.02972](http://arxiv.org/abs/2512.02972)|null|
|**2025-12-02**|**Lumos: Let there be Language Model System Certification**|Gagandeep Singh Team|[2512.02966](http://arxiv.org/abs/2512.02966)|null|
|**2025-12-02**|**Layout Anything: One Transformer for Universal Room Layout Estimation**|Muhammad Abdullah Adnan Team|[2512.02952](http://arxiv.org/abs/2512.02952)|null|
|**2025-12-02**|**Experimental Characterization of Fingertip Trajectory following for a 3-DoF Series-Parallel Hybrid Robotic Finger**|Nilanjan Chakraborty Team|[2512.02951](http://arxiv.org/abs/2512.02951)|null|
|**2025-12-02**|**Benchmarking Scientific Understanding and Reasoning for Video Generation using VideoScience-Bench**|Hao Zhang Team|[2512.02942](http://arxiv.org/abs/2512.02942)|null|
|**2025-12-02**|**LoVoRA: Text-guided and Mask-free Video Object Removal and Addition with Learnable Object-aware Localization**|Qi Tian Team|[2512.02933](http://arxiv.org/abs/2512.02933)|null|
|**2025-12-02**|**EGGS: Exchangeable 2D/3D Gaussian Splatting for Geometry-Appearance Balanced Novel View Synthesis**|Chen Chen Team|[2512.02932](http://arxiv.org/abs/2512.02932)|null|
|**2025-12-02**|**DiverseAR: Boosting Diversity in Bitwise Autoregressive Image Generation**|Chenyang Si Team|[2512.02931](http://arxiv.org/abs/2512.02931)|null|
|**2025-12-02**|**AutoNeural: Co-Designing Vision-Language Models for NPU Inference**|Han Yang Team|[2512.02924](http://arxiv.org/abs/2512.02924)|null|
|**2025-12-02**|**Learning Multimodal Embeddings for Traffic Accident Prediction and Causal Estimation**|Hongyang R. Zhang Team|[2512.02920](http://arxiv.org/abs/2512.02920)|null|
|**2025-12-02**|**MRD: Multi-resolution Retrieval-Detection Fusion for High-Resolution Image Understanding**|Kaihao Zhang Team|[2512.02906](http://arxiv.org/abs/2512.02906)|null|
|**2025-12-02**|**VLA Models Are More Generalizable Than You Think: Revisiting Physical and Spatial Modeling**|Guangrun Wang Team|[2512.02902](http://arxiv.org/abs/2512.02902)|null|
|**2025-12-02**|**Glance: Accelerating Diffusion Models with 1 Sample**|Alex Jinpeng Wang Team|[2512.02899](http://arxiv.org/abs/2512.02899)|null|
|**2025-12-02**|**Taming Camera-Controlled Video Generation with Verifiable Geometry Reward**|Changhu Wang Team|[2512.02870](http://arxiv.org/abs/2512.02870)|null|
|**2025-12-02**|**GraphMatch: Fusing Language and Graph Representations in a Dynamic Two-Sided Work Marketplace**|Andrew Rabinovich Team|[2512.02849](http://arxiv.org/abs/2512.02849)|null|
|**2025-12-02**|**Action Anticipation at a Glimpse: To What Extent Can Multimodal Cues Replace Video?**|Jose Garcia-Rodriguez Team|[2512.02846](http://arxiv.org/abs/2512.02846)|null|
|**2025-12-02**|**VLM as Strategist: Adaptive Generation of Safety-critical Testing Scenarios via Guided Diffusion**|Yong Shen Team|[2512.02844](http://arxiv.org/abs/2512.02844)|null|
|**2025-12-02**|**ReVSeg: Incentivizing the Reasoning Chain for Video Segmentation with Reinforcement Learning**|Yanwei Fu Team|[2512.02835](http://arxiv.org/abs/2512.02835)|null|
|**2025-12-02**|**Steering Vision-Language-Action Models as Anti-Exploration: A Test-Time Scaling Approach**|Xuelong Li Team|[2512.02834](http://arxiv.org/abs/2512.02834)|null|
|**2025-12-02**|**A Comparative Study on How Data Normalization Affects Zero-Shot Generalization in Time Series Foundation Models**|Volker Tresp Team|[2512.02833](http://arxiv.org/abs/2512.02833)|null|
|**2025-12-02**|**Radiologist Copilot: An Agentic Assistant with Orchestrated Tools for Radiology Reporting with Quality Control**|Xiaofan Zhang Team|[2512.02814](http://arxiv.org/abs/2512.02814)|null|
|**2025-12-02**|**Diagnose, Correct, and Learn from Manipulation Failures via Visual Symbols**|Yong-Lu Li Team|[2512.02787](http://arxiv.org/abs/2512.02787)|null|
|**2025-12-02**|**Reasoning-Aware Multimodal Fusion for Hateful Video Detection**|Zeyu Fu Team|[2512.02743](http://arxiv.org/abs/2512.02743)|null|
|**2025-12-02**|**RoboWheel: A Data Engine from Real-World Human Demonstrations for Cross-Embodiment Robotic Learning**|Haoqian Wang Team|[2512.02729](http://arxiv.org/abs/2512.02729)|null|
|**2025-12-02**|**Credal Graph Neural Networks**|Davide Bacciu Team|[2512.02722](http://arxiv.org/abs/2512.02722)|null|
|**2025-12-02**|**Emergent Bayesian Behaviour and Optimal Cue Combination in LLMs**|Zafeirios Fountas Team|[2512.02719](http://arxiv.org/abs/2512.02719)|null|
|**2025-12-02**|**GeoViS: Geospatially Rewarded Visual Search for Remote Sensing Visual Grounding**|Lei Wang Team|[2512.02715](http://arxiv.org/abs/2512.02715)|null|
|**2025-12-02**|**Training Data Attribution for Image Generation using Ontology-Aligned Knowledge Graphs**|Joemon M. Jose Team|[2512.02713](http://arxiv.org/abs/2512.02713)|null|
|**2025-12-02**|**VLM-Pruner: Buffering for Spatial Sparsity in an Efficient VLM Centrifugal Token Pruning Paradigm**|Xinghao Chen Team|[2512.02700](http://arxiv.org/abs/2512.02700)|null|
|**2025-12-02**|**ALDI-ray: Adapting the ALDI Framework for Security X-ray Object Detection**|Xinxin Zuo Team|[2512.02696](http://arxiv.org/abs/2512.02696)|null|
|**2025-12-02**|**ClimaOoD: Improving Anomaly Segmentation via Physically Realistic Synthetic Data**|Yong Liu Team|[2512.02686](http://arxiv.org/abs/2512.02686)|null|
|**2025-12-02**|**PolarGuide-GSDR: 3D Gaussian Splatting Driven by Polarization Priors and Deferred Reflection for Real-World Reflective Scenes**|Peng Lu Team|[2512.02664](http://arxiv.org/abs/2512.02664)|null|
|**2025-12-02**|**Distill, Forget, Repeat: A Framework for Continual Unlearning in Text-to-Image Diffusion Models**|Yuki Mitsufuji Team|[2512.02657](http://arxiv.org/abs/2512.02657)|null|
|**2025-12-02**|**Cybersecurity AI: The World's Top AI Agent for Security Capture-the-Flag (CTF)**|Vanesa Turiel Team|[2512.02654](http://arxiv.org/abs/2512.02654)|null|
|**2025-12-02**|**PoreTrack3D: A Benchmark for Dynamic 3D Gaussian Splatting in Pore-Scale Facial Trajectory Tracking**|Le Chang Team|[2512.02648](http://arxiv.org/abs/2512.02648)|null|
|**2025-12-02**|**Zero-Shot Instruction Following in RL via Structured LTL Representations**|Alessandro Abate Team|[2512.02633](http://arxiv.org/abs/2512.02633)|null|
|**2025-12-02**|**SeeNav-Agent: Enhancing Vision-Language Navigation with Visual Prompt and Step-Level Policy Optimization**|Deheng Ye Team|[2512.02631](http://arxiv.org/abs/2512.02631)|null|
|**2025-12-02**|**RULER-Bench: Probing Rule-based Reasoning Abilities of Next-level Video Generation Models for Vision Foundation Intelligence**|Boxi Wu Team|[2512.02622](http://arxiv.org/abs/2512.02622)|null|
|**2025-12-02**|**Content-Aware Texturing for Gaussian Splatting**|George Drettakis Team|[2512.02621](http://arxiv.org/abs/2512.02621)|**[link](https://repo-sam.inria.fr/nerphys/gs-texturing/)**|
|**2025-12-02**|**SAM2Grasp: Resolve Multi-modal Grasping via Prompt-conditioned Temporal Action Prediction**|Yong Zhao Team|[2512.02609](http://arxiv.org/abs/2512.02609)|null|
|**2025-12-02**|**Deep Q-Learning-Driven Power Control for Enhanced Noma User Performance**|Nam Hoang Nguyen Team|[2512.02582](http://arxiv.org/abs/2512.02582)|null|
|**2025-12-02**|**From Imitation to Discrimination: Toward A Generalized Curriculum Advantage Mechanism Enhancing Cross-Domain Reasoning Tasks**|Guoquan Zhang Team|[2512.02580](http://arxiv.org/abs/2512.02580)|null|
|**2025-12-02**|**Co-speech Gesture Video Generation via Motion-Based Graph Retrieval**|Bang Zhang Team|[2512.02576](http://arxiv.org/abs/2512.02576)|null|
|**2025-12-02**|**Reframing Human-Robot Interaction Through Extended Reality: Unlocking Safer, Smarter, and More Empathic Interactions with Virtual Robots and Foundation Models**|Danica Kragic Team|[2512.02569](http://arxiv.org/abs/2512.02569)|null|
|**2025-12-02**|**From Panel to Pixel: Zoom-In Vision-Language Pretraining from Biomedical Scientific Literature**|Serena Yeung-Levy Team|[2512.02566](http://arxiv.org/abs/2512.02566)|null|
|**2025-12-02**|**Intervention Strategies for Fairness and Efficiency at Autonomous Single-Intersection Traffic Flows**|Eric Feron Team|[2512.02562](http://arxiv.org/abs/2512.02562)|null|
|**2025-12-02**|**OmniPerson: Unified Identity-Preserving Pedestrian Generation**|Yifan Xu Team|[2512.02554](http://arxiv.org/abs/2512.02554)|null|
|**2025-12-02**|**WeMMU: Enhanced Bridging of Vision-Language Models and Diffusion Models via Noisy Query Tokens**|Zheng-Jun Zha Team|[2512.02536](http://arxiv.org/abs/2512.02536)|null|
|**2025-12-02**|**AID: Agent Intent from Diffusion for Multi-Agent Informative Path Planning**|Guillaume Sartoretti Team|[2512.02535](http://arxiv.org/abs/2512.02535)|null|
|**2025-12-02**|**Detection of Crowdsourcing Cryptocurrency Laundering via Multi-Task Collaboration**|Weigang Wu Team|[2512.02534](http://arxiv.org/abs/2512.02534)|null|
|**2025-12-02**|**On the Problem of Consistent Anomalies in Zero-Shot Anomaly Detection**|Tai Le-Gia Team|[2512.02520](http://arxiv.org/abs/2512.02520)|null|
|**2025-12-02**|**SkyMoE: A Vision-Language Foundation Model for Enhancing Geospatial Interpretation with Mixture of Experts**|Bo Yang Team|[2512.02517](http://arxiv.org/abs/2512.02517)|null|
|**2025-12-02**|**GeoDiT: A Diffusion-based Vision-Language Model for Geospatial Understanding**|Bo Yang Team|[2512.02505](http://arxiv.org/abs/2512.02505)|null|
|**2025-12-02**|**dots.ocr: Multilingual Document Layout Parsing in a Single Vision-Language Model**|Colin Zhang Team|[2512.02498](http://arxiv.org/abs/2512.02498)|null|
|**2025-12-02**|**YingVideo-MV: Music-Driven Multi-Stage Video Generation**|Zihao Chen Team|[2512.02492](http://arxiv.org/abs/2512.02492)|null|
|**2025-12-02**|**Masking Matters: Unlocking the Spatial Reasoning Capabilities of LLMs for 3D Scene-Language Understanding**|Jae-Pil Heo Team|[2512.02487](http://arxiv.org/abs/2512.02487)|null|
|**2025-12-02**|**UCAgents: Unidirectional Convergence for Visual Evidence Anchored Multi-Agent Medical Decision-Making**|Qi Dou Team|[2512.02485](http://arxiv.org/abs/2512.02485)|null|
|**2025-12-02**|**G-SHARP: Gaussian Surgical Hardware Accelerated Real-time Pipeline**|Sean D. Huver Team|[2512.02482](http://arxiv.org/abs/2512.02482)|null|
|**2025-12-02**|**Q-BERT4Rec: Quantized Semantic-ID Representation Learning for Multimodal Recommendation**|Ling Gai Team|[2512.02474](http://arxiv.org/abs/2512.02474)|null|
|**2025-12-02**|**Vision to Geometry: 3D Spatial Memory for Sequential Embodied MLLM Reasoning and Exploration**|Yu Kong Team|[2512.02458](http://arxiv.org/abs/2512.02458)|null|
|**2025-12-02**|**Does Hearing Help Seeing? Investigating Audio-Video Joint Denoising for Video Generation**|Yunhai Tong Team|[2512.02457](http://arxiv.org/abs/2512.02457)|**[link](https://jianzongwu.github.io/projects/does-hearing-help-seeing/)**|
|**2025-12-02**|**See, Think, Learn: A Self-Taught Multimodal Reasoner**|Sadbhawna Team|[2512.02456](http://arxiv.org/abs/2512.02456)|null|
|**2025-12-02**|**HouseLayout3D: A Benchmark and Training-Free Baseline for 3D Layout Estimation in the Wild**|Leonidas Guibas Team|[2512.02450](http://arxiv.org/abs/2512.02450)|**[link](https://houselayout3d.github.io)**|
|**2025-12-02**|**Temporal Dynamics Enhancer for Directly Trained Spiking Object Detectors**|Yanfeng Lu Team|[2512.02447](http://arxiv.org/abs/2512.02447)|null|
|**2025-12-02**|**Boosting Medical Vision-Language Pretraining via Momentum Self-Distillation under Limited Computing Resources**|Ngoc Quoc Ly Team|[2512.02438](http://arxiv.org/abs/2512.02438)|null|
|**2025-12-02**|**GUI Exploration Lab: Enhancing Screen Navigation in Agents via Multi-Turn Reinforcement Learning**|Daxin Jiang Team|[2512.02423](http://arxiv.org/abs/2512.02423)|null|
|**2025-12-02**|**Generalizing Vision-Language Models with Dedicated Prompt Guidance**|Jingjing Li Team|[2512.02421](http://arxiv.org/abs/2512.02421)|null|
|**2025-12-02**|**Enhancing Floor Plan Recognition: A Hybrid Mix-Transformer and U-Net Approach for Precise Wall Segmentation**|Yuriy Karyakin Team|[2512.02413](http://arxiv.org/abs/2512.02413)|null|
|**2025-12-02**|**Decentralized Multi-Agent System with Trust-Aware Communication**|Hiroyuki Sato Team|[2512.02410](http://arxiv.org/abs/2512.02410)|null|
|**2025-12-02**|**Reproducing and Extending RaDelft 4D Radar with Camera-Assisted Labels**|Ozan K. Tonguz Team|[2512.02394](http://arxiv.org/abs/2512.02394)|null|
|**2025-12-02**|**From Detection to Association: Learning Discriminative Object Embeddings for Multi-Object Tracking**|Xiao Sun Team|[2512.02392](http://arxiv.org/abs/2512.02392)|null|
|**2025-12-02**|**On-the-fly Feedback SfM: Online Explore-and-Exploit UAV Photogrammetry with Incremental Mesh Quality-Aware Indicator and Predictive Path Planning**|Zongqian Zhan Team|[2512.02375](http://arxiv.org/abs/2512.02375)|null|
|**2025-12-02**|**SAGE: Style-Adaptive Generalization for Privacy-Constrained Semantic Segmentation Across Domains**|Juepeng Zheng Team|[2512.02369](http://arxiv.org/abs/2512.02369)|null|
|**2025-12-02**|**VACoT: Rethinking Visual Data Augmentation with VLMs**|Chun Yuan Team|[2512.02361](http://arxiv.org/abs/2512.02361)|null|
|**2025-12-02**|**TALO: Pushing 3D Vision Foundation Models Towards Globally Consistent Online Reconstruction**|Yadan Luo Team|[2512.02341](http://arxiv.org/abs/2512.02341)|null|
|**2025-12-02**|**Reasoning Path and Latent State Analysis for Multi-view Visual Spatial Reasoning: A Cognitive Science Perspective**|Wei Gao Team|[2512.02340](http://arxiv.org/abs/2512.02340)|null|
|**2025-12-02**|**Towards autonomous normative multi-agent systems for Human-AI software engineering teams**|Cristina Conati Team|[2512.02329](http://arxiv.org/abs/2512.02329)|null|
|**2025-12-02**|**OmniGuard: Unified Omni-Modal Guardrails with Deliberate Reasoning**|Muhao Chen Team|[2512.02306](http://arxiv.org/abs/2512.02306)|null|
|**2025-12-02**|**VIGS-SLAM: Visual Inertial Gaussian Splatting SLAM**|Daniel Barath Team|[2512.02293](http://arxiv.org/abs/2512.02293)|**[link](https://vigs-slam.github.io)**|

<p align=right>(<a href=#updated-on-20251217>back to top</a>)</p>

