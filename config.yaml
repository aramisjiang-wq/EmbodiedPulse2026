# TODO: add papers by configuration file
base_url: "https://arxiv.paperswithcode.com/api/v0/papers/"
repo_name: "EmbodiedPulse2026"
show_authors: True
show_links: True
show_badge: False
max_results: 100

publish_readme: True
publish_gitpage: True
publish_wechat: False

# file paths
json_readme_path: './docs/cv-arxiv-daily.json'
json_gitpage_path: './docs/cv-arxiv-daily-web.json'
json_wechat_path: './docs/cv-arxiv-daily-wechat.json'

md_readme_path: 'README.md'
md_gitpage_path: './docs/index.md'
md_wechat_path: './docs/wechat.md'

# keywords to search
# 基于新论文标签体系配置（2025-12-15更新）
keywords:
    # ========== 感知与理解 (Perception & Understanding) ==========
    "Perception-2D":
        filters: ["perception", "2d perception", "visual perception", "computer vision", "image understanding"]
    
    "Perception-3D":
        filters: ["3d perception", "3d vision", "depth perception", "spatial perception", "volumetric"]
    
    "Perception-Detection":
        filters: ["object detection", "detection", "object recognition", "tracking", "multi-object tracking"]
    
    "Perception-Segmentation":
        filters: ["segmentation", "instance segmentation", "semantic segmentation", "panoptic segmentation"]
    
    "Perception-VLM":
        filters: ["vision language model", "VLM", "multimodal", "CLIP", "visual language", "visual grounding", "VQA"]
    
    "Perception-PointCloud":
        filters: ["point cloud", "pointcloud", "lidar", "3d point"]
    
    "Perception-SceneUnderstanding":
        filters: ["scene understanding", "3d scene", "scene reconstruction", "3DGS", "gaussian splatting", "nerf"]
    
    "Perception-Generation":
        filters: ["image generation", "video generation", "diffusion", "text to image", "text to video"]

    # ========== 决策 (Decision Making) ==========
    "Decision-Planning":
        filters: ["planning", "task planning", "motion planning", "path planning", "navigation", "long-horizon"]
    
    "Decision-Graph":
        filters: ["graph modeling", "graph neural", "knowledge graph", "scene graph"]

    # ========== 运动控制 (Motion Control) ==========
    "Motion-Locomotion":
        filters: ["locomotion", "walking", "legged", "gait", "navigation"]
    
    "Motion-Humanoid":
        filters: ["humanoid", "bipedal", "humanoid robot", "human-like robot"]
    
    "Motion-Quadruped":
        filters: ["quadruped", "quadrupedal", "four-legged", "legged robot"]
    
    "Motion-MobileManipulation":
        filters: ["mobile manipulation", "loco-manipulation", "mobile manipulator"]

    # ========== 操作与交互 (Operation & Interaction) ==========
    "Operation-Grasp":
        filters: ["grasp", "grasping", "manipulation", "pick and place", "object manipulation"]
    
    "Operation-Bimanual":
        filters: ["bimanual", "dual arm", "dual-arm", "two-arm", "coordinated manipulation"]
    
    "Operation-Dexterous":
        filters: ["dexterous", "dexterous hand", "fine manipulation", "in-hand manipulation"]
    
    "Operation-VLA":
        filters: ["vision language action", "VLA", "embodied agent", "embodied AI", "autonomous agent"]
    
    "Operation-Policy":
        filters: ["policy", "control policy", "visuomotor policy", "robot policy", "neural policy"]

    # ========== 学习与算法 (Learning & Algorithms) ==========
    "Learning-RL":
        filters: ["reinforcement learning", "deep reinforcement learning", "RL", "PPO", "SAC", "actor-critic"]
    
    "Learning-IL":
        filters: ["imitation learning", "behavioral cloning", "learning from demonstration", "IL"]
    
    "Learning-Lightweight":
        filters: ["lightweight", "efficient", "compression", "quantization", "model compression"]

    # ========== 基准 (Benchmark) ==========
    "Benchmark":
        filters: ["benchmark", "evaluation", "dataset", "testbed", "simulator", "simulation"]
    
    # ========== 通用 (General) ==========
    "General-Robot":
        filters: ["robot learning", "robotic learning", "embodied", "autonomous", "sim-to-real"]
