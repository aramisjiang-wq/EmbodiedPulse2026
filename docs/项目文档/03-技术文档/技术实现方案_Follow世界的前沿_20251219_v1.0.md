# æŠ€æœ¯å®ç°æ–¹æ¡ˆï¼šFollow ä¸–ç•Œçš„å‰æ²¿

**ç‰ˆæœ¬**: v1.0  
**åˆ›å»ºæ—¥æœŸ**: 2025-12-19  
**ç”¨é€”**: è¯¦ç»†æŠ€æœ¯å®ç°æ–¹æ¡ˆ  
**ç›®æ ‡**: æä¾›å¯æ‰§è¡Œçš„å¼€å‘æŒ‡å—

---

## ğŸ“‹ ç›®å½•

1. [æŠ€æœ¯æ¶æ„è®¾è®¡](#æŠ€æœ¯æ¶æ„è®¾è®¡)
2. [æ•°æ®åº“è®¾è®¡](#æ•°æ®åº“è®¾è®¡)
3. [åç«¯å®ç°](#åç«¯å®ç°)
4. [å‰ç«¯å®ç°](#å‰ç«¯å®ç°)
5. [å®šæ—¶ä»»åŠ¡å®ç°](#å®šæ—¶ä»»åŠ¡å®ç°)
6. [å¼€å‘æ­¥éª¤](#å¼€å‘æ­¥éª¤)
7. [æµ‹è¯•æ–¹æ¡ˆ](#æµ‹è¯•æ–¹æ¡ˆ)
8. [éƒ¨ç½²æ–¹æ¡ˆ](#éƒ¨ç½²æ–¹æ¡ˆ)
9. [è¿­ä»£è®¡åˆ’](#è¿­ä»£è®¡åˆ’)

---

## ğŸ—ï¸ æŠ€æœ¯æ¶æ„è®¾è®¡

### âš ï¸ é‡è¦è¯´æ˜ï¼šä¸ç°æœ‰ç³»ç»Ÿçš„é›†æˆå…³ç³»

**è¿™æ˜¯ä¸€ä¸ªä¸ç°æœ‰åŠŸèƒ½æ·±åº¦é›†æˆçš„æ–°åŠŸèƒ½ï¼Œè€Œéç‹¬ç«‹ç³»ç»Ÿã€‚**

#### æ ¸å¿ƒè®¾è®¡ç†å¿µ
1. **æ•°æ®ç»Ÿä¸€å­˜å‚¨**: ç ”ç©¶æœºæ„æŠ“å–çš„è®ºæ–‡**ç»Ÿä¸€å­˜å‚¨**åœ¨ç°æœ‰çš„ `papers` è¡¨ä¸­
2. **åŠŸèƒ½å¤ç”¨**: å¤ç”¨ç°æœ‰çš„è®ºæ–‡å±•ç¤ºã€æœç´¢ã€åˆ†ç±»ç­‰åŠŸèƒ½
3. **æ•°æ®æ‰©å±•**: é€šè¿‡æ‰©å±• `papers` è¡¨å­—æ®µæ¥æ ‡è¯†è®ºæ–‡æ¥æº
4. **æ–°å¢åŠŸèƒ½**: æ–°å¢æœºæ„ç®¡ç†å’Œæœºæ„è®ºæ–‡åˆ—è¡¨å±•ç¤ºåŠŸèƒ½

#### ä¸ç°æœ‰ç³»ç»Ÿçš„å…³ç³»

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ç°æœ‰ç³»ç»Ÿï¼ˆå·²å­˜åœ¨ï¼‰                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ è®ºæ–‡è¡¨ (papers)                                       â”‚   â”‚
â”‚  â”‚ - å­˜å‚¨ArXivè®ºæ–‡ï¼ˆå·²æœ‰ï¼‰                               â”‚   â”‚
â”‚  â”‚ - å­˜å‚¨æœºæ„è®ºæ–‡ï¼ˆæ–°å¢ï¼Œç»Ÿä¸€å­˜å‚¨ï¼‰                        â”‚   â”‚
â”‚  â”‚ - æ‰©å±•å­—æ®µï¼šsource_institute_id, source_url          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ è®ºæ–‡å±•ç¤ºåŠŸèƒ½ï¼ˆå¤ç”¨ï¼‰                                    â”‚   â”‚
â”‚  â”‚ - é¦–é¡µè®ºæ–‡åˆ—è¡¨ï¼ˆ/ï¼‰                                    â”‚   â”‚
â”‚  â”‚ - è®ºæ–‡æœç´¢ï¼ˆ/api/searchï¼‰                             â”‚   â”‚
â”‚  â”‚ - è®ºæ–‡åˆ†ç±»ï¼ˆ33ä¸ªåˆ†ç±»ï¼‰                                 â”‚   â”‚
â”‚  â”‚ - è®ºæ–‡ç»Ÿè®¡ï¼ˆæ€»æ•°ã€æ–°å¢æ•°ç­‰ï¼‰                            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ é›†æˆ
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     æ–°åŠŸèƒ½ï¼ˆæ–°å¢ï¼‰                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ æœºæ„è¡¨ (research_institutes) - æ–°è¡¨                   â”‚   â”‚
â”‚  â”‚ - å­˜å‚¨æœºæ„åŸºæœ¬ä¿¡æ¯                                     â”‚   â”‚
â”‚  â”‚ - å­˜å‚¨æŠ“å–é…ç½®                                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ æŠ“å–æ—¥å¿—è¡¨ (fetch_logs) - æ–°è¡¨                        â”‚   â”‚
â”‚  â”‚ - è®°å½•æ¯æ¬¡æŠ“å–çš„ç»“æœ                                   â”‚   â”‚
â”‚  â”‚ - è®°å½•é”™è¯¯ä¿¡æ¯                                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ æœºæ„è®ºæ–‡å±•ç¤ºï¼ˆæ–°é¡µé¢ï¼‰                                  â”‚   â”‚
â”‚  â”‚ - /research-institutesï¼ˆæœºæ„åˆ—è¡¨ï¼‰                     â”‚   â”‚
â”‚  â”‚ - /research-institutes/<id>/papersï¼ˆæœºæ„è®ºæ–‡åˆ—è¡¨ï¼‰    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ•´ä½“æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     å‰ç«¯å±•ç¤ºå±‚                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ æœºæ„åˆ—è¡¨é¡µé¢  â”‚  â”‚ æœºæ„è®ºæ–‡åˆ—è¡¨  â”‚  â”‚ ç°æœ‰è®ºæ–‡é¡µé¢  â”‚ â”‚
â”‚  â”‚ (æ–°)         â”‚  â”‚ (æ–°)         â”‚  â”‚ (å¤ç”¨)       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Flask API å±‚                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ /api/institutesâ”‚ â”‚ /api/papers  â”‚ â”‚ /api/search  â”‚ â”‚
â”‚  â”‚ (æ–°)         â”‚  â”‚ (å¤ç”¨)       â”‚  â”‚ (å¤ç”¨)       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ä¸šåŠ¡é€»è¾‘å±‚                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ æœºæ„ç®¡ç†æœåŠ¡  â”‚  â”‚ è®ºæ–‡ç®¡ç†æœåŠ¡  â”‚  â”‚ æŠ“å–è°ƒåº¦æœåŠ¡  â”‚ â”‚
â”‚  â”‚ (æ–°)         â”‚  â”‚ (å¤ç”¨+æ‰©å±•)  â”‚  â”‚ (æ–°)         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æ•°æ®æŠ“å–å±‚                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ AllenAIå®¢æˆ·ç«¯ â”‚  â”‚ NVIDIAå®¢æˆ·ç«¯ â”‚  â”‚ PIå®¢æˆ·ç«¯     â”‚ â”‚
â”‚  â”‚ (æ–°)         â”‚  â”‚ (æ–°)         â”‚  â”‚ (æ–°)         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æ•°æ®å­˜å‚¨å±‚                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ æœºæ„è¡¨(æ–°)    â”‚  â”‚ è®ºæ–‡è¡¨(æ‰©å±•) â”‚  â”‚ æŠ“å–æ—¥å¿—è¡¨(æ–°)â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ•°æ®æµå‘è¯´æ˜

```
ç ”ç©¶æœºæ„ç½‘ç«™
    â”‚
    â–¼
[æŠ“å–å®¢æˆ·ç«¯] (æ–°)
    â”‚
    â–¼
[è®ºæ–‡æ•°æ®] (æ ‡å‡†åŒ–)
    â”‚
    â–¼
[å»é‡æ£€æŸ¥] (å¤ç”¨ç°æœ‰é€»è¾‘)
    â”‚
    â–¼
[papersè¡¨] (ç°æœ‰è¡¨ï¼Œæ‰©å±•å­—æ®µ)
    â”‚
    â”œâ”€â”€â”€â–º [é¦–é¡µè®ºæ–‡åˆ—è¡¨] (å¤ç”¨ç°æœ‰é¡µé¢)
    â”œâ”€â”€â”€â–º [è®ºæ–‡æœç´¢] (å¤ç”¨ç°æœ‰åŠŸèƒ½)
    â”œâ”€â”€â”€â–º [è®ºæ–‡åˆ†ç±»] (å¤ç”¨ç°æœ‰åŠŸèƒ½)
    â””â”€â”€â”€â–º [æœºæ„è®ºæ–‡åˆ—è¡¨] (æ–°é¡µé¢)
```

### æ¨¡å—åˆ’åˆ†

#### 1. æ•°æ®æ¨¡å‹å±‚ (`research_institute_models.py`)
- `ResearchInstitute`: ç ”ç©¶æœºæ„æ¨¡å‹
- `FetchLog`: æŠ“å–æ—¥å¿—æ¨¡å‹

#### 2. å®¢æˆ·ç«¯å±‚ (`research_institute_clients/`)
- `base_client.py`: åŸºç¡€å®¢æˆ·ç«¯æŠ½è±¡ç±»
- `allenai_client.py`: AllenAIå®¢æˆ·ç«¯
- `nvidia_research_client.py`: NVIDIA Researchå®¢æˆ·ç«¯
- `physical_intelligence_client.py`: Physical Intelligenceå®¢æˆ·ç«¯

#### 3. æœåŠ¡å±‚ (`research_institute_service.py`)
- æœºæ„ç®¡ç†æœåŠ¡
- è®ºæ–‡æŠ“å–æœåŠ¡
- æ•°æ®å»é‡æœåŠ¡

#### 4. APIè·¯ç”±å±‚ (`app.py` æ‰©å±•)
- `/research-institutes`: æœºæ„åˆ—è¡¨
- `/research-institutes/<id>/papers`: æœºæ„è®ºæ–‡åˆ—è¡¨
- `/research-institutes/stats`: ç»Ÿè®¡æ•°æ®

#### 5. å®šæ—¶ä»»åŠ¡å±‚ (`scheduler_utils.py` æ‰©å±•)
- å®šæ—¶æŠ“å–ä»»åŠ¡
- é”™è¯¯é‡è¯•æœºåˆ¶

---

## ğŸ—„ï¸ æ•°æ®åº“è®¾è®¡

### âš ï¸ æ•°æ®åº“è®¾è®¡è¯´æ˜

**è¿™æ˜¯ä¸€ä¸ªæ‰©å±•æ€§è®¾è®¡ï¼Œè€Œéç‹¬ç«‹æ•°æ®åº“ï¼š**

1. **æ–°å¢è¡¨**ï¼ˆ2ä¸ªï¼‰:
   - `research_institutes`: å­˜å‚¨æœºæ„ä¿¡æ¯
   - `fetch_logs`: å­˜å‚¨æŠ“å–æ—¥å¿—

2. **æ‰©å±•ç°æœ‰è¡¨**ï¼ˆ1ä¸ªï¼‰:
   - `papers`: æ·»åŠ 3ä¸ªå­—æ®µæ ‡è¯†è®ºæ–‡æ¥æº
   - **é‡è¦**: æœºæ„è®ºæ–‡ä¸ArXivè®ºæ–‡ç»Ÿä¸€å­˜å‚¨åœ¨ `papers` è¡¨ä¸­

3. **æ•°æ®ç»Ÿä¸€æ€§**:
   - æ‰€æœ‰è®ºæ–‡ï¼ˆæ— è®ºæ¥æºï¼‰éƒ½åœ¨åŒä¸€ä¸ª `papers` è¡¨ä¸­
   - å¯ä»¥é€šè¿‡ `source_institute_id` å­—æ®µåŒºåˆ†è®ºæ–‡æ¥æº
   - å¦‚æœ `source_institute_id` ä¸º NULLï¼Œè¯´æ˜æ˜¯ArXivè®ºæ–‡ï¼ˆç°æœ‰æ•°æ®ï¼‰

### 1. research_institutes è¡¨ï¼ˆæ–°è¡¨ï¼‰

```sql
CREATE TABLE research_institutes (
    id SERIAL PRIMARY KEY,
    name VARCHAR(255) NOT NULL UNIQUE,  -- æœºæ„åç§°ï¼Œå¦‚ "AllenAI"
    slug VARCHAR(100) NOT NULL UNIQUE,  -- URLå‹å¥½æ ‡è¯†ï¼Œå¦‚ "allenai"
    website_url TEXT,  -- å®˜ç½‘URL
    papers_url TEXT NOT NULL,  -- è®ºæ–‡åˆ—è¡¨URL
    logo_url TEXT,  -- Logo URL
    description TEXT,  -- æœºæ„ç®€ä»‹
    fetch_method VARCHAR(50) NOT NULL DEFAULT 'crawler',  -- æŠ“å–æ–¹å¼ï¼šcrawler/api/rss
    fetch_config JSONB,  -- æŠ“å–é…ç½®ï¼ˆAPI keyã€CSSé€‰æ‹©å™¨ç­‰ï¼‰
    is_active BOOLEAN DEFAULT TRUE,  -- æ˜¯å¦å¯ç”¨
    last_fetch_at TIMESTAMP,  -- æœ€åæŠ“å–æ—¶é—´
    fetch_interval_hours INTEGER DEFAULT 24,  -- æŠ“å–é—´éš”ï¼ˆå°æ—¶ï¼‰
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- ç´¢å¼•
CREATE INDEX idx_research_institutes_active ON research_institutes(is_active);
CREATE INDEX idx_research_institutes_slug ON research_institutes(slug);
```

### 2. papers è¡¨æ‰©å±•ï¼ˆæ‰©å±•ç°æœ‰è¡¨ï¼‰

**è¯´æ˜**: è¿™æ˜¯å¯¹ç°æœ‰ `papers` è¡¨çš„æ‰©å±•ï¼Œä¸æ˜¯æ–°å»ºè¡¨ã€‚

```sql
-- æ·»åŠ æ–°å­—æ®µï¼ˆç”¨äºæ ‡è¯†è®ºæ–‡æ¥æºï¼‰
ALTER TABLE papers ADD COLUMN source_institute_id INTEGER REFERENCES research_institutes(id);
ALTER TABLE papers ADD COLUMN source_url TEXT;  -- åŸå§‹è®ºæ–‡é¡µé¢URL
ALTER TABLE papers ADD COLUMN fetch_method VARCHAR(50);  -- æŠ“å–æ–¹å¼

-- ç´¢å¼•
CREATE INDEX idx_papers_source_institute ON papers(source_institute_id);
```

**å­—æ®µè¯´æ˜**:
- `source_institute_id`: 
  - `NULL` = ArXivè®ºæ–‡ï¼ˆç°æœ‰æ•°æ®ï¼Œä¿æŒå…¼å®¹ï¼‰
  - `æœ‰å€¼` = ç ”ç©¶æœºæ„è®ºæ–‡ï¼ˆæ–°æ•°æ®ï¼‰
- `source_url`: è®ºæ–‡çš„åŸå§‹é¡µé¢URLï¼ˆæœºæ„ç½‘ç«™ä¸Šçš„é“¾æ¥ï¼‰
- `fetch_method`: æŠ“å–æ–¹å¼ï¼ˆ'crawler'/'api'/'rss'ï¼‰

**æ•°æ®å…¼å®¹æ€§**:
- ç°æœ‰ArXivè®ºæ–‡çš„ `source_institute_id` ä¸º `NULL`ï¼Œä¸å½±å“ç°æœ‰åŠŸèƒ½
- æ–°æŠ“å–çš„æœºæ„è®ºæ–‡ä¼šè®¾ç½® `source_institute_id`
- æ‰€æœ‰è®ºæ–‡éƒ½å¯ä»¥é€šè¿‡ç°æœ‰çš„ `/api/papers` å’Œ `/api/search` APIè®¿é—®

### 3. fetch_logs è¡¨ï¼ˆæ–°è¡¨ï¼‰

```sql
CREATE TABLE fetch_logs (
    id SERIAL PRIMARY KEY,
    institute_id INTEGER REFERENCES research_institutes(id),
    fetch_type VARCHAR(50) NOT NULL,  -- full/incremental
    status VARCHAR(50) NOT NULL,  -- success/failed/partial
    papers_found INTEGER DEFAULT 0,  -- å‘ç°è®ºæ–‡æ•°
    papers_new INTEGER DEFAULT 0,  -- æ–°å¢è®ºæ–‡æ•°
    papers_updated INTEGER DEFAULT 0,  -- æ›´æ–°è®ºæ–‡æ•°
    papers_skipped INTEGER DEFAULT 0,  -- è·³è¿‡è®ºæ–‡æ•°ï¼ˆé‡å¤ï¼‰
    error_message TEXT,  -- é”™è¯¯ä¿¡æ¯
    started_at TIMESTAMP NOT NULL,
    completed_at TIMESTAMP,
    duration_seconds INTEGER
);

-- ç´¢å¼•
CREATE INDEX idx_fetch_logs_institute ON fetch_logs(institute_id);
CREATE INDEX idx_fetch_logs_status ON fetch_logs(status);
CREATE INDEX idx_fetch_logs_started_at ON fetch_logs(started_at);
```

### 4. æ•°æ®åº“è¿ç§»è„šæœ¬

åˆ›å»º `migrate_add_research_institutes.py`:

```python
"""
æ•°æ®åº“è¿ç§»ï¼šæ·»åŠ ç ”ç©¶æœºæ„è¿½è¸ªåŠŸèƒ½
"""
from database import get_engine
from sqlalchemy import text
import logging

logger = logging.getLogger(__name__)

def migrate():
    """æ‰§è¡Œè¿ç§»"""
    engine = get_engine()
    
    with engine.connect() as conn:
        # 1. åˆ›å»º research_institutes è¡¨
        conn.execute(text("""
            CREATE TABLE IF NOT EXISTS research_institutes (
                id SERIAL PRIMARY KEY,
                name VARCHAR(255) NOT NULL UNIQUE,
                slug VARCHAR(100) NOT NULL UNIQUE,
                website_url TEXT,
                papers_url TEXT NOT NULL,
                logo_url TEXT,
                description TEXT,
                fetch_method VARCHAR(50) NOT NULL DEFAULT 'crawler',
                fetch_config JSONB,
                is_active BOOLEAN DEFAULT TRUE,
                last_fetch_at TIMESTAMP,
                fetch_interval_hours INTEGER DEFAULT 24,
                created_at TIMESTAMP DEFAULT NOW(),
                updated_at TIMESTAMP DEFAULT NOW()
            )
        """))
        
        # 2. åˆ›å»ºç´¢å¼•
        conn.execute(text("""
            CREATE INDEX IF NOT EXISTS idx_research_institutes_active 
            ON research_institutes(is_active)
        """))
        
        conn.execute(text("""
            CREATE INDEX IF NOT EXISTS idx_research_institutes_slug 
            ON research_institutes(slug)
        """))
        
        # 3. æ‰©å±• papers è¡¨
        try:
            conn.execute(text("""
                ALTER TABLE papers 
                ADD COLUMN IF NOT EXISTS source_institute_id INTEGER 
                REFERENCES research_institutes(id)
            """))
        except Exception as e:
            logger.warning(f"æ·»åŠ  source_institute_id å­—æ®µå¤±è´¥ï¼ˆå¯èƒ½å·²å­˜åœ¨ï¼‰: {e}")
        
        try:
            conn.execute(text("""
                ALTER TABLE papers 
                ADD COLUMN IF NOT EXISTS source_url TEXT
            """))
        except Exception as e:
            logger.warning(f"æ·»åŠ  source_url å­—æ®µå¤±è´¥ï¼ˆå¯èƒ½å·²å­˜åœ¨ï¼‰: {e}")
        
        try:
            conn.execute(text("""
                ALTER TABLE papers 
                ADD COLUMN IF NOT EXISTS fetch_method VARCHAR(50)
            """))
        except Exception as e:
            logger.warning(f"æ·»åŠ  fetch_method å­—æ®µå¤±è´¥ï¼ˆå¯èƒ½å·²å­˜åœ¨ï¼‰: {e}")
        
        # 4. åˆ›å»º papers è¡¨ç´¢å¼•
        try:
            conn.execute(text("""
                CREATE INDEX IF NOT EXISTS idx_papers_source_institute 
                ON papers(source_institute_id)
            """))
        except Exception as e:
            logger.warning(f"åˆ›å»ºç´¢å¼•å¤±è´¥: {e}")
        
        # 5. åˆ›å»º fetch_logs è¡¨
        conn.execute(text("""
            CREATE TABLE IF NOT EXISTS fetch_logs (
                id SERIAL PRIMARY KEY,
                institute_id INTEGER REFERENCES research_institutes(id),
                fetch_type VARCHAR(50) NOT NULL,
                status VARCHAR(50) NOT NULL,
                papers_found INTEGER DEFAULT 0,
                papers_new INTEGER DEFAULT 0,
                papers_updated INTEGER DEFAULT 0,
                papers_skipped INTEGER DEFAULT 0,
                error_message TEXT,
                started_at TIMESTAMP NOT NULL,
                completed_at TIMESTAMP,
                duration_seconds INTEGER
            )
        """))
        
        # 6. åˆ›å»º fetch_logs ç´¢å¼•
        conn.execute(text("""
            CREATE INDEX IF NOT EXISTS idx_fetch_logs_institute 
            ON fetch_logs(institute_id)
        """))
        
        conn.execute(text("""
            CREATE INDEX IF NOT EXISTS idx_fetch_logs_status 
            ON fetch_logs(status)
        """))
        
        conn.execute(text("""
            CREATE INDEX IF NOT EXISTS idx_fetch_logs_started_at 
            ON fetch_logs(started_at)
        """))
        
        conn.commit()
        logger.info("æ•°æ®åº“è¿ç§»å®Œæˆ")

if __name__ == '__main__':
    migrate()
```

---

## ğŸ”§ åç«¯å®ç°

### 1. æ•°æ®æ¨¡å‹ (`research_institute_models.py`)

```python
"""
ç ”ç©¶æœºæ„æ•°æ®æ¨¡å‹
"""
from sqlalchemy import Column, String, Text, DateTime, Integer, Boolean, JSON
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker, relationship
from datetime import datetime
from database import get_engine

Base = declarative_base()

class ResearchInstitute(Base):
    """ç ”ç©¶æœºæ„æ¨¡å‹"""
    __tablename__ = 'research_institutes'
    
    id = Column(Integer, primary_key=True)
    name = Column(String(255), nullable=False, unique=True)
    slug = Column(String(100), nullable=False, unique=True)
    website_url = Column(Text)
    papers_url = Column(Text, nullable=False)
    logo_url = Column(Text)
    description = Column(Text)
    fetch_method = Column(String(50), nullable=False, default='crawler')
    fetch_config = Column(JSON)
    is_active = Column(Boolean, default=True)
    last_fetch_at = Column(DateTime)
    fetch_interval_hours = Column(Integer, default=24)
    created_at = Column(DateTime, default=datetime.now)
    updated_at = Column(DateTime, default=datetime.now, onupdate=datetime.now)
    
    def to_dict(self):
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'id': self.id,
            'name': self.name,
            'slug': self.slug,
            'website_url': self.website_url,
            'papers_url': self.papers_url,
            'logo_url': self.logo_url,
            'description': self.description,
            'fetch_method': self.fetch_method,
            'is_active': self.is_active,
            'last_fetch_at': self.last_fetch_at.isoformat() if self.last_fetch_at else None,
            'fetch_interval_hours': self.fetch_interval_hours,
            'papers_count': self.papers_count if hasattr(self, 'papers_count') else 0
        }

class FetchLog(Base):
    """æŠ“å–æ—¥å¿—æ¨¡å‹"""
    __tablename__ = 'fetch_logs'
    
    id = Column(Integer, primary_key=True)
    institute_id = Column(Integer, nullable=False)
    fetch_type = Column(String(50), nullable=False)  # full/incremental
    status = Column(String(50), nullable=False)  # success/failed/partial
    papers_found = Column(Integer, default=0)
    papers_new = Column(Integer, default=0)
    papers_updated = Column(Integer, default=0)
    papers_skipped = Column(Integer, default=0)
    error_message = Column(Text)
    started_at = Column(DateTime, nullable=False, default=datetime.now)
    completed_at = Column(DateTime)
    duration_seconds = Column(Integer)
    
    def to_dict(self):
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'id': self.id,
            'institute_id': self.institute_id,
            'fetch_type': self.fetch_type,
            'status': self.status,
            'papers_found': self.papers_found,
            'papers_new': self.papers_new,
            'papers_updated': self.papers_updated,
            'papers_skipped': self.papers_skipped,
            'error_message': self.error_message,
            'started_at': self.started_at.isoformat() if self.started_at else None,
            'completed_at': self.completed_at.isoformat() if self.completed_at else None,
            'duration_seconds': self.duration_seconds
        }

def get_research_institute_session():
    """è·å–æ•°æ®åº“ä¼šè¯"""
    engine = get_engine()
    Session = sessionmaker(bind=engine)
    return Session()
```

### 2. åŸºç¡€å®¢æˆ·ç«¯ (`research_institute_clients/base_client.py`)

```python
"""
ç ”ç©¶æœºæ„å®¢æˆ·ç«¯åŸºç±»
"""
from abc import ABC, abstractmethod
import logging
from typing import List, Dict
from datetime import datetime

logger = logging.getLogger(__name__)

class BaseResearchInstituteClient(ABC):
    """ç ”ç©¶æœºæ„å®¢æˆ·ç«¯åŸºç±»"""
    
    def __init__(self, institute_config: Dict):
        """
        åˆå§‹åŒ–å®¢æˆ·ç«¯
        
        Args:
            institute_config: æœºæ„é…ç½®å­—å…¸ï¼ŒåŒ…å«name, papers_url, fetch_configç­‰
        """
        self.name = institute_config.get('name')
        self.papers_url = institute_config.get('papers_url')
        self.fetch_config = institute_config.get('fetch_config', {})
        self.timeout = self.fetch_config.get('timeout', 30)
        self.retry_times = self.fetch_config.get('retry_times', 3)
        self.retry_delay = self.fetch_config.get('retry_delay', 5)
    
    @abstractmethod
    def fetch_papers(self, max_papers: int = None) -> List[Dict]:
        """
        æŠ“å–è®ºæ–‡åˆ—è¡¨
        
        Args:
            max_papers: æœ€å¤§æŠ“å–æ•°é‡ï¼ŒNoneè¡¨ç¤ºæŠ“å–æ‰€æœ‰
        
        Returns:
            è®ºæ–‡åˆ—è¡¨ï¼Œæ¯ä¸ªè®ºæ–‡åŒ…å«ï¼š
            - title: æ ‡é¢˜
            - authors: ä½œè€…åˆ—è¡¨
            - publish_year: å‘è¡¨å¹´ä»½
            - venue: å‘è¡¨åœºæ‰€
            - paper_url: è®ºæ–‡é“¾æ¥
            - pdf_url: PDFé“¾æ¥ï¼ˆå¦‚æœæœ‰ï¼‰
            - abstract: æ‘˜è¦ï¼ˆå¦‚æœæœ‰ï¼‰
            - source_url: åŸå§‹é¡µé¢URL
        """
        pass
    
    def normalize_paper_data(self, raw_data: Dict) -> Dict:
        """
        æ ‡å‡†åŒ–è®ºæ–‡æ•°æ®
        
        Args:
            raw_data: åŸå§‹æ•°æ®
        
        Returns:
            æ ‡å‡†åŒ–åçš„æ•°æ®
        """
        return {
            'title': raw_data.get('title', '').strip(),
            'authors': raw_data.get('authors', []),
            'publish_year': raw_data.get('publish_year'),
            'venue': raw_data.get('venue', ''),
            'paper_url': raw_data.get('paper_url', ''),
            'pdf_url': raw_data.get('pdf_url', ''),
            'abstract': raw_data.get('abstract', ''),
            'source_url': raw_data.get('source_url', '')
        }
    
    def validate_paper_data(self, paper_data: Dict) -> bool:
        """
        éªŒè¯è®ºæ–‡æ•°æ®æ˜¯å¦å®Œæ•´
        
        Args:
            paper_data: è®ºæ–‡æ•°æ®
        
        Returns:
            æ˜¯å¦æœ‰æ•ˆ
        """
        required_fields = ['title', 'paper_url']
        return all(paper_data.get(field) for field in required_fields)
```

### 3. AllenAIå®¢æˆ·ç«¯ (`research_institute_clients/allenai_client.py`)

```python
"""
AllenAIå®¢æˆ·ç«¯
"""
import requests
from bs4 import BeautifulSoup
import time
import logging
from typing import List, Dict
from research_institute_clients.base_client import BaseResearchInstituteClient

logger = logging.getLogger(__name__)

class AllenAIClient(BaseResearchInstituteClient):
    """AllenAIå®¢æˆ·ç«¯"""
    
    def fetch_papers(self, max_papers: int = None) -> List[Dict]:
        """
        æŠ“å–AllenAIè®ºæ–‡åˆ—è¡¨
        
        å®ç°æ€è·¯ï¼š
        1. è®¿é—® https://allenai.org/papers
        2. è§£æHTMLï¼Œæå–è®ºæ–‡ä¿¡æ¯
        3. è¿”å›æ ‡å‡†åŒ–æ•°æ®
        """
        papers = []
        
        try:
            # è®¾ç½®è¯·æ±‚å¤´
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            # å‘é€è¯·æ±‚
            response = requests.get(
                self.papers_url,
                headers=headers,
                timeout=self.timeout
            )
            response.raise_for_status()
            
            # è§£æHTML
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # æ ¹æ®å®é™…HTMLç»“æ„æå–è®ºæ–‡
            # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…ç½‘ç«™ç»“æ„è°ƒæ•´é€‰æ‹©å™¨
            paper_elements = soup.select('.paper-item')  # ç¤ºä¾‹é€‰æ‹©å™¨
            
            for element in paper_elements:
                if max_papers and len(papers) >= max_papers:
                    break
                
                try:
                    paper_data = self._parse_paper_element(element)
                    if self.validate_paper_data(paper_data):
                        papers.append(self.normalize_paper_data(paper_data))
                except Exception as e:
                    logger.warning(f"è§£æè®ºæ–‡å…ƒç´ å¤±è´¥: {e}")
                    continue
            
            logger.info(f"AllenAIæŠ“å–å®Œæˆï¼Œå…±{len(papers)}ç¯‡è®ºæ–‡")
            
        except Exception as e:
            logger.error(f"AllenAIæŠ“å–å¤±è´¥: {e}")
            raise
        
        return papers
    
    def _parse_paper_element(self, element) -> Dict:
        """
        è§£æå•ä¸ªè®ºæ–‡å…ƒç´ 
        
        Args:
            element: BeautifulSoupå…ƒç´ 
        
        Returns:
            è®ºæ–‡æ•°æ®å­—å…¸
        """
        # æ ¹æ®å®é™…HTMLç»“æ„è°ƒæ•´
        title_elem = element.select_one('.paper-title')
        title = title_elem.get_text(strip=True) if title_elem else ''
        
        authors_elem = element.select('.paper-authors')
        authors = [a.get_text(strip=True) for a in authors_elem] if authors_elem else []
        
        year_elem = element.select_one('.paper-year')
        year = int(year_elem.get_text(strip=True)) if year_elem else None
        
        link_elem = element.select_one('a.paper-link')
        paper_url = link_elem.get('href', '') if link_elem else ''
        if paper_url and not paper_url.startswith('http'):
            paper_url = f"https://allenai.org{paper_url}"
        
        return {
            'title': title,
            'authors': authors,
            'publish_year': year,
            'venue': '',
            'paper_url': paper_url,
            'pdf_url': '',
            'abstract': '',
            'source_url': self.papers_url
        }
```

### 4. è®ºæ–‡æŠ“å–æœåŠ¡ (`research_institute_service.py`)

```python
"""
ç ”ç©¶æœºæ„è®ºæ–‡æŠ“å–æœåŠ¡
"""
import logging
from datetime import datetime
from typing import List, Dict, Tuple
from research_institute_models import get_research_institute_session, ResearchInstitute, FetchLog
from models import get_session, Paper
from save_paper_to_db import save_paper_to_db
from utils import is_duplicate_title
from research_institute_clients.allenai_client import AllenAIClient
from research_institute_clients.nvidia_research_client import NVIDIAResearchClient
from research_institute_clients.physical_intelligence_client import PhysicalIntelligenceClient

logger = logging.getLogger(__name__)

# å®¢æˆ·ç«¯æ˜ å°„
CLIENT_MAP = {
    'allenai': AllenAIClient,
    'nvidia_research': NVIDIAResearchClient,
    'physical_intelligence': PhysicalIntelligenceClient
}

def fetch_institute_papers(institute_id: int, max_papers: int = None) -> Dict:
    """
    æŠ“å–æŒ‡å®šæœºæ„çš„è®ºæ–‡
    
    Args:
        institute_id: æœºæ„ID
        max_papers: æœ€å¤§æŠ“å–æ•°é‡
    
    Returns:
        æŠ“å–ç»“æœå­—å…¸
    """
    session = get_research_institute_session()
    paper_session = get_session()
    
    try:
        # è·å–æœºæ„ä¿¡æ¯
        institute = session.query(ResearchInstitute).filter_by(id=institute_id).first()
        if not institute:
            return {'success': False, 'error': 'æœºæ„ä¸å­˜åœ¨'}
        
        if not institute.is_active:
            return {'success': False, 'error': 'æœºæ„æœªå¯ç”¨'}
        
        # åˆ›å»ºæŠ“å–æ—¥å¿—
        fetch_log = FetchLog(
            institute_id=institute_id,
            fetch_type='incremental',
            status='running',
            started_at=datetime.now()
        )
        session.add(fetch_log)
        session.commit()
        
        # åˆ›å»ºå®¢æˆ·ç«¯
        client_class = CLIENT_MAP.get(institute.slug)
        if not client_class:
            fetch_log.status = 'failed'
            fetch_log.error_message = f'ä¸æ”¯æŒçš„æœºæ„ç±»å‹: {institute.slug}'
            fetch_log.completed_at = datetime.now()
            session.commit()
            return {'success': False, 'error': fetch_log.error_message}
        
        client = client_class({
            'name': institute.name,
            'papers_url': institute.papers_url,
            'fetch_config': institute.fetch_config or {}
        })
        
        # æŠ“å–è®ºæ–‡
        papers = client.fetch_papers(max_papers=max_papers)
        fetch_log.papers_found = len(papers)
        
        # ä¿å­˜è®ºæ–‡
        papers_new = 0
        papers_updated = 0
        papers_skipped = 0
        
        for paper_data in papers:
            try:
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆåŸºäºæ ‡é¢˜ç›¸ä¼¼åº¦ï¼‰
                existing_paper = paper_session.query(Paper).filter_by(
                    title=paper_data['title']
                ).first()
                
                if existing_paper:
                    # å¦‚æœå·²å­˜åœ¨ï¼Œæ›´æ–°æ¥æºæœºæ„ä¿¡æ¯
                    if not existing_paper.source_institute_id:
                        existing_paper.source_institute_id = institute_id
                        existing_paper.source_url = paper_data.get('source_url')
                        existing_paper.fetch_method = institute.fetch_method
                        papers_updated += 1
                    else:
                        papers_skipped += 1
                    continue
                
                # æ£€æŸ¥æ ‡é¢˜ç›¸ä¼¼åº¦
                similar_papers = paper_session.query(Paper).all()
                is_duplicate = False
                for existing in similar_papers:
                    if is_duplicate_title(paper_data['title'], existing.title):
                        is_duplicate = True
                        break
                
                if is_duplicate:
                    papers_skipped += 1
                    continue
                
                # ä¿å­˜æ–°è®ºæ–‡
                paper_dict = {
                    'id': f"{institute.slug}_{paper_data['title'][:50]}",  # ç”Ÿæˆå”¯ä¸€ID
                    'title': paper_data['title'],
                    'authors': ', '.join(paper_data.get('authors', [])),
                    'publish_date': datetime(paper_data.get('publish_year', 2024), 1, 1).date() if paper_data.get('publish_year') else None,
                    'pdf_url': paper_data.get('pdf_url', ''),
                    'code_url': '',
                    'abstract': paper_data.get('abstract', ''),
                    'category': 'Other',  # é»˜è®¤åˆ†ç±»ï¼Œåç»­å¯ä»¥è‡ªåŠ¨åˆ†ç±»
                    'source_institute_id': institute_id,
                    'source_url': paper_data.get('source_url', ''),
                    'fetch_method': institute.fetch_method
                }
                
                success, action = save_paper_to_db(
                    paper_dict,
                    category='Other',
                    enable_title_dedup=False  # å·²ç»åœ¨ä¸Šé¢å¤„ç†äº†
                )
                
                if success and action == 'created':
                    papers_new += 1
                elif success and action == 'updated':
                    papers_updated += 1
                else:
                    papers_skipped += 1
                    
            except Exception as e:
                logger.error(f"ä¿å­˜è®ºæ–‡å¤±è´¥: {e}")
                papers_skipped += 1
                continue
        
        # æ›´æ–°æŠ“å–æ—¥å¿—
        fetch_log.status = 'success'
        fetch_log.papers_new = papers_new
        fetch_log.papers_updated = papers_updated
        fetch_log.papers_skipped = papers_skipped
        fetch_log.completed_at = datetime.now()
        fetch_log.duration_seconds = int((fetch_log.completed_at - fetch_log.started_at).total_seconds())
        
        # æ›´æ–°æœºæ„æœ€åæŠ“å–æ—¶é—´
        institute.last_fetch_at = datetime.now()
        
        session.commit()
        paper_session.commit()
        
        return {
            'success': True,
            'papers_found': len(papers),
            'papers_new': papers_new,
            'papers_updated': papers_updated,
            'papers_skipped': papers_skipped
        }
        
    except Exception as e:
        logger.error(f"æŠ“å–æœºæ„è®ºæ–‡å¤±è´¥: {e}")
        if 'fetch_log' in locals():
            fetch_log.status = 'failed'
            fetch_log.error_message = str(e)
            fetch_log.completed_at = datetime.now()
            session.commit()
        return {'success': False, 'error': str(e)}
    
    finally:
        session.close()
        paper_session.close()

def fetch_all_institutes(max_papers_per_institute: int = None) -> Dict:
    """
    æŠ“å–æ‰€æœ‰å¯ç”¨æœºæ„çš„è®ºæ–‡
    
    Args:
        max_papers_per_institute: æ¯ä¸ªæœºæ„æœ€å¤§æŠ“å–æ•°é‡
    
    Returns:
        æ€»ä½“æŠ“å–ç»“æœ
    """
    session = get_research_institute_session()
    
    try:
        institutes = session.query(ResearchInstitute).filter_by(is_active=True).all()
        
        results = {
            'total_institutes': len(institutes),
            'success_count': 0,
            'failed_count': 0,
            'details': []
        }
        
        for institute in institutes:
            try:
                result = fetch_institute_papers(institute.id, max_papers=max_papers_per_institute)
                results['details'].append({
                    'institute_id': institute.id,
                    'institute_name': institute.name,
                    'result': result
                })
                
                if result.get('success'):
                    results['success_count'] += 1
                else:
                    results['failed_count'] += 1
                    
            except Exception as e:
                logger.error(f"æŠ“å–æœºæ„ {institute.name} å¤±è´¥: {e}")
                results['failed_count'] += 1
                results['details'].append({
                    'institute_id': institute.id,
                    'institute_name': institute.name,
                    'result': {'success': False, 'error': str(e)}
                })
        
        return results
        
    finally:
        session.close()
```

### 5. APIè·¯ç”±æ‰©å±• (`app.py`)

```python
# åœ¨ app.py ä¸­æ·»åŠ ä»¥ä¸‹è·¯ç”±

from research_institute_models import get_research_institute_session, ResearchInstitute, FetchLog
from research_institute_service import fetch_institute_papers, fetch_all_institutes
from models import get_session, Paper
from sqlalchemy import func

@app.route('/research-institutes')
def research_institutes():
    """ç ”ç©¶æœºæ„åˆ—è¡¨é¡µé¢"""
    session = get_research_institute_session()
    try:
        institutes = session.query(ResearchInstitute).filter_by(is_active=True).all()
        
        # ç»Ÿè®¡æ¯ä¸ªæœºæ„çš„è®ºæ–‡æ•°
        paper_session = get_session()
        for institute in institutes:
            count = paper_session.query(Paper).filter_by(
                source_institute_id=institute.id
            ).count()
            institute.papers_count = count
        paper_session.close()
        
        return render_template('research_institutes.html', institutes=institutes)
    finally:
        session.close()

@app.route('/api/research-institutes')
def api_research_institutes():
    """ç ”ç©¶æœºæ„åˆ—è¡¨API"""
    session = get_research_institute_session()
    try:
        institutes = session.query(ResearchInstitute).filter_by(is_active=True).all()
        
        # ç»Ÿè®¡æ¯ä¸ªæœºæ„çš„è®ºæ–‡æ•°
        paper_session = get_session()
        result = []
        for institute in institutes:
            count = paper_session.query(Paper).filter_by(
                source_institute_id=institute.id
            ).count()
            result.append({
                **institute.to_dict(),
                'papers_count': count
            })
        paper_session.close()
        
        return jsonify(result)
    finally:
        session.close()

@app.route('/research-institutes/<int:institute_id>/papers')
def institute_papers(institute_id):
    """æœºæ„è®ºæ–‡åˆ—è¡¨é¡µé¢"""
    session = get_research_institute_session()
    paper_session = get_session()
    
    try:
        institute = session.query(ResearchInstitute).filter_by(id=institute_id).first()
        if not institute:
            return "æœºæ„ä¸å­˜åœ¨", 404
        
        # è·å–è®ºæ–‡åˆ—è¡¨
        papers = paper_session.query(Paper).filter_by(
            source_institute_id=institute_id
        ).order_by(Paper.publish_date.desc()).limit(100).all()
        
        return render_template('institute_papers.html', 
                             institute=institute, 
                             papers=papers)
    finally:
        session.close()
        paper_session.close()

@app.route('/api/research-institutes/<int:institute_id>/papers')
def api_institute_papers(institute_id):
    """æœºæ„è®ºæ–‡åˆ—è¡¨API"""
    paper_session = get_session()
    
    try:
        page = request.args.get('page', 1, type=int)
        per_page = request.args.get('per_page', 20, type=int)
        
        papers = paper_session.query(Paper).filter_by(
            source_institute_id=institute_id
        ).order_by(Paper.publish_date.desc())
        
        total = papers.count()
        papers = papers.offset((page - 1) * per_page).limit(per_page).all()
        
        return jsonify({
            'total': total,
            'page': page,
            'per_page': per_page,
            'papers': [p.to_dict() for p in papers]
        })
    finally:
        paper_session.close()

@app.route('/api/research-institutes/stats')
def api_research_institutes_stats():
    """ç ”ç©¶æœºæ„ç»Ÿè®¡æ•°æ®API"""
    session = get_research_institute_session()
    paper_session = get_session()
    
    try:
        institutes = session.query(ResearchInstitute).filter_by(is_active=True).all()
        
        stats = []
        for institute in institutes:
            papers = paper_session.query(Paper).filter_by(
                source_institute_id=institute.id
            )
            
            total = papers.count()
            recent = papers.filter(
                Paper.publish_date >= datetime.now().date() - timedelta(days=30)
            ).count()
            
            stats.append({
                'institute_id': institute.id,
                'institute_name': institute.name,
                'total_papers': total,
                'recent_papers': recent
            })
        
        return jsonify(stats)
    finally:
        session.close()
        paper_session.close()

@app.route('/api/research-institutes/<int:institute_id>/fetch', methods=['POST'])
@admin_required  # éœ€è¦ç®¡ç†å‘˜æƒé™
def api_fetch_institute_papers(institute_id):
    """æ‰‹åŠ¨è§¦å‘æœºæ„è®ºæ–‡æŠ“å–"""
    result = fetch_institute_papers(institute_id)
    return jsonify(result)
```

---

## ğŸ¨ å‰ç«¯å®ç°

### 1. æœºæ„åˆ—è¡¨é¡µé¢ (`templates/research_institutes.html`)

```html
{% extends "base.html" %}

{% block title %}ç ”ç©¶æœºæ„è¿½è¸ª - Embodied Pulse{% endblock %}

{% block content %}
<div class="container mt-4">
    <h1>Follow ä¸–ç•Œçš„å‰æ²¿</h1>
    <p class="lead">è¿½è¸ªå…·èº«æ™ºèƒ½é¢†åŸŸé¡¶çº§ç ”ç©¶æœºæ„çš„æœ€æ–°è®ºæ–‡</p>
    
    <div class="row mt-4">
        {% for institute in institutes %}
        <div class="col-md-4 mb-4">
            <div class="card">
                {% if institute.logo_url %}
                <img src="{{ institute.logo_url }}" class="card-img-top" alt="{{ institute.name }}">
                {% endif %}
                <div class="card-body">
                    <h5 class="card-title">{{ institute.name }}</h5>
                    <p class="card-text">{{ institute.description or '' }}</p>
                    <p class="text-muted">
                        <small>è®ºæ–‡æ•°: {{ institute.papers_count or 0 }}</small><br>
                        <small>æœ€åæ›´æ–°: {{ institute.last_fetch_at.strftime('%Y-%m-%d %H:%M') if institute.last_fetch_at else 'æœªæ›´æ–°' }}</small>
                    </p>
                    <a href="/research-institutes/{{ institute.id }}/papers" class="btn btn-primary">æŸ¥çœ‹è®ºæ–‡</a>
                </div>
            </div>
        </div>
        {% endfor %}
    </div>
</div>
{% endblock %}
```

### 2. æœºæ„è®ºæ–‡åˆ—è¡¨é¡µé¢ (`templates/institute_papers.html`)

```html
{% extends "base.html" %}

{% block title %}{{ institute.name }} - è®ºæ–‡åˆ—è¡¨{% endblock %}

{% block content %}
<div class="container mt-4">
    <h1>{{ institute.name }}</h1>
    <p class="lead">{{ institute.description or '' }}</p>
    
    <div class="mt-4">
        <h2>è®ºæ–‡åˆ—è¡¨</h2>
        <div id="papers-list">
            {% for paper in papers %}
            <div class="card mb-3">
                <div class="card-body">
                    <h5 class="card-title">
                        <a href="{{ paper.paper_url or paper.pdf_url }}" target="_blank">{{ paper.title }}</a>
                    </h5>
                    <p class="card-text">
                        <strong>ä½œè€…:</strong> {{ paper.authors }}<br>
                        <strong>å‘è¡¨æ—¥æœŸ:</strong> {{ paper.publish_date.strftime('%Y-%m-%d') if paper.publish_date else 'æœªçŸ¥' }}<br>
                        {% if paper.venue %}
                        <strong>å‘è¡¨åœºæ‰€:</strong> {{ paper.venue }}<br>
                        {% endif %}
                        {% if paper.citation_count %}
                        <strong>å¼•ç”¨æ•°:</strong> {{ paper.citation_count }}<br>
                        {% endif %}
                    </p>
                    {% if paper.abstract %}
                    <p class="card-text"><small class="text-muted">{{ paper.abstract[:200] }}...</small></p>
                    {% endif %}
                    <div class="mt-2">
                        {% if paper.pdf_url %}
                        <a href="{{ paper.pdf_url }}" class="btn btn-sm btn-primary" target="_blank">PDF</a>
                        {% endif %}
                        {% if paper.code_url %}
                        <a href="{{ paper.code_url }}" class="btn btn-sm btn-secondary" target="_blank">Code</a>
                        {% endif %}
                        <a href="{{ paper.source_url }}" class="btn btn-sm btn-info" target="_blank">åŸå§‹é¡µé¢</a>
                    </div>
                </div>
            </div>
            {% endfor %}
        </div>
    </div>
</div>
{% endblock %}
```

---

## â° å®šæ—¶ä»»åŠ¡å®ç°

### æ‰©å±• `scheduler_utils.py`

```python
# åœ¨ scheduler_utils.py ä¸­æ·»åŠ 

from research_institute_service import fetch_all_institutes
import logging

logger = logging.getLogger(__name__)

def schedule_research_institute_fetch():
    """å®šæ—¶æŠ“å–ç ”ç©¶æœºæ„è®ºæ–‡"""
    try:
        logger.info("å¼€å§‹å®šæ—¶æŠ“å–ç ”ç©¶æœºæ„è®ºæ–‡")
        result = fetch_all_institutes(max_papers_per_institute=50)  # æ¯æ¬¡æœ€å¤šæŠ“å–50ç¯‡
        
        logger.info(f"æŠ“å–å®Œæˆ: æˆåŠŸ{result['success_count']}ä¸ªæœºæ„, å¤±è´¥{result['failed_count']}ä¸ªæœºæ„")
        
        # è®°å½•è¯¦ç»†ç»“æœ
        for detail in result['details']:
            if detail['result'].get('success'):
                logger.info(f"{detail['institute_name']}: æ–°å¢{detail['result'].get('papers_new', 0)}ç¯‡, "
                          f"æ›´æ–°{detail['result'].get('papers_updated', 0)}ç¯‡")
            else:
                logger.error(f"{detail['institute_name']}: æŠ“å–å¤±è´¥ - {detail['result'].get('error')}")
                
    except Exception as e:
        logger.error(f"å®šæ—¶æŠ“å–ç ”ç©¶æœºæ„è®ºæ–‡å¤±è´¥: {e}")

# åœ¨åˆå§‹åŒ–è°ƒåº¦å™¨æ—¶æ·»åŠ ä»»åŠ¡
# scheduler.add_job(
#     schedule_research_institute_fetch,
#     'cron',
#     hour=2,  # æ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œ
#     id='fetch_research_institutes'
# )
```

---

## ğŸ“ å¼€å‘æ­¥éª¤

### é˜¶æ®µ1: æ•°æ®åº“å’Œæ¨¡å‹ï¼ˆ1-2å¤©ï¼‰

1. **åˆ›å»ºæ•°æ®åº“è¿ç§»è„šæœ¬**
   - [ ] åˆ›å»º `migrate_add_research_institutes.py`
   - [ ] æ‰§è¡Œè¿ç§»ï¼Œåˆ›å»ºè¡¨ç»“æ„
   - [ ] éªŒè¯è¡¨ç»“æ„

2. **åˆ›å»ºæ•°æ®æ¨¡å‹**
   - [ ] åˆ›å»º `research_institute_models.py`
   - [ ] å®ç° `ResearchInstitute` æ¨¡å‹
   - [ ] å®ç° `FetchLog` æ¨¡å‹
   - [ ] æµ‹è¯•æ¨¡å‹åŠŸèƒ½

3. **åˆå§‹åŒ–æœºæ„æ•°æ®**
   - [ ] åˆ›å»ºåˆå§‹åŒ–è„šæœ¬ï¼Œæ’å…¥3ä¸ªæœºæ„çš„åŸºç¡€æ•°æ®
   - [ ] éªŒè¯æ•°æ®

### é˜¶æ®µ2: å®¢æˆ·ç«¯å®ç°ï¼ˆ3-5å¤©ï¼‰

1. **å®ç°åŸºç¡€å®¢æˆ·ç«¯**
   - [ ] åˆ›å»º `research_institute_clients/base_client.py`
   - [ ] å®šä¹‰æŠ½è±¡æ¥å£

2. **å®ç°AllenAIå®¢æˆ·ç«¯**
   - [ ] åˆ†æç½‘ç«™ç»“æ„
   - [ ] å®ç°HTMLè§£æ
   - [ ] æµ‹è¯•æŠ“å–åŠŸèƒ½

3. **å®ç°NVIDIA Researchå®¢æˆ·ç«¯**
   - [ ] åˆ†æç½‘ç«™ç»“æ„
   - [ ] å®ç°æŠ“å–é€»è¾‘
   - [ ] æµ‹è¯•æŠ“å–åŠŸèƒ½

4. **å®ç°Physical Intelligenceå®¢æˆ·ç«¯**
   - [ ] åˆ†æç½‘ç«™ç»“æ„
   - [ ] å®ç°æŠ“å–é€»è¾‘
   - [ ] æµ‹è¯•æŠ“å–åŠŸèƒ½

### é˜¶æ®µ3: æœåŠ¡å±‚å®ç°ï¼ˆ2-3å¤©ï¼‰

1. **å®ç°æŠ“å–æœåŠ¡**
   - [ ] åˆ›å»º `research_institute_service.py`
   - [ ] å®ç° `fetch_institute_papers` å‡½æ•°
   - [ ] å®ç° `fetch_all_institutes` å‡½æ•°
   - [ ] å®ç°å»é‡é€»è¾‘
   - [ ] æµ‹è¯•æœåŠ¡åŠŸèƒ½

### é˜¶æ®µ4: APIå’Œå‰ç«¯ï¼ˆ2-3å¤©ï¼‰

1. **å®ç°APIè·¯ç”±**
   - [ ] åœ¨ `app.py` ä¸­æ·»åŠ æœºæ„åˆ—è¡¨API
   - [ ] æ·»åŠ æœºæ„è®ºæ–‡åˆ—è¡¨API
   - [ ] æ·»åŠ ç»Ÿè®¡æ•°æ®API
   - [ ] æ·»åŠ æ‰‹åŠ¨æŠ“å–API

2. **å®ç°å‰ç«¯é¡µé¢**
   - [ ] åˆ›å»ºæœºæ„åˆ—è¡¨é¡µé¢
   - [ ] åˆ›å»ºæœºæ„è®ºæ–‡åˆ—è¡¨é¡µé¢
   - [ ] æ·»åŠ æ•°æ®å¯è§†åŒ–ï¼ˆå¯é€‰ï¼‰

### é˜¶æ®µ5: å®šæ—¶ä»»åŠ¡ï¼ˆ1å¤©ï¼‰

1. **é›†æˆå®šæ—¶ä»»åŠ¡**
   - [ ] åœ¨ `scheduler_utils.py` ä¸­æ·»åŠ å®šæ—¶ä»»åŠ¡
   - [ ] é…ç½®æ‰§è¡Œæ—¶é—´
   - [ ] æµ‹è¯•å®šæ—¶ä»»åŠ¡

### é˜¶æ®µ6: æµ‹è¯•å’Œä¼˜åŒ–ï¼ˆ2-3å¤©ï¼‰

1. **åŠŸèƒ½æµ‹è¯•**
   - [ ] æµ‹è¯•æŠ“å–åŠŸèƒ½
   - [ ] æµ‹è¯•å»é‡é€»è¾‘
   - [ ] æµ‹è¯•å‰ç«¯å±•ç¤º

2. **æ€§èƒ½ä¼˜åŒ–**
   - [ ] ä¼˜åŒ–æŠ“å–é€Ÿåº¦
   - [ ] ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢
   - [ ] æ·»åŠ ç¼“å­˜ï¼ˆå¦‚éœ€è¦ï¼‰

3. **é”™è¯¯å¤„ç†**
   - [ ] å®Œå–„é”™è¯¯å¤„ç†
   - [ ] æ·»åŠ é‡è¯•æœºåˆ¶
   - [ ] æ·»åŠ æ—¥å¿—è®°å½•

---

## ğŸ§ª æµ‹è¯•æ–¹æ¡ˆ

### å•å…ƒæµ‹è¯•

```python
# tests/test_research_institute_client.py

import unittest
from research_institute_clients.allenai_client import AllenAIClient

class TestAllenAIClient(unittest.TestCase):
    def test_fetch_papers(self):
        client = AllenAIClient({
            'name': 'AllenAI',
            'papers_url': 'https://allenai.org/papers',
            'fetch_config': {}
        })
        papers = client.fetch_papers(max_papers=5)
        self.assertGreater(len(papers), 0)
        self.assertIn('title', papers[0])
        self.assertIn('paper_url', papers[0])
```

### é›†æˆæµ‹è¯•

```python
# tests/test_research_institute_service.py

import unittest
from research_institute_service import fetch_institute_papers

class TestResearchInstituteService(unittest.TestCase):
    def test_fetch_institute_papers(self):
        result = fetch_institute_papers(institute_id=1, max_papers=10)
        self.assertTrue(result.get('success'))
        self.assertGreater(result.get('papers_found', 0), 0)
```

---

## ğŸš€ éƒ¨ç½²æ–¹æ¡ˆ

### 1. æ•°æ®åº“è¿ç§»

```bash
# åœ¨æœåŠ¡å™¨ä¸Šæ‰§è¡Œ
cd /path/to/embodied-pulse
source venv/bin/activate
python migrate_add_research_institutes.py
```

### 2. ä»£ç éƒ¨ç½²

æŒ‰ç…§[ä»£ç ç®¡ç†è§„èŒƒä¸æµç¨‹](../è¿ç»´ç®¡ç†/ä»£ç ç®¡ç†è§„èŒƒä¸æµç¨‹_å®Œæ•´ç‰ˆ_20251219_v2.0.md)æ‰§è¡Œï¼š
1. æœ¬åœ°å¼€å‘å®Œæˆ
2. æ¨é€åˆ°GitHub
3. æœåŠ¡å™¨æ‹‰å–ä»£ç 
4. é‡å¯æœåŠ¡

### 3. åˆå§‹åŒ–æœºæ„æ•°æ®

```python
# scripts/init_research_institutes.py

from research_institute_models import get_research_institute_session, ResearchInstitute

def init_institutes():
    session = get_research_institute_session()
    
    institutes = [
        {
            'name': 'AllenAI',
            'slug': 'allenai',
            'website_url': 'https://allenai.org',
            'papers_url': 'https://allenai.org/papers',
            'description': 'Allen Institute for AI',
            'fetch_method': 'crawler'
        },
        {
            'name': 'NVIDIA Research',
            'slug': 'nvidia_research',
            'website_url': 'https://research.nvidia.com',
            'papers_url': 'https://research.nvidia.com/publications',
            'description': 'NVIDIA Research',
            'fetch_method': 'crawler'
        },
        {
            'name': 'Physical Intelligence',
            'slug': 'physical_intelligence',
            'website_url': 'https://www.physicalintelligence.company',
            'papers_url': 'https://www.physicalintelligence.company',
            'description': 'Physical Intelligence Company',
            'fetch_method': 'crawler'
        }
    ]
    
    for data in institutes:
        existing = session.query(ResearchInstitute).filter_by(slug=data['slug']).first()
        if not existing:
            institute = ResearchInstitute(**data)
            session.add(institute)
    
    session.commit()
    session.close()

if __name__ == '__main__':
    init_institutes()
```

---

## ğŸ“… è¿­ä»£è®¡åˆ’

### MVPç‰ˆæœ¬ï¼ˆ2å‘¨ï¼‰
- âœ… æ”¯æŒ1ä¸ªæœºæ„ï¼ˆAllenAIï¼‰
- âœ… åŸºç¡€æŠ“å–åŠŸèƒ½
- âœ… æœºæ„è®ºæ–‡åˆ—è¡¨é¡µé¢
- âœ… å®šæ—¶ä»»åŠ¡

### v1.0ç‰ˆæœ¬ï¼ˆ1å‘¨ï¼‰
- âœ… æ”¯æŒ3ä¸ªæœºæ„
- âœ… å®Œå–„å»é‡é€»è¾‘
- âœ… ç»Ÿè®¡æ•°æ®å±•ç¤º
- âœ… é”™è¯¯å¤„ç†å’Œæ—¥å¿—

### v1.1ç‰ˆæœ¬ï¼ˆåç»­ï¼‰
- â³ æ”¯æŒæ›´å¤šæœºæ„
- â³ APIæ¥å£æ”¯æŒ
- â³ RSS Feedæ”¯æŒ
- â³ é‚®ä»¶é€šçŸ¥åŠŸèƒ½

---

## âœ… æ€»ç»“

### æ ¸å¿ƒè®¾è®¡ç†å¿µ

**è¿™æ˜¯ä¸€ä¸ªä¸ç°æœ‰åŠŸèƒ½æ·±åº¦é›†æˆçš„æ–°åŠŸèƒ½ï¼Œè€Œéç‹¬ç«‹ç³»ç»Ÿã€‚**

#### 1. æ•°æ®ç»Ÿä¸€å­˜å‚¨
- âœ… æœºæ„è®ºæ–‡ä¸ArXivè®ºæ–‡**ç»Ÿä¸€å­˜å‚¨**åœ¨ `papers` è¡¨ä¸­
- âœ… é€šè¿‡ `source_institute_id` å­—æ®µåŒºåˆ†æ¥æº
- âœ… ç°æœ‰ArXivè®ºæ–‡ä¸å—å½±å“ï¼ˆ`source_institute_id` ä¸º `NULL`ï¼‰

#### 2. åŠŸèƒ½å¤ç”¨
- âœ… å¤ç”¨ç°æœ‰çš„è®ºæ–‡å±•ç¤ºé¡µé¢ï¼ˆé¦–é¡µï¼‰
- âœ… å¤ç”¨ç°æœ‰çš„è®ºæ–‡æœç´¢åŠŸèƒ½
- âœ… å¤ç”¨ç°æœ‰çš„è®ºæ–‡åˆ†ç±»åŠŸèƒ½ï¼ˆ33ä¸ªåˆ†ç±»ï¼‰
- âœ… å¤ç”¨ç°æœ‰çš„è®ºæ–‡ç»Ÿè®¡åŠŸèƒ½

#### 3. æ–°å¢åŠŸèƒ½
- âœ… æ–°å¢æœºæ„ç®¡ç†ï¼ˆæœºæ„è¡¨ï¼‰
- âœ… æ–°å¢æœºæ„è®ºæ–‡åˆ—è¡¨é¡µé¢
- âœ… æ–°å¢æœºæ„è®ºæ–‡æŠ“å–åŠŸèƒ½
- âœ… æ–°å¢æŠ“å–æ—¥å¿—è®°å½•

#### 4. æ•°æ®æµå‘
```
ç ”ç©¶æœºæ„ç½‘ç«™ â†’ æŠ“å–å®¢æˆ·ç«¯ â†’ å»é‡æ£€æŸ¥ â†’ papersè¡¨ â†’ ç°æœ‰å±•ç¤ºåŠŸèƒ½ + æ–°æœºæ„é¡µé¢
```

### æŠ€æœ¯è¦ç‚¹
1. **æ•°æ®è·å–**: ä½¿ç”¨ç½‘é¡µçˆ¬è™«ï¼Œåç»­å¯æ‰©å±•API/RSS
2. **æ•°æ®å­˜å‚¨**: æ‰©å±•ç°æœ‰papersè¡¨ï¼Œæ–°å¢æœºæ„è¡¨å’Œæ—¥å¿—è¡¨
3. **å»é‡ç­–ç•¥**: åŸºäºæ ‡é¢˜ç›¸ä¼¼åº¦å’ŒIDåŒ¹é…ï¼ˆå¤ç”¨ç°æœ‰é€»è¾‘ï¼‰
4. **å®šæ—¶ä»»åŠ¡**: é›†æˆåˆ°ç°æœ‰è°ƒåº¦ç³»ç»Ÿ

### å¼€å‘é‡ç‚¹
1. **ç½‘ç«™ç»“æ„åˆ†æ**: éœ€è¦ä»”ç»†åˆ†ææ¯ä¸ªç½‘ç«™çš„HTMLç»“æ„
2. **é”™è¯¯å¤„ç†**: å®Œå–„çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
3. **æ•°æ®è´¨é‡**: ç¡®ä¿æŠ“å–çš„æ•°æ®å®Œæ•´å‡†ç¡®
4. **æ€§èƒ½ä¼˜åŒ–**: é¿å…å¯¹ç›®æ ‡ç½‘ç«™é€ æˆå‹åŠ›
5. **å…¼å®¹æ€§**: ç¡®ä¿ä¸å½±å“ç°æœ‰ArXivè®ºæ–‡åŠŸèƒ½

### é£é™©æ§åˆ¶
1. **ç½‘ç«™ç»“æ„å˜åŒ–**: éœ€è¦ç›‘æ§å’ŒåŠæ—¶æ›´æ–°çˆ¬è™«
2. **åçˆ¬è™«æœºåˆ¶**: è®¾ç½®åˆç†çš„è¯·æ±‚é¢‘ç‡å’ŒUser-Agent
3. **æ•°æ®å»é‡**: ç¡®ä¿ä¸é‡å¤å­˜å‚¨ç›¸åŒè®ºæ–‡ï¼ˆå¤ç”¨ç°æœ‰å»é‡é€»è¾‘ï¼‰
4. **æ•°æ®å…¼å®¹**: ç¡®ä¿ç°æœ‰ArXivè®ºæ–‡åŠŸèƒ½ä¸å—å½±å“

---

**æœ€åæ›´æ–°**: 2025-12-19  
**ä¸‹ä¸€æ­¥**: å¼€å§‹é˜¶æ®µ1å¼€å‘

