# 数据库需求分析

## 当前数据存储方式

### 现状
- **存储方式**: JSON 文件 (`docs/cv-arxiv-daily.json`)
- **数据访问**: 每次 API 调用都读取整个 JSON 文件
- **数据更新**: 追加方式更新，使用 `update_json_file()` 函数
- **数据格式**: 
  ```json
  {
    "Manipulation": {
      "paper_id": "|日期|标题|作者|PDF链接|代码链接|"
    }
  }
  ```

### 当前问题

1. **性能问题**
   - 每次请求都要读取整个 JSON 文件（可能很大）
   - 没有索引，查询效率低
   - 随着数据量增长，性能会显著下降

2. **功能限制**
   - 无法进行复杂查询（如按作者、日期范围、关键词搜索）
   - 无法建立数据关系（如论文-作者多对多关系）
   - 无法进行数据统计和分析

3. **并发问题**
   - JSON 文件读写不是原子操作
   - 多用户同时访问可能导致数据不一致
   - 抓取任务和读取操作可能冲突

4. **数据管理**
   - 无法去重（同一篇论文可能被多次抓取）
   - 无法追踪数据变更历史
   - 无法实现软删除或数据归档

## 是否需要数据库？

### ✅ **建议使用数据库**，原因：

1. **数据量增长**
   - 每天抓取 20 篇 × 5 个类别 = 100 篇论文
   - 一个月 = 3000 篇
   - 一年 = 36000 篇
   - JSON 文件会变得非常大，读取效率低

2. **功能需求**
   - 需要搜索功能（按标题、作者、关键词）
   - 需要筛选功能（按日期、类别）
   - 需要统计功能（趋势分析、热门作者等）
   - 需要去重功能（避免重复抓取）

3. **用户体验**
   - 快速响应（数据库查询比读取大 JSON 文件快得多）
   - 支持分页（避免一次性加载所有数据）
   - 支持排序和筛选

4. **可扩展性**
   - 未来可能需要用户收藏、评论等功能
   - 可能需要推荐系统
   - 可能需要数据导出、API 接口等

## 数据库选型建议

### 方案 1: SQLite（推荐用于 MVP）
**优点**:
- 轻量级，无需单独服务器
- 文件数据库，易于部署
- 支持 SQL 查询
- 适合中小规模数据（< 100万条记录）

**缺点**:
- 并发写入性能有限
- 不适合大规模高并发场景

### 方案 2: PostgreSQL（推荐用于生产环境）
**优点**:
- 功能强大，支持复杂查询
- 优秀的并发性能
- 支持全文搜索（PostgreSQL Full-Text Search）
- 成熟稳定

**缺点**:
- 需要单独部署数据库服务器
- 配置相对复杂

### 方案 3: MongoDB（如果数据格式复杂）
**优点**:
- 文档数据库，适合 JSON 数据
- 灵活的 schema

**缺点**:
- 对于这种结构化数据，关系型数据库更合适

## 推荐方案：PostgreSQL + SQLAlchemy（生产环境）

### 当前状态
- ✅ **生产环境已全面升级为PostgreSQL 15+**
- ✅ 所有数据库统一使用PostgreSQL
- ✅ 支持连接池和自动重连机制
- ✅ Docker Compose集成PostgreSQL服务

### 为什么选择 PostgreSQL（生产环境）？
1. **简单**: 无需额外配置，适合快速开发
2. **足够**: 对于论文数据量（几万到几十万条），SQLite 完全够用
3. **迁移容易**: 未来可以轻松迁移到 PostgreSQL

### 数据库设计

```sql
-- 论文表
CREATE TABLE papers (
    id TEXT PRIMARY KEY,              -- ArXiv ID (如: 2512.05107)
    title TEXT NOT NULL,
    authors TEXT,                     -- 作者列表（JSON 或逗号分隔）
    publish_date DATE,
    update_date DATE,
    pdf_url TEXT,
    code_url TEXT,
    abstract TEXT,
    category TEXT,                    -- 类别（Manipulation, VLM等）
    keywords TEXT,                    -- 关键词（JSON）
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 作者表（如果需要建立关系）
CREATE TABLE authors (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT UNIQUE NOT NULL
);

-- 论文-作者关系表
CREATE TABLE paper_authors (
    paper_id TEXT,
    author_id INTEGER,
    PRIMARY KEY (paper_id, author_id),
    FOREIGN KEY (paper_id) REFERENCES papers(id),
    FOREIGN KEY (author_id) REFERENCES authors(id)
);

-- 索引
CREATE INDEX idx_papers_category ON papers(category);
CREATE INDEX idx_papers_date ON papers(publish_date);
CREATE INDEX idx_papers_title ON papers(title);
```

## 迁移计划

### 阶段 1: 添加数据库支持（保持 JSON 兼容）
1. 创建数据库模型（SQLAlchemy）
2. 实现数据迁移脚本（JSON → Database）
3. 修改 API 使用数据库查询
4. 保持 JSON 文件作为备份

### 阶段 2: 完全迁移到数据库
1. 移除 JSON 文件依赖
2. 优化查询性能
3. 添加缓存层（Redis，可选）

## 结论

**强烈建议使用数据库**，原因：
1. ✅ 数据量会持续增长
2. ✅ 需要查询和搜索功能
3. ✅ 需要更好的性能和并发支持
4. ✅ 为未来功能扩展做准备

**推荐实现**：
- 使用 SQLite + SQLAlchemy（开发阶段）
- 未来可迁移到 PostgreSQL（生产环境）

