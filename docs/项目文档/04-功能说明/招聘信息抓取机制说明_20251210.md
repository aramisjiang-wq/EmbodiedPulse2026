# 招聘信息抓取机制说明

**创建时间**：2025年12月10日  
**目的**：详细说明招聘信息是如何抓取的

---

## 📋 概述

招聘信息**不是通过爬取GitHub网页**获取的，而是通过**GitHub API**获取README.md文件内容，然后解析其中的招聘信息。

---

## 🔍 抓取流程

### 1. 数据源

**GitHub仓库**：`StarCycle/Awesome-Embodied-AI-Job`

这是一个专门收集具身智能（Embodied AI）相关招聘信息的开源仓库。

**仓库地址**：https://github.com/StarCycle/Awesome-Embodied-AI-Job

---

### 2. 抓取方式：GitHub API（非网页爬取）

#### ✅ 使用GitHub API的优势

1. **合法合规**：使用官方API，不违反GitHub服务条款
2. **稳定可靠**：API有完善的错误处理和重试机制
3. **性能更好**：直接获取文件内容，无需解析HTML
4. **速率限制友好**：有明确的速率限制说明，可以合理控制请求频率

#### ❌ 不使用网页爬取的原因

1. **违反服务条款**：GitHub明确禁止自动化爬取网页
2. **不稳定**：网页结构可能变化，导致解析失败
3. **效率低**：需要下载整个HTML页面，然后解析
4. **容易被封**：频繁请求可能触发反爬虫机制

---

### 3. 具体实现步骤

#### 步骤1：通过GitHub API获取README.md

```python
# 使用GitHub REST API
url = "https://api.github.com/repos/StarCycle/Awesome-Embodied-AI-Job/readme"

# API返回Base64编码的内容
response = requests.get(url, headers={
    'Accept': 'application/vnd.github.v3+json',
    'User-Agent': 'Embodied-AI-Daily/1.0'
})

# 解码获取Markdown内容
content = base64.b64decode(data['content']).decode('utf-8')
```

**关键点**：
- 使用GitHub官方REST API
- 返回的是Base64编码的Markdown文件内容
- 有重试机制（最多3次）
- 处理速率限制（403错误时指数退避）

---

#### 步骤2：提取"Rolling Recruitment | 滚动招聘"部分

README.md文件包含多个部分，我们需要提取其中的"滚动招聘"部分。

**提取逻辑**：
```python
# 使用正则表达式匹配
pattern = r'##+\s*\d+\.\s*Rolling\s+Recruitment[^\n]*滚动招聘[^\n]*\n(.*?)(?=##+\s+\d+\.\s+|$)'
match = re.search(pattern, markdown_content, re.DOTALL | re.IGNORECASE)
section = match.group(1).strip()
```

**为什么只提取这一部分？**
- 这个部分专门收集"滚动招聘"信息（持续开放的职位）
- 格式统一，便于解析
- 更新频率高，适合日常抓取

---

#### 步骤3：解析招聘条目

**Markdown格式示例**：
```markdown
**[2025.12.7]**
[蔚来(上海) - 多模态大模型/VLA/世界模型 - 全职](https://mp.weixin.qq.com/s/...)

**[2025.12.7]**
国家地方共建人形机器人创新中心 - 2025校招/社招集中招聘
```

**解析逻辑**：
1. 识别日期格式：`**[2025.12.7]**`
2. 提取链接格式：`[文本](URL)`
3. 解析标题格式：`公司(地点) - 职位描述 - 职位类型`
4. 提取公司、地点、职位类型等信息

**解析结果示例**：
```python
{
    'title': '蔚来(上海) - 多模态大模型/VLA/世界模型 - 全职',
    'description': '多模态大模型/VLA/世界模型',
    'link': 'https://mp.weixin.qq.com/s/...',
    'update_date': '2025.12.7',
    'source_date': '2025.12.7',
    'company': '蔚来',
    'location': '上海',
    'job_type': '全职'
}
```

---

#### 步骤4：保存到数据库

将解析后的招聘信息保存到独立的招聘信息数据库（`jobs.db`）。

**去重策略**：
- 基于 `link + source_date`（如果有链接）
- 或基于 `title + source_date`（如果没有链接）

**保存状态**：
- `created`：新建记录
- `updated`：更新现有记录
- `skipped`：跳过（已存在且无变化）
- `error`：保存失败

---

## 📊 数据流程

```
GitHub仓库 (StarCycle/Awesome-Embodied-AI-Job)
    ↓
GitHub API (获取README.md)
    ↓
Base64解码 (获取Markdown内容)
    ↓
正则表达式提取 (滚动招聘部分)
    ↓
解析招聘条目 (日期、标题、链接、公司等)
    ↓
保存到数据库 (jobs.db)
    ↓
前端展示 (通过/api/jobs接口)
```

---

## 🔧 技术实现

### 核心文件

1. **`github_jobs_client.py`** - GitHub API客户端
   - `fetch_readme_from_github()` - 获取README内容
   - `extract_rolling_recruitment_section()` - 提取滚动招聘部分
   - `parse_jobs_from_section()` - 解析招聘信息

2. **`save_jobs_to_db.py`** - 数据库保存逻辑
   - `save_job_to_db()` - 保存单条招聘信息
   - `batch_save_jobs()` - 批量保存

3. **`fetch_jobs.py`** - 主入口脚本
   - `fetch_and_save_jobs()` - 完整的抓取和保存流程

---

## ⚠️ 注意事项

### 1. GitHub API速率限制

**未认证请求**：每小时60次请求  
**认证请求**：每小时5000次请求

**当前实现**：
- 使用未认证请求（足够使用）
- 有重试机制和指数退避
- 单次抓取只请求1次API

### 2. 数据格式变化

如果GitHub仓库的README格式发生变化，解析逻辑可能需要调整。

**建议**：
- 定期检查抓取是否成功
- 监控错误日志
- 如果格式变化，及时更新解析逻辑

### 3. 数据准确性

招聘信息来自社区维护的GitHub仓库，准确性依赖于：
- 仓库维护者的更新频率
- 信息源的可靠性
- 解析逻辑的准确性

---

## 🎯 总结

**招聘信息抓取方式**：
- ✅ **使用GitHub API**（官方、合法、稳定）
- ❌ **不是网页爬取**（避免违反服务条款）

**数据来源**：
- GitHub仓库：`StarCycle/Awesome-Embodied-AI-Job`
- 提取部分：README.md中的"Rolling Recruitment | 滚动招聘"部分

**抓取频率**：
- 可通过定时任务配置（如每小时一次）
- 也可手动触发（点击"刷新全局数据"按钮）

**优势**：
1. 合法合规，使用官方API
2. 稳定可靠，有完善的错误处理
3. 性能优秀，直接获取文件内容
4. 易于维护，格式统一便于解析

---

**最后更新**：2025年12月10日  
**维护者**：AI开发助手





