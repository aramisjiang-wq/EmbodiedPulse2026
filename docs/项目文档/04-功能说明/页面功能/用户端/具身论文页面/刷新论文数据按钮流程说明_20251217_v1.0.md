# "刷新论文数据"按钮完整流程说明

## 一、流程概述

**不是简单的"前端到数据库的API同步"！**

实际流程是：
1. **前端触发** → 2. **后端执行抓取脚本** → 3. **从ArXiv API抓取数据** → 4. **保存到数据库** → 5. **前端重新加载数据**

---

## 二、详细流程

### 2.1 前端触发（templates/index.html + static/js/app.js）

**按钮定义**:
```html
<button id="refreshPapersBtn" class="btn btn-refresh">
    <i class="fas fa-sync-alt"></i> 刷新论文数据
</button>
```

**JavaScript事件处理** (`static/js/app.js`):
```javascript
const refreshPapersBtn = document.getElementById('refreshPapersBtn');
refreshPapersBtn.addEventListener('click', async function() {
    // 1. 调用后端API触发抓取
    const response = await fetch('/api/fetch', {
        method: 'POST',
        headers: {'Content-Type': 'application/json'}
    });
    
    // 2. 轮询抓取状态
    const checkStatus = async () => {
        const statusResponse = await fetch('/api/fetch-status');
        const statusResult = await statusResponse.json();
        
        if (!statusResult.running) {
            // 3. 抓取完成，重新加载数据
            loadPapers(true);
        } else {
            // 继续轮询
            setTimeout(checkStatus, 2000);
        }
    };
});
```

---

### 2.2 后端API处理（app.py）

**API路由**: `/api/fetch` (POST)

**处理逻辑**:
```python
@app.route('/api/fetch', methods=['POST'])
def trigger_fetch():
    """触发论文抓取 - 通过命令行执行 python3 fetch_new_data.py --papers"""
    
    def fetch_task():
        # 在后台线程中执行抓取脚本
        script_path = os.path.join(os.path.dirname(__file__), 'fetch_new_data.py')
        process = subprocess.Popen(
            [sys.executable, script_path, '--papers'],
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True
        )
        
        # 解析输出，更新状态
        for line in process.stdout:
            # 更新 fetch_status
            fetch_status['message'] = f'正在抓取 {keyword}...'
            fetch_status['progress'] = progress
    
    # 在新线程中启动抓取任务
    thread = threading.Thread(target=fetch_task)
    thread.start()
    
    return jsonify({
        'success': True,
        'message': '论文抓取任务已启动'
    })
```

**状态查询API**: `/api/fetch-status` (GET)
```python
@app.route('/api/fetch-status')
def get_fetch_status():
    """获取抓取任务状态"""
    with fetch_status_lock:
        return jsonify(fetch_status)
```

---

### 2.3 抓取脚本执行（fetch_new_data.py）

**脚本**: `fetch_new_data.py --papers`

**执行流程**:
```python
def fetch_papers():
    # 1. 加载配置
    config = load_config('config.yaml')
    config['days_back'] = 21  # 抓取最近21天的论文
    
    # 2. 调用 daily_arxiv.py 的 demo() 函数
    demo(**config)
    
    # 3. demo() 函数会：
    #    - 遍历 config.yaml 中的每个关键词
    #    - 使用检索词查询 ArXiv API
    #    - 获取匹配的论文
    #    - 调用 save_paper_to_db() 保存到数据库
```

---

### 2.4 ArXiv API查询（daily_arxiv.py）

**查询流程**:
```python
def get_daily_papers(topic, query, max_results=100, days_back=21):
    # 1. 构建ArXiv查询
    date_filter = f"submittedDate:[{start_date} TO {end_date}]"
    full_query = f"({query}) AND {date_filter}"
    
    # 2. 执行ArXiv API查询
    search = arxiv.Search(
        query=full_query,
        max_results=max_results,
        sort_by=arxiv.SortCriterion.SubmittedDate
    )
    results = list(client.results(search))
    
    # 3. 返回论文列表
    return papers
```

---

### 2.5 保存到数据库（save_paper_to_db.py）

**保存流程**:
```python
def save_paper_to_db(paper_data, category, ...):
    # 1. 去重检查（基于ID和标题相似度）
    # 2. 自动分类（如果需要）
    # 3. 保存到数据库
    paper = Paper(
        id=paper_id,
        title=title,
        category=normalized_category,
        ...
    )
    session.add(paper)
    session.commit()
```

---

### 2.6 前端重新加载数据（static/js/app.js）

**加载流程**:
```javascript
async function loadPapers(forceRefresh = false) {
    // 1. 调用后端API获取论文数据
    const response = await fetch('/api/papers?force=' + (forceRefresh ? '1' : '0'));
    const result = await response.json();
    
    // 2. 处理数据并渲染
    papersData = normalizePapersResponse(result.data);
    renderPapers(papersData);
}
```

**API路由**: `/api/papers` (GET)
```python
@app.route('/api/papers')
def get_papers():
    """获取论文列表API（使用数据库）"""
    # 从数据库查询所有论文
    papers = session.query(Paper).order_by(Paper.publish_date.desc()).all()
    
    # 按三层标签组织数据
    nested = build_nested_papers(papers)
    
    return jsonify({
        'success': True,
        'data': nested,
        'last_update': last_update,
        'total_count': total_count
    })
```

---

## 三、完整流程图

```
┌─────────────────────────────────────────────────────────────┐
│ 1. 用户点击"刷新论文数据"按钮                                 │
│    (templates/index.html)                                   │
└──────────────────┬──────────────────────────────────────────┘
                   │
                   ▼
┌─────────────────────────────────────────────────────────────┐
│ 2. 前端JavaScript调用 /api/fetch (POST)                      │
│    (static/js/app.js)                                       │
│                                                              │
│    fetch('/api/fetch', { method: 'POST' })                 │
└──────────────────┬──────────────────────────────────────────┘
                   │
                   ▼
┌─────────────────────────────────────────────────────────────┐
│ 3. 后端启动后台线程执行抓取脚本                                │
│    (app.py → trigger_fetch())                                │
│                                                              │
│    subprocess.Popen(['python3', 'fetch_new_data.py', '--papers']) │
└──────────────────┬──────────────────────────────────────────┘
                   │
                   ▼
┌─────────────────────────────────────────────────────────────┐
│ 4. 抓取脚本执行 (fetch_new_data.py)                          │
│                                                              │
│    - 加载 config.yaml 配置                                   │
│    - 调用 daily_arxiv.py 的 demo() 函数                      │
└──────────────────┬──────────────────────────────────────────┘
                   │
                   ▼
┌─────────────────────────────────────────────────────────────┐
│ 5. ArXiv API查询 (daily_arxiv.py)                           │
│                                                              │
│    - 遍历 config.yaml 中的每个关键词                         │
│    - 使用检索词构建ArXiv查询                                 │
│    - 调用ArXiv API获取匹配的论文                             │
└──────────────────┬──────────────────────────────────────────┘
                   │
                   ▼
┌─────────────────────────────────────────────────────────────┐
│ 6. 保存到数据库 (save_paper_to_db.py)                        │
│                                                              │
│    - 去重检查（ID + 标题相似度）                              │
│    - 自动分类（如果需要）                                    │
│    - 保存到 papers.db                                        │
└──────────────────┬──────────────────────────────────────────┘
                   │
                   ▼
┌─────────────────────────────────────────────────────────────┐
│ 7. 前端轮询抓取状态 (/api/fetch-status)                      │
│    (static/js/app.js)                                       │
│                                                              │
│    - 每2秒轮询一次状态                                        │
│    - 显示抓取进度                                            │
│    - 等待抓取完成                                            │
└──────────────────┬──────────────────────────────────────────┘
                   │
                   ▼
┌─────────────────────────────────────────────────────────────┐
│ 8. 抓取完成，前端重新加载数据                                  │
│    (static/js/app.js → loadPapers())                        │
│                                                              │
│    - 调用 /api/papers (GET)                                  │
│    - 从数据库获取最新论文数据                                 │
│    - 重新渲染页面                                            │
└─────────────────────────────────────────────────────────────┘
```

---

## 四、关键API端点

### 4.1 触发抓取
- **端点**: `/api/fetch` (POST)
- **功能**: 启动后台抓取任务
- **返回**: `{ "success": true, "message": "论文抓取任务已启动" }`

### 4.2 查询抓取状态
- **端点**: `/api/fetch-status` (GET)
- **功能**: 获取当前抓取任务状态
- **返回**: 
  ```json
  {
    "running": true,
    "message": "正在抓取 Perception-2D (1/20)...",
    "progress": 1,
    "total": 20,
    "current_keyword": "Perception-2D",
    "last_update": "2025-12-17 12:00:00"
  }
  ```

### 4.3 获取论文数据
- **端点**: `/api/papers` (GET)
- **功能**: 从数据库获取所有论文数据
- **返回**: 
  ```json
  {
    "success": true,
    "data": { /* 嵌套的论文数据 */ },
    "last_update": "2025-12-17 12:00:00",
    "total_count": 1000,
    "new_papers_count": 50
  }
  ```

---

## 五、总结

### 5.1 不是简单的"前端到数据库的API同步"

**实际流程**:
1. ✅ 前端触发后端执行抓取脚本
2. ✅ 后端脚本从ArXiv API抓取数据
3. ✅ 脚本将数据保存到数据库
4. ✅ 前端从数据库读取最新数据并刷新页面

### 5.2 数据流向

```
ArXiv API → 抓取脚本 → 数据库 → 后端API → 前端页面
```

**不是**:
```
前端 → 数据库API → 同步
```

### 5.3 关键特点

1. **异步执行**: 抓取任务在后台线程中执行，不阻塞前端
2. **状态轮询**: 前端通过轮询 `/api/fetch-status` 获取抓取进度
3. **自动刷新**: 抓取完成后，前端自动重新加载数据
4. **实时反馈**: 显示抓取进度和状态信息

---

## 六、与B站数据刷新的对比

### B站数据刷新（简单同步）
```
前端 → /api/bilibili/all?force=1 → 数据库 → 返回数据 → 前端刷新
```
- 直接从数据库读取数据
- 不涉及外部API抓取
- 同步操作，立即返回

### 论文数据刷新（复杂流程）
```
前端 → /api/fetch → 后台脚本 → ArXiv API → 数据库 → /api/papers → 前端刷新
```
- 需要从ArXiv API抓取数据
- 异步执行，需要轮询状态
- 涉及多个步骤和外部API调用

---

## 七、常见问题

### Q1: 为什么不是简单的API同步？
**A**: 因为需要从ArXiv API抓取新数据，这是一个耗时的外部API调用过程，不能同步执行。

### Q2: 抓取需要多长时间？
**A**: 取决于关键词数量和ArXiv API响应速度，通常需要几分钟到十几分钟。

### Q3: 如何知道抓取是否完成？
**A**: 前端会轮询 `/api/fetch-status`，当 `running` 为 `false` 时表示完成。

### Q4: 抓取失败怎么办？
**A**: 前端会显示错误信息，可以查看浏览器控制台或服务器日志获取详细错误信息。

