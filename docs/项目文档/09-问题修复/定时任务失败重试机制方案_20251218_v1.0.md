# å®šæ—¶ä»»åŠ¡å¤±è´¥é‡è¯•æœºåˆ¶æ–¹æ¡ˆ

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**åˆ›å»ºæ—¥æœŸ**: 2025-12-18  
**é—®é¢˜æè¿°**: å®šæ—¶ä»»åŠ¡ç¼ºå°‘å¤±è´¥é‡è¯•æœºåˆ¶  
**ä¼˜å…ˆçº§**: ä¸­

---

## ğŸ“‹ é—®é¢˜åˆ†æ

### å½“å‰çŠ¶æ€

#### 1. å®šæ—¶ä»»åŠ¡å®ç°æ–¹å¼
- ä½¿ç”¨ APScheduler çš„ `BackgroundScheduler`
- å®šæ—¶ä»»åŠ¡å‡½æ•°å†…éƒ¨æœ‰ `try-except` æ•è·å¼‚å¸¸
- **é—®é¢˜**ï¼šåªè®°å½•æ—¥å¿—ï¼Œå¤±è´¥åä¸ä¼šè‡ªåŠ¨é‡è¯•

#### 2. ç°æœ‰å®šæ—¶ä»»åŠ¡åˆ—è¡¨
1. **è®ºæ–‡æŠ“å–ä»»åŠ¡** (`scheduled_fetch`)
   - æ‰§è¡Œé¢‘ç‡ï¼šæ¯å°æ—¶æ•´ç‚¹
   - å¤±è´¥å¤„ç†ï¼šä»…è®°å½•é”™è¯¯æ—¥å¿—

2. **å…¨é‡è®ºæ–‡æŠ“å–ä»»åŠ¡** (`scheduled_full_fetch`)
   - æ‰§è¡Œé¢‘ç‡ï¼šæ¯å¤©å‡Œæ™¨2ç‚¹
   - å¤±è´¥å¤„ç†ï¼šä»…è®°å½•é”™è¯¯æ—¥å¿—

3. **æ‹›è˜ä¿¡æ¯æŠ“å–ä»»åŠ¡** (`scheduled_fetch_jobs`)
   - æ‰§è¡Œé¢‘ç‡ï¼šæ¯å°æ—¶æ•´ç‚¹
   - å¤±è´¥å¤„ç†ï¼šä»…è®°å½•é”™è¯¯æ—¥å¿—

4. **æ–°é—»ä¿¡æ¯æŠ“å–ä»»åŠ¡** (`scheduled_fetch_news`)
   - æ‰§è¡Œé¢‘ç‡ï¼šæ¯å°æ—¶æ•´ç‚¹
   - å¤±è´¥å¤„ç†ï¼šä»…è®°å½•é”™è¯¯æ—¥å¿—

5. **Bç«™æ•°æ®æŠ“å–ä»»åŠ¡** (`scheduled_fetch_bilibili`)
   - æ‰§è¡Œé¢‘ç‡ï¼šæ¯6å°æ—¶
   - å¤±è´¥å¤„ç†ï¼šä»…è®°å½•é”™è¯¯æ—¥å¿—

6. **Semantic Scholaræ›´æ–°ä»»åŠ¡** (3ä¸ª)
   - æ¯å¤©å‡Œæ™¨3ç‚¹ï¼šæ›´æ–°æœ€è¿‘30å¤©
   - æ¯å‘¨æ—¥å‡Œæ™¨3ç‚¹ï¼šæ›´æ–°æœ€è¿‘90å¤©
   - æ¯æœˆ1æ—¥å‡Œæ™¨3ç‚¹ï¼šæ›´æ–°æ‰€æœ‰è®ºæ–‡
   - å¤±è´¥å¤„ç†ï¼šä»…è®°å½•é”™è¯¯æ—¥å¿—

### é—®é¢˜å½±å“

1. **æ•°æ®æ›´æ–°ä¸åŠæ—¶**
   - ä»»åŠ¡å¤±è´¥åï¼Œéœ€è¦ç­‰åˆ°ä¸‹æ¬¡å®šæ—¶æ‰§è¡Œ
   - å¯èƒ½å¯¼è‡´æ•°æ®ç¼ºå¤±

2. **æ•…éšœéš¾ä»¥å‘ç°**
   - åªæœ‰æ—¥å¿—è®°å½•ï¼Œæ²¡æœ‰å‘Šè­¦æœºåˆ¶
   - éœ€è¦äººå·¥æŸ¥çœ‹æ—¥å¿—æ‰èƒ½å‘ç°é—®é¢˜

3. **ä¸´æ—¶æ•…éšœæ— æ³•æ¢å¤**
   - ç½‘ç»œä¸´æ—¶æ•…éšœã€APIä¸´æ—¶é™æµç­‰
   - æ— æ³•è‡ªåŠ¨é‡è¯•ï¼Œéœ€è¦ç­‰å¾…ä¸‹æ¬¡æ‰§è¡Œ

---

## ğŸ¯ è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆ1ï¼šAPSchedulerå†…ç½®é‡è¯•æœºåˆ¶ï¼ˆæ¨èï¼‰

#### ä¼˜ç‚¹
- åˆ©ç”¨APSchedulerå†…ç½®åŠŸèƒ½ï¼Œå®ç°ç®€å•
- æ”¯æŒå¤šç§é‡è¯•ç­–ç•¥
- é…ç½®çµæ´»

#### å®ç°æ–¹å¼
ä½¿ç”¨APSchedulerçš„ `max_instances`ã€`misfire_grace_time` å’Œè‡ªå®šä¹‰é‡è¯•è£…é¥°å™¨

#### ä»£ç å®ç°

```python
from functools import wraps
import time
import logging

logger = logging.getLogger(__name__)

def retry_on_failure(max_retries=3, retry_delay=60, backoff_factor=2):
    """
    å®šæ—¶ä»»åŠ¡å¤±è´¥é‡è¯•è£…é¥°å™¨
    
    Args:
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        retry_delay: åˆå§‹é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
        backoff_factor: é€€é¿å› å­ï¼ˆæ¯æ¬¡é‡è¯•å»¶è¿Ÿæ—¶é—´ç¿»å€ï¼‰
    """
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            last_exception = None
            
            for attempt in range(max_retries + 1):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    last_exception = e
                    if attempt < max_retries:
                        delay = retry_delay * (backoff_factor ** attempt)
                        logger.warning(
                            f"å®šæ—¶ä»»åŠ¡ {func.__name__} å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries + 1}): {e}"
                        )
                        logger.info(f"ç­‰å¾… {delay} ç§’åé‡è¯•...")
                        time.sleep(delay)
                    else:
                        logger.error(
                            f"å®šæ—¶ä»»åŠ¡ {func.__name__} å¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡: {e}"
                        )
                        # è®°å½•å¤±è´¥åˆ°æ•°æ®åº“æˆ–å‘é€å‘Šè­¦
                        raise
                else:
                    # æˆåŠŸæ‰§è¡Œ
                    if attempt > 0:
                        logger.info(f"å®šæ—¶ä»»åŠ¡ {func.__name__} é‡è¯•æˆåŠŸ (ç¬¬ {attempt + 1} æ¬¡å°è¯•)")
                    break
            
            if last_exception:
                raise last_exception
                
        return wrapper
    return decorator
```

#### ä½¿ç”¨ç¤ºä¾‹

```python
@retry_on_failure(max_retries=3, retry_delay=60, backoff_factor=2)
def scheduled_fetch():
    """å®šæ—¶æŠ“å–è®ºæ–‡ä»»åŠ¡"""
    global fetch_status
    if fetch_status['running']:
        logger.info("å®šæ—¶æŠ“å–ä»»åŠ¡è·³è¿‡ï¼šå·²æœ‰ä»»åŠ¡æ­£åœ¨è¿è¡Œ")
        return
    
    logger.info("å¼€å§‹æ‰§è¡Œå®šæ—¶è®ºæ–‡æŠ“å–ä»»åŠ¡...")
    from fetch_new_data import fetch_papers
    fetch_papers()
    logger.info("å®šæ—¶è®ºæ–‡æŠ“å–ä»»åŠ¡å®Œæˆ")
```

---

### æ–¹æ¡ˆ2ï¼šä»»åŠ¡çŠ¶æ€è·Ÿè¸ª + å»¶è¿Ÿé‡è¯•

#### ä¼˜ç‚¹
- å¯ä»¥è®°å½•ä»»åŠ¡æ‰§è¡Œå†å²
- æ”¯æŒæ›´å¤æ‚çš„é‡è¯•ç­–ç•¥
- å¯ä»¥ç»Ÿè®¡ä»»åŠ¡æˆåŠŸç‡

#### å®ç°æ–¹å¼
åœ¨æ•°æ®åº“ä¸­è®°å½•ä»»åŠ¡æ‰§è¡ŒçŠ¶æ€ï¼Œå¤±è´¥åå»¶è¿Ÿé‡è¯•

#### æ•°æ®åº“è¡¨è®¾è®¡

```sql
CREATE TABLE scheduled_job_executions (
    id SERIAL PRIMARY KEY,
    job_id VARCHAR(100) NOT NULL,
    job_name VARCHAR(200) NOT NULL,
    status VARCHAR(20) NOT NULL,  -- 'running', 'success', 'failed', 'retrying'
    started_at TIMESTAMP NOT NULL,
    completed_at TIMESTAMP,
    retry_count INTEGER DEFAULT 0,
    max_retries INTEGER DEFAULT 3,
    error_message TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_job_id_status ON scheduled_job_executions(job_id, status);
CREATE INDEX idx_started_at ON scheduled_job_executions(started_at);
```

#### ä»£ç å®ç°

```python
from datetime import datetime, timedelta
from sqlalchemy import Column, Integer, String, Text, DateTime, Index
from database import db

class ScheduledJobExecution(db.Model):
    """å®šæ—¶ä»»åŠ¡æ‰§è¡Œè®°å½•"""
    __tablename__ = 'scheduled_job_executions'
    
    id = Column(Integer, primary_key=True)
    job_id = Column(String(100), nullable=False, index=True)
    job_name = Column(String(200), nullable=False)
    status = Column(String(20), nullable=False, index=True)  # running, success, failed, retrying
    started_at = Column(DateTime, nullable=False, index=True)
    completed_at = Column(DateTime)
    retry_count = Column(Integer, default=0)
    max_retries = Column(Integer, default=3)
    error_message = Column(Text)
    created_at = Column(DateTime, default=datetime.now)

def execute_with_retry(job_id, job_name, func, max_retries=3, retry_delay=60):
    """
    æ‰§è¡Œå®šæ—¶ä»»åŠ¡ï¼Œå¸¦é‡è¯•æœºåˆ¶
    
    Args:
        job_id: ä»»åŠ¡ID
        job_name: ä»»åŠ¡åç§°
        func: è¦æ‰§è¡Œçš„å‡½æ•°
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        retry_delay: é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
    """
    execution = ScheduledJobExecution(
        job_id=job_id,
        job_name=job_name,
        status='running',
        started_at=datetime.now()
    )
    db.session.add(execution)
    db.session.commit()
    
    last_exception = None
    
    for attempt in range(max_retries + 1):
        try:
            result = func()
            execution.status = 'success'
            execution.completed_at = datetime.now()
            execution.retry_count = attempt
            db.session.commit()
            return result
        except Exception as e:
            last_exception = e
            execution.retry_count = attempt
            execution.error_message = str(e)
            
            if attempt < max_retries:
                execution.status = 'retrying'
                db.session.commit()
                
                delay = retry_delay * (2 ** attempt)  # æŒ‡æ•°é€€é¿
                logger.warning(
                    f"å®šæ—¶ä»»åŠ¡ {job_name} å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries + 1}): {e}"
                )
                logger.info(f"ç­‰å¾… {delay} ç§’åé‡è¯•...")
                time.sleep(delay)
            else:
                execution.status = 'failed'
                execution.completed_at = datetime.now()
                db.session.commit()
                
                logger.error(f"å®šæ—¶ä»»åŠ¡ {job_name} å¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡: {e}")
                # å‘é€å‘Šè­¦
                send_alert(job_name, str(e))
                raise
    
    if last_exception:
        raise last_exception
```

---

### æ–¹æ¡ˆ3ï¼šæ··åˆæ–¹æ¡ˆï¼ˆæ¨èç”¨äºç”Ÿäº§ç¯å¢ƒï¼‰

#### è®¾è®¡æ€è·¯
- **çŸ­æœŸé‡è¯•**ï¼šä½¿ç”¨è£…é¥°å™¨ï¼Œç«‹å³é‡è¯•ï¼ˆ1-3æ¬¡ï¼‰
- **é•¿æœŸé‡è¯•**ï¼šä½¿ç”¨æ•°æ®åº“è®°å½•ï¼Œå»¶è¿Ÿé‡è¯•ï¼ˆå¤±è´¥å1å°æ—¶ã€6å°æ—¶ã€24å°æ—¶ï¼‰

#### å®ç°æ¶æ„

```
å®šæ—¶ä»»åŠ¡æ‰§è¡Œ
    â†“
è£…é¥°å™¨é‡è¯•ï¼ˆç«‹å³ï¼Œ1-3æ¬¡ï¼‰
    â†“ å¤±è´¥
è®°å½•åˆ°æ•°æ®åº“
    â†“
å»¶è¿Ÿé‡è¯•ä»»åŠ¡ï¼ˆ1å°æ—¶åï¼‰
    â†“ å¤±è´¥
å»¶è¿Ÿé‡è¯•ä»»åŠ¡ï¼ˆ6å°æ—¶åï¼‰
    â†“ å¤±è´¥
å»¶è¿Ÿé‡è¯•ä»»åŠ¡ï¼ˆ24å°æ—¶åï¼‰
    â†“ å¤±è´¥
å‘é€å‘Šè­¦
```

---

## ğŸ”§ æ¨èå®ç°æ–¹æ¡ˆ

### é€‰æ‹©ï¼šæ–¹æ¡ˆ1ï¼ˆè£…é¥°å™¨é‡è¯•ï¼‰+ å‘Šè­¦æœºåˆ¶

#### åŸå› 
1. **å®ç°ç®€å•**ï¼šåªéœ€æ·»åŠ è£…é¥°å™¨ï¼Œæ— éœ€ä¿®æ”¹æ•°æ®åº“
2. **ç«‹å³ç”Ÿæ•ˆ**ï¼šå¤±è´¥åç«‹å³é‡è¯•ï¼Œæ— éœ€ç­‰å¾…
3. **é…ç½®çµæ´»**ï¼šä¸åŒä»»åŠ¡å¯ä»¥é…ç½®ä¸åŒçš„é‡è¯•ç­–ç•¥
4. **æ˜“äºç»´æŠ¤**ï¼šä»£ç æ¸…æ™°ï¼Œæ˜“äºç†è§£å’Œç»´æŠ¤

#### å®Œæ•´å®ç°ä»£ç 

```python
# åœ¨ app.py ä¸­æ·»åŠ 

from functools import wraps
import time
import logging
from datetime import datetime

logger = logging.getLogger(__name__)

def retry_on_failure(max_retries=3, retry_delay=60, backoff_factor=2, alert_on_final_failure=True):
    """
    å®šæ—¶ä»»åŠ¡å¤±è´¥é‡è¯•è£…é¥°å™¨
    
    Args:
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤3æ¬¡ï¼‰
        retry_delay: åˆå§‹é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼Œé»˜è®¤60ç§’ï¼‰
        backoff_factor: é€€é¿å› å­ï¼ˆé»˜è®¤2ï¼Œå³æ¯æ¬¡å»¶è¿Ÿæ—¶é—´ç¿»å€ï¼‰
        alert_on_final_failure: æœ€ç»ˆå¤±è´¥åæ˜¯å¦å‘é€å‘Šè­¦ï¼ˆé»˜è®¤Trueï¼‰
    """
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            last_exception = None
            task_name = func.__name__
            
            for attempt in range(max_retries + 1):
                try:
                    result = func(*args, **kwargs)
                    if attempt > 0:
                        logger.info(f"âœ… å®šæ—¶ä»»åŠ¡ {task_name} é‡è¯•æˆåŠŸ (ç¬¬ {attempt + 1} æ¬¡å°è¯•)")
                    return result
                except Exception as e:
                    last_exception = e
                    error_msg = str(e)
                    
                    if attempt < max_retries:
                        delay = retry_delay * (backoff_factor ** attempt)
                        logger.warning(
                            f"âš ï¸  å®šæ—¶ä»»åŠ¡ {task_name} å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries + 1}): {error_msg}"
                        )
                        logger.info(f"â³ ç­‰å¾… {delay} ç§’åé‡è¯•...")
                        time.sleep(delay)
                    else:
                        logger.error(
                            f"âŒ å®šæ—¶ä»»åŠ¡ {task_name} å¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡: {error_msg}"
                        )
                        import traceback
                        logger.error(traceback.format_exc())
                        
                        # å‘é€å‘Šè­¦
                        if alert_on_final_failure:
                            send_task_failure_alert(task_name, error_msg, max_retries)
                        raise
            
            if last_exception:
                raise last_exception
                
        return wrapper
    return decorator

def send_task_failure_alert(task_name, error_msg, retry_count):
    """
    å‘é€å®šæ—¶ä»»åŠ¡å¤±è´¥å‘Šè­¦
    
    Args:
        task_name: ä»»åŠ¡åç§°
        error_msg: é”™è¯¯ä¿¡æ¯
        retry_count: é‡è¯•æ¬¡æ•°
    """
    try:
        # è¿™é‡Œå¯ä»¥å®ç°å‘Šè­¦é€»è¾‘ï¼Œæ¯”å¦‚ï¼š
        # 1. å‘é€é‚®ä»¶
        # 2. å‘é€é£ä¹¦æ¶ˆæ¯
        # 3. å†™å…¥å‘Šè­¦æ—¥å¿—
        # 4. è°ƒç”¨å‘Šè­¦API
        
        alert_message = (
            f"ğŸš¨ å®šæ—¶ä»»åŠ¡å¤±è´¥å‘Šè­¦\n"
            f"ä»»åŠ¡åç§°: {task_name}\n"
            f"å¤±è´¥æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
            f"é‡è¯•æ¬¡æ•°: {retry_count}\n"
            f"é”™è¯¯ä¿¡æ¯: {error_msg}\n"
            f"è¯·æ£€æŸ¥ç³»ç»ŸçŠ¶æ€å¹¶åŠæ—¶å¤„ç†ã€‚"
        )
        
        logger.error(f"å‘Šè­¦ä¿¡æ¯: {alert_message}")
        
        # TODO: å®ç°å…·ä½“çš„å‘Šè­¦å‘é€é€»è¾‘
        # ä¾‹å¦‚ï¼šå‘é€é£ä¹¦æ¶ˆæ¯ã€å‘é€é‚®ä»¶ç­‰
        
    except Exception as e:
        logger.error(f"å‘é€å‘Šè­¦å¤±è´¥: {e}")

# ä½¿ç”¨ç¤ºä¾‹
@retry_on_failure(max_retries=3, retry_delay=60, backoff_factor=2)
def scheduled_fetch():
    """å®šæ—¶æŠ“å–è®ºæ–‡ä»»åŠ¡ - å¸¦é‡è¯•æœºåˆ¶"""
    global fetch_status
    if fetch_status['running']:
        logger.info("å®šæ—¶æŠ“å–ä»»åŠ¡è·³è¿‡ï¼šå·²æœ‰ä»»åŠ¡æ­£åœ¨è¿è¡Œ")
        return
    
    logger.info("=" * 60)
    logger.info("å¼€å§‹æ‰§è¡Œå®šæ—¶è®ºæ–‡æŠ“å–ä»»åŠ¡...")
    logger.info("=" * 60)
    
    from fetch_new_data import fetch_papers
    fetch_papers()
    
    logger.info("=" * 60)
    logger.info("å®šæ—¶è®ºæ–‡æŠ“å–ä»»åŠ¡å®Œæˆ")
    logger.info("=" * 60)
```

---

## ğŸ“Š é‡è¯•ç­–ç•¥é…ç½®

### ä¸åŒä»»åŠ¡çš„é‡è¯•ç­–ç•¥

| ä»»åŠ¡ç±»å‹ | æœ€å¤§é‡è¯•æ¬¡æ•° | åˆå§‹å»¶è¿Ÿ | é€€é¿å› å­ | è¯´æ˜ |
|---------|------------|---------|---------|------|
| è®ºæ–‡æŠ“å– | 3 | 60ç§’ | 2 | é‡è¦ä»»åŠ¡ï¼Œéœ€è¦ä¿è¯æ•°æ®æ›´æ–° |
| å…¨é‡è®ºæ–‡æŠ“å– | 2 | 300ç§’ | 2 | è€—æ—¶è¾ƒé•¿ï¼Œå‡å°‘é‡è¯•æ¬¡æ•° |
| æ‹›è˜ä¿¡æ¯ | 3 | 60ç§’ | 2 | é‡è¦ä»»åŠ¡ |
| æ–°é—»ä¿¡æ¯ | 3 | 60ç§’ | 2 | é‡è¦ä»»åŠ¡ |
| Bç«™æ•°æ® | 2 | 300ç§’ | 2 | æœ‰é¢‘ç‡é™åˆ¶ï¼Œå»¶è¿Ÿæ›´é•¿ |
| Semantic Scholar | 2 | 120ç§’ | 2 | APIæœ‰é¢‘ç‡é™åˆ¶ |

### é‡è¯•æ—¶é—´è¡¨ç¤ºä¾‹ï¼ˆè®ºæ–‡æŠ“å–ä»»åŠ¡ï¼‰

- **ç¬¬1æ¬¡å¤±è´¥**ï¼šç­‰å¾… 60ç§’ åé‡è¯•
- **ç¬¬2æ¬¡å¤±è´¥**ï¼šç­‰å¾… 120ç§’ åé‡è¯•
- **ç¬¬3æ¬¡å¤±è´¥**ï¼šç­‰å¾… 240ç§’ åé‡è¯•
- **ç¬¬4æ¬¡å¤±è´¥**ï¼šå‘é€å‘Šè­¦ï¼Œä¸å†é‡è¯•

**æ€»é‡è¯•æ—¶é—´**ï¼šçº¦ 7åˆ†é’Ÿï¼ˆ60 + 120 + 240ï¼‰

---

## ğŸš€ å®æ–½æ­¥éª¤

### æ­¥éª¤1ï¼šæ·»åŠ é‡è¯•è£…é¥°å™¨
1. åœ¨ `app.py` ä¸­æ·»åŠ  `retry_on_failure` è£…é¥°å™¨
2. æ·»åŠ  `send_task_failure_alert` å‘Šè­¦å‡½æ•°

### æ­¥éª¤2ï¼šåº”ç”¨è£…é¥°å™¨
1. ä¸ºæ‰€æœ‰å®šæ—¶ä»»åŠ¡å‡½æ•°æ·»åŠ  `@retry_on_failure` è£…é¥°å™¨
2. æ ¹æ®ä»»åŠ¡ç‰¹ç‚¹é…ç½®ä¸åŒçš„é‡è¯•å‚æ•°

### æ­¥éª¤3ï¼šå®ç°å‘Šè­¦æœºåˆ¶
1. é€‰æ‹©å‘Šè­¦æ–¹å¼ï¼ˆé‚®ä»¶ã€é£ä¹¦ã€æ—¥å¿—ç­‰ï¼‰
2. å®ç° `send_task_failure_alert` å‡½æ•°
3. æµ‹è¯•å‘Šè­¦åŠŸèƒ½

### æ­¥éª¤4ï¼šæµ‹è¯•éªŒè¯
1. æ¨¡æ‹Ÿä»»åŠ¡å¤±è´¥åœºæ™¯
2. éªŒè¯é‡è¯•æœºåˆ¶æ˜¯å¦æ­£å¸¸å·¥ä½œ
3. éªŒè¯å‘Šè­¦æ˜¯å¦æ­£å¸¸å‘é€

### æ­¥éª¤5ï¼šç›‘æ§å’Œä¼˜åŒ–
1. ç›‘æ§ä»»åŠ¡æ‰§è¡Œæƒ…å†µ
2. æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´é‡è¯•ç­–ç•¥
3. ä¼˜åŒ–å‘Šè­¦æœºåˆ¶

---

## ğŸ“ ä»£ç ä¿®æ”¹æ¸…å•

### éœ€è¦ä¿®æ”¹çš„æ–‡ä»¶

1. **app.py**
   - æ·»åŠ  `retry_on_failure` è£…é¥°å™¨
   - æ·»åŠ  `send_task_failure_alert` å‡½æ•°
   - ä¸ºæ‰€æœ‰å®šæ—¶ä»»åŠ¡å‡½æ•°æ·»åŠ è£…é¥°å™¨

### éœ€è¦ä¿®æ”¹çš„å‡½æ•°

1. `scheduled_fetch()` - è®ºæ–‡æŠ“å–ä»»åŠ¡
2. `scheduled_full_fetch()` - å…¨é‡è®ºæ–‡æŠ“å–ä»»åŠ¡
3. `scheduled_fetch_jobs()` - æ‹›è˜ä¿¡æ¯æŠ“å–ä»»åŠ¡
4. `scheduled_fetch_news()` - æ–°é—»ä¿¡æ¯æŠ“å–ä»»åŠ¡
5. `scheduled_fetch_bilibili()` - Bç«™æ•°æ®æŠ“å–ä»»åŠ¡
6. `scheduled_update_recent_semantic_scholar()` - Semantic Scholaræ›´æ–°ï¼ˆæœ€è¿‘30å¤©ï¼‰
7. `scheduled_update_weekly_semantic_scholar()` - Semantic Scholaræ›´æ–°ï¼ˆæœ€è¿‘90å¤©ï¼‰
8. `scheduled_update_monthly_semantic_scholar()` - Semantic Scholaræ›´æ–°ï¼ˆæ‰€æœ‰è®ºæ–‡ï¼‰

---

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **é¿å…é‡å¤æ‰§è¡Œ**
   - é‡è¯•æ—¶æ£€æŸ¥ `fetch_status['running']`ï¼Œé¿å…å¹¶å‘æ‰§è¡Œ
   - ç¡®ä¿ä»»åŠ¡å‡½æ•°æ˜¯å¹‚ç­‰çš„

2. **èµ„æºæ¶ˆè€—**
   - é‡è¯•ä¼šå¢åŠ ç³»ç»Ÿè´Ÿè½½
   - åˆç†è®¾ç½®é‡è¯•æ¬¡æ•°å’Œå»¶è¿Ÿæ—¶é—´

3. **å‘Šè­¦é¢‘ç‡**
   - é¿å…å‘Šè­¦é£æš´
   - å¯ä»¥è€ƒè™‘å‘Šè­¦å»é‡æˆ–é™æµ

4. **æ—¥å¿—è®°å½•**
   - è¯¦ç»†è®°å½•æ¯æ¬¡é‡è¯•çš„ä¿¡æ¯
   - ä¾¿äºé—®é¢˜æ’æŸ¥

---

## ğŸ¯ é¢„æœŸæ•ˆæœ

### æ”¹è¿›å‰
- ä»»åŠ¡å¤±è´¥åï¼Œéœ€è¦ç­‰åˆ°ä¸‹æ¬¡å®šæ—¶æ‰§è¡Œ
- æ•°æ®å¯èƒ½ç¼ºå¤±æ•°å°æ—¶
- éœ€è¦äººå·¥æŸ¥çœ‹æ—¥å¿—æ‰èƒ½å‘ç°é—®é¢˜

### æ”¹è¿›å
- ä»»åŠ¡å¤±è´¥åç«‹å³é‡è¯•ï¼ˆæœ€å¤š3æ¬¡ï¼‰
- ä¸´æ—¶æ•…éšœå¯ä»¥è‡ªåŠ¨æ¢å¤
- æœ€ç»ˆå¤±è´¥åå‘é€å‘Šè­¦ï¼ŒåŠæ—¶é€šçŸ¥ç®¡ç†å‘˜
- æ•°æ®æ›´æ–°æ›´åŠæ—¶ï¼Œç³»ç»Ÿæ›´ç¨³å®š

---

## ğŸ“š å‚è€ƒèµ„æ–™

- [APSchedulerå®˜æ–¹æ–‡æ¡£](https://apscheduler.readthedocs.io/)
- [Pythoné‡è¯•æ¨¡å¼](https://docs.python.org/3/library/functools.html)
- [æŒ‡æ•°é€€é¿ç®—æ³•](https://en.wikipedia.org/wiki/Exponential_backoff)

---

**æ–‡æ¡£ç»´æŠ¤**ï¼šæ ¹æ®å®æ–½æƒ…å†µæ›´æ–°  
**æœ€åæ›´æ–°**ï¼š2025-12-18

