#!/usr/bin/env python3
"""
è¯Šæ–­æ•°æ®é—®é¢˜ï¼šè®ºæ–‡å’Œè§†é¢‘æ•°æ®
"""
import os
import sys
from datetime import datetime, timedelta

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
script_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(script_dir)
sys.path.insert(0, project_root)

# å°è¯•ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒä¸­çš„Pythonï¼ˆå¦‚æœå­˜åœ¨ï¼‰
venv_python = os.path.join(project_root, 'venv', 'bin', 'python3')
if os.path.exists(venv_python):
    # å¦‚æœè™šæ‹Ÿç¯å¢ƒå­˜åœ¨ï¼Œä½†å½“å‰ä¸æ˜¯ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒçš„Pythonï¼Œç»™å‡ºæç¤º
    if sys.executable != venv_python:
        print("âš ï¸  æ£€æµ‹åˆ°è™šæ‹Ÿç¯å¢ƒï¼Œä½†å½“å‰ä½¿ç”¨çš„æ˜¯ç³»ç»ŸPython")
        print(f"   å½“å‰Python: {sys.executable}")
        print(f"   è™šæ‹Ÿç¯å¢ƒPython: {venv_python}")
        print("   å»ºè®®ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒè¿è¡Œ: source venv/bin/activate && python3 scripts/diagnose_data_issues.py")
        print("   æˆ–è€…ç›´æ¥ä½¿ç”¨: venv/bin/python3 scripts/diagnose_data_issues.py")
        print()

from dotenv import load_dotenv

load_dotenv()

print("=" * 60)
print("æ•°æ®é—®é¢˜è¯Šæ–­")
print("=" * 60)
print()

# 1. æ£€æŸ¥è®ºæ–‡æ•°æ®
print("=" * 60)
print("1. å…·èº«è®ºæ–‡æ•°æ®æ£€æŸ¥")
print("=" * 60)
print()

try:
    # æ£€æŸ¥æ•°æ®åº“ç±»å‹
    import os
    database_url = os.getenv('DATABASE_URL', 'sqlite:///./papers.db')
    
    # å¦‚æœæ˜¯PostgreSQLï¼Œæ£€æŸ¥psycopg2æ˜¯å¦å®‰è£…
    if database_url.startswith('postgresql://') or database_url.startswith('postgres://'):
        try:
            import psycopg2
        except ImportError:
            print("âŒ ç¼ºå°‘ psycopg2 æ¨¡å—ï¼ˆPostgreSQLé©±åŠ¨ï¼‰")
            print("   è¯·è¿è¡Œ: bash scripts/install_psycopg2.sh")
            print("   æˆ–è€…: pip install psycopg2-binary")
            raise
    
    from models import get_session, Paper
    
    session = get_session()
    
    # æ€»è®ºæ–‡æ•°
    total_papers = session.query(Paper).count()
    print(f"ğŸ“Š æ€»è®ºæ–‡æ•°: {total_papers} ç¯‡")
    
    # æ£€æŸ¥12æœˆ17æ—¥çš„è®ºæ–‡
    target_date = datetime(2025, 12, 17).date()
    papers_1217 = session.query(Paper).filter(Paper.publish_date == target_date).count()
    print(f"ğŸ“… 2025-12-17 è®ºæ–‡æ•°: {papers_1217} ç¯‡")
    
    # æ£€æŸ¥æœ€è¿‘7å¤©çš„è®ºæ–‡
    seven_days_ago = datetime.now().date() - timedelta(days=7)
    recent_papers = session.query(Paper).filter(Paper.publish_date >= seven_days_ago).count()
    print(f"ğŸ“… æœ€è¿‘7å¤©è®ºæ–‡æ•°: {recent_papers} ç¯‡")
    
    # æ£€æŸ¥æœ€æ–°è®ºæ–‡çš„æ—¥æœŸ
    latest_paper = session.query(Paper).order_by(Paper.publish_date.desc()).first()
    if latest_paper:
        print(f"ğŸ“… æœ€æ–°è®ºæ–‡æ—¥æœŸ: {latest_paper.publish_date}")
        print(f"   æ ‡é¢˜: {latest_paper.title[:50]}...")
    else:
        print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°è®ºæ–‡æ•°æ®")
    
    # æ£€æŸ¥ä»Šå¤©åˆ›å»ºçš„è®ºæ–‡ï¼ˆå¯èƒ½æ˜¯ä»Šå¤©æŠ“å–çš„ï¼‰
    today = datetime.now().date()
    today_created = session.query(Paper).filter(
        Paper.created_at >= datetime.combine(today, datetime.min.time())
    ).count()
    print(f"ğŸ“… ä»Šå¤©åˆ›å»ºçš„è®ºæ–‡æ•°: {today_created} ç¯‡")
    
    # æ£€æŸ¥12æœˆ17æ—¥åˆ›å»ºçš„è®ºæ–‡ï¼ˆå¯èƒ½æ˜¯ä»Šå¤©æŠ“å–çš„12æœˆ17æ—¥çš„è®ºæ–‡ï¼‰
    dec17_created = session.query(Paper).filter(
        Paper.created_at >= datetime(2025, 12, 17, 0, 0, 0),
        Paper.created_at < datetime(2025, 12, 18, 0, 0, 0)
    ).count()
    print(f"ğŸ“… 12æœˆ17æ—¥åˆ›å»ºçš„è®ºæ–‡æ•°: {dec17_created} ç¯‡")
    
    # æ£€æŸ¥12æœˆ17æ—¥çš„è®ºæ–‡è¯¦æƒ…
    if papers_1217 > 0:
        print(f"\nğŸ“‹ 12æœˆ17æ—¥çš„è®ºæ–‡åˆ—è¡¨ï¼ˆå‰5ç¯‡ï¼‰:")
        papers_list = session.query(Paper).filter(
            Paper.publish_date == target_date
        ).order_by(Paper.created_at.desc()).limit(5).all()
        for i, paper in enumerate(papers_list, 1):
            print(f"   {i}. {paper.title[:60]}...")
            print(f"      åˆ›å»ºæ—¶é—´: {paper.created_at}")
            print(f"      å‘å¸ƒæ—¥æœŸ: {paper.publish_date}")
    else:
        print("\nâš ï¸  æ²¡æœ‰æ‰¾åˆ°12æœˆ17æ—¥çš„è®ºæ–‡")
        # æ£€æŸ¥æ˜¯å¦æœ‰ç›¸è¿‘æ—¥æœŸçš„è®ºæ–‡
        nearby_papers = session.query(Paper).filter(
            Paper.publish_date >= target_date - timedelta(days=3),
            Paper.publish_date <= target_date + timedelta(days=3)
        ).order_by(Paper.publish_date.desc()).limit(5).all()
        if nearby_papers:
            print("\nğŸ“‹ ç›¸è¿‘æ—¥æœŸçš„è®ºæ–‡:")
            for paper in nearby_papers:
                print(f"   - {paper.publish_date}: {paper.title[:50]}...")
    
    session.close()
    
except Exception as e:
    print(f"âŒ æ£€æŸ¥è®ºæ–‡æ•°æ®å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

print()
print("=" * 60)
print("2. å…·èº«è§†é¢‘æ•°æ®æ£€æŸ¥")
print("=" * 60)
print()

try:
    # æ£€æŸ¥æ•°æ®åº“ç±»å‹
    import os
    bilibili_db_url = os.getenv('BILIBILI_DATABASE_URL', os.getenv('DATABASE_URL', 'sqlite:///./bilibili.db'))
    
    # å¦‚æœæ˜¯PostgreSQLï¼Œæ£€æŸ¥psycopg2æ˜¯å¦å®‰è£…
    if bilibili_db_url.startswith('postgresql://') or bilibili_db_url.startswith('postgres://'):
        try:
            import psycopg2
        except ImportError:
            print("âŒ ç¼ºå°‘ psycopg2 æ¨¡å—ï¼ˆPostgreSQLé©±åŠ¨ï¼‰")
            print("   è¯·è¿è¡Œ: bash scripts/install_psycopg2.sh")
            print("   æˆ–è€…: pip install psycopg2-binary")
            raise
    
    from bilibili_models import get_bilibili_session, BilibiliUp, BilibiliVideo
    
    bilibili_session = get_bilibili_session()
    
    # UPä¸»æ•°é‡
    total_ups = bilibili_session.query(BilibiliUp).count()
    active_ups = bilibili_session.query(BilibiliUp).filter_by(is_active=True).count()
    print(f"ğŸ“Š æ€»UPä¸»æ•°: {total_ups} ä¸ª")
    print(f"ğŸ“Š æ´»è·ƒUPä¸»æ•°: {active_ups} ä¸ª")
    
    # è§†é¢‘æ•°é‡
    total_videos = bilibili_session.query(BilibiliVideo).count()
    active_videos = bilibili_session.query(BilibiliVideo).filter_by(is_deleted=False).count()
    print(f"ğŸ“Š æ€»è§†é¢‘æ•°: {total_videos} ä¸ª")
    print(f"ğŸ“Š æœªåˆ é™¤è§†é¢‘æ•°: {active_videos} ä¸ª")
    
    # æ£€æŸ¥æœ€è¿‘30å¤©çš„è§†é¢‘
    thirty_days_ago = datetime.now() - timedelta(days=30)
    recent_videos = bilibili_session.query(BilibiliVideo).filter(
        BilibiliVideo.pubdate >= thirty_days_ago,
        BilibiliVideo.is_deleted == False
    ).count()
    print(f"ğŸ“… æœ€è¿‘30å¤©è§†é¢‘æ•°: {recent_videos} ä¸ª")
    
    # æ£€æŸ¥æ¯ä¸ªUPä¸»çš„è§†é¢‘æ•°
    print(f"\nğŸ“‹ å„UPä¸»çš„è§†é¢‘æ•°é‡:")
    ups = bilibili_session.query(BilibiliUp).filter_by(is_active=True).all()
    for up in ups:
        video_count = bilibili_session.query(BilibiliVideo).filter(
            BilibiliVideo.uid == up.uid,
            BilibiliVideo.is_deleted == False
        ).count()
        print(f"   {up.name}: {video_count} ä¸ªè§†é¢‘")
    
    # æ£€æŸ¥æœ€æ–°è§†é¢‘
    latest_video = bilibili_session.query(BilibiliVideo).filter_by(
        is_deleted=False
    ).order_by(BilibiliVideo.pubdate.desc()).first()
    if latest_video:
        print(f"\nğŸ“… æœ€æ–°è§†é¢‘:")
        print(f"   æ ‡é¢˜: {latest_video.title[:50]}...")
        print(f"   å‘å¸ƒæ—¶é—´: {latest_video.pubdate}")
        print(f"   UPä¸»: {latest_video.uid}")
    else:
        print("\nâš ï¸  æ²¡æœ‰æ‰¾åˆ°è§†é¢‘æ•°æ®")
    
    # æ£€æŸ¥æ•°æ®æ›´æ–°æ—¶é—´
    print(f"\nğŸ“… æ•°æ®æ›´æ–°æ—¶é—´:")
    for up in ups[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
        print(f"   {up.name}: {up.updated_at}")
    
    bilibili_session.close()
    
except Exception as e:
    print(f"âŒ æ£€æŸ¥è§†é¢‘æ•°æ®å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

print()
print("=" * 60)
print("3. æ•°æ®è·å–é…ç½®æ£€æŸ¥")
print("=" * 60)
print()

# æ£€æŸ¥å®šæ—¶ä»»åŠ¡é…ç½®
auto_fetch_enabled = os.getenv('AUTO_FETCH_ENABLED', 'false').lower() == 'true'
print(f"ğŸ“… è‡ªåŠ¨æŠ“å–å¯ç”¨: {'âœ… æ˜¯' if auto_fetch_enabled else 'âŒ å¦'}")

if auto_fetch_enabled:
    fetch_schedule = os.getenv('AUTO_FETCH_SCHEDULE', 'æœªè®¾ç½®')
    print(f"ğŸ“… è®ºæ–‡æŠ“å–è®¡åˆ’: {fetch_schedule}")
    
    bilibili_schedule = os.getenv('AUTO_FETCH_BILIBILI_SCHEDULE', 'æœªè®¾ç½®')
    print(f"ğŸ“… Bç«™æŠ“å–è®¡åˆ’: {bilibili_schedule}")

print()
print("=" * 60)
print("è¯Šæ–­å®Œæˆ")
print("=" * 60)

