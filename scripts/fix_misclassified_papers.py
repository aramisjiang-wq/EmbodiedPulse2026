#!/usr/bin/env python3
"""
ä¿®å¤è¯¯åˆ†ç±»çš„è®ºæ–‡
ä½¿ç”¨æ”¹è¿›çš„åˆ†ç±»ç®—æ³•é‡æ–°åˆ†ç±»è¢«é”™è¯¯åˆ†ç±»çš„è®ºæ–‡
"""
import sys
import os
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from models import get_session, Paper
from taxonomy import normalize_category, UNCATEGORIZED_KEY
from scripts.improved_classifier import classify_paper_by_keywords_improved
import logging

logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

def fix_misclassified_papers():
    """ä¿®å¤è¯¯åˆ†ç±»çš„è®ºæ–‡"""
    session = get_session()
    
    try:
        # æŸ¥æ‰¾è¢«é”™è¯¯åˆ†ç±»ä¸º"Learning/Imitation Learning"çš„è®ºæ–‡
        # è¿™äº›è®ºæ–‡å¯èƒ½ä¸åŒ…å«imitation learningç›¸å…³å…³é”®è¯
        il_papers = session.query(Paper).filter(
            Paper.category == 'Learning/Imitation Learning'
        ).all()
        
        logger.info(f"æ‰¾åˆ° {len(il_papers)} ç¯‡è¢«åˆ†ç±»ä¸º'Learning/Imitation Learning'çš„è®ºæ–‡")
        logger.info("å¼€å§‹æ£€æŸ¥å¹¶ä¿®å¤è¯¯åˆ†ç±»...")
        logger.info("=" * 60)
        
        fixed_count = 0
        kept_count = 0
        
        for i, paper in enumerate(il_papers, 1):
            try:
                # æ£€æŸ¥æ˜¯å¦çœŸçš„åŒ…å«imitation learningå…³é”®è¯
                text = (paper.title + ' ' + (paper.abstract or '')).lower()
                has_il_keywords = any(kw in text for kw in [
                    'imitation learning', 'behavioral cloning', 'learning from demonstration',
                    'demonstration learning', 'behavior cloning', 'lfd',
                    'inverse reinforcement', 'learning from human', 'expert demonstration',
                    'learning from data', 'demonstration data'
                ])
                
                if not has_il_keywords:
                    # ä½¿ç”¨æ”¹è¿›çš„åˆ†ç±»ç®—æ³•é‡æ–°åˆ†ç±»
                    new_tags = classify_paper_by_keywords_improved(paper)
                    if new_tags and new_tags[0] != 'Learning/Imitation Learning':
                        new_category = normalize_category(new_tags[0])
                        old_category = paper.category
                        paper.category = new_category
                        paper.updated_at = datetime.now()
                        fixed_count += 1
                        logger.info(f"[{i}/{len(il_papers)}] âœ… ä¿®å¤: {paper.title[:50]}...")
                        logger.info(f"     {old_category} â†’ {new_category}")
                    else:
                        kept_count += 1
                        logger.debug(f"[{i}/{len(il_papers)}] ä¿æŒ: {paper.title[:50]}...")
                else:
                    kept_count += 1
                    logger.debug(f"[{i}/{len(il_papers)}] ä¿æŒ: {paper.title[:50]}... (åŒ…å«ILå…³é”®è¯)")
                
                # æ¯10ç¯‡æäº¤ä¸€æ¬¡
                if i % 10 == 0:
                    session.commit()
                    logger.info(f"å·²å¤„ç† {i}/{len(il_papers)} ç¯‡...")
            
            except Exception as e:
                logger.error(f"å¤„ç†è®ºæ–‡å¤±è´¥ {paper.id}: {e}")
                continue
        
        session.commit()
        session.close()
        
        logger.info("=" * 60)
        logger.info(f"ä¿®å¤å®Œæˆï¼")
        logger.info(f"âœ… ä¿®å¤: {fixed_count} ç¯‡")
        logger.info(f"ğŸ“Œ ä¿æŒ: {kept_count} ç¯‡")
        
    except Exception as e:
        logger.error(f"ä¿®å¤è¿‡ç¨‹å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        session.rollback()
        session.close()

if __name__ == '__main__':
    fix_misclassified_papers()

