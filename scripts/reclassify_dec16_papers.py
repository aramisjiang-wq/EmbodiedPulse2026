#!/usr/bin/env python3
"""
é‡æ–°åˆ†ç±»12æœˆ16æ—¥çš„æœªåˆ†ç±»è®ºæ–‡
ä½¿ç”¨æ›´æ™ºèƒ½çš„åˆ†ç±»ç®—æ³•
"""
import sys
import os
from datetime import date
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from models import get_session, Paper
from sqlalchemy import func
from taxonomy import NEW_TAXONOMY, normalize_category, UNCATEGORIZED_KEY
from collections import defaultdict
import re
import logging
from datetime import datetime

logging.basicConfig(level=logging.INFO, format='[%(asctime)s] %(message)s', datefmt='%H:%M:%S')
logger = logging.getLogger(__name__)

def classify_paper_by_keywords(paper: Paper) -> str:
    """
    æ ¹æ®å…³é”®è¯åŒ¹é…å¯¹è®ºæ–‡è¿›è¡Œåˆ†ç±»
    ä½¿ç”¨æ›´å®½æ¾çš„åŒ¹é…ç­–ç•¥
    """
    title = (paper.title or '').lower()
    abstract = (paper.abstract or '').lower()
    
    if not title and not abstract:
        return UNCATEGORIZED_KEY
    
    text = title + ' ' + abstract
    tag_scores = defaultdict(int)
    
    # éå†æ‰€æœ‰æ ‡ç­¾ï¼Œè®¡ç®—åŒ¹é…åˆ†æ•°
    for tag_key, (chinese, english, keywords) in NEW_TAXONOMY.items():
        score = 0
        
        # æ£€æŸ¥å…³é”®è¯åŒ¹é…
        for keyword in keywords:
            keyword_lower = keyword.lower()
            
            # 1. ç²¾ç¡®åŒ¹é…ï¼ˆå•è¯è¾¹ç•Œï¼‰- æƒé‡æœ€é«˜
            pattern = r'\b' + re.escape(keyword_lower) + r'\b'
            if re.search(pattern, title):
                score += 5  # æ ‡é¢˜ç²¾ç¡®åŒ¹é…æƒé‡é«˜
            elif re.search(pattern, abstract):
                score += 3  # æ‘˜è¦ç²¾ç¡®åŒ¹é…æƒé‡ä¸­ç­‰
            
            # 2. éƒ¨åˆ†åŒ¹é…
            if keyword_lower in title:
                score += 2
            if keyword_lower in abstract:
                score += 1
        
        # 3. æ£€æŸ¥è‹±æ–‡æ ‡ç­¾å
        eng_lower = english.lower()
        if eng_lower in title:
            score += 3
        if eng_lower in abstract:
            score += 2
        
        # 4. æ£€æŸ¥ä¸­æ–‡æ ‡ç­¾åï¼ˆå¦‚æœå¯èƒ½ï¼‰
        chinese_lower = chinese.lower()
        if chinese_lower in title or chinese_lower in abstract:
            score += 2
        
        if score > 0:
            tag_scores[tag_key] = score
    
    # å¦‚æœæœ‰åŒ¹é…ï¼Œè¿”å›å¾—åˆ†æœ€é«˜çš„æ ‡ç­¾
    if tag_scores:
        sorted_tags = sorted(tag_scores.items(), key=lambda x: -x[1])
        best_tag = sorted_tags[0][0]
        best_score = sorted_tags[0][1]
        
        # å¦‚æœå¾—åˆ†å¤ªä½ï¼Œå¯èƒ½éœ€è¦æ›´å®½æ¾çš„ç­–ç•¥
        if best_score < 3:
            # å°è¯•æ›´å®½æ¾çš„åŒ¹é…
            return classify_with_fallback(paper, tag_scores)
        
        return best_tag
    
    # å¦‚æœå®Œå…¨æ²¡åŒ¹é…ï¼Œä½¿ç”¨å…œåº•åˆ†ç±»
    return classify_with_fallback(paper, {})

def classify_with_fallback(paper: Paper, tag_scores: dict) -> str:
    """
    å…œåº•åˆ†ç±»ç­–ç•¥ï¼šåŸºäºå¸¸è§å…³é”®è¯çš„ç®€å•åŒ¹é…
    """
    title = (paper.title or '').lower()
    abstract = (paper.abstract or '').lower()
    text = title + ' ' + abstract
    
    # æœºå™¨äººç›¸å…³
    if any(kw in text for kw in ['robot', 'robotic', 'robotics', 'autonomous']):
        if any(kw in text for kw in ['humanoid', 'bipedal']):
            return 'Motion/Humanoid'
        elif any(kw in text for kw in ['quadruped', 'legged']):
            return 'Motion/Quadruped'
        elif any(kw in text for kw in ['manipulation', 'grasp', 'grasping']):
            return 'Operation/Grasp'
        elif any(kw in text for kw in ['navigation', 'locomotion', 'walking']):
            return 'Motion/Locomotion'
        else:
            return 'General-Robot'
    
    # æ„ŸçŸ¥ç›¸å…³
    if any(kw in text for kw in ['perception', 'vision', 'visual', 'image', 'camera']):
        if any(kw in text for kw in ['3d', 'depth', 'point cloud', 'lidar', 'stereo']):
            return 'Perception/3D Perception'
        elif any(kw in text for kw in ['detection', 'detect', 'object detection']):
            return 'Perception/Object Detection'
        elif any(kw in text for kw in ['segmentation', 'segment', 'mask']):
            return 'Perception/Instance Segmentation'
        elif any(kw in text for kw in ['vlm', 'vision language', 'multimodal', 'clip']):
            return 'Perception/Vision-Language Model'
        else:
            return 'Perception/2D Perception'
    
    # VLAç›¸å…³
    if any(kw in text for kw in ['vla', 'vision language action', 'embodied agent', 'embodied ai']):
        return 'Operation/VLA'
    
    # å­¦ä¹ ç›¸å…³
    if any(kw in text for kw in ['reinforcement learning', 'rl', 'ppo', 'sac', 'actor-critic']):
        return 'Learning/RL'
    elif any(kw in text for kw in ['imitation learning', 'behavioral cloning', 'demonstration']):
        return 'Learning/IL'
    
    # è§„åˆ’ç›¸å…³
    if any(kw in text for kw in ['planning', 'navigation', 'path planning', 'task planning']):
        return 'Decision/Task Planning'
    
    # æ“ä½œç›¸å…³
    if any(kw in text for kw in ['grasp', 'grasping', 'manipulation', 'pick and place']):
        return 'Operation/Grasp'
    elif any(kw in text for kw in ['dexterous', 'fine manipulation', 'in-hand']):
        return 'Operation/Dexterous'
    elif any(kw in text for kw in ['bimanual', 'dual arm', 'two-arm']):
        return 'Operation/Bimanual'
    
    # å¦‚æœtag_scoresä¸­æœ‰ä½åˆ†åŒ¹é…ï¼Œè¿”å›å¾—åˆ†æœ€é«˜çš„
    if tag_scores:
        sorted_tags = sorted(tag_scores.items(), key=lambda x: -x[1])
        return sorted_tags[0][0]
    
    return UNCATEGORIZED_KEY

def reclassify_dec16_papers():
    """é‡æ–°åˆ†ç±»12æœˆ16æ—¥çš„æœªåˆ†ç±»è®ºæ–‡"""
    session = get_session()
    target_date = date(2025, 12, 16)
    
    # è·å–12æœˆ16æ—¥çš„æœªåˆ†ç±»è®ºæ–‡
    uncategorized = session.query(Paper).filter(
        func.date(Paper.publish_date) == target_date,
        Paper.category == UNCATEGORIZED_KEY
    ).all()
    
    logger.info(f"æ‰¾åˆ° {len(uncategorized)} ç¯‡12æœˆ16æ—¥çš„æœªåˆ†ç±»è®ºæ–‡")
    logger.info("å¼€å§‹é‡æ–°åˆ†ç±»...")
    logger.info("=" * 60)
    
    reclassified = 0
    still_uncategorized = 0
    
    for i, paper in enumerate(uncategorized, 1):
        try:
            # å°è¯•åˆ†ç±»
            new_category = classify_paper_by_keywords(paper)
            
            if new_category != UNCATEGORIZED_KEY:
                # è§„èŒƒåŒ–ç±»åˆ«
                normalized_category = normalize_category(new_category)
                paper.category = normalized_category
                paper.updated_at = datetime.now()
                reclassified += 1
                logger.info(f"[{i}/{len(uncategorized)}] âœ… {paper.title[:50]}...")
                logger.info(f"     -> {normalized_category}")
            else:
                still_uncategorized += 1
                logger.info(f"[{i}/{len(uncategorized)}] âš ï¸  æ— æ³•åˆ†ç±»: {paper.title[:50]}...")
            
            # æ¯10ç¯‡æäº¤ä¸€æ¬¡
            if i % 10 == 0:
                session.commit()
                logger.info(f"å·²å¤„ç† {i}/{len(uncategorized)} ç¯‡...")
        
        except Exception as e:
            logger.error(f"å¤„ç†è®ºæ–‡å¤±è´¥ {paper.id}: {e}")
            continue
    
    session.commit()
    session.close()
    
    logger.info("=" * 60)
    logger.info(f"é‡æ–°åˆ†ç±»å®Œæˆï¼")
    logger.info(f"âœ… æˆåŠŸåˆ†ç±»: {reclassified} ç¯‡")
    logger.info(f"âš ï¸  ä»ä¸ºæœªåˆ†ç±»: {still_uncategorized} ç¯‡")
    
    # éªŒè¯ç»“æœ
    session = get_session()
    final_uncategorized = session.query(func.count(Paper.id)).filter(
        func.date(Paper.publish_date) == target_date,
        Paper.category == UNCATEGORIZED_KEY
    ).scalar()
    session.close()
    
    logger.info(f"ğŸ“Š æœ€ç»ˆæœªåˆ†ç±»æ•°é‡: {final_uncategorized} ç¯‡")

if __name__ == '__main__':
    reclassify_dec16_papers()

